 1/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
 1/2: ana_path='/net/thermo/atmosdyn/atroman/phd/FEB18/cdf/'
 1/3: date='20180201_17'
 1/4: p_file = ana_path+'/'+'P'+date
 1/5:
level=310

#set plotting range
lonmin=140
lonmax=180
latmin=20
latmax=60
 1/6: p_data = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','U','V','PS','ORO','Z','TH','LSP_6H', 'CP_6H','SF_6H', 'SICE','SKT','T2M','TCC','TD2M','U10','V10'])
 1/7: p_data
 1/8: p_data.lon
 1/9: len(p_data.lon)
1/10: p_data.domxmin
1/11: p_data.domxmax
1/12: LON =np.linspace(p_data.domxmin,p_data.domxmax,num=len(p_data.lon))
1/13: LON
1/14: p_data.lon
1/15: p_data.lon*2
1/16: p_data.lon*1
1/17: LON - p_data.lon*1
1/18: LON - p_data.lon*1[0]
1/19: (LON - p_data.lon*1)[0]
1/20: p_data.lon[0]
1/21: p_data.lon - LON
1/22: p_data.lon - LON [0]
1/23: d = LON - p_data.lon
1/24: d[0]
1/25: LON[0]
1/26: LON
1/27: LON[0]
1/28: LON[0] -p_data[0]
1/29: LON[0] -p_data.lon[0]
1/30: LON[0] -np.asarray(p_data.lon)[0]
1/31: (LON -np.asarray(p_data.lon))[0]
1/32: p_data
1/33: p_data.lev
1/34: p_data.PV
 2/1:
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
 2/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
 2/3: month = 'FEB18'
 2/4: ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'
 2/5: date = '20180201_17'
 2/6: s_file = ana_path+'/'+'S'+date
 2/7: s = ana_path+'/'+'S'+date
 2/8: s.lon
 2/9: s.header
2/10: s.PV
2/11: s = xr.open_dataset(s_file, drop_variables=['U','V','P'])
2/12: s.lon
2/13: s.PV
2/14: s.PV[0,:,:,:]
2/15: np.asarray(s.PV[0,:,:,:])
2/16: np.asarray(s.PV[1,:,:,:])
2/17: np.asarray(s.PV[0,:,225,900])
2/18: len(np.asarray(s.PV[0,:,225,900]))
2/19: len(np.asarray(s.P[0,:,225,900]))
2/20: s = xr.open_dataset(s_file, drop_variables=['U','V'])
2/21: len(np.asarray(s.P[0,:,225,900]))
2/22: np.asarray(s.P[0,:,225,900])
2/23: np.asarray(s.P[0,:,225,901])
2/24: np.asarray(s.P[0,:,225,9])
2/25: np.asarray(s.P[0,:,8,9])
2/26: ls
2/27: ls /net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/
2/28: s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180201_17.nc')
2/29: s.FLAG
2/30: np.where(s.FLAG == 73)
2/31: np.where(s.FLAG == 46)
2/32: max(s.Flag)
2/33: max(s.FLAG)
2/34: max(np.asarray(s.FLAG))
2/35: max(np.asarray(s.FLAG)[0,:,:])
2/36: max(np.asarray(s.FLAG)[0,:])
2/37: max(np.asarray(s.FLAG)[0])
2/38: np.asarray(s.FLAG)[0]
2/39: np.asarray(s.FLAG)[0,0]
2/40: np.asarray(s.FLAG)[0,0,0]
2/41: np.asarray(s.FLAG)[:,:,:]
2/42: np.asarray(s.FLAG)[0,1]
2/43: np.asarray(s.FLAG)[0,2]
2/44: np.asarray(s.FLAG)[1,2]
2/45: max(np.asarray(s.FLAG)[0,:])
2/46: less /net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/TRACKED_CYCLONES
2/47: max(np.asarray(s.FLAG)[0,-1])
2/48:
for k in range(0,82):
    max(np.asarray(s.FLAG)[0,k])
2/49:
for k in range(0,82):
    print(max(np.asarray(s.FLAG)[0,k]))
2/50: s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180209_17.nc')
2/51:
for k in range(0,82):
    print(max(np.asarray(s.FLAG)[0,k]))
2/52: s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180209_04.nc')
2/53:
for k in range(0,82):
    print(max(np.asarray(s.FLAG)[0,k]))
2/54: s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180209_17.nc')
2/55:
for k in range(0,82):
    print(np.where(np.asarray(s.FLAG)[0,k] == 46))
2/56:
for k in range(0,82):
    print(np.asarray(s.FLAG)[0,k])
2/57: np.asarray(s.FLAG)
2/58: len(np.asarray(s.FLAG)[0,:])
2/59:
for k in range(0,225):
    print(np.where(np.asarray(s.FLAG)[0,k] == 46))
2/60: np.where(np.asarray(s.FLAG)[0,:]==46)
2/61: np.where(np.asarray(s.FLAG)[0,:,:]==46)
2/62: np.where(np.asarray(s.FLAG)[0,:,:]==46)
2/63: np.where(np.asarray(s.FLAG)[0,:,:]==46)
2/64:
for k in range(0,225):
    print(np.where(np.asarray(s.FLAG)[0,k] == 46))
2/65: len(np.asarray(s.P)[0,0])
2/66: len(np.asarray(s.FLAG)[0,0])
 3/1:
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
 3/2: import sys
 3/3:
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
 3/4: s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180209_17.nc')
 3/5: s.FLAG
 3/6: s.FLAG.shape
 3/7: s.FLAG[0,:].shape
 3/8: np.where(s.FLAG[0,:] == 46)
 3/9: test = np.stack(np.asarray(s.FLAG[0,:]))
3/10: test
3/11: test[0,0]
3/12: np.where(np.asarray(test)==46)
3/13: k = np.where(np.asarray(test)==46)
3/14: k[0]
3/15: k = np.where(test==46)
3/16: k[0]
3/17: k[1]
3/18: test = np.stack(np.asarray(np.asarray(s.FLAG[0,:])))
3/19: test
3/20: np.stack(test)
3/21: FLAG = np.zeros(226,901)
3/22: FLAG = np.zeros(226,901,dtype=float32)
3/23: FLAG = np.zeros([226 901])
3/24: FLAG = np.zeros(226 901)
3/25: FLAG = np.zeros(1)
3/26: FLAG
3/27: FLAG = np.zeros(2)
3/28: FLAG
3/29: FLAG = np.zeros(2, 2)
3/30: FLAG = np.zeros((2,2))
3/31: FLAG
3/32: FLAG = np.zeros((226,901))
3/33: FLAG[10,0] = 1
3/34: Flag
3/35: FLAG
3/36: FLAG[1:3,0] = 1
3/37: FLAG
3/38: FLAG[500]
3/39: FLAG[226]
3/40: FLAG[225]
3/41: id = np.where(s.FLAG[0,:]==46)
3/42: ids = np.where(s.FLAG[0,:]==46)
3/43: id
3/44: ids
3/45: ids
3/46: ids
3/47: FLAG
3/48: s.FLAG[0,ids]
3/49: ls
3/50: np.where(s.FLAG[0,:,;]==0)
3/51: np.where(s.FLAG[0,:,:]==0)
3/52: np.where(s.FLAG[0,:,:]==46)
3/53: np.unique(np.where(s.FLAG[0,:,:]==46)[0])
3/54: np.where(np.where(s.FLAG[0,:,:]==46)[0] == 94)
3/55: np.where(np.where(s.FLAG[0,:,:]==46)[0] == 95)
3/56: np.where(np.where(s.FLAG[0,:,:]==46)[0] == 96)
3/57: latu = np.unique(np.where(s.FLAG[0,:,:]==46)[0])
3/58: latu
3/59:
for k in latu:
    for l in np.asarray(np.where(np.where(s.FLAG[0,:,:]==46)[0]==k))
3/60:
for k in latu:
    for l in np.asarray(np.where(np.where(s.FLAG[0,:,:]==46)[0]==k)):
        print(k,l)
3/61:
for k in latu:
    for l in np.where(np.where(s.FLAG[0,:,:]==46)[0]==k):
        print(k,l)
3/62:
for k in latu:
    lonu, = np.where(np.where(s.FLAG[0,:,:]==46)[0]==k) 
    for l in lonu:
        print(k,l)
3/63: I, = np.where(s.FLAG[0,:,:]==46)
3/64: I, = np.where(s.FLAG[0,:]==46)
3/65: s.FLAG
3/66: np.where(s.FLAG[0,:]==46)
3/67: I =np.where(s.FLAG[0,:]==46)
3/68: I[0]
3/69: I[1,0]
3/70: I[1]
3/71: I[1][0]
3/72: np.max(I[1][:])
3/73: np.min(I[1][:])
3/74: np.where(I[1][:] ==507)
3/75: k = I[1]
3/76: k
3/77: minlongc = 467
3/78: maxlonc = 506
3/79: minlongc:maxlonc
3/80: a = minlongc:maxlonc
3/81: range(minlongc,maxlongc)
3/82: range(minlongc,maxlonc)
3/83:
for k in range(minlongc,maxlonc):
    print(k)
3/84: k = I[1]
3/85: k
3/86: unique(k)
3/87: np.unique(k)
3/88: s
3/89: s.lon
3/90: lon = np.asarray(s.lon)
3/91: lon
 4/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
 5/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
 5/2: date = '20180209_17'
 5/3: CYID = 46
 5/4: pressure = 850
 5/5: month='FEB18'
 5/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

#Path where the analyis data sits
#ana_path='/net/litho/atmosdyn/raphaelp/cutoff/cases/archive/ana/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ month + '/cyclones/'
 5/7:
lonmin=-10
lonmax=35
latmin=25
latmax=45

#filenames
s_file = ana_path+'/'+'S'+date
p_file = ana_path+'/'+'P'+date
cy = cycl_path+'/'+'CY'+date+'.nc'
#i_file = ana_path+'/'+'I'+date

cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
#longs = np.where(s.FLAG[0,:]==CYID)[1]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

PV = np.zeros((len(lonu), len(latu)))
THE = np.zeros((len(lonu), len(latu)))
U = np.zeros((len(lonu), len(latu)))
V = np.zeros((len(lonu), len(latu)))

#""" data loading """
s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
 5/8: PV
 5/9: PV.shape
5/10: latu
5/11:
for k in latu:
    for n in lonu:
        I, = np.where((s.P[:,k,n]-pressure)==np.min((s.P[:,k,n]-pressure)))
5/12: s.P
5/13: s.P[0,300,50]
5/14: s.P[0,101,500]
5/15: s.P[0,:,101,500]
5/16: s.PV[0,:,101,500]
5/17: s.PV
5/18: p.U
5/19:
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        I, = np.where((s.P[0,:,k,n]-pressure)==np.min((s.P[0,:,k,n]-pressure)))
        PV[n,k] = s.PV[0,I,k,n]
        THE[n,k] = s.THE[0,I,k,n]
        U[n,k] = p.U[0,I,k,n]
        V[n,k] = p.V[0,I,k,n]
5/20:
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        I, = np.where((s.P[0,:,k,n]-pressure)==np.min((s.P[0,:,k,n]-pressure)))
        PV[n-minlonc,k-minlatu] = s.PV[0,I,k,n]
        THE[n-minlonc,k-minlatu] = s.THE[0,I,k,n]
        U[n-minlonc,k-minlatu] = p.U[0,I,k,n]
        V[n-minlonc,k-minlatu] = p.V[0,I,k,n]
5/21:
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        I, = np.where((s.P[0,:,k,n]-pressure)==np.min((s.P[0,:,k,n]-pressure)))
        PV[n-minlonc,k-minlatc] = s.PV[0,I,k,n]
        THE[n-minlonc,k-minlatc] = s.THE[0,I,k,n]
        U[n-minlonc,k-minlatc] = p.U[0,I,k,n]
        V[n-minlonc,k-minlatc] = p.V[0,I,k,n]
5/22: PV
5/23:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
5/24:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(lonmin+10-30,lonmax+1+30,30)
latgrids=np.arange(latmin+10-30,latmax+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([lonmin, lonmax, latmin, latmax], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(lon,lat,pv,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
5/25:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(lonmin+10-30,lonmax+1+30,30)
latgrids=np.arange(latmin+10-30,latmax+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minlonc, maxlonc, minlatc, maxlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(lonu,latu,PV,cmap=cmap,extend='both')
5/26:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
5/27:
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
5/28: ax.set_extent([minlonc, maxlonc, minlatc, maxlatc], ccrs.PlateCarree())
5/29: cmap,pv_levels,norm,ticklabels=PV_cmap2()
5/30: h=ax.contourf(lonu,latu,PV,cmap=cmap)
5/31: lonu
5/32: latu
5/33: PV.shape
5/34: h2=ax.contour(lonu,latu,PV)
5/35: shape.PV
5/36: PV.shape
5/37: h2=ax.contour(latu,lonu,PV)
5/38:
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
5/39: h=ax.contourf(latu,lonu,PV,cmap=cmap)
5/40:
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
5/41:
figname=figpath+'PV-at-P-'+'%03d'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
#close it
plt.close()
5/42: ls
 6/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
 6/2:
date='20180209_17'
CYID=46
pressure=850
#lstep=int(args.lstep)
month='FEB18'
 6/3:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

#Path where the analyis data sits
#ana_path='/net/litho/atmosdyn/raphaelp/cutoff/cases/archive/ana/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ month + '/cyclones/'
 6/4:
s_file = ana_path+'/'+'S'+date
p_file = ana_path+'/'+'P'+date
cy = cycl_path+'/'+'CY'+date+'.nc'
 6/5:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
#longs = np.where(s.FLAG[0,:]==CYID)[1]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

PV = np.zeros((len(latu), len(lonu)))
THE = np.zeros((len(latu), len(lonu)))
U = np.zeros((len(latu), len(lonu)))
V = np.zeros((len(latu), len(lonu)))
 6/6:
s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
 6/7:
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        I, = np.where((s.P[0,:,k,n]-pressure)==np.min((s.P[0,:,k,n]-pressure)))
        PV[k-minlatc,n-minlonc] = s.PV[0,I,k,n]
        THE[k-minlatc,n-minlonc] = s.THE[0,I,k,n]
        U[k-minlatc,n-minlonc] = p.U[0,I,k,n]
        V[k-minlatc,n-minlonc] = p.V[0,I,k,n]
 6/8: PV.shape
 6/9: v=get_field_at_level(s_data.PV.values[0,:,:,:], z,1)
6/10: v=get_field_at_level(s.PV.values[0,:,:,:], z,1)
6/11: z=np.asarray(p_data.lev)
6/12: z=np.asarray(p.lev)
6/13: pvv=get_field_at_level(s.PV.values[0,:,:,:], z,1)
6/14: pvv
6/15: pvv.shape
6/16: PV
6/17: pV.values
6/18: PV.values
6/19: s.PV.values[0,:,:,:]
6/20: s.PV
6/21: pvv
6/22: pvv.shape
6/23: PV.shape
6/24: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
6/25:
ax=axes
#add coastlines
ax.coastlines()
6/26:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
6/27: cmap,pv_levels,norm,ticklabels=PV_cmap2()
6/28: h=ax.contourf(lonu,latu,PV,cmap=cmap)
6/29: h2=ax.contour(lonu,latu,PV,alpha=1)
6/30: plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
6/31: cbax = fig.add_axes([0, 0, 0.1, 0.1])
6/32: cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
6/33:
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
6/34: plt.show()
6/35:
lonmin=-10
lonmax=35
latmin=25
latmax=45
6/36:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
 ax=axes
#add coastlines
 ax.coastlines()
# set the ticks such that plot doesnt look too crowded
 lonticks=np.arange(lonmin+10,lonmax+1,30)
 latticks=np.arange(latmin+10,latmax+1,30)
 ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
 ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
 ax.set_xticklabels(labels=lonticks,fontsize=10)
 ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
 ax.xaxis.set_major_formatter(LongitudeFormatter())
 ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
 longrids=np.arange(lonmin+10-30,lonmax+1+30,30)
 latgrids=np.arange(latmin+10-30,latmax+1+30,30)
6/37:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(lonmin+10-30,lonmax+1+30,30)
latgrids=np.arange(latmin+10-30,latmax+1+30,30)
6/38: plt.show()
6/39:
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([lonmin, lonmax, latmin, latmax], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
6/40: plt.show()
6/41: h=ax.contourf(lon,lat,pvv,levels=pv_levels,cmap=cmap,extend='both')
6/42: h=ax.contourf(range(0,901),range(0,225),pvv,levels=pv_levels,cmap=cmap,extend='both')
6/43: h=ax.contourf(range(0,901),range(0,226),pvv,levels=pv_levels,cmap=cmap,extend='both')
6/44: plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
6/45: cbax = fig.add_axes([0, 0, 0.1, 0.1])
6/46: cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
6/47: func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
6/48: fig.canvas.mpl_connect('draw_event', func)
6/49: cbar.ax.tick_params(labelsize=10)
6/50: cbar.ax.set_xlabel('PVU',fontsize=10)
6/51: fig.show()
6/52: fig.savefig('test.png',dpi=300,bbox_inches="tight")
6/53: fig.savefig(figpath+'test.png',dpi=300,bbox_inches="tight")
6/54:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
# lonticks=np.arange(lonmin+10,lonmax+1,30)
# latticks=np.arange(latmin+10,latmax+1,30)
# ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
# ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
# ax.set_xticklabels(labels=lonticks,fontsize=10)
# ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
#ax.set_extent([minlonc, maxlonc, minlatc, maxlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
6/55: h=ax.contourf(lonu,latu,PV,levels=pv_levels,cmap=cmap,extend='both')
6/56:
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/57:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
6/58: fig.show()
6/59: ax.set_extent([minlonc, maxlonc, minlatc, maxlatc], ccrs.PlateCarree())
6/60: np.linspace()
6/61: np.linspace(-180,180,901)
6/62: np.linspace(-90,90,226)
6/63: np.linspace(-180,180,901)[500]
6/64: np.linspace(-180,180,901)[467]
6/65: latu
6/66: lonu
6/67: np.linspace(-180,180,901)[lonu]
6/68:
pltlat =np.linspace(-90,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]
#longs = np.where(s.FLAG[0,:]==CYID)[1]

minlatc = np.min(latu)
maxlatc = np.max(latu)
minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]


minlonc = np.min(lonu)
maxlonc = np.max(lonu)
minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]
6/69:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
6/70: fig.show()
6/71:
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/72:
slp = np.zeros((len(latu), len(lonu)))
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]
6/73:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/74: cy_data.FLAG
6/75: cy_data.FLAG.values
6/76: cy_data.FLAG.values.shape
6/77: cy_data.FLAG.values[0,latu,lonu]
6/78: cy_data.FLAG.values[0,latu[:],lonu[:]]
6/79: test =  np.zeros((len(latu), len(lonu)))
6/80: test[:,:] = cy_data.FLAG.values[0,latu,lonu]
6/81: p.SLP.values.shape
6/82: flag = np.zeros((len(latu), len(lonu)))
6/83:
for k in latu:
#    lonu = np.where(np.where(s.FLAG[0,:,:]==CYID)[0]==k)
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
6/84:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
flaglevels = np.arange(0, CYID + 20,5)
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
h3=ax.contour(pltlon,pltlat,flag,levels=flaglevels,colors='cyan',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
plt.clabel(h3, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/85:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
flaglevels = CYID
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
h3=ax.contour(pltlon,pltlat,flag,levels=flaglevels,colors='cyan',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
plt.clabel(h3, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/86:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
flaglevels = np.arange(CYID,CYID+1)
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
h3=ax.contour(pltlon,pltlat,flag,levels=flaglevels,colors='cyan',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
plt.clabel(h3, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/87:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
flaglevels = np.arange(CYID-1,CYID+1)
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
h3=ax.contour(pltlon,pltlat,flag,levels=flaglevels,colors='cyan',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
plt.clabel(h3, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/88:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#since we have only one figure (=one axis) we set the axis equal to the figure axes
ax=axes
#add coastlines
ax.coastlines()
# set the ticks such that plot doesnt look too crowded
lonticks=np.arange(lonmin+10,lonmax+1,30)
latticks=np.arange(latmin+10,latmax+1,30)
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
# set ticklabels and fontsize
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
# format the ticks as e.g 60°W
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
#set gridline ranges
longrids=np.arange(minlonc+10-30,maxlonc+1+30,30)
latgrids=np.arange(minlatc+10-30,maxlatc+1+30,30)
#add gridlines
ax.gridlines(xlocs=longrids, ylocs=latgrids)
#set the extent of the map
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
#get the colormap for PV
cmap,pv_levels,norm,ticklabels=PV_cmap2()
#plot the PV contours
h=ax.contourf(pltlon,pltlat,PV,levels=pv_levels,cmap=cmap,extend='both')
#set the range for SLP
plevels=np.arange(960,1041,5)
flaglevels = np.arange(CYID-1,CYID+1)
#plot the SLP contours
h2=ax.contour(pltlon,pltlat,slp,levels=plevels,colors='purple',animated=True,linewidths=1, alpha=1)
h3=ax.contour(pltlon,pltlat,flag,levels=flaglevels,colors='cyan',animated=True,linewidths=1, alpha=1)
#plot the labels into the SLP lines
plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
#plt.clabel(h3, inline=1, fontsize=8, fmt='%1.0f')
### Add the colorbar (it's a trick to make the colorbar fit the plot; uses another function resize_colorbar_vert from the module "useful__functions")
#add random colorbar axes
cbax = fig.add_axes([0, 0, 0.1, 0.1])
#create the colorbar
cbar=plt.colorbar(h, ticks=pv_levels,cax=cbax)
#resize the colorbar
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
#format colorbar
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
#""" SAVE AND CLOSE THE FIGURE """
#define the figure name
figname=figpath+'PV-at-P-'+'%03d-'%pressure+date+'.png'
#save the figure
fig.savefig(figname,dpi=300,bbox_inches="tight")
6/89: tt = np.array([10 11 12 13])
6/90: tt = np.array([10, 11, 12, 13])
6/91: ttt = np.insert(tt, [0], np.arange(np.min(tt)-5,(np.min(tt))), axis=0)
6/92: ttt
6/93: ttt = np.insert(tt, [-1], np.arange(np.max(tt)+1,np.max+5(tt)), axis=0)
6/94: ttt = np.insert(tt, [-1], np.arange(np.max(tt)+1,np.max(tt)+5), axis=0)
6/95: ttt
6/96: ttt = np.insert(tt, [-0], np.arange(np.max(tt)+1,np.max(tt)+5), axis=0)
6/97: ttt
6/98: ttt = np.insert(tt, [len(tt)-1], np.arange(np.max(tt)+1,np.max(tt)+5), axis=0)
6/99: ttt
6/100: ttt = np.insert(tt, [len(tt)], np.arange(np.max(tt)+1,np.max(tt)+5), axis=0)
6/101: ttt
6/102: pltlat
6/103: latu
6/104: PV[PV<-999]
6/105: slp
6/106: slp[slp<-99]
6/107: slp[slp<-999]
6/108: slp[slp>1000]
6/109: PV
6/110: s.PV.values
6/111: s.PV.values.shape
6/112: np.min(s.PV.values[0,5,:,:])
6/113: np.max(s.PV.values[0,5,:,:])
6/114: np.mean(s.PV.values[0,5,:,:])
6/115: np.mean(s.P.values[0,5,:,:])
6/116: I
6/117: pv_levels
6/118: pv_levels = np.arange(-0.5, 3.0,0.5)
6/119: pv_levels
6/120: pv_levels[0]
6/121: len(U)
6/122: len(V)
6/123: U.shape
6/124: V.shape
6/125: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
6/126:
ax=axes
ax.coastlines()
6/127:
qv=ax.quiver(pltlon[::5],pltlat[::5],U[::5,::5],V[::5,::5],units='width')
qk=ax.quiverkey(qv,0.9,0.1,10,r'$2$\,m\,s$^{-1}$', labelpos='E', coordinates='figure')
6/128: fig.show
6/129: fig.show()
6/130: PV_cmap2()
6/131: cmaps
6/132: ticklabels
6/133: THE.shape
6/134: s.THE.values.shape
6/135: center
6/136:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)
minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minlonc = np.min(lonu)
maxlonc = np.max(lonu)
minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

THE = np.zeros((len(latu), len(lonu)))
U = np.zeros((len(latu), len(lonu)))
V = np.zeros((len(latu), len(lonu)))
flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))


s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])

for k in latu:
    for n in lonu:
        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
        THE[k-minlatc,n-minlonc] = s.THE.values[0,I,k,n]
        U[k-minlatc,n-minlonc] = p.U.values[0,I,k,n]
        V[k-minlatc,n-minlonc] = p.V.values[0,I,k,n]
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
6/137: plotaround=10
6/138:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)
minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minlonc = np.min(lonu)
maxlonc = np.max(lonu)
minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

THE = np.zeros((len(latu), len(lonu)))
U = np.zeros((len(latu), len(lonu)))
V = np.zeros((len(latu), len(lonu)))
flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))


s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])

for k in latu:
    for n in lonu:
        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
        THE[k-minlatc,n-minlonc] = s.THE.values[0,I,k,n]
        U[k-minlatc,n-minlonc] = p.U.values[0,I,k,n]
        V[k-minlatc,n-minlonc] = p.V.values[0,I,k,n]
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
6/139: center.shape
6/140: center
6/141: center[20,30]
6/142: center[center!=0]
6/143: center[20,:]
6/144: latu
6/145: np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0]))
6/146: np.round(np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])))
6/147: centerlat = np.round(np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])))
6/148: centerlon = np.round(np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])))
6/149: lonu
6/150: pltlon
6/151: np.mean(plt.lat)
6/152: np.mean(pltlat)
6/153: pltlat
6/154: centerlat = np.linspace(0,90,226)[106]
6/155: centerlat
6/156: centerlat  = np.round(np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])))
6/157: centerlat
6/158: int(centerlat)
6/159: centerlat  = int(np.round(np.mean(np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0]))))
6/160: centerlat
6/161:
zlv = np.arange(1,84)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/162: zlv
6/163: zlv[0]
6/164:
zlv = np.arange(0,83)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/165: zlv
6/166:
zlv = np.arange(0,83,dtype=int8)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/167:
zlv = np.arange(0,83,dtype=int64)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/168: zlv = np.arange(0,83,dtype=int64)
6/169: zlv = np.arange(0,83,1,dtype=int64)
6/170: zlv = np.arange(0,83,1)
6/171: zlv
6/172:
zlv = np.arange(0,83,dtype=int64)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/173:
zlv = np.arange(0,83,1)
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/174:
zlv = int(np.arange(0,83,1))
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/175: zlv
6/176: int(zlv)
6/177: zlv = np.arange(int(0),int(83))
6/178: zlv
6/179:
zlv = np.cumsum(np.ones((1,83)))
the = np.zeros(len(zlv),len(lonu))
th = np.zeros(len(zlv),len(lonu))
pv = np.zeros(len(zlv),len(lonu))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/180:
zlv = np.cumsum(np.ones((1,83)))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/181: s.THE.values.shape
6/182: z
6/183:
zlv = int(np.cumsum(np.ones((1,83))))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/184:
zlv = int(np.cumsum(np.ones((1,83))))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for int(z) in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/185:
zlv = int(np.cumsum(np.ones((1,83))))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in int(zlv):
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/186: zlb
6/187: zlv
6/188:
zlv = np.cumsum(np.ones((1,83,dtype=int)))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in int(zlv):
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/189:
zlv = np.cumsum(np.ones((1,83,dtype=int32)))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in int(zlv):
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/190:
zlv = np.cumsum(np.ones((1,83),dtype=int))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in int(zlv):
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/191:
zlv = np.cumsum(np.ones((1,83),dtype=int))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in zlv:
        the[z,n] = s.THE.values[0,z,centerlat,n]
        pv[z,n] = s.PV.values[0,z,centerlat,n]
        th[z,n] = s.TH.values[0,z,centerlat,n]
6/192: minlonc
6/193:
zlv = np.cumsum(np.ones((1,83),dtype=int))
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in zlv:
        the[z,n-minlonc] = s.THE.values[0,z,centerlat,n]
        pv[z,n-minlonc] = s.PV.values[0,z,centerlat,n]
        th[z,n-minlonc] = s.TH.values[0,z,centerlat,n]
6/194:
zlv = np.cumsum(np.ones((1,83),dtype=int)) - 1
the = np.zeros((len(zlv),len(lonu)))
th = np.zeros((len(zlv),len(lonu)))
pv = np.zeros((len(zlv),len(lonu)))
for n in lonu:
    for z in zlv:
        the[z,n-minlonc] = s.THE.values[0,z,centerlat,n]
        pv[z,n-minlonc] = s.PV.values[0,z,centerlat,n]
        th[z,n-minlonc] = s.TH.values[0,z,centerlat,n]
6/195: s.P.values[0,:,centerlat,n]
6/196: s.P.values[0,:,centerlat,n-10]
6/197: pltlat
6/198: pltlon
 7/1:
import sys
import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
import os
 7/2: sys.path.append('/home/raphaelp/phd/scripts/basics/')
 7/3: path='/net/thermo/atmosdyn/atroman/phd/FEB18/cdf/'
 7/4: date='20180209_17'
 7/5: ftype==s
 7/6: ftype=S
 7/7: ftype='S'
 7/8: f=path+'/'+ftype+date
 7/9: os.path.isfile(f)
7/10: ncfile = netCDF4.Dataset(f)
7/11: ymin=np.int(np.squeeze(ncfile.variables['P'].ymin))
7/12: ymin
7/13: ymax=np.int(np.squeeze(ncfile.variables['P'].ymax))
7/14: ymax
7/15: dim=nc.read_dimensions(f)
7/16: dim
7/17: dim[i]
7/18: xlen=[dim[i] for i in dim.keys() if i[0:4]=='dimx'][0]
7/19: dim[i] for i in dim.keys()
7/20: [dim[i] for i in dim.keys()]
7/21: [ for i in dim.keys() dim[i]]
7/22: [for i in dim.keys(): dim[i]]
7/23: [dim[i] for i in dim.keys()]
7/24: [dim[i] for i in dim.keys()][0]
7/25: xlen=[dim[i] for i in dim.keys() if i[0:3]=='dimx'][0]
7/26: xlen=[dim[i] for i in dim.keys() if i=='dimx'][0]
7/27: [dim[i] for i in dim.keys() if i=='dimx']
7/28: [dim[i] for i in dim.keys() if i[0:4]=='dimx']
7/29: [dim[i] for i in dim.keys()]
 8/1:
import numpy as np
import xarray as xr
import os
import argparse
 8/2: Date = '20180209_17'
 8/3: Month = 'FEB'
 8/4: CYID = 46
 8/5:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
plotaround=10
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
 8/6: Month = 'FEB18'
 8/7:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
plotaround=10
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
 8/8: latlon = np.meshgrid(lonu,latu)
 8/9: latlon
8/10: latlon[0][0]
8/11: center = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/46/20180209_17-center.txt')
8/12: center
8/13: lon = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/46/20180209_17-lon.txt')
8/14: path = '/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/46/20180209_17-'
8/15: lat = np.loadtxt(path + 'lat.txt')
8/16: np.where(center==46)
8/17: latlon[np.where(center==46)]
8/18: latlon[np.where(center==46)[0],np.where(center==46)[1]]
8/19: center[center==46]
8/20: center==46
8/21: latlon[center==46]
8/22: unique(np.where(center==46))
8/23: np.unique(np.where(center==46))
8/24: np.unique(np.where(center==46)[1])
8/25: lat = lonlat[1][0]
8/26: lat = latlon[1][0]
8/27: lat[np.unique(np.where(center==46)[1])]
8/28: lat = latlon[0][0]
8/29: lat
8/30: lat = latlon[1][0]
8/31: lat
8/32: lat = latlon[1][:,0]
8/33: lat
8/34: lat[np.unique(np.where(center==46)[1])]
8/35: np.where(center==46)[1]
8/36: np.unique(np.where(center==46)[1])
8/37: lat[np.unique(np.where(center==46)[1])]
8/38: np.mean(lat)
8/39: int(np.round(np.mean(lat)))
8/40: lon
8/41: lon[0]
8/42:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))
8/43: month='FEB18'
8/44:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))
8/45: date='20180209_17'
8/46:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))
8/47: lattxt
8/48: np.linespace(0,90,226)[latcenter]
8/49: np.linspace(0,90,226)[latcenter]
8/50: latcenter
8/51: np.unique(np.where(center==46)[1])
8/52: lat[np.unique(np.where(center==46)[1])]
8/53:
pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]
8/54: pltlatcenter
8/55: lattxt
8/56: np.linspace(0,90,226)
8/57: np.linspace(0,90,226)[84]
8/58: np.linspace(0,90,226)[0]
8/59: np.linspace(0,90,226)[0 1]
8/60: np.linspace(0,90,226)[0,1]
8/61: lattxt
8/62: latxt[0]
8/63: lattxt[0]
8/64: np.linspace(0,90,226)[int(lattxt[0])]
8/65:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = np.linspace(0,90,226)[int(lattxt[0])]
maxpltlatc = np.linspace(0,90,226)[int(lattxt[-1])]

minpltlonc = np.linspace(-180,180,901)[int(lontxt[0])]
maxpltlonc = np.linspace(-180,180,901)[int(lontxt[-1])]


lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

coos=((lon1,lat1),(lon2,lat2))
ftype='S'

f=ana_path+'/'+ftype+date
filename=f
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
8/66:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats

    ncfile.close()

    return lon,lat,z
8/67:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = np.linspace(0,90,226)[int(lattxt[0])]
maxpltlatc = np.linspace(0,90,226)[int(lattxt[-1])]

minpltlonc = np.linspace(-180,180,901)[int(lontxt[0])]
maxpltlonc = np.linspace(-180,180,901)[int(lontxt[-1])]


lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

coos=((lon1,lat1),(lon2,lat2))
ftype='S'

f=ana_path+'/'+ftype+date
filename=f
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
8/68:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
8/69:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = np.linspace(0,90,226)[int(lattxt[0])]
maxpltlatc = np.linspace(0,90,226)[int(lattxt[-1])]

minpltlonc = np.linspace(-180,180,901)[int(lontxt[0])]
maxpltlonc = np.linspace(-180,180,901)[int(lontxt[-1])]


lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

coos=((lon1,lat1),(lon2,lat2))
ftype='S'

f=ana_path+'/'+ftype+date
filename=f
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
8/70:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}
8/71:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
8/72: cross
8/73: print(cross)
8/74: print(cross.distance)
8/75: x, zi = np.meshgrid(cross.distances, cross.pressure)
8/76: x
8/77: len(x)
8/78: x.shape
8/79: pltlatcenter
8/80: pltloncenter
8/81: maxpltlon
8/82: maxpltlon
8/83: maxpltlonc
8/84: minpltlonc
8/85: np.linspace(round(minpltlonc,2),round(maxpltlonc,2),1000)
8/86: kl = np.linspace(round(minpltlonc,2),round(maxpltlonc,2),1000)
8/87: np.where(kl[:]==pltloncenter)
8/88: np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))
 9/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
 9/2:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats

    ncfile.close()

    return lon,lat,z
 9/3: date = '20180209_17'
 9/4: CYID = 46
 9/5: month = 'FEB18'
 9/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

txtpath=figpath+month+'/'+str(CYID)+'/'+date+'-'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[1])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[0])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)


lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))
ftype='S'

f=ana_path+'/'+ftype+date
filename=f
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
 9/7:
vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
 9/8:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}
 9/9:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
9/10: shape.x
9/11: x.shape
9/12: x
9/13: x[0]
9/14: x[1]
9/15: x[1]-x[0]
9/16: centerid
9/17: centerid[0]
9/18: x[:,1]
9/19: x[:,centerid]
9/20: x-x[:,centerid]
9/21:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 100])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')

the_levels=np.arange(280,331,3)
ticklabels =the_levels
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_levels, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.array(np.round(np.arange(np.min(x),np.max(x)+1,np.round((np.max(x)-np.min(x))/5))/100.)*100,dtype=np.int)
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
if np.max(x) not in xticks:
   xticks.append(np.max(x))
xticks=sorted(xticks)
9/22:
if xticks[1]<np.diff(xticks)[0]/2.:
   xticks.remove(xticks[1])
if xticks[-2]>np.max(x)-np.diff(xticks)[0]/2.:
   xticks.remove(xticks[-2])
ax.set_xticks(xticks)

#create xticklabels from xticks
for n,i in enumerate(xticks):
    if i==0:
       xticks[n]=str(lat1)+'°N /\n'+str(lon1)+'°E'
    elif i==np.max(x):
       xticks[n]=str(lat2)+'°N /\n'+str(lon2)+'°E'
    else:
       xticks[n]=str(i)
ax.set_xticklabels(xticks)


#save figure
figname='THE-vertical-latcenter'+date+'.png'
fig.savefig(figname,dpi=300,bbox_inches="tight")
#figname='CS_'+date+'.pdf'
#fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
9/23:
figname='THE-vertical-latcenter-'+date+'-'+str(CYID)+'.png'
fig.savefig(figname,dpi=300,bbox_inches="tight")
#figname='CS_'+date+'.pdf'
#fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
9/24: figpath
9/25: fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
9/26:
figname='THE-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
9/27: td = np.max(x)-np.min(x)
9/28: td
9/29: np.floor(td/500.)
9/30: int(np.floor(td/500.)) + 1
9/31:
for ll in np.range(1,5,1):
    x0 = (1-ll)*500
9/32:
for ll in range(1,5,1):
    x0 = (1-ll)*500
9/33: x0
9/34:
if( (np.abs(np.min(x[0]-x[0,centerid]))-ll*500)>0):
 x0 = 0
9/35:
for ll in range(1,5,1):
    if( (np.abs(np.min(x[0]-x[0,centerid]))-ll*500)>0):
        x0 = (1-ll)*500
9/36: x0
9/37:
for ll in range(1,5,1):
    if( (abs(np.min(x[0]-x[0,centerid]))-ll*500)>0):
        x0 = -ll*500
9/38: x0
9/39: xti = range(x0,np.max(x[0]-x[0,centerid]),500)
9/40: xti = range(x0,int(np.max(x[0]-x[0,centerid])),500)
9/41: xti
9/42: xti = np.arange(x0,int(np.max(x[0]-x[0,centerid])),500)
9/43: xti
9/44:
lon1=round(pltloncenter,2)
lat1=round(minpltlatc,2)
lon2=round(pltloncenter,2)
lat2=round(maxpltlatc,2)

kl = np.linspace(minpltlatc,maxpltlatc,1000)
centerid, = np.where(abs(kl[:]-pltlatcenter)==np.min(abs(kl[:]-pltlatcenter)))

coos=((lon1,lat1),(lon2,lat2))
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
9/45:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}
9/46:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]
    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
9/47: x
9/48: minpltlonc
9/49: maxpltlonc
9/50: minpltlatc
9/51: maxpltlatc
9/52: dypy.small_tools.CrossSection
9/53: CrossSection
9/54: print(CrossSection)
9/55: import dypy.small_tools
9/56: dypy.small_tools.CrossSection
9/57: help
9/58: help(dypy.small_tools.CrossSection)
9/59: x
9/60: centerid
9/61: x[:,centerid]
9/62: latcenter
9/63: minpltlatc
9/64: lattxt[latcenter]
9/65: lattxt
9/66: center
9/67: center.shape
9/68: lon.shap
9/69: lon.shape
9/70: lontxt.shape
9/71: lattxt.shape
9/72: lattxt
9/73: np.where(center==CYID)
10/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
10/2: PV_map2
10/3: PV_cmap2
10/4: PV_cmap2()
10/5: cmap,pv_levels,norm,ticklabels=PV_cmap2()
10/6: cmap
10/7: cmap()
10/8: cmap.shape
10/9: cmap
11/1: import netCDF4
11/2: time.calendar
11/3: time = ncfile.variables['time']
11/4: time = /net/thermo/atmosdyn/atroman/phd/DEC17/cdf/S20171212_13.variables['time']
11/5: time = /net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171212_13.nc.variables['time']
11/6: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171212_13.nc', 'r')
11/7: time = ncfile.variables['time']
11/8: time
11/9: time.values
11/10: time.Values
11/11: time.shape
11/12: time[0]
11/13: time[0,0]
12/1: import datetime
12/2: newtime = datetime(1950,1,1,)
12/3: newtime = datetime.datetime(1950,1,1,)
12/4: newtime
12/5: newtime = datetime.datetime(1950,1,1,0)
12/6: newtime
12/7: datetime.date(1950,1,1,0)
12/8: datetime.date(1950,1,1)
12/9: newtime
12/10: step = 595645
12/11: delta = datetime.timedelta(step)
12/12: delta
11/14: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180209_17.nc', 'r')
11/15: time = ncfile.variables['time']
11/16: time[0]
11/17: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180213_06.nc', 'r')
11/18: time[0]
11/19: time = ncfile.variables['time']
11/20: time[0]
11/21: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180217_04.nc', 'r')
11/22: time = ncfile.variables['time']
11/23: time[0]
11/24: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180221_18.nc', 'r')
11/25: time = ncfile.variables['time']
11/26: time[0]
11/27: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171213_12.nc', 'r')
11/28: time = ncfile.variables['time']
11/29: time[0]
13/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
13/2:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats

    ncfile.close()

    return lon,lat,z
13/3: date = '20171213_12'
13/4: CYID = 73
13/5: month = 'DEC17'
13/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
13/7:
lon1=round(pltloncenter,2)
lat1=round(minpltlatc,2)
lon2=round(pltloncenter,2)
lat2=round(maxpltlatc,2)

kl = np.linspace(minpltlatc,maxpltlatc,1000)
centerid, = np.where(abs(kl[:]-pltlatcenter)==np.min(abs(kl[:]-pltlatcenter)))

coos=((lon1,lat1),(lon2,lat2))
lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
13/8:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}
13/9:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]
    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
13/10: centerid
13/11: x = np.arange(1,1,1)
13/12: x
13/13: x = np.arange(1,2,1)
13/14: x
13/15: x[0]
13/16:  x, zi = np.meshgrid(cross.distances, cross.pressure)
13/17: centerid
13/18: x
13/19: x[:,centerid[0]]
13/20: x-x[:,centerid[0]]
13/21: x-x[:,centerid[0]][0]
14/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
15/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
15/2: time:units = "hours since 1950-1-1 00:00 UTC"
15/3: time
15/4: import time
15/5: times.units = "hours since 1950-01-01 00:00:00.0"
15/6: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/FEB18/cyclones/CY20180217_03.nc', 'r')
15/7: time = ncfile.variables['time']
15/8: time[0]
15/9: ncfile = netCDF4.Dataset('/net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171213_12.nc', 'r')
15/10: time = ncfile.variables['time']
15/11: time[0]
16/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
#raphaels modules

#cartopy
#import cartopy.crs as ccrs
#from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
#from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
#import matplotlib.pyplot as plt
#import numpy as np
#import xarray as xr
#import argparse

def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
16/2:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
16/3: month='DEC17'
16/4: date='20171213_12'
16/5: CYID = 73
16/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
16/7:
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}
16/8:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]



    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
16/9: cross
16/10: cross.PV
16/11: cross.THE
16/12: np.mean(cross.THE[:,:],axis=1)
16/13: np.transpose(np.mean(cross.THE[:,:],axis=1))
16/14: cross.THE-np.mean(cross.THE[:,:],axis=1)
16/15: cross.THE-np.mean(cross.THE[:,:],axis=1)[0]
16/16:
fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/17:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/18: cross.THE = cross.THE - np.mean(cross.THE[:,:],axis=1)[0]
16/19:
the_levels=np.arange(-20,31,1)
the_ticks=np.arange(-20,31,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-anomaly-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
16/20:
the_levels=np.arange(-50,5,1)
the_ticks=np.arange(-50,5,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-anomaly-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
16/21:
fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/22:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/23:
the_levels=np.arange(-50,5,1)
the_ticks=np.arange(-50,5,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-anomaly-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
16/24:
fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/25:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
cross.THE = cross.THE - np.mean(cross.THE[:,:],axis=1)[0]
x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/26:
the_levels=np.arange(-50,5,1)
the_ticks=np.arange(-50,5,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-anomaly-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
16/27: cross.THE
16/28:
fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/29:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
cross.THE = cross.THE - np.mean(cross.THE[:,:],axis=0)[0]
x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')
16/30:
the_levels=np.arange(-50,5,1)
the_ticks=np.arange(-50,5,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-anomaly-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
17/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
17/2:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
17/3: date = '20180209_16'
17/4: month = 'FEB18'
17/5: CYID = 46
17/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
17/7: filetypes_all=list(set(filetypes))
17/8: filetypes
17/9: filetypes_all
17/10: vardict=dict()
17/11: vardict
17/12:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
17/13: i
17/14: filetypes[i]
17/15: vardict[filestypes[i]]
17/16: vardict[filetypes[i]]
17/17: read_var_bbox
17/18: var = dict()
17/19:
if (filetypes[0] not in var):
    var[filetypes[0]] = {}
17/20: var
17/21: var['S']
17/22: var['S'][0]
17/23: var['S']['THE']=np.array([])
17/24: var
17/25: var['S']
17/26: var['S']['THE']
17/27: var_str = var[ftype].keys()
17/28: var_str
17/29: var[ftype]
17/30: ftype
17/31: var[ftype].keys()
17/32: var_str=sorted(varlist_str)
17/33: var_str
17/34: var_str=sorted(var_str)
17/35: var_str
17/36: var_str = var[ftype].keys()
17/37: var_str=sorted(var_str)
17/38: var_str
17/39:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
17/40: varlist_str
17/41: vardict
17/42: vardict['S']
17/43:
for i in range(len(vari)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[ftype]={}

        #append variables to dictionary
    vardict[ftype][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
17/44: varlist_str
17/45: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
17/46: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[0]
17/47: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[1]
17/48: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[0]
17/49: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[5]
17/50: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[6]
17/51: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[8]
17/52: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[7]
17/53: varlist_str
17/54: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[5]
17/55: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[6]
17/56: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[6]
17/57: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[5]
17/58: vari
17/59: len(varlist_str)
17/60: blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)
17/61: blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
17/62: blat
17/63: blon
17/64: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[0]
17/65: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[1]
17/66: var1
17/67: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[2]
17/68: var1
17/69: var2
17/70: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[3]
17/71: var3
17/72: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[4]
17/73: var4
17/74: var3
17/75: var4
17/76: var3
17/77: var4
17/78: var3
17/79: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[4]
17/80: var4
17/81: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[5]
17/82: index
17/83: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[6]
17/84: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=False)[5]
17/85: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[5]
17/86: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[6]
17/87: blat
17/88: read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)[1]
17/89: vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
17/90: vari=list(vari)
17/91:
for i in range(len(vari)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[ftype]={}

        #append variables to dictionary
    vardict[ftype][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
17/92: varlist_str
17/93:
vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
17/94:
vari=list(vari)
filetypes=list(filetypes)
17/95:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    print(i)
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
           print(i)
17/96:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)

    print(varlist_str)
    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    print(i)
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
           print(i)
17/97: vari
17/98: vari[0]
18/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
18/2: date = '20180209_16'
18/3: month='FEB18'
18/4: CYID=46
18/5:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
18/6:
txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))
18/7:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))
18/8:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)

    print(varlist_str)
    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/9:
ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)
18/10:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
18/11: varlist_str
18/12:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
PVR = []
varlist_plot = []
18/13: blon
18/14: index
18/15:
for jk in range(2,len(vari)-1):
       PVR[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, PVR[jk-2]]
18/16:
for jk in range(2,len(vari)-1):
       print(jk)
       PVR[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, PVR[jk-2]]
18/17:
PVR = []
varlist_plot = []
for jk in range(2,len(vari)-1):
       PVR = [PVR, var_[jk]]
       varlist_plot=[varlist_plot, PVR[jk-2]]
18/18:
Vars= []
varlist_plot = []
for jk in range(2,len(vari)-1):
       varlist_plot=[varlist_plot, var_[jk]]
18/19: varlist_plot
18/20: varlist_plot[0]
18/21: varlist_plot[0,0]
18/22: varlist_plot[0][0]
18/23:
Vars=np.array([])
varlist_plot = []
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, var_[jk]]
18/24:
Vars={}
varlist_plot = []
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, var_[jk]]
18/25: Vars
18/26: Vars[0]
18/27:
Vars={}
varlist_plot = []
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, Vars[jk-2]]
18/28: varlist_plot
18/29:
Vars={}
varlist_plot = []
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, Vars[jk-2]]
18/30:
Vars={}
varlist_plot = []
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=[varlist_plot, Vars[jk-2]]
18/31:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/32:
Vars={}
varlist_plot = {}
for jk in range(2,len(vari)-1):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]= Vars[jk-2]
18/33:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/34: Vars[0]
18/35: Vars[0][0]
18/36: Vars[0][1]
18/37: Vars[0].shape
18/38:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i][:,:,:]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/39: Vars[0]
18/40: Vars[0]<-999
18/41: varlist_plot
18/42: varlist_plot[0]
18/43: varlist_plot[1]
18/44: varlist_plot[1][5]
18/45: varlist_plot[1][83]
18/46: varlist_plot[1][82]
18/47: varlist_plot[1][varlist_plot[1]<-999]=np.nan
18/48: varlist_str
18/49: len(varlist_str)
18/50: len(Vars)
18/51: vari
18/52: len(vari)
18/53:
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=Vars[jk-2]
18/54:
i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/55:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/56:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]
18/57: vardict.keys()
18/58: vardict[ftype].keys()
18/59: name='p'
18/60: var='P'
18/61: variables[name]=vardict[ftype][var][::-1,:,:]
18/62: variables={}
18/63: variables[name]=vardict[ftype][var][::-1,:,:]
18/64: variables[name]=vardict[ftype]['P'][::-1,:,:]
18/65: variables['p']=vardict[ftype]['P'][::-1,:,:]
18/66: variables['p']=vardict[ftype]['P']
18/67: variables['p']
18/68:
i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/69:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/70: vardict['S']['THE']
18/71:
vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
18/72:
vari=list(vari)
filetypes=list(filetypes)
18/73:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)

    print(varlist_str)
    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/74: vardict['S']['THE']
19/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc


def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
19/2: date = '20180209_16'
19/3: month='FEB18'
19/4: CYID=46
19/5:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
19/6:
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
19/7: varlist_str
18/75: varlist+str
18/76: varlist_str
19/8:
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
19/9: vardict
18/77: vardict
18/78:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
18/79: vardict
18/80:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]
18/81: varlist_plot
18/82: varlist_plot[0]
19/10:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2-1):
       Vars[jk-2] = var_[jk]
       varlist_plot=Vars[jk-2]
19/11:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2-1):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]
19/12: varlist_plot[0]
19/13:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
18/83:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
19/14: varlist_plot[i]
19/15: varlist_plot[0]
19/16:
varlist_plot = {}
for jk in range(2,len(vari)+3-1):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]
19/17:
i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1
19/18:
variables={}

    #add variables
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]
18/84:
vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)
18/85:
lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
18/86:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}

    #add variables
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]



    #add lat lon
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]


cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)
18/87: vari
18/88: vari[0]
18/89: vari[0]-'
18/90: variables'
18/91: variables
18/92: vari[0,0]
18/93: vari[0][0]
18/94: vari[0][1]
18/95: vari[0][2]
18/96: str(vari[0])
18/97: vari[0]
18/98: test =  'cross.' + vari[0]
18/99: test
18/100: cross
18/101: print(cross)
18/102:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)
18/103: cross
18/104: getattr(cross,'THE')
18/105:
for k in range(len(vari)):
    getattr(cross,vari[k])
18/106:
for k in range(len(vari)):
    if(vari[k]=='P'):
        vari[k]='p'
    getattr(cross,vari[k])
18/107: vari
18/108:
for k in range(len(vari)):
    if(vari[k]=='P'):
        vari[k]='p'
    print(getattr(cross,vari[k]))
18/109: print(getattr(cross,'PVRCONV'))
18/110: vari
18/111: print(getattr(cross,'PVRCONVT'))
18/112: print(getattr(cross,'PVRCONVT')())
18/113: pv_map,pvlevels,norm,ticklabels=PV_cmap2()
18/114: pv_map
18/115: print(pv_map)
18/116: print(pv_map[0])
18/117: print(pv_map{0})
18/118: print(pv_map[0])
18/119: PV_cmap2()
20/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
20/2:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
20/3: Date ='20180209_16'
20/4: CYID=46
20/5: month='FEB18'
20/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
20/7: date = Date
20/8:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
20/9:
for i in range(len(filetypes)):

                #create key if not there yet
    if filetypes[i] not in vardict:
       vardict[filetypes[i]]={}

        #append variables to dictionary
    vardict[filetypes[i]][vari[i]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


    if len(varlist_str)== 1:
              blon,blat,var1,index= read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1]
    elif len(varlist_str)==2:
              blon,blat,var1,var2,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2]
    elif len(varlist_str)==3:
              blon,blat,var1,var2,var3,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3]
    elif len(varlist_str)==4:
              blon,blat,var1,var2,var3,var4,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax), lon=lon,lat=lat,return_index=True)
              varlist_plot=[var1,var2,var3,var4]
    elif len(varlist_str)==5:
              blon,blat,var1,var2,var3,var4,var5,index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5]
    elif len(varlist_str)==6:
              blon,blat,var1,var2,var3,var4,var5,var6, index = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
              varlist_plot=[var1,var2,var3,var4,var5,var6]

    i=0
    for var in varlist_str:
                   #deal with nans
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
                   #put to dictionary
           vardict[ftype][var]=varlist_plot[i]
           #raise running variable
           i+=1

variables={}

    #add variables
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
                #deal with pressure variable name
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]
20/10:
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
20/11: variables
20/12: variables[0]
20/13: variables[0]
20/14: variables
20/15: varlist_plot[0]
20/16: varlist_plot[0][varlist_plot[0]==np.nan]
20/17: varlist_plot[1][varlist_plot[1]==np.nan]
20/18: varlist_plot[2][varlist_plot[2]==np.nan]
20/19: varlist_plot[3][varlist_plot[3]==np.nan]
20/20: varlist_plot[4][varlist_plot[4]==np.nan]
20/21:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)
20/22: cross.THE[cross.THE==nan]
20/23: cross.THE[cross.THE==np.nan]
20/24: cross.THE.shape
20/25: varlist_str
20/26: varlist
20/27: vardict
20/28: varlist_plot
20/29: varlist_plot.shape
20/30: varlist_plot[0].shape
20/31: varlist_plot[0].[:]
20/32: varlist_plot[0][:]
20/33: varlist_plot[0][:].shape
20/34: varlist_plot[0][:,:].shape
20/35: varlist_plot[0][:,:,:].shape
20/36: varlist_plot[0][:,5,1].shape
20/37: varlist_plot[0][:,1,1].shape
20/38: varlist_plot[0][5,1,1].shape
20/39: varlist_plot[0][5,:,:].shape
20/40: for l in range(0,83):varlist_plot[0][5,:,:].shape
20/41: for l in range(0,83): varlist_plot[0][5,:,:].shape
20/42:
for l in range(0,83):
    varlist_plot[3][l,:,:]=varlist_plot[3][l,:,:] -np.mean(varlist_plot[3][l,:,:])
20/43: varlist_plot[0][5,:,:]
20/44: varlist_plot[3][5,:,:]
20/45:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')

the_levels=np.arange(-20,31,1)
the_ticks=np.arange(-20,31,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-minav-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
#figname='CS_'+date+'.pdf'
#fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
20/46:
cross = CrossSection(variables,coos,pressure,version='regular',int2p=True)
x, zi = np.meshgrid(cross.distances, cross.pressure)

x = x - x[:,centerid]

fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()

s_file = ana_path+'/'+'S'+date
s = xr.open_dataset(s_file)

pvlevels=np.array([2, 2 + 1e-10])
cs2 = plt.contour(x, zi, cross.PV, levels=pvlevels,colors='black',linewidths=1)

th_spec=np.linspace(250,420, num=35)
cs2=plt.contour(x,zi,cross.TH,th_spec,colors='#606060',linewidths=1)
plt.clabel(cs2, inline=1, fontsize=8, fmt='%1.0f')

the_levels=np.arange(-10,21,1)
the_ticks=np.arange(-10,21,6)
ticklabels =the_ticks
cf=ax.contourf(x,zi,cross.THE,levels=the_levels,cmap=matplotlib.cm.seismic,extend='both',zorder=0,linewidths=1)

ax.set_ylabel("pressure [hPa]")
ax.set_xlabel("distance cyclone center [km]")

cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf, ticks=the_ticks, orientation='vertical',label=r'$\theta_e$ [K]',cax=cbax)
func=resize_colorbar_vert(cbax,ax)
fig.canvas.mpl_connect('draw_event',func)
#cbar.ax.tick_params(labelsize=15)
cbar.ax.set_yticklabels(ticklabels,fontsize=10)
#draw it
plt.draw()

#create x-ticks
xticks=np.arange(-1500, 1500, 300)#np.round(np.min(x)),np.round(np.max(x)+1),np.round((np.max(x)-np.min(x))/5))/100.))
xticks=list(xticks)
if 0 not in xticks:
   xticks.append(0)
#if np.max(x) not in xticks:
#   xticks.append(np.max(x))
xticks=sorted(xticks)
while((xticks[0]<np.min(x)) or (xticks[-1]>np.max(x))):
    if (xticks[0]<np.min(x)):
        xticks = np.delete(xticks, 0)
    if (xticks[-1]>np.max(x)):
        xticks = np.delete(xticks, -1)
ax.set_xticks(xticks)

figname='THE-minav-vertical-latcenter-'+date+'-Cyclone-'+str(CYID)+'.png'

fig.savefig(figpath+figname,dpi=300,bbox_inches="tight")
#figname='CS_'+date+'.pdf'
#fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
20/47: varlist_str=='PV'
20/48: varlist_str[:]=='PV'
20/49: varlist_str
20/50: varlist_str[1]=='PV'
21/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc

def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
21/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
21/3: date = '20180209_16'
21/4: month='FEB18'
21/5: CYID=46
21/6:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
21/7: Gf = ana_path + '/' + 'G' + date
21/8: Gf
21/9: Gf = ana_path + 'G' + date
21/10: Gf
21/11: gd = xr.open(Gf)
21/12: gd = xr.open_dataset(Gf)
21/13: gd
21/14: gd.Values
21/15: gd.LSP.Values
21/16: gd.LSP
21/17: gd.LSP[0]
21/18: gd.LSP.shape
21/19: gd.LSP.values
21/20: gd.LSP.values[0,0]
21/21: np.max(gd.LSP.values[0,0])
21/22: np.max(gd.CP.values[0,0])
21/23: lontxt
21/24: gd.CP.values[0,0,:,lontxt]
21/25: gd.CP.values[0,0,:,int(lontxt)]
21/26: center
21/27: center[center!=0]
21/28:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
21/29: centert
21/30: lontxt
21/31: np.savetxt(test.txt,lontxt,result.astype(int),fmt='%i',delimiter=' ',newline='\n')
21/32: np.savetxt('test.txt',lontxt,result.astype(int),fmt='%i',delimiter=' ',newline='\n')
21/33: np.savetxt('test.txt',lontxt.astype(int),fmt='%i',delimiter=' ',newline='\n')
21/34: ls
21/35: less test.txt
21/36:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
21/37: center
21/38: lontxt
21/39:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt',dtype=int)
lattxt = np.loadtxt(txtpath+'lat.txt',dtype=int)[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt'dtype=int)[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
21/40:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt',dtype=int)
lattxt = np.loadtxt(txtpath+'lat.txt',dtype=int)[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt',dtype=int)[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH']
filetypes = ['S', 'S', 'S', 'S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
21/41: lattxt
21/42: gd
21/43: gd.LSP.values[0,0,:,lontxt]
21/44: gd.LSP.values[0,0,lattxt,lontxt]
21/45: LSP = gd.LSP.values[0,0]
21/46: CP = gd.CP.values[0,0]
21/47: TP = CP+LSP
21/48: TP
21/49: TP[lattxt,:]
21/50: TP[:,lontxt]
21/51:
LSP = gd.LSP.values[0,0]
CP = gd.CP.values[0,0]
TP = LSP + CP
tp = np.zeros((len(lattxt),len(lontxt)))
21/52:
for k in lattxt:
    for l in lontxt:
        tp[k-lattxt[0],l-lontxt[0]] = TP[k,l]
21/53: tp
21/54: lattxt
21/55: tp.shape
21/56: date[0]
21/57: date[0:4]
21/58: int(date[0:4])
21/59: int(date[4:6])
21/60: int(date[6:8])
21/61: int(date[9:])
21/62: MONTHSN = [1,2,3,4,5,6,7,8,9,10,11,12]
21/63: MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
21/64: month = MONTHS[MONTHSN==int(date[4:6])]
21/65: month
21/66: MONTHSN = [0,1,2,3,4,5,6,7,8,9,10,11,12]
21/67: month = MONTHS[MONTHSN==int(date[4:6])]
21/68: month
21/69: month = MONTHS[np.where(MONTHSN==int(date[4:6]))]
21/70: np.where(MONTHS[:] == (int(MONTHSN== int(date[4:6]))))
21/71: np.where(MONTHS[:] == (MONTHSN== int(date[4:6])))
21/72: date[4:6]
21/73: int(date[4:6])
21/74: monthn = int(date[4:6])
21/75: np.where(monthn ==MONTHSN)
21/76: np.where(monthn ==MONTHSN)
21/77: MONTHSN
21/78: MONTHSN = [1,2,3,4,5,6,7,8,9,10,11,12]
21/79: MONTHSN = np.arange(1,13,1)
21/80: np.where(monthn ==MONTHSN)
21/81: np.where(MONTHSN==monthn)
21/82: MONTHS[np.where(MONTHSN==monthn)]
21/83: monthid, = np.where(MONTHSN==monthn)
21/84: monthid
21/85: MONTHS[monthid]
21/86: monthid
21/87: MONTHS[monthid[0]]
21/88: month = MONTHS[monthid[0]] + date[2:4]
21/89: month
22/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
22/2: from helperfunctions import lonlat_from_P
22/3: date='20180209_16'
22/4: CYID = 46
22/5:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(date[4:6])
monthid, = np.where(MONTHSN==monthn)
month = MONTHS[monthid[0]] + date[2:4]

figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f
22/6:
vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
22/7:
vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
22/8:
vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)
22/9: source helperfunctions.py
23/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython

from helperfunctions import lonlat_from_P
23/2: date='20180209_16'
23/3: CYID=46
23/4:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(date[4:6])
monthid, = np.where(MONTHSN==monthn)
month = MONTHS[monthid[0]] + date[2:4]

figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]
23/5:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/6:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/7:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython

import helperfunctions
23/8:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=helperfunctions.lonlat_from_P(f,'P')
lon1d,lat1d,z=helperfunctions.lonlat_from_P(f,'P',linear=1)
23/9:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython

import helperfunctions
23/10:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=helperfunctions.lonlat_from_P(f,'P')
lon1d,lat1d,z=helperfunctions.lonlat_from_P(f,'P',linear=1)
23/11:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
23/12:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/13:
import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
23/14:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/15: from helperfunctions import lonlat_from_P
23/16:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/17:
def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z
23/18:
minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)
23/19: vari
23/20:
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)
    
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}

for ftype in vardict.keys():
   for var in vardict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
23/21:
resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}

for ftype in vardict.keys():
   for var in vardict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
23/22:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
23/23: varlist_plot
23/24: varlist_str
23/25:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
23/26:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
23/27:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
23/28:
var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
23/29:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
23/30: var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
23/31:
vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
23/32: var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
23/33:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
23/34: varlist_str
23/35: varlist_plot
23/36: varlist_plot[0]
23/37: varlist_str
23/38: vardict['S'].keys()
23/39: vari_2 = ['PVRTURB','PVRCONV','PVRLS','PVRls','PVRTOT']
23/40: vari_2 = list(vari_2)
23/41: var2dict = dict()
23/42:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)
23/43: var2list_plot = {}
23/44: idturb = np.arange(-4,-2,1)
23/45: idturb
23/46: idconv = np.arange(4,6,1)
23/47: idls = np.arange(10,11,1)
23/48: idls
23/49: var2list_str
23/50: var2list_plot[0] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
23/51: var2list_plot[1] = varlist_plot[idls[0]]
23/52: var2list_plot[2] = varlist_plot[idls[0]]
23/53:
for u in range(2,len(varlist_str)-2):
    if(u==2):
        var2list_plot[2] = varlist_plot[u]
    else:
        var2list_plot[2] = var2list_plot[2] + varlist_plot[u]
23/54: var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
23/55: varlist_plot
23/56: varlist_plot.shape
23/57: len(varlist_plot)
23/58: idturb=np.arange(19,21,1)
23/59: var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
23/60: var2list_str
23/61: var2list_str[-1]
23/62: var2list_str[-1]={}
23/63: var2list_str
23/64: var2list_str.remove('{}')
23/65: var2list_str.remove({})
23/66: var2list_str
23/67:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]

variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
23/68: var_
23/69:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
23/70: var2dict
23/71:
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1
23/72:
i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1
23/73:
i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1
23/74:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
23/75: var2dict
23/76:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
23/77: var
23/78: var.remove(PVRls)
23/79: var2dict.keys()
23/80: var2dict['S'].keys()
23/81: var2dict.keys().remove('PVRls')
23/82: var2dict
23/83: var2dict[-1]
23/84: var2dict[4]
23/85: var2dict[3]
23/86: var2dict['S']
23/87: var2dict['S'][0]
23/88: var2dict['S']['PVRls']
23/89: del var2dict['S']['PVRls']
23/90: var2dict.keys()
23/91: var2dict['S'].keys()
23/92:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
23/93:
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
23/94: cross = CrossSection(variables2,coos,pressure,version='regular',int2p=True)
23/95: %save?
23/96: %save combinedpvr 1-999
23/97: ls
24/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z

date='20180209_16'
CYID=46
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(date[4:6])
monthid, = np.where(MONTHSN==monthn)
month = MONTHS[monthid[0]] + date[2:4]

figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'
24/2:
txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

filetypes_all=list(set(filetypes))
24/3:
import pickel
import netCDF4
24/4:
import pickle
import netCDF4
24/5:
txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

filetypes_all=list(set(filetypes))
24/6: import dypy.netcdf as nc
24/7:
txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

filetypes_all=list(set(filetypes))
24/8:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)

var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
24/9:
resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2
24/10:
vardict=dict()

for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}
24/11:
for ftype in vardict.keys():
   for var in vardict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
24/12: varlist_str
24/13: varlist_plot
24/14: varlist_plot[0]
24/15: len(varlist_plot)
24/16: vari_2 = ['P','PVRTURB','PVRCONV','PVRLS']
24/17:
vari_2 = list(vari_2)
var2dict = dict()
24/18: idturb = np.arange(-4,-2,1)
24/19: idconv = np.arange(4,6,1)
24/20: idls = np.arange(10,11,1)
24/21:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)
24/22: var2list_str
24/23: varlist_str
24/24:
var2list_plot = {}
idturb = np.arange(-4,-2,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)
24/25: var2list_plot[0] = varlist_plot[0]
24/26: var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
24/27:
var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
24/28:
for u in range(2,len(varlist_str)-2):
    if(u==2):
        PVRTOT = varlist_plot[u]
    else:
        PVRTOT = PVRTOT + varlist_plot[u]
24/29:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]

variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
24/30: ftype
24/31:
for var in var2dict[ftype].keys():
    print(var)
24/32:
i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1
24/33:
for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
24/34: len(variables2)
24/35: len(var2list_str)
24/36: len(var2list_plot)
24/37: var2dict
24/38:
i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1
24/39: var2dict
24/40:
variables2={}

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
24/41:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython

import pickle
import netCDF4
import dypy.netcdf as nc

def lonlat_from_P(filename, name_fld, linear=None):
    ncfile = netCDF4.Dataset(filename)
    ymin=np.int(np.squeeze(ncfile.variables[name_fld].ymin))
    ymax=np.int(np.squeeze(ncfile.variables[name_fld].ymax))
    xmin=np.int(np.squeeze(ncfile.variables[name_fld].xmin))
    xmax=np.int(np.squeeze(ncfile.variables[name_fld].xmax))
    zmin=np.int(np.squeeze(ncfile.variables[name_fld].zmin))
    zmax=np.int(np.squeeze(ncfile.variables[name_fld].zmax))

    dim=nc.read_dimensions(filename)
    xlen=[dim[i] for i in dim.keys()][0]
    ylen=[dim[i] for i in dim.keys()][1]
    zlen=[dim[i] for i in dim.keys()][4]

    z=np.linspace(np.min([zmin,zmax]),np.max([zmin,zmax]),zlen,dtype=int)
    lats = np.linspace(ymin,ymax,ylen)
    lons = np.linspace(xmin,xmax,xlen)

    if linear is None:
           lon,lat=np.meshgrid(lons,lats)
    else:
           lon=lons
           lat=lats
    ncfile.close()
    return lon,lat,z

date='20180209_16'
CYID=46
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(date[4:6])
monthid, = np.where(MONTHSN==monthn)
month = MONTHS[monthid[0]] + date[2:4]
24/42:
figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + str(month) + '/' + str(CYID) + '/' + date + '/'

txtpath=figpath
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

center = np.loadtxt(txtpath+'center.txt')
lattxt = np.loadtxt(txtpath+'lat.txt')[:,0]
lontxt = np.loadtxt(txtpath+'lon.txt')[0]

### round or floor are quasi identical
latcenter = int(np.round(np.mean(lattxt[np.unique(np.where(center==CYID)[0])])))
loncenter = int(np.round(np.mean(lontxt[np.unique(np.where(center==CYID)[1])])))

pltlatcenter=np.linspace(0,90,226)[latcenter]
pltloncenter=np.linspace(-180,180,901)[loncenter]

minpltlatc = round(np.linspace(0,90,226)[int(lattxt[0])],2)
maxpltlatc = round(np.linspace(0,90,226)[int(lattxt[-1])],2)

minpltlonc = round(np.linspace(-180,180,901)[int(lontxt[0])],2)
maxpltlonc = round(np.linspace(-180,180,901)[int(lontxt[-1])],2)

ftype='S'
f=ana_path+'/'+ftype+date
filename=f

vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
filetypes = ['S']
vari=list(vari)
filetypes=list(filetypes)

lon1=round(minpltlonc,2)
lat1=round(pltlatcenter,2)
lon2=round(maxpltlonc,2)
lat2=round(pltlatcenter,2)

kl = np.linspace(minpltlonc,maxpltlonc,1000)
centerid, = np.where(abs(kl[:]-pltloncenter)==np.min(abs(kl[:]-pltloncenter)))

coos=((lon1,lat1),(lon2,lat2))

lon,lat,z=lonlat_from_P(f,'P')
lon1d,lat1d,z=lonlat_from_P(f,'P',linear=1)

filetypes_all=list(set(filetypes))

resolution=np.diff(lon)[0,0]

lonmin=min([lon1,lon2])-resolution*2
lonmax=max([lon1,lon2])+resolution*2
latmin=min([lat1,lat2])-resolution*2
latmax=max([lat1,lat2])+resolution*2

pressure=np.arange(100.,1001.,25)

    #remove duplicate filetypes
filetypes_all=list(set(filetypes))

    ### connect filetypes and variables in dict ###
vardict=dict()
24/43:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in vardict:
       vardict[filetypes[i]]={}
    for j in range(len(vari)):
        #append variables to dictionary
        vardict[filetypes[i]][vari[j]]=np.array([])

    varlist_str=vardict[ftype].keys()
    varlist_str=sorted(varlist_str)


var_ = read_var_bbox(filename,varlist_str,(lonmin,lonmax,latmin,latmax),lon=lon,lat=lat, return_index=True)
blon = var_[0]
blat = var_[1]
index = var_[-1]
Vars = {}
varlist_plot = {}
for jk in range(2,len(vari)+2):
       Vars[jk-2] = var_[jk]
       varlist_plot[jk-2]=Vars[jk-2]

i=0
for var in varlist_str:
           varlist_plot[i][varlist_plot[i]<=-999]=np.nan
           vardict[ftype][var]=varlist_plot[i]
           i+=1

variables={}

for ftype in vardict.keys():
   for var in vardict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables[name]=vardict[ftype][var][::-1,:,:]
        else:
           name=var
           variables[var]=vardict[ftype][var][::-1,:,:]

variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
vari_2 = ['PVRTURB','PVRCONV','PVRLS','PVRls','PVRTOT']
vari_2 = list(vari_2)
var2dict = dict()
24/44:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
for u in range(2,len(varlist_str)-2):
    if(u==2):
        var2list_plot[2] = varlist_plot[u]
    else:
        var2list_plot[2] = var2list_plot[2] + varlist_plot[u]

variables2={}

i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
24/45:
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
for u in range(2,len(varlist_str)-2):
    if(u==2):
        var2list_plot[2] = varlist_plot[u]
    else:
        var2list_plot[2] = var2list_plot[2] + varlist_plot[u]

variables2={}
24/46:
i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1
24/47: var2dict()
24/48: var2dict
24/49: len(var2dict)
24/50: var2dict.keys()
24/51: var2dict['S'].keys()
24/52:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
for u in range(2,len(varlist_str)-2):
    if(u==2):
        var2list_plot[2] = varlist_plot[u]
    else:
        var2list_plot[2] = var2list_plot[2] + varlist_plot[u]

variables2={}

i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
24/53: cross = CrossSection(variables2,coos,pressure,version='regular',int2p=True)
24/54:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[3] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
for u in range(2,len(varlist_str)-2):
    if(u==2):
        PVRTOT = varlist_plot[u]
    else:
        PVRTOT = PVRTOT + varlist_plot[u]

variables2={}

i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]

cross = CrossSection(variables2,coos,pressure,version='regular',int2p=True)
24/55: cross.PVRTURB
24/56: PVRTOT
24/57:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS','PVRTOT']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[4] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
for u in range(2,len(varlist_str)-2):
    if(u==2):
        var2list_plot[3] = varlist_plot[u]
    else:
        var2list_plot[3] = var2list_plot[3] + varlist_plot[u]

variables2={}

i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]

cross = CrossSection(variables2,coos,pressure,version='regular',int2p=True)
24/58: cross.PVRTOT
24/59: var2list_plot[3]-var2list_plot[2] - var2list_plot[1] - var2list_plot[0]- var2list_plot[4]
24/60: var2list_plot[3]-var2list_plot[2] - var2list_plot[1]- var2list_plot[4]
24/61: np.max(var2list_plot[3]-var2list_plot[2] - var2list_plot[1]- var2list_plot[4])
24/62: np.max(var2list_plot[3]-var2list_plot[2] - var2list_plot[1]- var2list_plot[4])-np.max(var2list_plot[2])
24/63: vari2
24/64: vari_2
24/65: vari
24/66: varilist_str
24/67: varlist_str
24/68: lsids = np.array([2 3 6 7 8 9 11 12 13 14 15 16 17 18],dtype=int)
24/69: lsids = np.array([2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18],dtype=int)
24/70: lsids
24/71:
for r in lsids:
    if (r==2)
24/72:
for r in lsids:
    if (r==2):
        pvrls = varlist_plot[r]
    else:
        pvrls = pvrls + varlist_plot[r]
24/73: pvrls
24/74: pvrls - var2list_plot[2]
24/75: np.max(pvrls - var2list_plot[2])
24/76: np.min(pvrls - var2list_plot[2])
24/77: varlist_str
24/78: lsids = np.array([2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17],dtype=int)
24/79: radids = np.array([11, 12, 18],dtype=int)
24/80:
for r in lsids:
    if (r==lsids[0]):
        pvrls = varlist_plot[r]
    else:
        pvrls = pvrls + varlist_plot[r]
24/81: np.max(pvrls - var2list_plot[2])
24/82: np.min(pvrls - var2list_plot[2])
24/83: lsids = np.array([2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17,18],dtype=int)
24/84:
for r in lsids:
    if (r==lsids[0]):
        pvrls = varlist_plot[r]
    else:
        pvrls = pvrls + varlist_plot[r]
24/85: np.max(pvrls - var2list_plot[2])
24/86: lsids = np.array([2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17],dtype=int)
24/87: varlist_str
24/88: varlist_str[lsids]
24/89: np.mean(pvrls - var2list_plot[2])
24/90:
variables['lon']=lon1d[index[-1]]
variables['lat']=lat1d[index[-2]]
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS','PVRTOT','PVRRAD']
vari_2 = list(vari_2)
24/91:
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)
24/92: var2list_str
24/93:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS','PVRRAD']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)
24/94: var2list_str
24/95: radids
24/96:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS','PVRRAD']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[4] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
lsids = np.array([2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17],dtype=int)
radids = np.array([11, 12, 18],dtype=int)
24/97:
for u in radids:
    if(u==radids[0]):
        var2list_plot[3] = varlist_plot[u]
    else:
        var2list_plot[3] = var2list_plot[3] + varlist_plot[u]


variables2={}

i=0
for var in var2list_str:
           var2list_plot[i][var2list_plot[i]<=-999]=np.nan
           var2dict[ftype][var]=var2list_plot[i]
           i+=1

for ftype in var2dict.keys():
   for var in var2dict[ftype].keys():
        if var=='P':
           name='p'
           #reverse first dimension of pressure values such that they are increasing along that dimension (required for CrossSection(...))
           variables2[name]=var2dict[ftype][var][::-1,:,:]
        else:
           name=var
           variables2[var]=var2dict[ftype][var][::-1,:,:]
variables2['lon']=lon1d[index[-1]]
variables2['lat']=lat1d[index[-2]]
24/98: cross = CrossSection(variables2,coos,pressure,version='regular',int2p=True)
24/99: cross.shape
24/100: len(cross)
24/101: vari2
24/102: var_2
24/103: vari_2
24/104:
vari_2 = ['P','PVRTURB','PVRCONV','PVRLS','PVRRAD','PVRTOT']
vari_2 = list(vari_2)
var2dict = dict()
for i in range(len(filetypes)):

                #create key if not there yet
    if ftype not in var2dict:
       var2dict[filetypes[i]]={}
    for j in range(len(vari_2)):
        #append variables to dictionary
        var2dict[filetypes[i]][vari_2[j]]=np.array([])

    var2list_str=var2dict[ftype].keys()
    var2list_str=sorted(var2list_str)

var2list_plot = {}
idturb=np.arange(19,21,1)
idconv = np.arange(4,6,1)
idls = np.arange(10,11,1)

var2list_plot[0] = varlist_plot[0]
var2list_plot[1] = varlist_plot[idconv[0]] + varlist_plot[idconv[1]]
var2list_plot[2] = varlist_plot[idls[0]]
var2list_plot[4] = varlist_plot[idturb[0]] + varlist_plot[idturb[1]]
lsids = np.array([2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17],dtype=int)
radids = np.array([11, 12, 18],dtype=int)
24/105: var2list_str
24/106:
from matplotlib.colors import ListedColormap, BoundaryNorm
    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib import cm
    from matplotlib.colors import ListedColormap, LinearSegmentedColormap
24/107:
from matplotlib.colors import ListedColormap, BoundaryNorm
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
24/108:
_pv_levels = np.arange(-4,4.1,0.2)
n = len(_pv_levels)
jet = cm.get_cmap('jet',512)
24/109: jet
24/110: jet[0]
24/111: _pv_data = ListedColormap(jet(np.linspace(0.0,1.0,n)))
24/112: _pv_data
24/113: print(_pv_data)
24/114: _pv_data.shape
24/115: jet(np.linspace(0.0,1.0,n))
25/1: import numpy as np
25/2: lon = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180216_18/lon.txt')
25/3: lat =  np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180216_18/lat.txt')
25/4: lon = np.linspace(-180,180,901)[lon]
25/5: lon = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180216_18/lon.txt',dtype=int)
25/6: lon = np.linspace(-180,180,901)[lon]
25/7: lat =  np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180216_18/lat.txt',dtype=int)
25/8: lat = np.linspace(0,90,226)[lat]
25/9: lat
25/10: lon
26/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse

def saturation_pressure(T):
    return 287.058 * (T+273.15) * 1.25
26/2: T = np.arrange([5,4],[3,2])
26/3: T = np.array([5,4],[3,2])
26/4: T = np.array([5,4],[3,2],dtype=float)
26/5: T = np.array(([5,4],[3,2]),dtype=float)
26/6: T
26/7: es = saturation_pressure(T)
26/8: es
26/9:
def drypressure(T):
    return 287.058 * (T+273.15) * 1.25
26/10:
def saturation_pressure(T):
    retrun 6.1094e2*np.exp((17.625*T)/(T + 243.04))
26/11:
def saturation_pressure(T):
    return 6.1094e2*np.exp((17.625*T)/(T + 243.04))
26/12: es = saturation_pressure(T)
26/13: es
26/14:
def drypressure(T):
    return 287.058 * (T+273.15) * 1.25

def saturation_pressure(T):
    return 6.1094e2*np.exp((17.625*T)/(T + 243.04))

def qs(T):
    return 0.622 * saturation_pressure(T)/drypressure(T)
26/15: qs(T)
26/16:
def drypressure(T):
    return 287.058 * (T+273.15) * 1.25

def saturation_pressure(T):
    return 6.1094e2*np.exp((17.625*T)/(T + 243.04))

def qs(T):
    return 0.622 * saturation_pressure(T)/drypressure(T)
27/1: import numpy as np
27/2: 2*np.pi * 6370e3/901
27/3: 2*np.pi * 6370/901
27/4: np.pi*0.5*6370/226
27/5: np.linspace(0,2*np.pi * 6370,901)
27/6: np.where(np.linspace(0,2*np.pi * 6370,901)==1500)
27/7: np.where(np.linspace(0,2*np.pi * 6370,901)>1500)
27/8: np.min(np.where(np.linspace(0,2*np.pi * 6370,901)>1500))
27/9: Date='20180209_16'
27/10: Month='FEB18'
27/11:
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
27/12:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
27/13: import xarray as xr
27/14:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
27/15: CYID=46
27/16:
cy_data = xr.open_dataset(cy)
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
27/17: latu
27/18: len(latu)
27/19: np.mean(latu)
27/20: np.floor(np.mean(latu))
27/21: int(np.floor(np.mean(latu)))
27/22:
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
27/23: plotaround=10
27/24:
latu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[0])
latu = np.insert(latu, len(latu), np.arange(np.max(latu)+1,np.max(latu)+plotaround + 1),axis=0)
latu = np.insert(latu, [0], np.arange(np.min(latu)-plotaround,np.min(latu)),axis=0)

lonu = np.unique(np.where(cy_data.FLAG[0,:,:] == CYID)[1])
lonu = np.insert(lonu, len(lonu), np.arange(np.max(lonu)+1,np.max(lonu)+plotaround + 1),axis=0)
lonu = np.insert(lonu, [0], np.arange(np.min(lonu)-plotaround,np.min(lonu)),axis=0)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
27/25: center
27/26: np.where(center!=0)
27/27: np.unique(np.where(center!=0)[0])
27/28: np.mean(np.unique(np.where(center!=0)[0]))
27/29: np.mean(np.unique(np.where(center!=0)[1]))
27/30: len(center[0])
27/31: cy_data.CENTRES.velues[0,:,:]
27/32: cy_data.CENTRES.values[0,:,:]
27/33: np.where(cy_data.CENTRES.values[0,:,:]==CYID)
27/34: int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
27/35: int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
27/36: np.arange(104-35,104+35,1)
27/37: np.arange(104-36,104+36,1)
27/38: ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)i>1500)))
27/39: ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
27/40: ran
27/41:
latu = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latu-ran,latu+ran,1)
27/42: latu
27/43:
lonu = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonu-ran,lonu+ran,1)
27/44: lonu
27/45:
ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran,1)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]


minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)


flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
DisX = np.zeros((len(latu), len(lonu)))
DisY = np.zeros((len(latu), len(lonu)))

disx = np.linspace(0,2*np.pi*6370,901)-np.linspace(0,2*np.pi*6370,901)[lonc]
disy = np.linspace(0,0.5*np.pi*6370,226)-np.linspace(0,0.5*np.pi*6370,226)[latc]
27/46: disx
27/47:
for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k,n]
        DisY[k-minlatc,n-minlonc] = disy[k,n]
27/48: k
27/49: disx[k]
27/50: latu
27/51: len(latu)
27/52:
for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k-minlatc,n-minlonc]
        DisY[k-minlatc,n-minlonc] = disy[k-minlatc,n-minlonc]
27/53: minlatc
27/54: disx[0]
27/55: disx[latc]
27/56: disx[lonc]
27/57: len(np.arange(disx[latc-ran]))
27/58: len(np.arange(disx[lonc-ran],disx[lonc-ran+len(lonu)-1]))
27/59: len(np.arange(disx[lonc-ran],disx[lonc-ran+len(lonu)-1]),len(lonu))
27/60: len(np.arange(disx[lonc-ran],disx[lonc-ran+len(lonu)-1],len(lonu)))
27/61: XX, YY = np.meshgrid(disx,disy)
27/62: XX
27/63: YY
27/64: YY[5,5]
27/65: disx, disy = np.meshgrid(disx,disy)
27/66: XX.shape
27/67:
for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k,n]
        DisY[k-minlatc,n-minlonc] = disy[k,n]
27/68: DisX
27/69: DisX[0]
27/70: DisY[0]
27/71: DisY[:,0]
27/72:
ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]


minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)


flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
DisX = np.zeros((len(latu), len(lonu)))
DisY = np.zeros((len(latu), len(lonu)))

disx = np.linspace(0,2*np.pi*6370,901)-np.linspace(0,2*np.pi*6370,901)[lonc]
disy = np.linspace(0,0.5*np.pi*6370,226)-np.linspace(0,0.5*np.pi*6370,226)[latc]

disx, disy = np.meshgrid(disx,disy)

for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k,n]
        DisY[k-minlatc,n-minlonc] = disy[k,n]
27/73: DisY[:,0]
27/74: np.loadtxt(figpath+'disx.txt')
27/75: figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + month + '/'  + str(CYID) + '/' + date + '/'
27/76: month='FEB18'
27/77: CYID=46
27/78: figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + month + '/'  + str(CYID) + '/' + date + '/'
27/79: date='20180209_16'
27/80: figpath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/' + month + '/'  + str(CYID) + '/' + date + '/'
27/81: disx = np.loadtxt(figpath+'disx.txt')
27/82: disx
27/83: disx[0]
27/84: disx[0,5]
27/85: disy[:,0]
27/86: latc
27/87: np.linspace(0,90,226)[104]
27/88: 300/44.57
28/1: Date='20180209_16'
28/2:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
for r in range(0,h):
    kk=hh+r
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+str(MM)+str(DD)+'_%02d'%(kk)
    Date
28/3: h=61
28/4:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
for r in range(0,h):
    kk=hh+r
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+str(MM)+str(DD)+'_%02d'%(kk)
    Date
28/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
for r in range(0,h):
    kk=hh+r
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+str(MM)+str(DD)+'_%02d'%(kk)
    print(Date)
28/6: Date
28/7:
Date='20180209_16'
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
for r in range(0,h):
    kk=hh+1
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+str(MM)+str(DD)+'_%02d'%(kk)
    print(Date)
28/8:
Date='20180209_16'
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
for r in range(0,h):
    kk=hh+1
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    print(Date)
28/9:
Date='20180209_16'
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    print(Date)
    kk=kk+1
28/10: Date = '20171212_05'
28/11:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    print(Date)
    kk=kk+1
29/1: import numpy as np
29/2: Date='20171212_06'
29/3: CYID = 73
29/4:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
29/5: storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
29/6:
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]

storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'

cy_data = xr.open_dataset(cy)

ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)
29/7: import xarray as xr
29/8:
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]

storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'

cy_data = xr.open_dataset(cy)

ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)
29/9:
for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dPa.txt'%p)
29/10: storepath
29/11: storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
29/12:
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]

storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'

cy_data = xr.open_dataset(cy)

ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)
29/13:
for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dPa.txt'%p)
29/14:
for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)
29/15: center = np.loadtxt(storepath+'center.txt')
29/16: center
29/17: np.where(center!=0)
29/18: np.mean(np.unique(center[0]))
29/19: np.unique(np.where(center!=0)[0])
29/20: np.unique(np.where(center!=0)[1])
29/21: np.unique(np.where(center==73)[1])
29/22: np.unique(np.where(center==73)[0])
29/23: np.mean(np.unique(np.where(center==73)[0]))
29/24: np.mean(np.unique(np.where(center==73)[1]))
29/25: np.where(center==73)
29/26: np.where(center==73)[0]
29/27: len(np.where(center==73)[0])
29/28: len(np.where(center==73)[1])
29/29: PV
29/30: PV.shape
29/31: pvav = 0
29/32:
clon = np.where(center==73)[1]
clat = np.where(center==73)[0]

for ki in range(0,len(clat)):
    pvav =pvav + PV[clat[ki],clon[ki]]
29/33: pvav = pvav/len(clat)
29/34: pvav
30/1:
import numpy as np
import xarray as xr
import os
import argparse
30/2: Date='20171212_06'
30/3: CYID=73
30/4: h=61
30/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh


PV3 = np.zeros((1,h))
PV5 = np.zeros((1,h))
PV8 = np.zeros((1,h))
THE3 = np.zeros((1,h))
THE5 = np.zeros((1,h))
THE8 = np.zeros((1,h))
zeta3 = np.zeros((1,h))
zeta5 = np.zeros((1,h))
zeta8 = np.zeros((1,h))

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
30/6:
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'
    cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
    cy = cycl_path+'/'+'CY'+Date+'.nc'

    cy_data = xr.open_dataset(cy)
    center = np.loadtxt(storepath+'center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]

    for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)

        pvav=0
        theav=0
        zetaav=0
30/7: r
30/8:
for ki in range(0,len(clat)):
            pvav =pvav + PV[clat[ki],clon[ki]]/len(clat)
            theav =theav + THE[clat[ki],clon[ki]]/len(clat)
            zetaav = zetaav + zeta[clat[ki],clon[ki]]/len(clat)
30/9:
 if(p==300):
            PV3[r]=pvav
            THE3[r]=theav
            zeta3[r]=zetaav
        elif(p==500):
            PV5[r]=pvav
            THE5[r]=theav
            zeta5[r]=zetaav
        else:
            PV8[r]=pvav
            THE8[r]=theav
            zeta8[r]=zetaav
30/11:
if(p==300):
            PV3[r]=pvav
            THE3[r]=theav
            zeta3[r]=zetaav
elif(p==500):
            PV5[r]=pvav
            THE5[r]=theav
            zeta5[r]=zetaav
else:
            PV8[r]=pvav
            THE8[r]=theav
            zeta8[r]=zetaav
30/12: PV3
30/13: PV3.shape
30/14:
PV3 = np.zeros(h)
PV5 = np.zeros(h)
PV8 = np.zeros(h)
THE3 = np.zeros(h)
THE5 = np.zeros(h)
THE8 = np.zeros(h)
zeta3 = np.zeros(h)
zeta5 = np.zeros(h)
zeta8 = np.zeros(h)

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'

for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'

    center = np.loadtxt(storepath+'center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]

    for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)

        pvav=0
        theav=0
        zetaav=0

        for ki in range(0,len(clat)):
            pvav =pvav + PV[clat[ki],clon[ki]]/len(clat)
            theav =theav + THE[clat[ki],clon[ki]]/len(clat)
            zetaav = zetaav + zeta[clat[ki],clon[ki]]/len(clat)

        if(p==300):
            PV3[r]=pvav
            THE3[r]=theav
            zeta3[r]=zetaav
        elif(p==500):
            PV5[r]=pvav
            THE5[r]=theav
            zeta5[r]=zetaav
        else:
            PV8[r]=pvav
            THE8[r]=theav
            zeta8[r]=zetaav
30/15:
PV3 = np.zeros(h)
PV5 = np.zeros(h)
PV8 = np.zeros(h)
THE3 = np.zeros(h)
THE5 = np.zeros(h)
THE8 = np.zeros(h)
zeta3 = np.zeros(h)
zeta5 = np.zeros(h)
zeta8 = np.zeros(h)
30/16: PV.shape
30/17: PV3.shape
30/18: PV3[r]
30/19: PV3[2]
30/20: r
30/21: storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
30/22:
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'

    center = np.loadtxt(storepath+'center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]

    for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)

        pvav=0
        theav=0
        zetaav=0
30/23: Date='20171212_06'
30/24:
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'

    center = np.loadtxt(storepath+'center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]

    for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)

        pvav=0
        theav=0
        zetaav=0

        for ki in range(0,len(clat)):
            pvav =pvav + PV[clat[ki],clon[ki]]/len(clat)
            theav =theav + THE[clat[ki],clon[ki]]/len(clat)
            zetaav = zetaav + zeta[clat[ki],clon[ki]]/len(clat)

        if(p==300):
            PV3[r]=pvav
            THE3[r]=theav
            zeta3[r]=zetaav
        elif(p==500):
            PV5[r]=pvav
            THE5[r]=theav
            zeta5[r]=zetaav
        else:
            PV8[r]=pvav
            THE8[r]=theav
            zeta8[r]=zetaav
30/25: storebase
30/26: storepath
30/27:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh


PV3 = np.zeros(h)
PV5 = np.zeros(h)
PV8 = np.zeros(h)
THE3 = np.zeros(h)
THE5 = np.zeros(h)
THE8 = np.zeros(h)
zeta3 = np.zeros(h)
zeta5 = np.zeros(h)
zeta8 = np.zeros(h)

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
30/28: Date
30/29: Date='20171212_06'
30/30: Date
30/31: kk
30/32: hh
30/33:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])
30/34: hh
30/35: kk=hh
30/36:
for r in range(0,h):
    if(kk==24):
        kk=0
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'

    center = np.loadtxt(storepath+'center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]

    for p in [300, 500, 850]:
        PV = np.loadtxt(storepath+'PV-at-%dhPa.txt'%p)
        THE = np.loadtxt(storepath+'THE-at-%dhPa.txt'%p)
        zeta = np.loadtxt(storepath+'VORT-at-%dhPa.txt'%p)

        pvav=0
        theav=0
        zetaav=0

        for ki in range(0,len(clat)):
            pvav =pvav + PV[clat[ki],clon[ki]]/len(clat)
            theav =theav + THE[clat[ki],clon[ki]]/len(clat)
            zetaav = zetaav + zeta[clat[ki],clon[ki]]/len(clat)

        if(p==300):
            PV3[r]=pvav
            THE3[r]=theav
            zeta3[r]=zetaav
        elif(p==500):
            PV5[r]=pvav
            THE5[r]=theav
            zeta5[r]=zetaav
30/37:
ho = np.ones((1,h))
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(1,3)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')

ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')

ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')

figname='avtext.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
30/38: import matplotlib.pyplot as plt
30/39:
ho = np.ones((1,h))
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(1,3)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')

ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')

ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')

figname='avtext.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
30/40: pwd
30/41: ho
30/42:
ho = np.ones(h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(1,3)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')

ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')

ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')

figname='avtext.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
30/43:
ho = np.ones(1,h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(3,1)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')
ax1.set_ylabel('PV [PVU]')


ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')
ax2.set_ylabel(r'$\theta_e [K]')
ax2.legend(['300 hPa','500 hPa', '850 hPa'])


ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')
ax3.set_ylabel(r'$\zeta [\text{s}^{-1}]$')
ax3.set_xlabel('time since first identification [h]')


figname=storebase + str(Month) + '/' + str(CYID) + '/hrzt-averages.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
30/44:
ho = np.ones(1,h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(3,1)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')
ax1.set_ylabel('PV [PVU]')
30/45:
ho = np.ones(1,h)
ho[0]=0
ho=np.cumsum(ho)
30/46: h
30/47:
ho = np.ones(h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(3,1)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')
ax1.set_ylabel('PV [PVU]')


ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')
ax2.set_ylabel(r'$\theta_e [K]')
ax2.legend(['300 hPa','500 hPa', '850 hPa'])


ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')
ax3.set_ylabel(r'$\zeta [\text{s}^{-1}]$')
ax3.set_xlabel('time since first identification [h]')


figname=storebase + str(Month) + '/' + str(CYID) + '/hrzt-averages.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
30/48:
ho = np.ones(h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(3,1)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')
ax1.set_ylabel('PV [PVU]')


ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')
ax2.set_ylabel(r'$\theta_e [K]')
ax2.legend(['300 hPa','500 hPa', '850 hPa'])


ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')
ax3.set_ylabel(r'$\zeta$[s$^{-1}$]')
ax3.set_xlabel('time since first identification [h]')


figname=storebase + str(Month) + '/' + str(CYID) + '/hrzt-averages.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
30/49:
ho = np.ones(h)
ho[0]=0
ho=np.cumsum(ho)
fig, (ax1, ax2, ax3) = plt.subplots(3,1)

ax1.plot(ho,PV3,'red')
ax1.plot(ho,PV5,'blue')
ax1.plot(ho,PV8,'orange')
ax1.set_ylabel('PV [PVU]')


ax2.plot(ho,THE3,'red')
ax2.plot(ho,THE5,'blue')
ax2.plot(ho,THE8,'orange')
ax2.set_ylabel(r'$\theta_e$ [K]')
ax2.legend(['300 hPa','500 hPa', '850 hPa'])


ax3.plot(ho,zeta3,'red')
ax3.plot(ho,zeta5,'blue')
ax3.plot(ho,zeta8,'orange')
ax3.set_ylabel(r'$\zeta$[s$^{-1}$]')
ax3.set_xlabel('time since first identification [h]')


figname=storebase + str(Month) + '/' + str(CYID) + '/hrzt-averages.png'

fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
31/1:
import numpy as np
import xarray as xr
import os
31/2: Date='20171212_06'
31/3: CYID=73
31/4: h=61
31/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
31/6: kk
31/7:
for r in range(0,h):
 if(kk==24):
        kk=0
        DD=DD+1
 Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 kk=kk+1

 MONTHSN = np.arange(1,13,1)
 monthn = int(Date[4:6])
 monthid, = np.where(MONTHSN==monthn)
 Month = MONTHS[monthid[0]] + Date[2:4]


 storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
 storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
 if (os.path.isdir(storepath+'verticaldata')==0):
    os.mkdir(storepath+'verticaldata')
 storepath=storepath+'verticaldata/'
 print(storepath, Date)
 for pressure in range(100, 201, 25):
     print(pressure)
     for k in [0, 1, 2]:
         print(k)
32/1: 5
32/2: Date='20171212_06'
32/3: CYID=73
32/4: h=61
32/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
 if(kk==24):
        kk=0
        DD=DD+1
 print(kk)
 Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 kk=kk+1
32/6: Date='20171212_06'
32/7:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
p_file = ana_path+'/'+'P'+Date
p = xr.open_dataset(p_file)
32/8:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]
kk=hh
Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
p_file = ana_path+'/'+'P'+Date
p = xr.open_dataset(p_file)
32/9: import numpy as np
32/10:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]
kk=hh
Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
p_file = ana_path+'/'+'P'+Date
p = xr.open_dataset(p_file)
32/11: import xarray as xr
32/12:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]
kk=hh
Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
p_file = ana_path+'/'+'P'+Date
p = xr.open_dataset(p_file)
32/13: p
32/14: p.values
32/15: p.P.values
32/16: p
32/17: s_file = ana_path+'/'+'S'+Date
32/18: s = xr.open_dataset(s_file)
32/19: s.P.values
32/20:
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
 cy = cycl_path+'/'+'CY'+Date+'.nc'
 cy_data = xr.open_dataset(cy)
32/21:
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
cy_data = xr.open_dataset(cy)
32/22:
ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]
32/23: P = s.P.values[0,:,latu,lonu]
32/24: P
32/25: P.shape
32/26: s.P.values.shape
32/27: s.P.values[0].shape
32/28: s.P.values[0][0].shape
32/29: s.P.values[0][0][0].shape
32/30: s.P.values[0][0][0][0].shape
32/31: s.P.values[0][0][0][0]
32/32: P = s.P.values[0][:][latu,lonu]
32/33: s.P.values[0,:].shape
32/34: s.P.values[0,:,5].shape
32/35: s.P.values[0,:,5,7].shape
32/36: s.P.values[0,:,5:7,7].shape
32/37: s.P.values[0,:,:,:].shape
32/38: s.P.values[0,:,latu,:].shape
32/39: s.P.values[0,:,latu,lonu].shape
32/40: len(lonu)
32/41: lonu
32/42: latu
32/43: s.P.values[0,:,75:143,lonu].shape
32/44: s.P.values[0,:,75:143,454:522].shape
32/45: s.P.values[0,:,75:144,454:523].shape
32/46: s.P.values[0,:,latu,lonu].shape
32/47: s.P.values[0,:,:,latu,lonu].shape
32/48: s.P.values[0,:,latu,lonu].shape
32/49: s.P.values[0][:,latu,lonu].shape
32/50: s.P.values[0][:,latu].shape
32/51: s.P.values[0][:,np.min(latu)].shape
32/52: s.P.values[0][:,np.min(latu):np.max(latu)].shape
32/53: s.P.values[0][:,np.min(latu):np.max(latu)+1].shape
32/54: s.P.values[0][:,np.min(latu):np.max(latu)+1,np.min(lonu):np.max(lonu)+1].shape
32/55: P = s.P.values[0][:,np.min(latu):np.max(latu)+1,np.min(lonu):np.max(lonu)+1].shape
32/56: P.shape
32/57: P
32/58: P = s.P.values[0][:,np.min(latu):np.max(latu)+1,np.min(lonu):np.max(lonu)+1]
32/59: P.shape
32/60: P[:]
32/61: P-100
32/62: abs(P-100)
32/63: np.min(abs(P-100))
32/64: np.min(abs(P-850))
32/65: np.min(abs(P[:]-850))
32/66: np.min(abs(P[:,5,5]-850))
33/1: import numpy as np
33/2: P=np.array([5, 7, 8],[7, 6, 9])
33/3: P=np.array([5, 7, 8],[7, 6, 9],dtype=int)
33/4: P=np.array(([5, 7, 8],[7, 6, 9]),dtype=int)
33/5: P
33/6: P.shape
33/7: P==5
33/8: I = (P==5)
33/9: I
33/10: P[I]
33/11: P[I][0]
33/12: I, = (P==5)
33/13: I = (P==5)[0]
33/14: P[I][0]
33/15: P[I]
33/16: I
33/17: I = (P==5)
33/18: I
33/19: P[I]
33/20: P[I][0]
33/21: I = (P==7)
33/22: P[I]
33/23: P[I][0]
33/24: I
34/1: import numpy as np
34/2: import xarray as xr
34/3: Date='20171212_06'
34/4: CYID=73
34/5: h=1
34/6:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
 if(kk==24):
        kk=0
        DD=DD+1
 Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 kk=kk+1

 MONTHSN = np.arange(1,13,1)
 monthn = int(Date[4:6])
 monthid, = np.where(MONTHSN==monthn)
 Month = MONTHS[monthid[0]] + Date[2:4]


 storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
 ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
 cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
 cy = cycl_path+'/'+'CY'+Date+'.nc'
 cy_data = xr.open_dataset(cy)
 s_file = ana_path+'/'+'S'+Date
 p_file = ana_path+'/'+'P'+Date
 g_file = ana_path+'/'+'G'+Date

 ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
 latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
 latu = np.arange(latc-ran,latc+ran+1,1)

 lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
 lonu = np.arange(lonc-ran,lonc+ran+1,1)

 pltlat =np.linspace(0,90,226)[latu]
 pltlon = np.linspace(-180,180,901)[lonu]

 minlatc = np.min(latu)
 maxlatc = np.max(latu)

 minlonc = np.min(lonu)
 maxlonc = np.max(lonu)

 PV = np.zeros((len(latu), len(lonu)))
s = xr.open_dataset(s_file)
 p = xr.open_dataset(p_file)
 storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
 if (os.path.isdir(storepath+'verticaldata')==0):
    os.mkdir(storepath+'verticaldata')
 storepath=storepath+'verticaldata/'
 print(storepath)
34/7:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
 if(kk==24):
        kk=0
        DD=DD+1
 Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 kk=kk+1

 MONTHSN = np.arange(1,13,1)
 monthn = int(Date[4:6])
 monthid, = np.where(MONTHSN==monthn)
 Month = MONTHS[monthid[0]] + Date[2:4]


 storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
 ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
 cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
 cy = cycl_path+'/'+'CY'+Date+'.nc'
 cy_data = xr.open_dataset(cy)
 s_file = ana_path+'/'+'S'+Date
 p_file = ana_path+'/'+'P'+Date
 g_file = ana_path+'/'+'G'+Date

 ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
 latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
 latu = np.arange(latc-ran,latc+ran+1,1)

 lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
 lonu = np.arange(lonc-ran,lonc+ran+1,1)

 pltlat =np.linspace(0,90,226)[latu]
 pltlon = np.linspace(-180,180,901)[lonu]

 minlatc = np.min(latu)
 maxlatc = np.max(latu)

 minlonc = np.min(lonu)
 maxlonc = np.max(lonu)

 PV = np.zeros((len(latu), len(lonu)))
 s = xr.open_dataset(s_file)
 p = xr.open_dataset(p_file)
 storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
 if (os.path.isdir(storepath+'verticaldata')==0):
    os.mkdir(storepath+'verticaldata')
 storepath=storepath+'verticaldata/'
 print(storepath)
34/8: import os
34/9:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
for r in range(0,h):
 if(kk==24):
        kk=0
        DD=DD+1
 Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
 kk=kk+1

 MONTHSN = np.arange(1,13,1)
 monthn = int(Date[4:6])
 monthid, = np.where(MONTHSN==monthn)
 Month = MONTHS[monthid[0]] + Date[2:4]


 storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
 ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
 cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
 cy = cycl_path+'/'+'CY'+Date+'.nc'
 cy_data = xr.open_dataset(cy)
 s_file = ana_path+'/'+'S'+Date
 p_file = ana_path+'/'+'P'+Date
 g_file = ana_path+'/'+'G'+Date

 ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1500)))
 latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
 latu = np.arange(latc-ran,latc+ran+1,1)

 lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
 lonu = np.arange(lonc-ran,lonc+ran+1,1)

 pltlat =np.linspace(0,90,226)[latu]
 pltlon = np.linspace(-180,180,901)[lonu]

 minlatc = np.min(latu)
 maxlatc = np.max(latu)

 minlonc = np.min(lonu)
 maxlonc = np.max(lonu)

 PV = np.zeros((len(latu), len(lonu)))
 s = xr.open_dataset(s_file)
 p = xr.open_dataset(p_file)
 storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'
 if (os.path.isdir(storepath+'verticaldata')==0):
    os.mkdir(storepath+'verticaldata')
 storepath=storepath+'verticaldata/'
 print(storepath)
34/10: abs(s.P.values[0,:,0,0]-100)==np.min(abs(s.P.values[0,:,0,0]-100))
34/11: I = abs(s.P.values[0,:,0,0]-100)==np.min(abs(s.P.values[0,:,0,0]-100))
34/12: PV[k-minlatc,n-minlonc] = s.PV.values[0,I,k,n]
34/13: PV[k-minlatc,n-minlonc] = s.PV.values[0,I,0,0]
34/14: PV[0,0] = s.PV.values[0,I,0,0]
34/15: PV[0,0]
35/1: import numpy as np
35/2: d = np.loadtxt('/atmosdyn2/ascherrmann/002-2020-08-05-Identify-DJF1718-medcyclones/DEC17/TRACKED_CYCLONES')
35/3: np.where(d[:,1]==73)
35/4: d(np.where(d[:,1]==73),7)
35/5: d(np.where(d[:,1]==73)[0],7)
35/6: I,= np.where(d[:,1]==73)[0]
35/7: I,= np.where(d[:,1]==73)
35/8: I,= np.where(d[:,1]==73)
35/9: I
35/10: d(I,6)
35/11: d[np.where(d[:,1]==73),6]
35/12: np.where(d[np.where(d[:,1]==73),6]==np.min(d[np.where(d[:,1]==73),6]))
35/13: d[np.where(d[np.where(d[:,1]==73),6]==np.min(d[np.where(d[:,1]==73),6]))]
35/14: I
35/15: d[I,6]
35/16: np.min(d[I,6])
35/17: np.where(d[I,6]==np.min(d[I,6]))
35/18: cd /net/thermo/atmosdyn/atroman/phd/FEB18/cdf/
35/19: import xarray as xr
35/20: t = xr.open_dataset('S20180209_16')
35/21: t.VORT
35/22: t.VORT.values
35/23: t = 1
35/24: t.shape
35/25: t = 1.5
35/26: t.shape
35/27: if(!t.shape)
35/28: if(! t.shape)
35/29: t.shape
35/30: t[0]
35/31: len(t)
35/32: isinstance(t)
35/33: isinstance(t,list)
35/34: k=np.array(([1, 2, 3],[2, 1,3]),dtype=int)
35/35: u = np.where(k==1)
35/36: u
35/37: k=np.array(([1, 2, 3,1]),dtype=int)
35/38: u = np.where(k==1)
35/39: u
35/40: u, = np.where(k==1)
35/41: isinstance(u,list)
35/42: isinstance(u,array)
35/43: isinstance(u,np.array)
35/44: u.type
35/45: type(u)
35/46: type(t)
35/47: type(u)=='numpy.ndarray'
35/48: type(u)==numpy.ndarray
35/49: k=np.array(([1, 2, 3]),dtype=int)
35/50: u, = np.where(k==1)
35/51: type(u)
35/52: u
35/53: type(u[0])
35/54:
if(type(u[0])==np.int64):
    print(1)
35/55:
def drypressure(T):
    return 287.058 * (T+273.15) * 1.25

def saturation_pressure(T):
    return 6.1094e2*np.exp((17.625*T)/(T + 243.04))

def qs(T):
    return 0.622 * saturation_pressure(T)/drypressure(T)
36/1:
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
36/2:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
import mycolormaps
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
36/3: vari = ['THE', 'P', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
36/4: vari=list(vari)
36/5: di = dict()
36/6:
for i in range(len(vari)):
    di[vari[i]] = np.array([])
36/7: di
36/8: storebase = '/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
36/9: Date='20180217_04'
36/10:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh
36/11:
Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)

MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]
36/12: storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'
36/13: CYID=73
36/14: storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/'
36/15: di
36/16: di['THE']
36/17: di[vari[0]]
36/18: vari[12]
36/19: vari[12]+'-at-%dhPa.txt'%300
36/20:
for i in range(len(vari)):
    di[vari[i]] = np.loadtxt(storebase+vari[i]+'-at-%dhPa.txt'%300)
36/21: vari
36/22: di
36/23: p = 300
36/24: THE = np.loadtxt(storebase+vari[0]+'-at-%dhPa.txt'%p)
36/25: storepath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata/'
36/26: THE = np.loadtxt(storepath+vari[0]+'-at-%dhPa.txt'%p)
36/27:
for i in range(len(vari)):
    di[vari[i]] = np.loadtxt(storepath+vari[i]+'-at-%dhPa.txt'%p)
36/28: di = dict()
36/29: vari = ['THE', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
36/30: vari = list(vari)
36/31:
for i in range(len(vari)):
    di[vari[i]] = np.loadtxt(storepath+vari[i]+'-at-%dhPa.txt'%p)
36/32: di
36/33: vari
36/34: i = ['THE','U', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
36/35: len(i)
36/36: di['THE']
36/37: di['THE'][0]
36/38:
center = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/center.txt')
    clat = np.where(center==CYID)[0]
    clon = np.where(center==CYID)[1]
36/39:
center = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/center.txt')
clat = np.where(center==CYID)[0]
clon = np.where(center==CYID)[1]
36/40: di['THE'][clat,clon]
36/41: di['THE'][clat,:]
36/42: di['THE'][clat,clon]
36/43: u = np.array([5,6,7],dtype=int)
36/44: u
36/45: np.flip(u)
36/46:
dpath=storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata'
di = dict()
diav = dict()
var = ['THE','U', 'T', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
var=list(var)
for q in range(len(var)):
        diav[var[q]] = np.array([])

for p in range(100,1001,25):
   for q in range(len(var)):
            di[var[q]] = np.loadtxt(dpath+var[q]+'-at-%dhPa.txt'%p)
            diav[var[q]] = np.append(diav[var[q]],np.mean(di[var[q]][clat,clon]))
36/47:
dpath=storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata/'
di = dict()
diav = dict()
var = ['THE','U', 'T', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']
var=list(var)
for q in range(len(var)):
        diav[var[q]] = np.array([])

for p in range(100,1001,25):
   for q in range(len(var)):
            di[var[q]] = np.loadtxt(dpath+var[q]+'-at-%dhPa.txt'%p)
            diav[var[q]] = np.append(diav[var[q]],np.mean(di[var[q]][clat,clon]))
36/48: diav['THE']
36/49: diav['PV']
36/50: diav['T']
36/51: pressure = np.arange(100,1001,25)
36/52:
fig, ax = plt.subplots()
ax.set_ylim(ymin=100, ymax=1000)
ax.invert_yaxis()
36/53: ax.plot(diav['T'],pressure)
36/54: fig.show
36/55: fig.show()
36/56: t = dict()
36/57: t['T'] = np.array([])
36/58: t
36/59: t['T']['unit'] = 'K'
36/60:  unit = ['K',r'm s$^{-1}$',r'$^{\circ}$ C',r'm s$^{-1}$', r's$^{-1}$', r'kg kg$^{-1}$', r'Pa s$^{-1}', r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$','PVU','K',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$']
36/61: len(unit)
36/62: di
36/63: di['PVRLS'] + di['PVRCONVT']
36/64: di['PVRLS'][0] + di['PVRCONVT'][0]
36/65: fig, axes  = plt.subplots(1,4)
36/66: axes
36/67:
for ax in axes:
    print(ax)
36/68: kk=20
36/69: kk=kk+0
36/70: kk=kk+9
36/71:
if kk>=24:
    kk = kk-24
36/72: kk
36/73: range(0,18,9)
36/74:
for i in range(0,18,9):
    print(i)
36/75:
for i in range(0,19,9):
    print(i)
36/76: di
36/77: vari
36/78: var
36/79: diav
36/80: diav['TH']
36/81: d = np.loadtxt(dpath+'TH-at-900hPa.txt')
36/82: d
36/83: getattr(di)
36/84: getattr(di,1)
36/85: getattr(di,'THE')
36/86: tp = '/net/thermo/atmosdyn/atroman/phd/FEB18/cdf/'
36/87: import xarray as xr
36/88: s = xr.open_data_set(tp+'S20180217_04')
36/89: s = xr.open_dataset(tp+'S20180217_04')
36/90: atr = getattr(s, 'PV')
36/91: atr
36/92: atr.values
36/93: atr.values[0,0,0,0]
36/94: atr.values[0,0,0,0]
36/95: atr.values[0,0,0,0]
36/96: atr.values[0,0,0,1]
36/97: atr.values[0,0,0,2]
36/98: atr.values[0,5,0,2]
36/99: Date
36/100: center = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/center.txt')
36/101: clat = np.where(center==CYID)[0]
36/102: clon = np.where(center==CYID)[1]
36/103: clat
36/104: clon
36/105: disx = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disx.txt')
36/106: disy = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disy.txt')
36/107: disx
36/108: lon =  np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt')
36/109: lat =  np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lat.txt')
36/110: lat
36/111: center
36/112: latc
36/113: latu
36/114: center
36/115: center.shape
36/116: lat.shape
36/117: lat
36/118: disx
36/119: disx.shape
36/120: disy
36/121: disx
36/122: np.where(disx<300)
36/123: np.where(abs(disx)<300)
36/124: np.where(abs(disx)<300).shape
36/125: k, = np.where(abs(disx)<300)
36/126: k, = np.where(abs(disy)<300)
36/127: np.where(abs(disy)<300)
36/128: np.where(abs(disy)<300)[0]
36/129: np.where(abs(disy)<300)[0][:]
36/130: np.where(abs(disy)<300)[0][0]
36/131: np.where(abs(disx)<300)[0]
36/132: np.where(abs(disx)<300)[1]
36/133: disx[0]
36/134: clat = np.where(abs(disy)<400)[0]
36/135: len(clat)
36/136: np.unique(clat)
36/137: r = np.array([5 , 6 , 8])
36/138: q = np.array([1, 2, 3])
36/139: rr, qq = np.meshgrid(r,q)
36/140: rr
36/141: qq
36/142: center.shape
36/143: lon
36/144: clat
36/145: clon
36/146: lonc
36/147: lat
36/148: disx
36/149: disx[0]
36/150: disx[0][lon[0]]
36/151: lon[0]
36/152: int(lon[0])
36/153: lat
36/154: lon =  np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt',dtype=int)
36/155: lon
36/156: disx[0][lon[0]]
36/157: disy
37/1:
import numpy as np
import xarray as xr
import os
import argparse
import matplotlib
import matplotlib.pyplot as plt
37/2: Date = '20180216_19'
37/3: CYID=73
37/4: dis=300
37/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
37/6:
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]

dpath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata/'
figpath = storebase + str(Month) + '/' + str(CYID) + '/'
37/7: disx = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disx.txt')
37/8: disy = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disy.txt')
37/9: r = np.sqrt(disx**2 + disy**2)
37/10: r
37/11: ran=np.where(r<dis)
37/12: ran
37/13: clat, lcon =np.where(r<dis)
37/14: clat
37/15: clon
37/16: clat, clon =np.where(r<dis)
37/17: clo
37/18: clon
37/19:
di = dict()
diav = dict()

var = ['THE','U', 'T', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']

var=list(var)
pressure = np.arange(100,1001,25)
diunit = dict()

unit = ['K',r'm s$^{-1}$',r'$^{\circ}$ C',r'm s$^{-1}$', r's$^{-1}$', r'kg kg$^{-1}$', r'Pa s$^{-1}', r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$','PVU','K',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$']

for q in range(len(var)):
        diav[var[q]] = np.array([])
for p in range(100,1001,25):
        for q in range(len(var)):
            di[var[q]] = np.loadtxt(dpath+var[q]+'-at-%dhPa.txt'%p)
            diav[var[q]] = np.append(diav[var[q]],np.mean(di[var[q]][clat,clon]))
37/20:
LAT = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lat.txt')
LON = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt')
37/21: clat = clat -np.min(LAT[:,0])
37/22: clon=clon-np.min(LON[0])
37/23:
di = dict()
diav = dict()

var = ['THE','U', 'T', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']

var=list(var)
pressure = np.arange(100,1001,25)
diunit = dict()

unit = ['K',r'm s$^{-1}$',r'$^{\circ}$ C',r'm s$^{-1}$', r's$^{-1}$', r'kg kg$^{-1}$', r'Pa s$^{-1}', r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$','PVU','K',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$']

for q in range(len(var)):
        diav[var[q]] = np.array([])
for p in range(100,1001,25):
        for q in range(len(var)):
            di[var[q]] = np.loadtxt(dpath+var[q]+'-at-%dhPa.txt'%p)
            diav[var[q]] = np.append(diav[var[q]],np.mean(di[var[q]][clat,clon]))
37/24: clat
37/25:
LAT = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lat.txt',dtype=int)
LON = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt',dtype=int)
37/26: clat, clon =np.where(r<dis)
37/27: clat
37/28: clat = clat -np.min(LAT[:,0])
37/29: clat
37/30: clon = clon -np.min(LON[0])
37/31:
di = dict()
diav = dict()

var = ['THE','U', 'T', 'V', 'VORT', 'Q', 'OMEGA', 'SWC', 'RWC', 'IWC', 'LWC', 'PV', 'TH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF']

var=list(var)
pressure = np.arange(100,1001,25)
diunit = dict()

unit = ['K',r'm s$^{-1}$',r'$^{\circ}$ C',r'm s$^{-1}$', r's$^{-1}$', r'kg kg$^{-1}$', r'Pa s$^{-1}', r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$',r'g kg$^{-1}$','PVU','K',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$',r'PVU h$^{-1}$']

for q in range(len(var)):
        diav[var[q]] = np.array([])
for p in range(100,1001,25):
        for q in range(len(var)):
            di[var[q]] = np.loadtxt(dpath+var[q]+'-at-%dhPa.txt'%p)
            diav[var[q]] = np.append(diav[var[q]],np.mean(di[var[q]][clat,clon]))
37/32: clon
38/1: import numpy as np
38/2: 533-465
38/3: 68 * 44
38/4: np.linspace(0,0.5*np.pi*6370,226)
38/5: np.linspace(0,0.5*np.pi,226)
38/6: np.linspace(0,0.5*np.pi,226)[30]
38/7: np.linspace(0,np.cos(np.linspace(0,0.5*np.pi,226)[30]) * 2 * np.pi * 6370,901)
39/1:
import numpy as np
import xarray as xr
import os
import argparse
import matplotlib
import matplotlib.pyplot as plt
39/2:
def colorline(x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
    if z is None:
        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
    if not hasattr(z, "__iter__"):
        z = np.array([z])

    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc


def make_segments(x, y):
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    return segments


x = np.linspace(0, 4. * np.pi, 100)
y = np.sin(x)
fig, ax = plt.subplots()
lc = colorline(x, y, cmap='hsv')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
plt.ylim(-1.0, 1.0)
39/3:
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
39/4:
def colorline(x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
    if z is None:
        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
    if not hasattr(z, "__iter__"):
        z = np.array([z])

    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc


def make_segments(x, y):
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    return segments


x = np.linspace(0, 4. * np.pi, 100)
y = np.sin(x)
fig, ax = plt.subplots()
lc = colorline(x, y, cmap='hsv')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
plt.ylim(-1.0, 1.0)
39/5: plt.show()
40/1:
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
40/2:
def colorline(x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
    if z is None:
        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
    if not hasattr(z, "__iter__"):
        z = np.array([z])

    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc


def make_segments(x, y):
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    return segments


x = np.linspace(0, 4. * np.pi, 100)
y = np.sin(x)
fig, ax = plt.subplots()
lc = colorline(x, y, cmap='hsv')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
plt.ylim(-1.0, 1.0)
40/3:
def colorline(x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
    if z is None:
        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
    if not hasattr(z, "__iter__"):
        z = np.array([z])

    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc


def make_segments(x, y):
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    return segments


x = np.linspace(0, 4. * np.pi, 100)
y = np.sin(x)
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
plt.ylim(-1.0, 1.0)
40/4: plt.show()
40/5: plt.show()
40/6: y = np.exp(x)
40/7:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/8: plt.show()
40/9:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/10:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/11: plt.ylim(1.0,200)
40/12: plt.show()
40/13:
def colorline(x, y, z, cmap='jet', norm=plt.Normalize(0.0, np.max(z)),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc


def make_segments(x, y):
    points = np.array([x, y]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    return segments
40/14:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/15: plt.ylim(1.0,200)
40/16: plt.show()
40/17:
def colorline(x, y, z, cmap='jet'):#, norm=plt.Normalize(0.0, np.max(z)),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/18:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/19:
def colorline(x, y, z, cmap='jet'):#, norm=plt.Normalize(0.0, np.max(z)),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/20:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/21:
def colorline(x, y, z, cmap='jet',,linewidth=3, alpha=1.0):#, norm=plt.Normalize(0.0, np.max(z)),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/22:
def colorline(x, y, z, cmap='jet',linewidth=3, alpha=1.0):#, norm=plt.Normalize(0.0, np.max(z)),linewidth=3, alpha=1.0):

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/23:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/24: plt.show()
40/25:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/26: plt.ylim(1.0,200)
40/27: plt.show()
40/28:
def colorline(x, y, z, cmap='jet', np.max(z)),linewidth=3, alpha=1.0):
    norm=plt.Normalize(np.min(z)

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/29:
def colorline(x, y, z, cmap='jet',linewidth=3, alpha=1.0):
    norm=plt.Normalize(np.min(z),np.max(z))

    # Default colors equally spaced on [0,1]:
#    if z is None:
#        z = np.linspace(0.0, 1.0, len(x))

    # Special case if a single number:
    # to check for numerical input -- this is a hack
#    if not hasattr(z, "__iter__"):
#        z = np.array([z])

#    z = np.asarray(z)

    segments = make_segments(x, y)
    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,
                              linewidth=linewidth, alpha=alpha)

    ax = plt.gca()
    ax.add_collection(lc)

    return lc
40/30:
fig, ax = plt.subplots()
z=np.arange(-1,10.1,0.5)
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/31: plt.ylim(1.0,200)
40/32: plt.show()
40/33:
fig, ax = plt.subplots()
z=np.linspace(-1,10,len(x))
lc = colorline(x, y, z=z, cmap='jet')
plt.colorbar(lc)
plt.xlim(x.min(), x.max())
40/34: plt.ylim(1.0,200)
40/35: plt.show()
40/36: np
42/1:
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
42/2: Date = '20171213_13'
42/3: CYID=73
42/4:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
hx = np.array([0, 0])
hy = np.array([100, 1001])
42/5: h = 1
42/6:
for r in range(0,h,9):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+9

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    dpath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata/'
    figpath = storebase + str(Month) + '/' + str(CYID) + '/'
    disx = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disx.txt')
    disy = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disy.txt')
    rr = np.sqrt(disx**2 + disy**2)

    LAT = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lat.txt',dtype=int)
    LON = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt',dtype=int)
42/7: rr
42/8: rsort = np.sort(rr)
42/9: rsort
42/10: dis=200
42/11: clat, clon = np.where(rr<dis)
42/12: rr(clat)
42/13: rr[clat]
42/14: rr[clat,clon]
42/15: np.unique(rr[clat,clon])
42/16: clon
42/17: clat
42/18: rr[np.unique(clat),clon]
42/19: rr[6,clon]
42/20: rr[86,clon]
42/21: ru = np.unique(rr)
42/22: ru
42/23: ru = np.unique(rr[clat,clon])
42/24: ru
42/25: np.sqrt(44.470989**2*2)
42/26: np.sqrt(44.470989**2*5)
43/1:
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
43/2: DD
43/3: Date = '20171213_13'
43/4: CYID=73
43/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
kk=hh

storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
hx = np.array([0, 0])
hy = np.array([100, 1001])
43/6: h=1
43/7:
for r in range(0,h,9):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+9

    MONTHSN = np.arange(1,13,1)
    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    dpath = storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/verticaldata/'
    figpath = storebase + str(Month) + '/' + str(CYID) + '/'
    disx = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disx.txt')
    disy = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/disy.txt')
    rr = np.sqrt(disx**2 + disy**2)

    LAT = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lat.txt',dtype=int)
    LON = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date + '/lon.txt',dtype=int)
43/8: ur = rr[clat,clon]
43/9: clat, clon = np.where(rr<dis)
43/10: dis=200
43/11: clat, clon = np.where(rr<dis)
43/12: ur = rr[clat,clon]
43/13: ur
43/14: clat
43/15: ulat = np.unique(clat)
43/16: ulat
43/17:
for t in range(0, len(ulat)):
    np.where(clat==ulat[t])
43/18:
for t in range(0, len(ulat)):
    print(np.where(clat==ulat[t]))
43/19:
for t in range(0, len(ulat)):
    print(clon[np.where(clat==ulat[t]))]
43/20:
for t in range(0, len(ulat)):
    print(clon[np.where(clat==ulat[t])])
43/21:
for t in range(0, len(ulat)):
    print(r[ulat[t],clon[np.where(clat==ulat[t])]])
43/22: ulat[t]
43/23: r[86,[498 499 500 501 502]]
43/24: clon[np.where(clat==ulat[t])]
43/25: rr[:,clon[np.where(clat==ulat[t])]]
43/26: ulat[t]
43/27: rr[ulat[t],clon[np.where(clat==ulat[t])]]
43/28:
for t in range(0, len(ulat)):
    print(rr[ulat[t],clon[np.where(clat==ulat[t])]])
43/29: rdic = dict()
43/30: ur
43/31: ur = np.unique(r)
43/32: ur
44/1: Date1 = '20171212_21'
44/2: Date2 = '20171212_23'
44/3: CYID=73
44/4: storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
44/5:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])
44/6:
yyyy = int(Date1[0:4])
MM = int(Date1[4:6])
DD = int(Date1[6:8])
hh = int(Date1[9:])
44/7: Month='DEC17'
44/8: center1 = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date1 + '/center.txt')
44/9: import numpy as np
44/10: center1 = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date1 + '/center.txt')
44/11: center2 = np.loadtxt(storebase + str(Month) + '/' + str(CYID) + '/' + Date2 + '/center.txt')
44/12:
clat1 = np.where(center1==CYID)[0]
clon1 = np.where(center1==CYID)[1]
44/13:
clat2 = np.where(center2==CYID)[0]
clon2 = np.where(center2==CYID)[1]
44/14: len(clat1)
44/15: len(clat2)
44/16: clat2-clat1
44/17: clon2-clon1
44/18: Date='20171212_22'
44/19: CYID
44/20:
yyyy = int(Date[0:4])
MM = int(Date[4:6])
DD = int(Date[6:8])
hh = int(Date[9:])

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
monthn = int(Date[4:6])
monthid, = np.where(MONTHSN==monthn)
Month = MONTHS[monthid[0]] + Date[2:4]
44/21:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
cy_data = xr.open_dataset(cy)
s_file = ana_path+'/'+'S'+Date
p_file = ana_path+'/'+'P'+Date
g_file = ana_path+'/'+'G'+Date
44/22: import xarray as xr
44/23:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date+'.nc'
cy_data = xr.open_dataset(cy)
s_file = ana_path+'/'+'S'+Date
p_file = ana_path+'/'+'P'+Date
g_file = ana_path+'/'+'G'+Date
44/24: ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>2100)))
44/25: ran
44/26: latc = int(np.floor(np.mean(np.unique(np.where(center1==CYID)[0]))))
44/27: latc
44/28: cy_data
44/29:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date1+'.nc'
cy_data = xr.open_dataset(cy)
s_file = ana_path+'/'+'S'+Date
p_file = ana_path+'/'+'P'+Date
g_file = ana_path+'/'+'G'+Date
44/30:
ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>2100)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]


minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)


flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
DisX = np.zeros((len(latu), len(lonu)))
DisY = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
prec = np.zeros((len(latu), len(lonu)))

disx = np.linspace(0,2*np.pi*6370,901)-np.linspace(0,2*np.pi*6370,901)[lonc]
disy = np.linspace(0,0.5*np.pi*6370,226)-np.linspace(0,0.5*np.pi*6370,226)[latc]

disx, disy = np.meshgrid(disx,disy)

s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file)
g = xr.open_dataset(g_file)

pressure = 300

for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k,n]
        DisY[k-minlatc,n-minlonc] = disy[k,n]
        slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]
        prec[k-minlatc,n-minlonc] = g.LSP.values[0,0,k,n] + g.CP.values[0,0,k,n]

latlon = np.meshgrid(lonu,latu)
44/31:
if (os.path.isdir(storepath+str(Month))==0):
    os.mkdir(storepath + str(Month))
    os.mkdir(storepath + str(Month) + '/' + str(CYID))
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

elif(os.path.isdir(storepath + str(Month) + '/' + str(CYID))==0):
    os.mkdir(storepath + str(Month) + '/' +  str(CYID))
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

elif(os.path.isdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date) ==0 ):
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'

np.savetxt(storepath +'center.txt',center.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'flag.txt',flag.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'coldfront.txt',CFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'warmfront.txt',WFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lon.txt',latlon[0].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lat.txt',latlon[1].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'bentbackfront.txt',BBFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'disx.txt',DisX.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'disy.txt',DisY.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'prec.txt',prec.astype(float),fmt='%f', delimiter=' ',newline='\n')
44/32: import os
44/33:
if (os.path.isdir(storepath+str(Month))==0):
    os.mkdir(storepath + str(Month))
    os.mkdir(storepath + str(Month) + '/' + str(CYID))
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

elif(os.path.isdir(storepath + str(Month) + '/' + str(CYID))==0):
    os.mkdir(storepath + str(Month) + '/' +  str(CYID))
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

elif(os.path.isdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date) ==0 ):
    os.mkdir(storepath + str(Month) + '/' + str(CYID) + '/' + Date +'/')

storepath = storepath + str(Month) + '/' + str(CYID) + '/' + Date + '/'

np.savetxt(storepath +'center.txt',center.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'flag.txt',flag.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'coldfront.txt',CFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'warmfront.txt',WFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lon.txt',latlon[0].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lat.txt',latlon[1].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'bentbackfront.txt',BBFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'disx.txt',DisX.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'disy.txt',DisY.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'prec.txt',prec.astype(float),fmt='%f', delimiter=' ',newline='\n')
44/34:
storepath='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
cycl_path='/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/'
cy = cycl_path+'/'+'CY'+Date1+'.nc'
cy_data = xr.open_dataset(cy)
s_file = ana_path+'/'+'S'+Date1
p_file = ana_path+'/'+'P'+Date1
g_file = ana_path+'/'+'G'+Date1
44/35:
s_file = ana_path+'/'+'S'+Date
p_file = ana_path+'/'+'P'+Date
g_file = ana_path+'/'+'G'+Date
ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>2100)))
latc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[0]))))
latu = np.arange(latc-ran,latc+ran+1,1)

lonc = int(np.floor(np.mean(np.unique(np.where(cy_data.CENTRES[0,:,:] == CYID)[1]))))
lonu = np.arange(lonc-ran,lonc+ran+1,1)

pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]


minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)


flag = np.zeros((len(latu), len(lonu)))
center = np.zeros((len(latu), len(lonu)))
WFR = np.zeros((len(latu), len(lonu)))
CFR = np.zeros((len(latu), len(lonu)))
BBFR = np.zeros((len(latu), len(lonu)))
DisX = np.zeros((len(latu), len(lonu)))
DisY = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
prec = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
disx = np.linspace(0,2*np.pi*6370,901)-np.linspace(0,2*np.pi*6370,901)[lonc]
disy = np.linspace(0,0.5*np.pi*6370,226)-np.linspace(0,0.5*np.pi*6370,226)[latc]

disx, disy = np.meshgrid(disx,disy)

s = xr.open_dataset(s_file)
p = xr.open_dataset(p_file)
g = xr.open_dataset(g_file)

pressure = 300
cy_data2 = xr.open_dataset(cycl_path+'/'+'CY'+Date+'.nc')

for k in latu:
    for n in lonu:
        flag[k-minlatc,n-minlonc] = cy_data.FLAG.values[0,k,n]
        center[k-minlatc,n-minlonc] = cy_data.CENTRES.values[0,k,n]
        WFR[k-minlatc,n-minlonc] = cy_data2.WFRONTS.values[0,k,n]
        CFR[k-minlatc,n-minlonc] = cy_data2.CFRONTS.values[0,k,n]
        BBFR[k-minlatc,n-minlonc] = cy_data2.BBFRONTS.values[0,k,n]
        DisX[k-minlatc,n-minlonc] = disx[k,n]
        DisY[k-minlatc,n-minlonc] = disy[k,n]
        slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]
        prec[k-minlatc,n-minlonc] = g.LSP.values[0,0,k,n] + g.CP.values[0,0,k,n]
        
latlon = np.meshgrid(lonu,latu)
44/36:
np.savetxt(storepath +'center.txt',center.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'flag.txt',flag.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'coldfront.txt',CFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'warmfront.txt',WFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lon.txt',latlon[0].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'lat.txt',latlon[1].astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'bentbackfront.txt',BBFR.astype(int),fmt='%i', delimiter=' ',newline='\n')
np.savetxt(storepath +'disx.txt',DisX.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'disy.txt',DisY.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'prec.txt',prec.astype(float),fmt='%f', delimiter=' ',newline='\n')
np.savetxt(storepath +'slp.txt',slp.astype(float),fmt='%f', delimiter=' ',newline='\n')
45/1: import numpy as np
45/2: np.linspace(-180,180,901)[450,451,452]
45/3: np.linspace(-180,180,901)[450 451 452]
45/4: np.linspace(-180,180,901)[450]
45/5: np.linspace(-180,180,901)[451]
45/6: np.linspace(-180,180,1201)[600]
45/7: np.linspace(-180,180,1201)[601]
45/8: np.linspace(-180,180,1501)[751]
45/9: np.linspace(-180,180,1501)[750]
45/10: 226*1501/901
46/1: import numpy as np
46/2: import xarray as xr
46/3:
lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]
46/4: Date='20121201_00'
46/5:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
46/6: date=Date
46/7:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
46/8: h=1
46/9: P=np.zeros((len(latu), len(lonu)))
46/10: slp = np.zeros((len(latu), len(lonu)))
46/11:
for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '%dhPa-PV-evo/'%pressure
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
46/12:
for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
46/13: Date='20171201_00'
46/14:
date=Date
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'
46/15:
for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
46/16: z, klat, klon = np.where(abs(s.PV.values[0.,:]-2)==np.min(abs(s.PV.values[0.,:]-2)))
46/17: k = np.where(abs(s.PV.values[0.,:]-2)==np.min(abs(s.PV.values[0.,:]-2)))
46/18: k = np.where(abs(s.PV.values[0,:]-2)==np.min(abs(s.PV.values[0,:]-2)))
46/19: k.shape
46/20: k[0]
46/21: k = np.where(abs(s.PV.values[0,:,latu,lonu]-2)==np.min(abs(s.PV.values[0,:,latu,lonu]-2)))
46/22: latu
46/23: lonu
46/24: s.PV.values[0,:].shape
46/25: s.PV.values[0,:,latu,:].shape
46/26: s.PV.values[0,:,latu,lonu].shape
46/27: s.PV.values[0,latu,lonu].shape
46/28: s.PV.values[0,5,latu,lonu].shape
46/29: s.PV.values[0,5,3,lonu].shape
46/30: s.PV.values[0,5,3,1].shape
46/31: s.PV.values[0,5,latu,lonu].shape
46/32: s.PV.values[0,5,lonu,latu].shape
47/1: date='20171201_00'
47/2: h=1
47/3:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))
47/4: import numpy as np
47/5: import xarray as xr
47/6:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))
47/7:
for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
47/8:
for k in [np.min(latu)]:
        for n in [np.min(lonu)]:
            twoPVUindex[k-minlatc,n-minlonc], = np.where(abs(s.PV.values[0,:,k,n]-2)==np.min(abs(s.PV.values[0,:,k,n]-2)))
47/9: k
47/10: n
47/11: twoPVUindex
47/12: twoPVUindex[twoPVUindex!=0]
47/13: s.PV.values.shape
47/14: s.PV.values
47/15: s.PV.values[0]
47/16: s.PV.values[0].shape
47/17: s.PV.values[0,:,0,300].shape
47/18: s.PV.values[0,:,0,300]
47/19: np.where(abs(s.PV.values[0,:,0,300]-2)==np.min(abs(s.PV.values[0,:,0,300]-2)))
48/1: date='20171201_00'
48/2: h=1
48/3:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
from matplotlib.colors import LinearSegmentedColormap

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os


""" parser stuff"""

parser = argparse.ArgumentParser(description="PV at model level I on large area:")
parser.add_argument('date',default='',type=str,help='date of data e.g. 20180201_05')
parser.add_argument('hours',default=1, type=int, help='number of hours to plot from date')


args = parser.parse_args()
date=str(args.date)
h = int(args.hours)


yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(abs(s.PV.values[0,:,k,n]-2)==np.min(abs(s.PV.values[0,:,k,n]-2)))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/4:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
from matplotlib.colors import LinearSegmentedColormap

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os



yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(abs(s.PV.values[0,:,k,n]-2)==np.min(abs(s.PV.values[0,:,k,n]-2)))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/5: np.max(P)
48/6: np.min(P)
48/7: np.where(P>600)
48/8: len(np.where(P>600)[0])
48/9: P.shape
48/10: 226*300
48/11: len(np.where(P>700)[0])
48/12: len(np.where(P>850)[0])
48/13:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
from matplotlib.colors import LinearSegmentedColormap

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os



yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.1))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/14: date='20171201_00'
48/15:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
from matplotlib.colors import LinearSegmentedColormap

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os



yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.1))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/16: date='20171201_00'
48/17:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.1))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/18: h
48/19: r
48/20: h1=1
48/21:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.1))
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/22:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.1))[0]
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/23:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & (abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.3))[0]
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/24:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.3))[-1]
            twoPVUindex[k-minlatc,n-minlonc]=I
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/25:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2))<0.3))
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/26:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2)))<0.3)
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/27:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2)))<0.3)
            print(I)
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/28:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2)))<0.3)
            print(I[-1])
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I,k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/29:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2)))<0.3)
            print(I[-1])
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/30:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where((abs(s.PV.values[0,:,k,n]-2)-np.min(abs(s.PV.values[0,:,k,n]-2)))<0.1)
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/31: fig.show()
48/32:
for z in range(0,1):
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,1000,50)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/33: fig.show()
48/34:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>0) & ((s.PV.values[0,:,k,n]-2)<0.2))
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/35:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.1) & ((s.PV.values[0,:,k,n]-2)<0.2))
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/36:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.1) & ((s.PV.values[0,:,k,n]-2)<0.2))
            print(I)
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/37:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.2) & ((s.PV.values[0,:,k,n]-2)<0.2))
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/38:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.2) & ((s.PV.values[0,:,k,n]-2)<0.3))
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/39:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.2) & ((s.PV.values[0,:,k,n]-2)<0.3))
            if(I==[]):
                I=[80]
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/40:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.2) & ((s.PV.values[0,:,k,n]-2)<0.3))
            if(len(I)==0):
                I=[80]
            twoPVUindex[k-minlatc,n-minlonc]=I[-1]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[-1],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/41: fig.show()
48/42:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
kk=hh
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
storebase='/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/'


lonu = np.arange(300,601,1)
latu = np.arange(0,226,1)
pltlat =np.linspace(0,90,226)[latu]
pltlon = np.linspace(-180,180,901)[lonu]

minlatc = np.min(latu)
maxlatc = np.max(latu)

minlonc = np.min(lonu)
maxlonc = np.max(lonu)

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

P = np.zeros((len(latu), len(lonu)))
slp = np.zeros((len(latu), len(lonu)))
twoPVUindex = np.zeros((len(latu), len(lonu)))

cmap,pv_levels,norm,ticklabels=PV_cmap2()

for r in range(0,h1,1):
    if(kk>=24):
        kk=kk-24
        DD=DD+1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    kk=kk+1

    monthn = int(Date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    Month = MONTHS[monthid[0]] + Date[2:4]

    figpath = storebase + str(Month) + '/' + '2PVU-surface/'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'


    s_file = ana_path+'/'+'S'+Date
    p_file = ana_path+'/'+'P'+Date

    s = xr.open_dataset(s_file)
    p = xr.open_dataset(p_file, drop_variables=['Q','T','OMEGA','RWC','LWC','IWC','SWC','CC'])
    for k in latu:
        for n in lonu:
            I, = np.where(((s.PV.values[0,:,k,n]-2)>-0.1) & ((s.PV.values[0,:,k,n]-2)<0.2))
            if(len(I)==0):
                I=[62]
            twoPVUindex[k-minlatc,n-minlonc]=I[0]
            P[k-minlatc,n-minlonc] = s.P.values[0,I[0],k,n]
            slp[k-minlatc,n-minlonc] = p.SLP.values[0,0,k,n]

    P[P<-999]=np.nan
    slp[slp<-999]=np.nan
    storepath = storebase + str(Month) + '/2PVU-surface/'

    np.savetxt(storepath+Date+'-2PVUindex.txt',twoPVUindex.astype(int),fmt='%i',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-P-at-2PVU.txt',P.astype(float),fmt='%f',delimiter=' ',newline='\n')
    np.savetxt(storepath+Date+'-slp-large.txt',slp.astype(float),fmt='%f',delimiter=' ',newline='\n')
#open a new figure (ccrs.PlateCarre() ist the simplest projection of cartopy. For other projections have a look at: http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html )
    fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
    ax=axes
    ax.coastlines()

    lonticks=np.arange(minpltlonc, maxpltlonc,15)
    latticks=np.arange(minpltlatc, maxpltlatc,15)

    ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
    ax.set_yticks(latticks, crs=ccrs.PlateCarree());
    ax.set_xticklabels(labels=lonticks,fontsize=10)
    ax.set_yticklabels(labels=latticks,fontsize=10)

    ax.xaxis.set_major_formatter(LongitudeFormatter())
    ax.yaxis.set_major_formatter(LatitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
    ax.set_title(Date + ' @ 2PVU')
    plevels=np.arange(200,600,25)
#    cmap,pv_levels,norm,ticklabels=PV_cmap2()
#    pv_levels = np.array(-1, -0.5, 0., 0.5, 1., 1.5, 2.0, 3.0, 4.0, 5.0. 6.0, 8.0, 10.0, 12.)
    h=ax.contourf(pltlon,pltlat,P,levels=plevels,cmap=matplotlib.cm.jet,extend='both')

    pslevels=np.arange(960,1041,5)

    h2=ax.contour(pltlon,pltlat,slp,levels=pslevels,colors='purple',animated=True,linewidths=1, alpha=1)

    plt.clabel(h2, inline=1, fontsize=8, fmt='%1.0f')
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(h, ticks=plevels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('pressure',fontsize=10)
    cbar.ax.set_xticklabels(np.arange(200,500,25))

    figname=figpath+'2PVU-pressure-at-'+Date+'.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")
48/43: fig.show()
48/44: I
48/45: P[-1,-1]
48/46:       np.mean(P)
48/47: np.mean(twoPVUindex)
48/48: P
48/49: np.sort(P)
48/50: np.ravel(P)
48/51: len(np.ravel(P))
48/52: np.sort(np.ravel(P))
49/1: np.sort(np.ravel(P))
50/1: datenum
50/2: from datetime import date
50/3: print(date.toordinale(date(1950,1,1,0,0,0)))
50/4: print(date.toordinal(date(1950,1,1,0,0,0)))
50/5: print(date.toordinal(date(1950,1,1)))
50/6: ft = date.toordinal(date(1950,1,1))
50/7: step = 595645
50/8: ft1 = date.fromordinal(ft+step/24.)
50/9: ft1 = date.fromordinal(ft)
50/10: ft1
50/11: ft
50/12:
def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)
50/13: ft+366
50/14: print(datenum_to_datetime(ft+366))
50/15: from datetime import datetime
50/16: print(datenum_to_datetime(ft+366))
50/17: from datetime import timedelta
50/18: import datetime
50/19: print(datenum_to_datetime(ft+366))
50/20: import datetime as datetime
50/21: print(datenum_to_datetime(ft+366))
50/22: from datetime import date
50/23: from datetime import date
50/24: import datetime as datetime
50/25:
def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)
50/26: print(datenum_to_datetime(ft+366))
50/27: from datetime import datetime
50/28: print(datenum_to_datetime(ft+366))
50/29: k = datenum_to_datetime(ft+366)
50/30: k
50/31: [0]
50/32: k.shape
50/33: k[1]
50/34: k[0,1]
50/35: k = print(datenum_to_datetime(ft+366))
50/36: k
50/37: k
50/38: k
50/39: k[0]
50/40: k = str(datenum_to_datetime(ft+366))
50/41: k
50/42: k[0]
50/43: k.shape
50/44: k[1]
50/45: k[0:4]
50/46: k[0:4]+k[5:7]
50/47: k[0:4]+k[5:7]+k[8:10]+'_'+k[12:14]
50/48: k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
50/49: k = str(datenum_to_datetime(ft+366+595645))
50/50: k
50/51: k = str(datenum_to_datetime(ft+366+595645/24))
50/52: k
51/1: from datetime import datetime, date
51/2:
def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


ft = date.toordinal(date(1950,1,1))


k = str(datenum_to_datetime(ft+366+595645/24))

Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
51/3: from datetime import timedelta
51/4:
def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


ft = date.toordinal(date(1950,1,1))


k = str(datenum_to_datetime(ft+366+595645/24))

Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
51/5: Date
52/1:
from datetime import datetime, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


ft = date.toordinal(date(1950,1,1))


k = str(datenum_to_datetime(ft+366+595645/24))

Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
52/2:
ft = datetime.toordinal(date(1950,1,1))


k = str(datenum_to_datetime(ft+366+595645/24))

Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
52/3:
from datetime import datetime, date, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


ft = date.toordinal(date(1950,1,1))


k = str(datenum_to_datetime(ft+366+595645/24))

Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
52/4: Date
52/5: np
52/6: d = np.loadtxt('/atmosdyn2/ascherrmann/002-2020-08-05-Identify-DJF1718-medcyclones/FEB18/TRACKED_CYCLONES')
52/7: d[0,0]
52/8: d[0,1]
52/9: d[0,2]
52/10: d[0,3]
52/11: d[0,4]
52/12: d[0,5]
52/13: d.shape
52/14: LON =np.linspace(-180,180,901)
52/15: LON
52/16: LAT = np.linspace(0,90,226)
52/17: np.where(LON==-54.2)
52/18: np.where(LON==-55.2)
52/19: LON[0]
52/20: np.where(LON==(-180))
52/21: np.where(LON==(-55.2))
52/22: np.where(LON==(-55.4))
52/23: np.where(LON==(-55.2))
52/24: np.where(LON==(-180))
52/25: np.where(np.round(LON,1)==(-55.2))
52/26: np.where(np.round(LON,1)==(-55.2))[0]
52/27: np.where(np.round(LON,1)==(-55.2))[0,0]
52/28: np.where(np.round(LON,1)==(-55.2))[0][0]
53/1: import numpy as np
53/2: clat = 80
53/3: clon = 421
53/4:
LON =np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
53/5: tmp = [0, 0, -55.2, 54.4]
53/6:
LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)
53/7: ,np.where(LAT==tmp[3])[0]
53/8: np.where(LAT==tmp[3])[0]
53/9: np.where(LAT==tmp[3])[0,0]
53/10: np.where(LAT==tmp[3])[0][0]
53/11: np.linspace(0,2 * np.pi * 6370,901)-np.linspace(0,2 * np.pi * 6370,901)[clon]
53/12: disx = np.linspace(0,2 * np.pi * 6370,901)-np.linspace(0,2 * np.pi * 6370,901)[clon]
53/13: disy = np.linspace(0,0.5 * np.pi * 6370,226)-np.linspace(0,0.5 * np.pi * 6370,226)[clat]
53/14: lonu,latu = np.where(np.sqrt(disx**2 + disy**2)<200)
53/15: lonu, = np.where(abs(disx)<200)
53/16: lonu
53/17: latu, = np.where(abs(disy)<200)
53/18: latu
53/19: len(latu)
53/20: len(lonu)
53/21: disx[lonu]
53/22: clat
53/23: clon
53/24: np.meshgrid(disx[lonu],disy[latu])
53/25: mg  = np.meshgrid(disx[lonu],disy[latu])
53/26: lon, lat  = np.meshgrid(disx[lonu],disy[latu])
53/27: dix, diy  = np.meshgrid(disx[lonu],disy[latu])
53/28: np.where(np.sqrt(dix**2 + diy**2)<200)
53/29: latid, lonid = np.where(np.sqrt(dix**2 + diy**2)<200)
53/30: diy, dix  = np.meshgrid(disx[lonu],disy[latu])
53/31: latid, lonid = np.where(np.sqrt(dix**2 + diy**2)<200)
53/32: latid
53/33: lonid
53/34: np.where(np.sqrt(dix**2 + diy**2) ==0 )
53/35: latid-4
53/36: lonid04
53/37: lonid-4
53/38: r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
53/39: ,np.where(LAT==tmp[3])[0][0]
53/40: np.where(LAT==tmp[3])[0][0]
53/41: r200_lonids + np.where(LAT==tmp[3])[0][0]
53/42: clatt = np.array([])
53/43: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0])
53/44: clatt
53/45: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0])
53/46: clatt
53/47: clatt = {}
53/48: clatt[0] = r200_lonids + np.where(LAT==tmp[3])[0][0]
53/49: clatt[1] = r200_lonids + np.where(LAT==tmp[3])[0][0]
53/50: clatt
53/51: clatt[0]
53/52: clatt[1]
53/53: clatt
53/54: clat
53/55: clatt = np.array([])
53/56: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=0)
53/57: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=0)
53/58: clatt
53/59: clatt = np.array([])
53/60: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=1)
53/61: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0])
53/62: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=1)
53/63: clatt = np.array([])
53/64: clatt = np.vstack((clatt, r200_lonids + np.where(LAT==tmp[3])[0][0]))
53/65: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=1)
53/66: clatt = np.append(clatt, r200_lonids + np.where(LAT==tmp[3])[0][0],axis=0)
53/67: clatt
53/68: clatt = np.vstack((clatt, r200_lonids + np.where(LAT==tmp[3])[0][0]))
53/69: clatt
53/70:
from datetime import datetime, date, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']



LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)


ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
53/71:
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + 'TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[cappaer]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_lonids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))



clat = np.delete(clat,0,0)
clon = np.delete(clon,0,0)
53/72:
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[cappaer]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_lonids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))



clat = np.delete(clat,0,0)
clon = np.delete(clon,0,0)
53/73:
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_lonids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))



clat = np.delete(clat,0,0)
clon = np.delete(clon,0,0)
53/74: dates
53/75: len(dates)
53/76: clat
53/77: clat = np.delete(clat,0,0)
53/78: clat
53/79:
dates = np.array([])
clat = np.array([])
clon = np.array([])

for Month in ['DEC17']:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))
53/80:
dates = np.array([])
clat = np.array([])
clon = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

for Month in ['DEC17']:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))
53/81: clat
53/82: clon
53/83:
dates = np.array([])
clat = np.array([])
clon = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

for Month in ['JAN18']:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))
53/84:
dates = np.array([])
clat = np.array([])
clon = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

for Month in ['JAN18']:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                print(tmp[3],tmp[2])
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==tmp[3])[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==tmp[2])[0][0]))
53/85:
dates = np.array([])
clat = np.array([])
clon = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

for Month in ['JAN18']:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                print(tmp[3],tmp[2])
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]))
53/86:
dates = np.array([])
clat = np.array([])
clon = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]))
53/87: dates
53/88: dates[dates==dates[0]]
53/89: dates
53/90: np.sort(dates)
53/91: np.argsort(dates)
53/92: len(dates)
53/93: len(np.unique(dates))
53/94: dates[np.argsort(dates)]
53/95:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
53/96:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
53/97: label
53/98:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
     print(label)
53/100:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
    print(label)
53/101:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        print(label)
53/102:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/103: d
53/104:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 18):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/105:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/106:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    print(IDs)
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/107:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        print(cappear)
        if (len(cappear) >= 24):
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/108:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            print(cappear)
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/109:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
kkkk = 0
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            kkkk = kkkk+1
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/110: kkkk
53/111: d[0,2]
53/112: d[0,3]
53/113:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
label = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
kkkk = 0
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            kkkk = kkkk+1
            slpminid, = np.where(d[cappear,6] == np.min(d[cappear,6]))
            print(slpminid)
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:
            print(label)
53/114:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
53/115:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
         if label == 2:
53/117:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
         if label==2:
53/119:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:       
            print(label)
53/120:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 18):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:       
            print(label)
53/121:
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
        if label==2:       
            print(label)
54/1:
from datetime import datetime, date, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']



LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)

LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])

pjump = 5.

r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
54/2:
IDS = np.array([])
labels = np.array([])
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs:
        cappear, = np.where(d[:,1]==ids)
        if (len(cappear) >= 24):
          slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
          if (np.max(d[cappear,6])- np.min(d[cappear,6]) >= pjump):
            if (d[cappear[0],-3]==0):
                label = 0 #tropical cyclone
            elif ( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                label = 2 # mediterranean
            else:
                label = 1 # extratropical non mediterranean
            for i in cappear:
                tmp = d[i]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]))
                labels = np.append(labels, label)
54/3:
clat = np.delete(clat,0,0)
clon = np.delete(clon,0,0)

datesort = np.argsort(dates)
dates = dates[datesort]
clat = clat[datesort]
clon = clon[datesort]
labels = labels[datesort]
54/4: np.where(labels==2)
54/5: len(labels)
54/6: dates
54/7: clat
54/8: len(clat)
54/9: np.where(dates=='20180308_00')
54/10: np.count_nonzero(dates=='20180308_00')
54/11: np.unique(dates)
54/12: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/centerlatitude.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')
54/13: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/centerlongitude.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')
54/14: test = np.zeros((len(dates),2))
54/15: test[:,0] = dates[:]
54/16: test[:,1] = labels[:]
54/17: test
54/18: test[0,0]
54/19: test = np.array([])
54/20: test[0]
54/21: test[:,0] = dates[:]
54/22: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')
54/23: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')
54/24: less /atmosdyn2/ascherrmann/scripts/vertical-PV-colorlines.py
54/25: less /atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin.txt
54/26: test = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin.txt')
54/27: np.unique(test)
54/28: less /atmosdyn2/ascherrmann/004-composite-analysis/centerlongitude.txt
54/29: less /atmosdyn2/ascherrmann/004-composite-analysis/dates.txt
54/30: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
54/31: dates = np.loadtxt(pt + 'dates.txt',dtype=str)
54/32: dates
54/33: ud = np.unique(dates)
54/34: ud
54/35: di = dict()
54/36: di[-130] = np.array([])
54/37: di
54/38: di[-130]
54/39: di[-120][100]
54/40: di[-120][100] = np.array([])
54/41: di[-120] = np.zeros((36,len(clat[0]),len(clon[0])))
54/42: di[-120]
54/43: di[-120][0]
54/44:
Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
54/45: di[100] = np.zeros((lp,llat,llon))
54/46: di[100].shape
54/47: di[100] = np.zeros((1,lp,llat,llon))
54/48: di[100].shape
54/49: di[100]
54/50: di[100] = {0,np.zeros((1,lp,llat,llon))}
54/51: di[100] = {0,np.zeros((lp,llat,llon))}
54/52: di[50] = {0,np.zeros((lp,llat,llon))}
54/53: di[50] = np.array([0,np.zeros((lp,llat,llon))])
54/54: di[50]
54/55: di[50][1]
54/56: less /atmosdyn2/ascherrmann/Scdf.txt
54/57: less /atmosdyn2/ascherrmann/scripts/multi-var-vertical-pressure-txt.py
54/58: less /atmosdyn2/ascherrmann/Scdf.txt
54/59: clon[0]
55/1: import mpi4py
55/2: from mpi4py import MPI
55/3: import numpy as np
55/4: t = np.zeros((100,100))
55/5: p = dict()
55/6: p[100] =  np.zeros((100,100))
55/7: at = {t, p}
55/8: at = np.array([t, p])
55/9: len(at)
55/10: at[0]
55/11: at[0][0]
55/12: at[0,0]
55/13: at[0][0]
55/14: at[0][0,0]
55/15:
import argparse
import numpy as np
import xarray as xr


import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<dis)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
55/16:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


ud = np.unique(dates)
uh = np.unique(htM)[0]

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
55/17:
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,plevels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
55/18: uh = np.unique(htM)[0:2]
55/19: uh
55/20:
Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    comapll[uh[k]] = np.zeros((lp,llat))
55/21:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
55/22: compall
55/23:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + Date[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
55/24:
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
55/25:
ud = np.unique(dates)[0:2]
uh = np.unique(htM)[0:2]

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,plevels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
55/26:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
55/27: dur
55/28: t
55/29:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        lonmin = clon[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                    for n in clon[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/30: diM
55/31:
ud = np.unique(dates)[0:2]
uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,plevels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
55/32:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        lonmin = clon[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                    for n in clon[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/33:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                    for n in clon[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,k,n]-pressure)==np.min(abs(s.P.values[0,:,k,n]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/34:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                    for n in clon[a]:
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/35:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in clat[a]:
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/36:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k-latmin] = diM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k-latmin] = diNM[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k-latmin] = diT[h2M][m,k-latmin] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/37: h2m
55/38: h2M
55/39: dim[h2M]
55/40: diM[h2M]
55/41: diM[h2M].shape
55/42:
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I,clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I,clat[a,k],clon[a,k]]

        a = a + 1
55/43:
pressure = Plvl
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.arrray([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.colorbar(lc)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")

 a = a + 1
55/44:
pressure = Plvl
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.colorbar(lc)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")

 a = a + 1
55/45:
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")

 a = a + 1
55/46: cmap,pv_levels,norm,ticklabels = PV_cmap2()
55/47:
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")

 a = a + 1
55/48: plt.close()
55/49:
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close()
 a = a + 1
55/50: fig.close()
55/51: plt.close('all')
55/52: plt.close(fig)
55/53: plt.close(fig)
55/54: plt.close(fig)
55/55: plt.close(fig)
55/56: plt.close(fig)
55/57: plt.close(fig)
55/58: plt.close(fig)
55/59: plt.close(fig)
55/60: plt.close(fig)
55/61: plt.close(fig)
55/62: plt.close(fig)
55/63: plt.close(fig)
55/64:
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close()
 a = a + 1
55/65:
a = 0

for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close('all')
 a = a + 1
55/66:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
55/67:
timeit.timeit(for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat)),number=1)
55/68:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
55/69: datetime.datetime.now()
55/70: import datetime
55/71: datetime.datetime.now()
55/72: k = datetime.datetime.now()
55/73: z = datetime.datetime.now()
55/74: z-k
55/75: print(z-k)
55/76:
import argparse
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)
55/77:
ud = np.unique(dates)
uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
a = 0
55/78: diT
55/79: diT[-190]
55/80: diT[190]
55/81: diT[190].shape
55/82: diT[190][0,65]
55/83: I
55/84: I[0]
55/85: clon[clon==901]
55/86: len(clon[clon==901])
55/87: s.PV.values.shape
55/88:
if(clon[:,-1]>900):
    print('yes')
55/89: len(clon[clon>901])
55/90: len(clon[clon>902])
55/91: len(clon[clon>903])
55/92:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)
55/93: len(clon[clon>902])
55/94: len(clon[clon==900])
55/95: len(clon[clon==901])
55/96: len(clat[clat==226])
55/97: len(clat[clat==225])
55/98: len(clat[:,0])
55/99: diM
55/100: diM[150]
55/101: diM[150]/20
55/102:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


ud = np.unique(dates)
uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
55/103:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


ud = np.unique(dates)[0:50]
uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
55/104:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
a = 0
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        a = a + 1
taftercalc = datetime.datetime.now()
55/105: print(taftercalc-tprecalc)
55/106: diT[0]
55/107: diM[0]
55/108: Mcounter[0]
55/109: np.where(uh==0)
55/110: Mcounter[132]
55/111: Tcounter[132]
55/112: NMcounter[132]
55/113: a
55/114: htM[a]
55/115: hourid, = np.where(uh==h2M)
55/116: hourid
55/117: NMcounter[123]
55/118:
pressure = Plvl
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0
preplottime = datetime.datetime.now()
for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)
    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close('all')
 a = a + 1
afterplottime  = datetime.datetime.now()
55/119:
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0
preplottime = datetime.datetime.now()
for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + 'v-PVlines-'+ lab[r] + '-' + str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close('all')
 a = a + 1
afterplottime  = datetime.datetime.now()
55/120: len(ud)
55/121: dates
55/122: len(dates)
55/123: ud = np.unique(dates)
55/124: len(ud)
55/125: print(afterplottime-preplottime)
55/126: uh
55/127: htM
55/128: np.where(htM==-24)
55/129: DATES = dates[np.where(htM==-24)]
55/130: DATES
55/131: DATES = np.append(DATES,dates[np.where(htM==-23)])
55/132: DATES
55/133: DATES = np.unique(DATES)
55/134: ls
55/135: len(DATES)
55/136: DATES = dates[np.where(htM==0)]
55/137: len(DATES)
55/138: len(np.unique(DATES))
55/139: dates
55/140: oi, = np.where(h2M==-12)
55/141: dates[oi]
55/142: oi
55/143: h2M
55/144: htM
55/145: oi, = np.where(htM==-12)
55/146: dates[oi]
55/147: oi = np.array([])
55/148: oi = np.append(oi,np.where(htM==-12)[0])
55/149: oi
55/150: oi = oi.astype(int)
55/151: oi
55/152: DATES = np.array([])
55/153: DATES = np.append(DATES,dates[oi])
55/154: DATES
55/155: oi = np.append(oi,np.where(htM==-11)[0])
55/156: oi = np.append(oi,np.where(htM==-10)[0])
55/157: oi = np.append(oi,np.where(htM==-9)[0])
55/158: oi = np.append(oi,np.where(htM==-8)[0])
55/159: oi = np.append(oi,np.where(htM==-7)[0])
55/160:
for k in range(-6,13):
    oi = np.append(oi,np.where(htM==-7)[0])
oi = oi.astype(int)
55/161: oi
55/162: len(oit)
55/163: len(oi)
55/164: Dates = dates[oi]
55/165: Dates
55/166: sorting = np.argsort(Dates)
55/167: oi = oi[sorting]
55/168: Dates = Dates[sorting]
55/169: Dates
55/170: len(np.unique(Dates))
55/171: oi
55/172: Hours = htM[oi]
55/173: Hours
55/174: Dates
55/175: uDates = np.unique(Dates)
55/176: np.where(htM==0)
55/177: len(htM)
55/178: clat[20066]
55/179: clon[20066]
55/180:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))

DATES = dates[oi]
Hours = htM[oi]
55/181:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
55/182: oi
55/183:
sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
55/184: oi
55/185: Hours
55/186: uDates = np.unique(DATES)
55/187: uDAtes
55/188: uDates
55/189:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]

ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
a = 0
55/190:
for t in ud[0:50]:
    print(t)
55/191: uh
55/192: Mcounter
55/193:
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        a = a + 1
55/194:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]

ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
55/195:
pressure = Plvl
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0
preplottime = datetime.datetime.now()
for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + lab[r] + '/v-PVlines-'+ str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close('all')
 a = a + 1
55/196:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]

ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
55/197:
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        a = a + 1
55/198:
clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]

ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
a = 0
55/199:
for t in ud[0:5]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        a = a + 1
55/200:
pressure = Plvl
totcounter = Mcounter + NMcounter + Tcounter
a = 0
for q in diM.keys():
    if(totcounter[a]>0):
        compall[q] = (diM[q] + diT[q] +diNM[q])/totcounter[a]

    if(Mcounter[a]>0):
        diM[q] = diM[q]/Mcounter[a]

    if(NMcounter[a]>0):
        diNM[q] = diNM[q]/NMcounter[a]

    if(Tcounter[a]>0):
        diT[q] = diT[q]/Tcounter[a]
    a = a+1

ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
a = 0
preplottime = datetime.datetime.now()
for hours in uh:
 for r in range(0,len(ar)):
  if(ac[r][a]>0):
    figname = pt + lab[r] + '/v-PVlines-'+ str(hours) + '-to-SLPmin.png'
    fig, ax = plt.subplots()
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVU',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    plt.savefig(figname,dpi=300,bbox_inches="tight")
    plt.close('all')
 a = a + 1
56/1:
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)
56/2:
import argparse
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


clat = np.loadtxt(pt + 'centerlatitude.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt',dtype=str)
56/3:
labels = np.loadtxt(pt + 'labels.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]

ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0
56/4:
linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
a = 0
56/5: clat
56/6: len(clat[:,0])
56/7: uh
56/8: ud
56/9: len(ud)
56/10: clon
56/11: np.where(clon>899)
56/12: np.where(clon>900)
56/13: labels
56/14: labels[0:100]
56/15: rt
56/16: rt.shape
56/17: ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[0,0])[0])))
56/18: ll
56/19: rt[:,0]
56/20: Mcounter
56/21: NMcounter
57/1: d  = dict()
57/2: d[1] = dict()
57/3: d
57/4: d[1][1] = np.array([])
57/5: import numpy as np
57/6: d[1][1] = np.array([])
57/7: d
57/8: a = [-5, 4, -3, -2, 10, 7]
57/9: np.where(a[::-1]==-5)
57/10: a[::-1]
57/11: np.where(a[::-1]==(-5))
57/12: np.where(a[:]==(-5))
57/13: a[a==-5]
57/14: a[a[:]==-5]
57/15: a = np.array([-5, 4, -3, -2, 10, 7])
57/16: np.where(a[:]==(-5))
57/17: np.where(a[::-1]==(-5))
59/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse
59/2: norm = plt.Normalize(-200,100)
59/3: norm = plt.Normalize(-200,100,30)
59/4: norm
59/5: ls /atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180217_04/
59/6: ls /atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/FEB18/73/20180217_22
60/1:
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments
60/2:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)

add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates.txt' + add + '',dtype=str)
labels = np.loadtxt(pt + 'labels.txt' + add + '',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
60/3:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)

add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels.txt' + add + '',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
60/4:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)

add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
60/5: len(ud)
60/6: np.where(labels==2)
60/7:
for t in ud[200:201]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
60/8: s.VORT.values
60/9: f = 2 * np.pi *np.sin(LAT[clat[200]])
60/10: f = 2 * np.pi *np.sin(LAT[clat[20]])
60/11: f
60/12: clat
60/13: clat.shape
60/14: LAT
60/15: f = 2 * np.pi *np.sin(np.linspace(0,0.5*np.pi*6370,226)[clat[200]])
60/16: f
60/17: f = 2 * np.pi *np.sin(np.linspace(0,0.5*np.pi*6370,226)[clat[200]] * pi/180)
60/18: f = 2 * np.pi *np.sin(np.linspace(0,0.5*np.pi*6370,226)[clat[200]] * np.pi/180)
60/19: f
60/20: f = 2 * np.pi *np.sin(np.linspace(0,0.5*np.pi*6370,226)[clat[200]] * np.pi/180)/86400
60/21: f
60/22: llat = len(clat[0])
60/23: a = 200
60/24: vort = np.zeros(llat)
60/25: zeta = np.zeros(llat)
60/26:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]-f[k]
60/27:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]-f[k]
60/28:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]-f[k]
60/29: zeta
60/30:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]*1e-4-f[k]
60/31: zeta
60/32: np.mean(zeta)
60/33: np.where(ud=='20171213_13')
60/34:
for t in ud[268:269]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
60/35: a= 268
60/36:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]*1e-4-f[k]
60/37: zeta
60/38: np.mean(zeta)
60/39: clat[a]
60/40: lat = np.linspace(0,0.5*6370*np.pi,226)
60/41: lat[clat[a]]
60/42: lat = np.linspace(0,90.pi,226)
60/43: lat = np.linspace(0,90,226)
60/44: lat[clat[a]]
60/45: np.where(ud=='20171213_13' & labels==2)
60/46: np.where((ud=='20171213_13') & (labels==2))
60/47: np.where((DATES=='20171213_13') & (labels==2))
60/48: a = 787
60/49:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]*1e-4-f[k]
60/50: zeeta
60/51: zeta
60/52: np.mean(zeta)
61/1:
import argparse
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)

add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
61/2:
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
61/3: np.where(ud=='20181213_13')
61/4: ud
61/5: np.where(ud=='20171213_13')
61/6:
for t in ud[268]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/7:
for t in ud[268:269]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/8: t
61/9: a = 787
61/10:
zeta = np.zeros(llat)
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I[0],clat[a,k],clon[a,k]]*1e-4
61/11: zeta
61/12: clat[a]
61/13: np.linspace(0,90,226)[clat[a]]
61/14: np.mean(zeta)
61/15: cy = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171213_13')
61/16: cy = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/DEC17/cyclones/CY20171213_13.nc')
61/17: np.linspace(0,90,226)[clat[a]]
61/18: clat
61/19: clat[a]
61/20: np.where((DATES=='20171213_13') & (labels==2))
61/21: a
61/22: LON = np.round(np.linspace(-180,180,901),1)
61/23: LON
61/24:
LAT = np.round(np.linspace(0,90,226),1)

LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])

pjump = 5.

r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
labels = np.array([])
hourstoSLPmin = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
61/25:
from datetime import datetime, date, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)


dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']



LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)

LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])

pjump = 5.

r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
IDS = np.array([])
labels = np.array([])
hourstoSLPmin = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
61/26: d = np.loadtxt(dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES')
61/27: ID = 73
61/28: cappear, = np.where(d[:,1]==ID)
61/29: cappear
61/30: slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
61/31:
if ( ((d[slpminid,0]-d[cappear[0],0])>8) & ((d[cappear[-1],0]-d[slpminid,0])>8)):
    hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
    for i in cappear:
                    tmp = d[i]
                    k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                    Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                    dates = np.append(dates,Date)
                    addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                    addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                    clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                    clon = np.vstack((clon, addlon))
                    labels = np.append(labels, label)
61/32: label=2
61/33:
if ( ((d[slpminid,0]-d[cappear[0],0])>8) & ((d[cappear[-1],0]-d[slpminid,0])>8)):
    hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
    for i in cappear:
                    tmp = d[i]
                    k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                    Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                    dates = np.append(dates,Date)
                    addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                    addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                    clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                    clon = np.vstack((clon, addlon))
                    labels = np.append(labels, label)
61/34: clat
61/35: np.where(dates=='20171213_13')
61/36: len(dates)
61/37: len(clon)
61/38: clat = np.delete(clat,0,0)
61/39: cla
61/40: clat
61/41: clat[32]
61/42: clatt = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
61/43: a
61/44: clatt[a]
61/45: LAT
61/46: LAT[clatt[a]]
61/47: add
61/48: add=''
61/49: clatt = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
61/50: clatt[a]
61/51: LAT[clatt[a]]
61/52: DATES=np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
61/53: labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
61/54: np.where( (np.where(DATES=='20171213_13')) & (labels==73) )
61/55: DATES
61/56: len(dates)
61/57: len(DATES)
61/58: len(labels)
61/59: np.where( (np.where(DATES=='20171213_13')) & (labels==2) )
61/60: np.where( ((DATES=='20171213_13')) & (labels==2) )
61/61: tr = 2657
61/62: clatt[tr]
61/63: LAT[clatt[tr]]
61/64: s
61/65: clonn = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
61/66: clat
61/67: clat[32]
62/1:
import argparse
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)

add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
62/2: np.where( (dates=='20171213_13') & (labels==2) )
62/3: LAT = np.linspace(0,90,226)
62/4: LON= np.linspace(-180,180,901)
62/5: a = 2190
62/6: LAT[clat[a]]
62/7: LON[clon[a]]
62/8:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
62/9: DATES
62/10: np.where( (DATES=='20171213_13') & (labels==2)  )
62/11: LAT[clat[787]]
62/12: LON[clon[787]]
62/13: date = np.array(['20180307_16','20171201_07','20171201_05','20171201_06','20180307_14','20180118_19'])
62/14: lats = np.array([1,2,3,4,5,6])
62/15: hours = np.array([8,-6,8,3,-2,1])
62/16:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
62/17: oi
62/18:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(hours==zz))
62/19: oi
62/20: oi = oi.astype(int)
62/21: oi = np.array([])
62/22: oi = np.append(oi,np.where(htM==0))
62/23: oi
62/24: add
62/25: add=''
62/26: oi = oi.astype(int)
62/27:
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
62/28: dates
62/29:
clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
62/30: add
62/31: oi = np.array([])
62/32: oi = np.append(oi,np.where(htM==0))
62/33: oi = oi.astype(int)
62/34: oi
62/35:
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
62/36:
sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
62/37: labels = labels[sorting]np.where( (DATES=='20171213_13') & (labels==2) )
62/38: labels = labels[sorting] np.where( (DATES=='20171213_13') & (labels==2) )
62/39: labels = labels[sorting]
62/40: np.where( (DATES=='20171213_13') & (labels==2) )
62/41: LAT[clat[43]]
61/68: add
61/69:
clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)
61/70:
add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)


oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)
61/71:
diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
61/72:
diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
61/73:
for t = ud[np.where(ud=='20171213_13')]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/74:
for t=ud[np.where(ud=='20171213_13')]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/75:
for t in [ud[np.where(ud=='20171213_13')]]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/76:
for t in ud[np.where(ud=='20171213_13')]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
61/77: t
61/78: yyyy
61/79: s
61/80: dur, = np.where(DATES==t)
61/81: dur
61/82: labels[dur]
61/83: zeta = np.zeros(llat)
61/84:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I,clat[a,k],clon[a,k]]
61/85: zeta
61/86:
for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/87: zeta
61/88: np.mean(zeta)
61/89: zeta = np.zeros((19,ll))
61/90: zeta = np.zeros((19,llat))
61/91:
e0 = -9
d0 = '20171213_04'
for m in range(0,19):
    e = e0 + m
    dk = d0[0::9] + str(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/92:
e0 = -9
d0 = '20171213_04'
for m in range(0,19):
    e = e0 + m
    dk = d0[0::9] + str(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    print(t, dk)
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/93:
e0 = -9
d0 = '20171213_04'
print(d0,d0[0::9],d0[9:])
for m in range(0,19):
    dk = d0[0::9] + str(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/94: d0
61/95: d0[1]
61/96: d0[0:2]
61/97: d0[0:3]
61/98: d0[0:4]
61/99: d0[0:5]
61/100: d0[0:6]
61/101: d0[0:7]
61/102: d0[0:8]
61/103: d0[0:9]
61/104:
e0 = -9
d0 = '20171213_04'
print(d0,d0[0:9],d0[9:])
for m in range(0,19):
    dk = d0[0:9] + str(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/105:
e0 = -9
d0 = '20171213_04'
print(d0,d0[0:9],d0[9:])
for m in range(0,19):
    dk = d0[0:9] + '%02d'%(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/106:
e0 = -9
d0 = '20171213_04'
print(d0,d0[0:9],d0[9:])
for m in range(0,19):
    dk = d0[0:9] + '%02d'%(int(d0[9:])+m)
    a, = np.where( (DATES==dk) & (labels==2))
    t = dk
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    for k in range(0,llat):
                        I = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-850)))[0]
                        I = I[0]
                        zeta[m,k] = s.VORT.values[0,I,clat[a,k],clon[a,k]] * 1e-4
61/107: zeta
61/108:
for k in range(len(zeta[:,0])):
    print(np.mean(zeta[k]))
61/109:
for k in range(len(zeta[:,0])):
    print(-9 + k, np.mean(zeta[k]))
61/110:
olvl = np.arange(-200,101,10)
oticks = np.arange(-200,101,20)
61/111: ovals = np.array([-210, olvl, 110])
61/112: ovals
61/113: ovals = np.array([-210, olvl[:], 110])
61/114: ovals
61/115: ovals = np.array([-210, olvl[0:-1], 110])
61/116: ovals
61/117: ovals = np.append(olvl,101)
61/118: ovals
61/119:
ovals = np.append(olvl,101)
ovals = np.append(olvl,-201,0)
61/120:
olvl = np.arange(-200,101,10)
oticks = np.arange(-200,101,20)

ovals = np.zeros(len(olvl))
print(len(ovals),len(olvl))
61/121: ovals[0:-1] = olvl
61/122: ovals[0:-0] = olvl
61/123: ovals[0:] = olvl
61/124: ovals= np.zeros(len(olvl))
61/125: ovals= np.zeros(len(olvl)+2)
61/126: ovals
61/127: ovals[1:-1] = olvl
63/1:
import argparse
import numpy as np
import xarray as xr
import datetime

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments

parser = argparse.ArgumentParser(description="plot vertical PV around given distance, dis, coded by color")


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
63/2:
sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
63/3:
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
63/4: a
63/5: cycl
63/6: cycl.FLAG.values[clat[a]]
63/7: cycl.FLAG.values[0,clat[a]]
63/8: cycl.FLAG.values[0,clat[a]].shape
63/9: cycl.FLAG.values[0,clat[a],clon[a]]
63/10: clat[a]
63/11: clon[a]
63/12: cycl.FLAG.values
63/13: cycl.FLAG.values[clat[a,34],clon[a,34]]
63/14: cycl.FLAG.values[0,clat[a,34],clon[a,34]]
63/15:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
63/16:
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
add = 'pm9h-nopjump'
63/17:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
63/18:
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
63/19:
sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)
63/20:
diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
add = 'pm9h-nopjump'
63/21:
for t in ud[200:201]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+str(Month))==0):
            os.mkdir(storepath + str(Month))
            os.mkdir(storepath + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(storepath + str(Month) + '/' + str(cyid))==0):
            os.mkdir(storepath + str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
63/22: a = 0
63/23:
for t in ud[200:201]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+str(Month))==0):
            os.mkdir(pt + str(Month))
            os.mkdir(pt + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt + str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
63/24: cyid
63/25: a = 0
63/26:
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+str(Month))==0):
            os.mkdir(pt + str(Month))
            os.mkdir(pt + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt + str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
63/27: a = 0
63/28:
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + add + '/' + '/' +str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
63/29: z
63/30: rt[q,0]
63/31: directPVplotting
63/32:
fig, ax = plt.subplots()
    lines = 0
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
63/33:
fig, ax = plt.subplots()
lines = 0
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
63/34:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
63/35: plt.close('all')
63/36:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
63/37: fig.show()
63/38: plt.show()
63/39: plt.close()
63/40:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
63/41: plt.show()
63/42: plt.close()
63/43:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
63/45:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
63/46: plt.show()
63/47: plt.show()
63/48: plt.close('all')
63/49:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
63/50: plt.savefig(figname,dpi=300,bbox_inches="tight")
63/51: plt.savefig(fname,dpi=300,bbox_inches="tight")
63/52:
fig, ax = plt.subplots()
ax=plt.gca()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
63/53: plt.show()
63/54: plt.close('all')
63/55:
fig, ax = plt.subplots(1,1)
ax=plt.gca()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
63/56: plt.show()
63/57:
fig, ax = plt.subplots(1,1)
lines = 0
plt.xlim(-200,200)
plt.ylim(-200,200)
axplt.gca()
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
63/58:
fig, ax = plt.subplots(1,1)
lines = 0
plt.xlim(-200,200)
plt.ylim(-200,200)
ax=plt.gca()
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
63/59: plt.show()
64/1: plt.show()
64/2:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll

def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.argsort(rt,axis=0)[:,0]
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
64/3:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
add = 'pm9h-nopjump'
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + add + '/' + '/' +str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
        a =a +1
64/4:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
a = 0
add = 'pm9h-nopjump'
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
        a =a +1
64/5: cyid
64/6:
fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
    os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
    os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
elif(os.path.isdir(pt +  lab2[labels[a]] + add + '/' + str(Month) + '/' + str(cyid))==0):
    os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
64/7: os.path.isdir(pt +  lab2[labels[a]] + add + '/' + str(Month) + '/' + str(cyid))
64/8: os.path.isdir(pt +  lab2[labels[a]] +'/' add + '/' + str(Month) + '/' + str(cyid))
64/9: os.path.isdir(pt +  lab2[labels[a]] +'/' +add + '/' + str(Month) + '/' + str(cyid))
64/10:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
cyclID = 0
a = 0
add = 'pm9h-nopjump'
for t in ud[0:1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['PS','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
#    dur,= np.where(dates==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        h2M = Hours[a]
#        h2M = htM[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        I, = np.where(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)==np.min(abs(s.P.values[0,:,clat[a,k],clon[a,k]]-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            htmp = htmp * (-1)
        fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp) + 'htoSLPmin.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
64/11:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')

cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
 cbar.ax.set_xticklabels(ticklabels)
64/12:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/13: plt.show()
64/14: plt.close('all')
64/15:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
ax.set_title(r'%d h to SLP min'%h2M)
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)
cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/16: z
64/17: plt.show()
64/18: srtid
64/19: directPVplotting[:,srtid]
64/20: directPVplotting[:,srtid].shpae
64/21: directPVplotting[:,srtid].shape
64/22: directPVplotting[:,srtid[q]].shape
64/23: directPVplotting[:,srtid[q]]
64/24: plt.show()
64/25: plt.close('all')
64/26:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
64/27:
ar = np.array([compall, diM, diNM, diT])
ac = np.array([totcounter, Mcounter,NMcounter,Tcounter])
a = 0
64/28:
fig, ax = plt.subplots()
lines = 0
for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
64/29:
for r in range(0,len(ar)):
  if(ac[r][a]>0):
    fig, ax = plt.subplots()
    lines = 0
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
#    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')
64/30: hours=-12
64/31:
for r in range(0,len(ar)):
  if(ac[r][a]>0):
    fig, ax = plt.subplots()
    lines = 0
    for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = make_segments(rt[q]+4*lines-4*ll,pressure)
             z=np.array(ar[r][hours][:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
#    ax.set_title(r'composite of %d cyclones'%ac[r][a])
    ax.invert_yaxis()
    ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
    plt.xlim(-200,200)
    plt.ylim(1000,100)
    plt.xlabel('West-East distance from center [km]')
    plt.ylabel('pressure [hPa]')
64/32: plt.show()
64/33: plt.close()
64/34:
k=0
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
64/35: plt.show()
64/36: fig.show()
64/37: plt.close('all')
64/38:
k=0
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(directPVplotting[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)
plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
64/39: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/40: srtid
64/41: rwe
64/42: tr
64/43: rt
64/44: rwe
64/45:
rt = np.zeros((len(clat),len(pressure)))

for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
64/46: rt
64/47:
rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
64/48: rt
64/49: srtid=np.argsort(rwe,axis=0)[:,0]
64/50: srtid=np.argsort(r,axis=0)[:,0]
64/51: srtid=np.argsort(rt,axis=0)[:,0]
64/52: srtid
64/53: rwe
64/54: plt.close('all')
64/55:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0
PV = directPVplotting
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/56:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0
PV = directPVplotting
plevel=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/57:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0
PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/58: plt.show()
64/59: PV
64/60: z
64/61:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0
PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/62: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/63: norm
64/64: cmap,plevels,norm,ticklabels = PV_cmap2()
64/65: norm
64/66:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0
PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/67: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/68:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
64/69: cmap,plevels,norm,ticklabels = PV_cmap2()
64/70:
def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments
64/71: plt.show()
64/72: plt.close()
64/73: plt.show
64/74: plt.show()
64/75: ax
64/76: ax.add_collection(lc)
64/77: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/78:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0

PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         #ax=plt.gca()
         ax.add_collection(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

#    plt.colorbar(lc)
plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/79: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/80:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0

PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         print(ax)
         ax.add_collection(lc)
         print(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/81: plt.savefig(pt + 'test.png',dpi=300,bbox_inches="tight")
64/82: fig.savefig(pt + 'test2.png',dpi=300,bbox_inches="tight")
64/83: seg
64/84:
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
print(rwe[srtid])
k=0

PV = directPVplotting
plevels=pv_levels
print(pressure)
fig, ax = plt.subplots()
for q in range(0,len(rt[:,0])):
         if (rt[q,0]>rt[q-1,0]):
             k=0
         ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
         seg = make_segments(rt[q]+4*k-4*ll,pressure)
         print(seg)
         z=np.array(PV[:,srtid[q]])
         ###adjust colorbar that PV segments are more readable
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         print(ax)
         ax.add_collection(lc)
         print(lc)
         k=k+1
ax.invert_yaxis()
ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
plt.xlim(-200,200)
plt.ylim(1000,100)

plt.xlabel('West-East distance from center [km]')
plt.ylabel('pressure [hPa]')
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=plevels,cax=cbax)
func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=10)
cbar.ax.set_xlabel('PVU',fontsize=10)
cbar.ax.set_xticklabels(ticklabels)
64/85: pressure
65/1:
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse
def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
65/2:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse
def make_segments(x, y):
     points = np.array([x, y]).T.reshape(-1, 1, 2)
     segments = np.concatenate([points[:-1], points[1:]], axis=1)
     return segments


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = '-pm9h-nopjump'

clat = np.loadtxt(pt + 'centerlatitude' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels' + add + '.txt',dtype=int)
htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
65/3:
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
65/4: ud
65/5: np.where(ud[:,4:6]=='03')
65/6: ud[:,4:6]
65/7: ud[:][4:6]
65/8: ud
65/9: ud[:]
65/10: ud[:][0]
65/11: udv = np.transpose(ud)
65/12: udv
65/13: udv = np.transpose(ud,axes=1)
65/14: udv = np.transpose(ud,axis=1)
65/15: udv = np.transpose(ud,axes=0)
65/16: udv
65/17: udv
65/18: ud
65/19: np.vstack(ud)
65/20: udv = np.vstack(ud)
65/21: udv[:,1]
65/22: udv[:][0]
65/23: udv[0]
65/24: np.where(ud=='20180301_00')
65/25: np.delete(ud,0)
65/26: np.delete(ud,2044)
65/27: np.delete(ud,2044:(len(ud)-1))
65/28: np.delete(ud,np.arange(2044,len(ud)))
65/29: import mpi4py
66/1:
from datetime import datetime, date, timedelta
import numpy as np

def datenum_to_datetime(datenum):
    """
    Convert Matlab datenum into Python datetime.
    :param datenum: Date in datenum format
    :return:        Datetime object corresponding to datenum.
    """
    days = datenum % 1
    hours = days % 1 * 24
    minutes = hours % 1 * 60
    seconds = minutes % 1 * 60
    return datetime.fromordinal(int(datenum)) \
           + timedelta(days=int(days)) \
           + timedelta(hours=int(hours)) \
           + timedelta(minutes=int(minutes)) \
           + timedelta(seconds=round(seconds)) \
           - timedelta(days=366)
66/2:
r200_latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
66/3:
dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']
66/4:
LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)
66/5:
LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
66/6:
IDS = np.array([])
labels = np.array([])
hourstoSLPmin = np.array([])

clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
66/7:
import xarray as xr

hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappaer))
            dates = np.zeros(len(cappear))
            
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date,drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = s.VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/8:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))
IDS = np.array([])
labels = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date,drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = s.VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/9: clon
66/10: clon[-1]
66/11: clon[-1,e]
66/12:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                s = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date,drop_variables=['PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(s.P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = s.VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/13: clat
66/14: len(clat)
66/15: hours
66/16: zeta
66/17: np.max(zeta)
66/18:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])

data = dict()
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0])[0:10]:
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date,drop_variables=['PV',PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/19:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])

data = dict()
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0])[0:10]:
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date)#,drop_variables=['PV',PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/20:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])

data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0])[0:10]:
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date,drop_variables=['PV',PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/21:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])

data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0])[0:10]:
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/22:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
months = ['DEC17','JAN18','FEB18']
data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0]):
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/23:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
months = ['DEC17','JAN18','FEB18']
data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    for z in np.unique(d[:,0]):
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    print(Month)
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/24:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
months = ['DEC17','JAN18','FEB18']
data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    print(Month)
    for z in np.unique(d[:,0]):
        k = str(datenum_to_datetime(ft+366+tmp[0]/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
  
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/25:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
months = ['DEC17','JAN18','FEB18']
data = dict()
for Month in months:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
    d = np.loadtxt(track)
    print(Month)
    for z in np.unique(d[:,0]):
        k = str(datenum_to_datetime(ft+366+z/24))
        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
  
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:1]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear[0:10]:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/26: labels
66/27: hours
66/28: hourszeta
66/29:
hourszeta = np.array([])
DATES = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
IDS = np.array([])
labels = np.array([])
months = ['DEC17','JAN18','FEB18']
#data = dict()
#for Month in months:
#    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
#    d = np.loadtxt(track)
#    print(Month)
#    for z in np.unique(d[:,0]):
#        k = str(datenum_to_datetime(ft+366+z/24))
#        Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
#        data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','PS','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
   
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
  
    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:10]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))] 
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                DATES = np.append(DATES,Date)
                hours[u-cappear[0]] = tmp[0]
                
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) & ((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)
66/30: clat
66/31: len(clat)
66/32: cappear
66/33: len(cappear)
66/34: clat = np.delete(clat,np.arange(-len(cappear),0))
66/35: c;at
66/36: clat
66/37: len(clat)
66/38: clat
66/39: clon
66/40: clon[-1]
66/41: np.delete(clon,-1)
66/42: np.delete(clon,-1,axis=0)
66/43: hourszeta
66/44: len(hourszeta)
66/45: len(cappear)
66/46: hourszeta = np.delete(hourszeta,np.arange(-len(cappear),0))
66/47: hourszeta
66/48: leshourszeta
66/49: len(hourszeta)
66/50: np.delete(hourszeta,np.arange(-len(cappear),0))
66/51: np.delete(hourszeta,np.arange(len(cappear)*(-1),0))
66/52: np.delete(hourszeta,np.arange(len(cappear)*(-1),0,1))
66/53: np.delete(hourszeta,np.arange(len(cappear)*(-1),0,1),axis=1)
66/54: np.delete(hourszeta,np.arange(len(cappear)*(-1),0,1),axis=0)
66/55: hourszeta
66/56: np.delete(hourszeta,0)
66/57: np.delete(hourszeta,)
66/58: np.delete(hourszeta,-1)
66/59: np.delete(hourszeta,range(-10,0))
66/60: np.delete(clon,-1,axis=0)
66/61: np.delete(clon,np.arange(-2,0),axis=0)
66/62: np.delete(clon,np.arange(-3,0),axis=0)
66/63: np.delete(clon,np.arange(0,2),axis=0)
66/64: np.arange(0,2)
66/65: np.delete(clon,np.arange(0,100),axis=0)
66/66: np.delete(clon,np.arange(0,200),axis=0)
66/67: np.delete(clon,np.arange(0,300),axis=0)
66/68: np.delete(clon,np.arange(0,320),axis=0)
66/69: np.delete(clon,np.arange(0,310),axis=0)
66/70: np.delete(clon,np.arange(-310,0),axis=0)
66/71: np.arange(-310,0)
66/72: np.delete(clon,np.arange(-310,0),axis=-1)
66/73: np.delete(clon,0,axis=-1)
66/74: np.delete(clon,np.arange(0,10),axis=-1)
66/75: np.delete(clon,-1,axis=-1)
66/76: np.delete(clon,0,axis=-1)
66/77: np.delete(clon,1,axis=-1)
66/78: np.delete(clon,np.arange(0,310),axis=-1)
66/79: np.delete(clon,np.arange(0,10),axis=-1)
66/80: np.delete(clon,np.arange(0,200),axis=-1)
66/81: np.delete(clon,-1)
66/82: np.delete(clon,-1,axis=0)
66/83: clon
66/84: np.delete(np.delete(clon,-1,axis=0),-1,axis=0)
66/85:
clat = np.zeros((len(r200_lonids)))
clon = np.zeros((len(r200_lonids)))

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
66/86:
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            cappear, = np.where(abs(hourstoSLPmin)<25)
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[D
ate].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)

                    labels = np.append(labels, label)

        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/87:
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            cappear, = np.where(abs(hourstoSLPmin)<25)
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)

                    labels = np.append(labels, label)

        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/88:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
66/89:
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            cappear, = np.where(abs(hourstoSLPmin)<25)
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)

                    labels = np.append(labels, label)

        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/90:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            cappear, = np.where(abs(hourstoSLPmin)<25)
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/91:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            cappear, = np.where(abs(hourstoSLPmin)<25)
            cappear = cappear1[cappear]
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/92:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear1, = np.where(d[:,1]==ids)
        if(len(cappear1) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear1,0]-d[slpminid,0])
            print(cappear1)
            cappear, = np.where(abs(hourstoSLPmin)<25)
            print(cappear)
            cappear = cappear1[cappear]
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/93:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if(len(cappear)>60):
                cappear = cappear[np.where(abs((d[cappear1,0]-d[slpminid,0])<25))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/94: hourszeta
66/95:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if(len(cappear)>60):
                cappear = cappear[np.where(abs((d[cappear1,0]-d[slpminid,0])<25))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/96:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if(len(cappear)>70):
                cappear = cappear[np.where(abs((d[cappear1,0]-d[slpminid,0])<35))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/97:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            #if(len(cappear)>70):
            #    cappear = cappear[np.where(abs((d[cappear1,0]-d[slpminid,0])<35))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/98:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if(len(cappear)>50):
                cappear = cappear[np.where(abs((d[cappear1,0]-d[slpminid,0])<25))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/99:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
            if(len(cappear)>50):
                cappear = cappear[np.where(abs((d[cappear,0]-d[slpminid,0])<25))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]<(-8)) & (hours[-1]>8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/100:
clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)

hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
    for ids in IDs[0:2]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]
                
            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            dates = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(datenum_to_datetime(ft+366+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]

                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))
                for e in range(llat):
                    I, = np.where(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)==np.min(abs(data[Date].P.values[0,:,clat[-1,e],clon[-1,e]]-850)))
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            print(hours)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            print(hours)
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &
((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


        if((hours[0]>(-8)) | (hours[-1]<8)):
            for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
66/101: hourszeta
67/1: import mpi4py
67/2: import mpi4py as mpi
67/3: from mpi4py import MPI
67/4: MPI
67/5: mpi
67/6: MPI_Reduce
67/7: MPI_allreduce
67/8: print(MPI.)
67/9: print(MPI)
68/1: import numpy as np
68/2: d = np.array([])
68/3: d2 = np.arange(1,10)
68/4: d2 + d
68/5: d2 = np.append(d2,d)
68/6: d2
68/7: np.append(d2,d)
68/8: di =dict()
68/9: di2 = dict()
68/10: di[0] = np.array([])
68/11: di2[0] = np.arange(1,10)
68/12: di[0]
68/13: di2[0]
68/14: di
68/15: di2
68/16: np.append(di2[0],di[0])
68/17: di[0] = np.arange(1,20)
68/18: di2
68/19: import mpi4py
68/20: pwd
68/21: cd experimentalmpi/
68/22: mpiexec -n 6 ./mpicomposite-relvort.py --mpi=mpi4py
68/23: mpiexec -n 4 ./mpicomposite-relvort.py --mpi=mpi4py
68/24: mpiexec
68/25: mpirun
69/1: import numpy as np
69/2: a = np.array([1,2,3,4,5])
69/3: b = np.vstack((np.array([6,7,8,9,10]),np.array([11,12,13,14,15])))
69/4: c = [a,b]
69/5: c
69/6: np.vstack((c[0],c[1]))
69/7: np.vstack((c[0],c[1]))[:,0]
69/8: np.array_split(np.vstack((c[0],c[1])))
69/9: np.array_split(np.vstack((c[0],c[1])),axis=0)
69/10: np.array_split(np.vstack((c[0],c[1])),axis=1)
69/11: np.array_split(np.vstack((c[0],c[1])),3)
69/12: np.array_split(np.vstack((c[0],c[1])),3)[0]
69/13: np.array_split(np.vstack((c[0],c[1])),3)[0][0]
70/1: dates = np.array(['2017','2018'])
70/2: import numpy as np
70/3: dates = np.array(['2017','2018'])
70/4:
if(dates=='2017'):
    print('its in')
70/5:
if(dates.any()=='2017'):
    print('its in')
70/6: dates
70/7: np.where(dates=='2017')
70/8:
if (np.where(dates=='2017')>0):
    print('its in')
70/9: np.any(dates)
70/10: np.any(dates=='2017')
70/11: np.any(!dates=='2017')
70/12: !np.any(dates=='2017')
70/13:
if (! np.any(dates=='2017')):
    print('test')
70/14:
if (np.any(dates=='2017')):
    print('test')
70/15:
if (np.any(dates=='2019')==False):
    print('test')
70/16:
if (np.any(dates=='2018')==False):
    print('test')
70/17: LAT = np.linspace(0,90,226)
70/18: LON = np.linspace(-180,180,901)
70/19: disx = np.linspace(0,2 *np.pi *6370,901)
70/20: disy = np.linspace(0,0.5 * np.pi  *6370,226)
70/21: Disx = disx - disx[200]
70/22: Disx = disx - disx[100]
70/23: Disx = disx - disx[200]
70/24: Disy = disy - disy[100]
70/25: rr = np.sqrt(Disx**2 + Disy**2)
70/26: x,y = meshgrid(Disx,Disy)
70/27: x,y = np.meshgrid(Disx,Disy)
70/28: x
70/29: y
70/30: y[:,0]
70/31: x[:,0]
70/32: rr = np.sqrt(x**2 + y**2)
70/33: rr
70/34: rr[:,0]
70/35: np.where(rr<200)
70/36: idx, idy = np.where(rr<200)
70/37: idx
70/38: idy
70/39: idx = idx -100
70/40: idxy = idy -200
70/41: idx
70/42: idx, idy = np.where(rr<500)
70/43: idy = idy -200
70/44: idx = idx -100
70/45: idx
70/46: idy
70/47: np.argsort(idy)
70/48: len(idy)
70/49: np.argsort(idy)
70/50: np.sort(idy)
70/51: idx(np.argsort(idy))
70/52: idx[np.argsort(idy)]
70/53: idt = np.vstack((idy,idx))
70/54: idt
70/55: idx, idy = np.where(rr<500)
70/56: idx = idx -100
70/57: idy = idy -200
70/58: idx
70/59: idy
70/60: idt = np.vstack((idx,idy))
70/61: idty
70/62: idt
70/63: np.sort(idt)
70/64: np.sort(idt[0])
70/65: np.sort(idt,axis=0)
70/66: idt = np.vstack(())
70/67: idy
70/68: idlon = idy
70/69: idlat =idx
70/70: idt = np.vstack((idlon,idlat))
70/71: idt
70/72: np.sort(idt,axis=1)
70/73: np.sort(idt,axis=0)
70/74: r
70/75: rr
70/76: idtlo = np.sort(idt,axis=0)[0]+200
70/77: idtla = np.sort(idt,axis=0)[1]+100
70/78: rr[idtlo,idtla]
70/79: rr[idtla,idtlo]
70/80: Disx[idtlo]
70/81: idx, idy = np.where(rr<200)
70/82: idx
70/83: Disx
70/84: Disx[idx]
70/85: Disx[idy]
70/86: idlat = idx
70/87: idlon = idy
70/88: Disx[idlon]
70/89: Disy[idlat]
70/90: idlat
70/91: idlat2 = idlat-100
70/92: idlon2 = idlon-200
70/93: ls
70/94: idlon2
70/95: Disx[idlat2+200]
70/96: Disy[idlon2+100]
70/97: import helper as h
70/98: import /atmosdyn2/ascherrmann/scripts/helper as h
70/99: import '/atmosdyn2/ascherrmann/scripts/helper.py' as h
70/100: import sys
70/101: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
70/102: import helper as h
70/103: h
70/104: h.keys()
70/105: help
70/106: help(helper)
70/107: help(h)
70/108: import helper as h
70/109: help(h)
70/110: import xarray as xr
70/111:
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
70/112: lonadd, latadd =
70/113: import sys
70/114: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
70/115: import helper as h
70/116: lonadd, latadd = h.radial_ids_around_center(500)
70/117: import helper as h
70/118: lonadd, latadd = h.radial_ids_around_center(500)
71/1: import sys
71/2: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
71/3: import numpy as np
71/4: import xarray as xr
71/5: import helper as h
71/6: lonadd, latadd = h.radial_ids_around_center(500)
71/7: source helper.py
71/8: source helper
71/9: import helper as h
71/10: lonadd, latadd = h.radial_ids_around_center(500)
72/1: import numpy as np
72/2: import helper as h
72/3: print(h.radial_ids_around_center(500))
72/4: Lonadd, Latadd = h.radial_ids_around_center(500)
72/5: ls
72/6: ls ../
72/7: ls ../002-2020-08-05-Identify-DJF1718-medcyclones/
73/1: import numpy as np
73/2: d = np.array(['2017','2018'])
73/3: d
73/4: d=='2017'
73/5: np.any(d=='2017')
73/6: k = np.array([])
73/7: len(k)
73/8: np.where(k=='2017')
73/9: ls ../
73/10: ls ../003-2020-08-10-Mcases/
73/11: import os
73/12: help(os)
73/13: os.isdir
73/14: os.is_dir
73/15: os.isdirectory
73/16: u = 5
73/17: len(u)
73/18:
if(len(u)=False):
    print('test')
73/19:
if(len(u)==False):
    print('test')
73/20: u.shape
73/21: isinstance(u)
73/22: type(u)
73/23: k = np.array([0,0.1,5])
73/24: type(k)
74/1: import helper
74/2: vari = helper.S_variables()
74/3: vari
74/4: del(vari[1])
74/5: vari
75/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars

#raphaels modules)
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import matplotlib

#cartopy
import cartopy.crs as ccrs
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os
from datetime import datetime, date, timedelta
75/2: fig,axes = plt.subplots(2, 3)
75/3: axes
75/4: axes[0]
75/5: len(axes)
75/6:
t = 0
for a in range(len(axes)):
    for ax in axes[a]:
        print(t)
        t +=1
75/7: axes[a]
75/8: axes[0]
76/1: import numpy as np
76/2: import xarray as xr
76/3: s = xr.open_dataset('/atmosdyn/atroman/phd/FEB18/cdf/S20180217_04')
76/4: Ps = s.P.values[0]
76/5: Ps.shape
76/6: test = np.flatten(Ps)
76/7: test = Ps.flatten()
76/8: test.shape
76/9: test = Ps.flatten(order='F')
76/10: test.shape
76/11: test = Ps.flatten(order='A')
76/12: test.shape
76/13: test = np.array([])
76/14: test = np.append(test,Ps[0])
76/15: test = np.append(test,Ps[1])
76/16: test
76/17: test.shape
76/18: Ps
76/19: Ps.shape
76/20: Ps[0]
76/21: Ps[0].shape
76/22: test = Ps.[0]
76/23: test = Ps[0]
76/24: test
76/25: test.append(Ps[1])
76/26: test.shape
76/27: test
76/28: test = np.append(test,Ps[1])
76/29: test
76/30: test
76/31: test = Ps[0]
76/32: test
76/33: test = np.concentrate((test,Ps[1]))
76/34: test = np.concatenate((test,Ps[1]))
76/35: test
76/36: test.shape
77/1: import numpy as np
77/2: import xarray as xr
77/3: s = xr.open_dataset('/atmosdyn/atroman/phd/FEB18/cdf/S20180217_04')
77/4: Ps = s.P.values[0]
77/5: test = np.concatenate((np.array([]),Ps))
77/6: test = Ps[0]
77/7:
for q in range(1,len(Ps)):
    test = np.concatenate((test,Ps[q]))
77/8: test.shape
77/9: test.shape[0]
77/10: test.shape[0]/226
77/11: lvl = np.ones(83)
77/12: lvl = np.cumsum(np.ones(83) * 226)
77/13: lv
77/14: lvl
77/15: s.lon
77/16: s.lat
77/17: s.lat.values
78/1: import numpy as np
78/2: test = np.arange(0,69)
78/3: test
78/4: u = np.arange(-4,5)
78/5: u
78/6: ul = u
78/7: ulo = np.array([])
78/8: r200_lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
78/9:
for u in range(1,len(r200_lonids)):
    if (r200_lonids[u]<r200_lonids[u-1]):
        ulo = np.append(ulo,u)
78/10: ulo
78/11: ulo = ulo.astype(int)
78/12: ulo
78/13: ulo = ulo-1
78/14: ulo
78/15: di = dict()
78/16:
for u in ulo:
    di[u] = np.array([])
78/17: di
78/18:

ulo = ulo+1
for u in range(len(ulo)):
    if u==0:
        di[u] = ul[0::ulo[u]]
    else:
        di[u] = ul[ulo[u-1]::ulo[u]]
78/19: di
78/20:

ulo = ulo+1
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = ul[0::ulo[u]]
    else:
        di[ulo[u]] = ul[ulo[u-1]::ulo[u]]
78/21: di
78/22:

ulo = ulo+1
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = ul[0:ulo[u]]
    else:
        di[ulo[u]] = ul[ulo[u-1]:ulo[u]]
78/23: di
78/24: ulo
78/25: ulo = ulo - 2
78/26:
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = ul[0:ulo[u]]
    else:
        di[ulo[u]] = ul[ulo[u-1]:ulo[u]]
78/27: di
78/28: ulo
78/29: ul
78/30: del(di)
78/31: di = dict()
78/32:
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = r200_lonids[0:ulo[u]]
    else:
        di[ulo[u]] = r200_lonids[ulo[u-1]:ulo[u]]
78/33: di
78/34: ulo
78/35: ulo = np.append(ulo,68)
78/36:
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = r200_lonids[0:ulo[u]]
    else:
        di[ulo[u]] = r200_lonids[ulo[u-1]:ulo[u]]
78/37: di
78/38: ulo = np.append(ulo,69)
78/39:
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = r200_lonids[0:ulo[u]]
    else:
        di[ulo[u]] = r200_lonids[ulo[u-1]:ulo[u]]
78/40: di
78/41: ulo
78/42: ulo = np.delete(ulo,-2)
78/43: ulo
78/44:
for u in range(len(ulo)):
    if u==0:
        di[ulo[u]] = r200_lonids[0:ulo[u]]
    else:
        di[ulo[u]] = r200_lonids[ulo[u-1]:ulo[u]]
78/45: di
78/46: del(di[68])
78/47: di
78/48:
test = np.array([])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]])
78/49: test
78/50:
test = np.array([])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=0)
78/51: test
78/52:
test = np.array([])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=1)
78/53:
test = np.array([],[])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=1)
78/54:
test = np.array([],[])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=0)
78/55:
test = np.array([],[])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=0)
78/56:
test = np.array(([],[]))
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=0)
78/57:
test = np.array([])
for u in range(len(ulo)):
    if u==0:
        test = np.append(test,di[ulo[u]],axis=0)
    else:
        test = np.concatenate(test,di[ulo[u]])
78/58:
test = np.array([])
for u in range(len(ulo)):
    if u==0:
        test = np.append(test,di[ulo[u]])
    else:
        test = np.concatenate(test,di[ulo[u]])
78/59:
test = np.array([])
for u in range(len(ulo)):
    if u==0:
        test = np.append(test,di[ulo[u]])
    else:
        test = np.concatenate((test,di[ulo[u]]))
78/60: test
78/61:
test = np.array([])
for u in range(len(ulo)):
    if u==0:
        test = np.append(test,di[ulo[u]])
    else:
        test = np.concatenate((test,di[ulo[u]]),axis=0)
78/62: test
78/63:
test = np.array([])
for u in range(len(ulo)):
    if u==0:
        test = np.append(test,di[ulo[u]])
    else:
        test = np.concatenate((test,di[ulo[u]]),axis=1)
78/64: test
78/65:
test = np.array(([],[]))
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]],axis=0)
78/66:
test = np.array([])
for u in range(len(ulo)):
    test = np.append(test,di[ulo[u]])
78/67: test
78/68: srt = np.argsort(test)
78/69: srt
78/70: latids = np.array([-4, -4, -4, -4, -4, -3, -3, -3, -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0, 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2, 2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4, 4])
78/71: lonids = np.array([-2, -1,  0,  1,  2, -3, -2, -1,  0,  1,  2,  3, -4, -3, -2, -1,  0, 1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1, 0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -4, -3, -2, -1,  0,  1,  2,  3,  4, -3, -2, -1,  0,  1,  2,  3, -2, -1,  0,  1, 2])
78/72: srtlon = np.argsort(lonids)
78/73: latsortedlon = latids[srtlon]
78/74: latsortedlon
78/75: ulon = np.unique(lonids)
78/76: ulon
78/77: np.where(lonids==ulon[0])
78/78: len(np.where(lonids==ulon[0])[0])
79/1:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse
79/2:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
79/3:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
79/4: dates
79/5: htM
79/6:
dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']

LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)

LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))
79/7: from datetime import datetime, date, timedelta
79/8: helper
79/9: h
79/10: lon = np.array([180,-178.2])
79/11:
if(lon.any()<0):
    print('test')
79/12: lon.any()<0
79/13: np.any(lon)<0
79/14: lon
79/15: lon[1]<0
79/16: np.any(lon<0)
80/1: import numpy as np
80/2: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
80/3: ls
80/4: cd pt
80/5: ls /atmosdyn2/ascherrmann/004-composite-analysis/
80/6: cd /atmosdyn2/ascherrmann/004-composite-analysis/
80/7: t = np.loadtxt('centerlatitude-24h-pjump5.txt',dtype=int)
80/8: t
80/9: t-1
80/10: t = t-1
80/11: np.savetxt('centerlatitude-24h-pjump5.txt',t.astype(int),delimiter='',newline='\n')
80/12:
for u in *.txt:
    print('text')
80/13:
for u in '*.txt':
    print('text')
80/14: t = t+1
80/15: np.savetxt('centerlatitude-24h-pjump5.txt',t.astype(int),delimiter='',newline='\n')
80/16:
for u in '*.txt':
    print(u)
80/17: st = 'centerlatitude-24h-pjump5.txt'
80/18: ls
80/19: t = np.loadtxt(st,dtype=int)
80/20: t
80/21: t = np.loadtxt(st)
80/22: t
80/23: t.shape
80/24: np.savetxt(st,t.astype(int),fmt='%i', delimiter=' ', newline='\n')
80/25: tt = np.loadtxt(st)
80/26: tt.shape
80/27: ls
80/28: st = 'centerlatitude-pm9h-nopjump.txt'
80/29: sts = ['centerlatitude-pm9h-nopjump.txt', 'centerlatitude-vorticitymature.txt', 'centerlongitude-24h-pjump5.txt','centerlongitude-pm9h-nopjump.txt','centerlongitude-vorticitymature.txt']
80/30:
for st in sts:
    tt = np.loadtxt(st,dtype=int)
    tt = tt-1
    np.savetxt(st,t.astype(int),fmt='%i', delimiter=' ', newline='\n')
80/31:
for st in sts:
    tt = np.loadtxt(st,dtype=int)
    tt = tt-1
    np.savetxt(st,tt.astype(int),fmt='%i', delimiter=' ', newline='\n')
80/32: t
80/33: st = 'centerlatitude-24h-pjump5.txt'
80/34: t = t-1
80/35: np.savetxt(st,t.astype(int),fmt='%i', delimiter=' ', newline='\n')
80/36: ls /atmosdyn/atroman/phd/FEB18/cdf/
80/37: d = np.loadtxt('/atmosdyn/atroman/phd/FEB18/cdf/b0cn_cst')
80/38:
aklay = [0, 0.01878906, 0.1329688, 0.4280859, 0.924414, 1.62293, 2.524805,
    3.634453, 4.962383, 6.515274, 8.3075, 10.34879, 12.65398, 15.23512,
    18.10488, 21.27871, 24.76691, 28.58203, 32.7325, 37.22598, 42.06668,
    47.25586, 52.7909, 58.66457, 64.86477, 71.37383, 78.16859, 85.21914,
    92.48985, 99.93845, 107.5174, 115.1732, 122.848, 130.4801, 138.0055,
    145.3589, 152.4757, 159.2937, 165.7537, 171.8026, 177.3938, 182.4832,
    187.0358, 191.0384, 194.494, 197.413, 199.8055, 201.683, 203.0566,
    203.9377, 204.339, 204.2719, 203.7509, 202.7876, 201.398, 199.5966,
    197.3972, 194.8178, 191.874, 188.585, 184.9708, 181.0503, 176.8462,
    172.382, 167.6805, 162.7672, 157.6719, 152.4194, 147.0388, 141.5674,
    136.03, 130.4577, 124.8921, 119.3581, 113.8837, 108.5065, 103.253,
    98.1433, 93.19541, 88.42463, 83.83939, 79.43383, 75.1964]
80/39: aklay
80/40: aklay = [0, 0.01878906, 0.1329688, 0.4280859, 0.924414, 1.62293, 2.524805,3.634453, 4.962383, 6.515274, 8.3075, 10.34879, 12.65398, 15.23512, 18.10488, 21.27871, 24.76691, 28.58203, 32.7325, 37.22598, 42.06668,    47.25586, 52.7909, 58.66457, 64.86477, 71.37383, 78.16859, 85.21914,    92.48985, 99.93845, 107.5174, 115.1732, 122.848, 130.4801, 138.0055,    145.3589, 152.4757, 159.2937, 165.7537, 171.8026, 177.3938, 182.4832,   187.0358, 191.0384, 194.494, 197.413, 199.8055, 201.683, 203.0566,    203.9377, 204.339, 204.2719, 203.7509, 202.7876, 201.398, 199.5966,    197.3972, 194.8178, 191.874, 188.585, 184.9708, 181.0503, 176.8462,    172.382, 167.6805, 162.7672, 157.6719, 152.4194, 147.0388, 141.5674,    136.03, 130.4577, 124.8921, 119.3581, 113.8837, 108.5065, 103.253,    98.1433, 93.19541, 88.42463, 83.83939, 79.43383, 75.1964]
80/41: aklay
80/42:
bklay = [0.9988151, 0.9963163, 0.9934933, 0.9902418, 0.9865207, 0.9823067,
    0.977575, 0.9722959, 0.9664326, 0.9599506, 0.9528069, 0.944962,
    0.9363701, 0.9269882, 0.9167719, 0.9056743, 0.893654, 0.8806684,
    0.8666805, 0.8516564, 0.8355686, 0.8183961, 0.8001264, 0.7807572,
    0.7602971, 0.7387676, 0.7162039, 0.692656, 0.6681895, 0.6428859,
    0.6168419, 0.5901701, 0.5629966, 0.5354602, 0.5077097, 0.4799018,
    0.4521973, 0.424758, 0.3977441, 0.3713087, 0.3455966, 0.3207688,
    0.2969762, 0.274298, 0.2527429, 0.2322884, 0.212912, 0.1945903,
    0.1772999, 0.1610177, 0.145719, 0.1313805, 0.1179764, 0.1054832,
    0.0938737, 0.08312202, 0.07320328, 0.06408833, 0.05575071, 0.04816049,
    0.04128718, 0.03510125, 0.02956981, 0.02465918, 0.02033665, 0.01656704,
    0.01331083, 0.01053374, 0.008197418, 0.006255596, 0.004674384,
    0.003414039, 0.002424481, 0.001672322, 0.001121252, 0.0007256266,
    0.0004509675, 0.0002694785, 0.0001552459, 8.541815e-05, 4.1635e-05,
    1.555435e-05, 3.39945e-06]
80/43: bklay
80/44: (aklay + bklay) * 1000
80/45: aklay + bklay
80/46: aklay = np.array([0, 0.01878906, 0.1329688, 0.4280859, 0.924414, 1.62293, 2.524805,3.634453, 4.962383, 6.515274, 8.3075, 10.34879, 12.65398, 15.23512, 18.10488, 21.27871, 24.76691, 28.58203, 32.7325, 37.22598, 42.06668,    47.25586, 52.7909, 58.66457, 64.86477, 71.37383, 78.16859, 85.21914,    92.48985, 99.93845, 107.5174, 115.1732, 122.848, 130.4801, 138.0055,    145.3589, 152.4757, 159.2937, 165.7537, 171.8026, 177.3938, 182.4832,   187.0358, 191.0384, 194.494, 197.413, 199.8055, 201.683, 203.0566,    203.9377, 204.339, 204.2719, 203.7509, 202.7876, 201.398, 199.5966,    197.3972, 194.8178, 191.874, 188.585, 184.9708, 181.0503, 176.8462,    172.382, 167.6805, 162.7672, 157.6719, 152.4194, 147.0388, 141.5674,    136.03, 130.4577, 124.8921, 119.3581, 113.8837, 108.5065, 103.253,    98.1433, 93.19541, 88.42463, 83.83939, 79.43383, 75.1964])
80/47: aklay
80/48:
bklay = np.array([0.9988151, 0.9963163, 0.9934933, 0.9902418, 0.9865207, 0.9823067,
    0.977575, 0.9722959, 0.9664326, 0.9599506, 0.9528069, 0.944962,
    0.9363701, 0.9269882, 0.9167719, 0.9056743, 0.893654, 0.8806684,
    0.8666805, 0.8516564, 0.8355686, 0.8183961, 0.8001264, 0.7807572,
    0.7602971, 0.7387676, 0.7162039, 0.692656, 0.6681895, 0.6428859,
    0.6168419, 0.5901701, 0.5629966, 0.5354602, 0.5077097, 0.4799018,
    0.4521973, 0.424758, 0.3977441, 0.3713087, 0.3455966, 0.3207688,
    0.2969762, 0.274298, 0.2527429, 0.2322884, 0.212912, 0.1945903,
    0.1772999, 0.1610177, 0.145719, 0.1313805, 0.1179764, 0.1054832,
    0.0938737, 0.08312202, 0.07320328, 0.06408833, 0.05575071, 0.04816049,
    0.04128718, 0.03510125, 0.02956981, 0.02465918, 0.02033665, 0.01656704,
    0.01331083, 0.01053374, 0.008197418, 0.006255596, 0.004674384,
    0.003414039, 0.002424481, 0.001672322, 0.001121252, 0.0007256266,
    0.0004509675, 0.0002694785, 0.0001552459, 8.541815e-05, 4.1635e-05,
    1.555435e-05, 3.39945e-06])
80/49: bklay
80/50: (aklay + bklay)
80/51: (aklay + bklay) * 1000
80/52:
bklev = np.array([0.9976301, 0.9950025, 0.991984, 0.9884995, 0.9845419, 0.9800716,
    0.9750784, 0.9695134, 0.9633517, 0.9565495, 0.9490644, 0.9408596,
    0.9318808, 0.9220957, 0.9114482, 0.8999005, 0.8874075, 0.8739293,
    0.8594318, 0.8438811, 0.8272561, 0.809536, 0.7907168, 0.7707976,
    0.7497966, 0.7277387, 0.704669, 0.680643, 0.655736, 0.6300358, 0.6036481,
    0.5766922, 0.5493011, 0.5216192, 0.4938003, 0.4660033, 0.4383912,
    0.4111248, 0.3843633, 0.3582542, 0.3329391, 0.3085985, 0.285354,
    0.2632419, 0.242244, 0.2223329, 0.2034912, 0.1856894, 0.1689104,
    0.153125, 0.1383129, 0.1244481, 0.1115047, 0.09946167, 0.08828574,
    0.07795831, 0.06844825, 0.05972841, 0.05177302, 0.04454796, 0.0380264,
    0.0321761, 0.02696352, 0.02235484, 0.01831845, 0.01481563, 0.01180602,
    0.00926146, 0.007133377, 0.005377815, 0.003970954, 0.002857124,
    0.001991838, 0.001352806, 0.0008896979, 0.0005615553, 0.0003403797,
    0.0001985774, 0.0001119143, 5.8922e-05, 2.4348e-05, 6.7607e-06, 3.82e-08])
80/53: (bklev + bklay) * 1000
80/54: aklay + bklay * 1000
80/55: less /atmosdyn2/ascherrmann/Scdf.txt
80/56: sfile = '/atmosdyn/atroman/phd/FEB18/cdf/S20180210_10'
81/1: import numpy as np
81/2: import xarray as xr
81/3: sfile = '/atmosdyn/atroman/phd/FEB18/cdf/S20180210_10'
81/4: import helper
81/5: import sys
81/6: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
81/7: import helper
81/8: sfile = '/atmosdyn/atroman/phd/FEB18/cdf/S20180210_10'
81/9: s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
81/10: clon, clat = helper.lonlatids(52.4,52.4,200)
81/11: clon
81/12: SLP = s.PS.values[0,:,clat,clon]
81/13: SLP
81/14: SLP = s.PS.values[0,:,clat,clon[0]]
81/15: SLP
81/16: SLP = s.PS.values[0,:,clat]
81/17: SLP
81/18: SLP = s.PS.values[0,0,clat]
81/19: SLP
81/20: SLP = s.PS.values[0,0,clat,clon]
81/21: SLP
81/22: P = SLP *
81/23: LtP = helper.modellevel_to_pressure()
81/24: P = SLP * LtP
81/25: P = SLP[0] * LtP
81/26: P
81/27: SLP[0]
81/28: ltP
81/29: LtP
82/1: import numpy as np
82/2: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
82/3: add = 'vorticitymature'
82/4: htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
82/5:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
82/6: oi
82/7: oi = oi.astype(int)
82/8: oi
82/9:
clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
82/10:
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
82/11: DATES
82/12:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
    print(np.where(htM==zz))
82/13:
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
    print(zz, np.where(htM==zz))
82/14:
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse
82/15:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)
82/16:
DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]

srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))
82/17:
for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
a = 0
82/18: np.where(ud=='20171213_04')
82/19: a = 287
82/20:
for t in ud[287:288]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
         ###adjust colorbar that PV segments are more readable
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to SLP min'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig(fname,dpi=300,bbox_inches="tight")
        plt.close()
        a =a +1
        print(a,fname)
82/21: cyid
82/22: cycl.FLAG.values
82/23: cycl.FLAG.values.shape
82/24: clon
82/25: clon[287]
82/26: clat[287]
82/27: clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
82/28: clon
82/29: clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
82/30: clat
82/31: cd /atmosdyn2/ascherrmann/004-composite-analysis/
82/32: ls
82/33: clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
82/34: clat
82/35: clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
82/36: clon
82/37: less centerlatitude-vorticitymature.txt
82/38: less centerlatitude-vorticitymature.txt
82/39: less centerlongitude-vorticitymature.txt
82/40: clat
82/41: clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
82/42: clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
82/43: clat
82/44: clat[0]
82/45: clon[0]
82/46: clon[5]
82/47: clon[6]
82/48: clon[7]
82/49: clon[8]
82/50: clon[9]
82/51: clon[10]
82/52: clon[1]
82/53:
for i in range(len(clon)):
    print(clon[i,0])
82/54: clat[0]
82/55: clon[0]
82/56: helper
82/57: import helper
82/58: import sys
82/59: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
82/60: import helper
82/61: r200_lonids, r200_latids = helper.radial_ids_around_center(200)
82/62: r200_lon
82/63: r200_lonids
82/64: r200_latids
82/65: less centerlongitude-vorticitymature.txt
82/66: help.make_segments
83/1: import numpy as np
83/2: import sys
83/3: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
83/4: import helper
83/5: helper.make_segments
83/6:
x = np.array([-5, -5, -5, -5, -5, -4, -4, -4, -4, -4, -4, -4, -3, -3, -3, -3, -3,
       -3, -3, -3, -3, -2, -2, -2, -2, -2, -2, -2, -2, -2, -1, -1, -1, -1,
       -1, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,
        1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,
        3])
83/7: plvl =np.arange(100,1001,25)
84/1: import numpy as np
84/2:
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
import argparse


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
84/3:
sorting = np.where(Hours==0)#np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
a = 0
84/4: np.where(ud=='20171213_04')
84/5: np.where(ud=='20171213_05')
84/6: np.where(ud=='20171213_03')
84/7: ud
84/8: np.where(ud=='20171213_02')
84/9: a = 39
84/10:
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
84/11: fig.show()
84/12:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
84/13: plt.show()
84/14: plt.savefig('test.png',dpi=300,bbox_inches="tight")
84/15: plt.close()
84/16:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
84/17: plt.savefig('test.png',dpi=300,bbox_inches="tight")
84/18: a
84/19: clat[a]
84/20: clon[a]
84/21: srtid
84/22:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = srtid[k]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
84/23: plt.show
84/24: plt.show()
84/25: clon[sqrtid]
84/26: clon[srtid]
84/27: clon[a,srtid]
84/28: clat[a,srtid]
84/29:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        #norm = plt.Normalize(0,68)
        #cmap = matplotlib.cm.jet
        #pv_levels= np.arange(0,69)
        #ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
84/30:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        #norm = plt.Normalize(0,68)
        #cmap = matplotlib.cm.jet
        #pv_levels= np.arange(0,69)
        #ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test2.png',dpi=300,bbox_inches="tight")
84/31: cmap,pv_levels,norm,ticklabels = PV_cmap2()
84/32:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        #norm = plt.Normalize(0,68)
        #cmap = matplotlib.cm.jet
        #pv_levels= np.arange(0,69)
        #ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test2.png',dpi=300,bbox_inches="tight")
84/33:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        #norm = plt.Normalize(0,68)
        #cmap = matplotlib.cm.jet
        #pv_levels= np.arange(0,69)
        #ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
84/34:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
84/35: plt.close('all')
84/36:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+3*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/37:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.75*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/38:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+3*lines-3*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/39:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.95*lines-2.9*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/40:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.9*lines-2.85*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/41:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.8*lines-2.75*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/42:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/43:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,sqrtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/44:
plt.close()
for t in ud[39:40]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/45: clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
84/46: clat
84/47: clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
84/48:
clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
84/49: rwe
84/50:
for u in range(len(rt[:,0])):
         rt[u] = rwe[u]
84/51: rt
84/52: rwe
84/53: idx
84/54: idy
84/55:
idy, idx = np.where(rr<200)
rwe = disx[idx,idy]
84/56:
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]
84/57: rwe
84/58: rt
84/59:
sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
a = 0
84/60:
clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
84/61:
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
a = 0
84/62:
rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = rwe[u]
84/63: a = np.where(DATES=='20171213_02')
84/64: a
84/65: a = np.where(DATES=='20171213_02')[0][0]
84/66: a
84/67: a = np.where(DATES=='20171213_02')[0]
84/68: a
84/69:
a = 937
for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/70:
a = 937
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        
        for q in range(0,len(rt[:,0])):           
             rid = np.where(rrr==rt[q,0])[0][0]
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*linecounterr[rid]-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             linecounter[rid] +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/71:
a = 937
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        
        for q in range(0,len(rt[:,0])):           
             rid = np.where(rrr==rt[q,0])[0][0]
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*linecounterr[rid]-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             linecounterr[rid] +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/72:
rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
84/73:
a = 937
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        
        for q in range(0,len(rt[:,0])):           
             rid = np.where(rrr==rt[q,0])[0][0]
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*linecounterr[rid]-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             linecounterr[rid] +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/74:
a = 937
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/75:
a = 938
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/76:
a = 939
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[a:a+1]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/77: labels[a]
84/78: labels[a-1]
84/79: labels[a-2]
84/80: a
84/81: np.where((DATES=='20171212_23')&(labels==2))
84/82: DATES
84/83:
rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.argsort(DATES)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
84/84: np.where((DATES=='20171212_23')&(labels==2))
84/85: np.where((DATES=='20171213_06')&(labels==2))
84/86:
rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.where(htM==0)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
84/87:
rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]

sorting = np.where(Hours==0)

DATES = DATES[sorting]
Hours = Hours[sorting]
oi = oi[sorting]
clat = clat[sorting]
clon = clon[sorting]
labels = labels[sorting]
a = 0
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])
84/88: DATES[np.where(labels==2)]
84/89: np.where(DATES=='20171214_02')
84/90: a = 41
84/91: np.where(ud=='20171214_02')
84/92:
for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/93:
for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid, = np.where(uh==h2M)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = k
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        norm = plt.Normalize(0,68)
        cmap = matplotlib.cm.jet
        pv_levels= np.arange(0,69)
        ticklabels= pv_levels
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+4*lines-4*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)
        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/94: a = 41
84/95: ud
84/96: ud[40]
84/97:
a = 41
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/98:
ud = np.unique(DATES)
march = np.where(ud=='20180301_00')[0]
#ud = np.delete(ud,np.arange(march[0].astype(int),len(ud)))
uh = np.arange(-12,13,1)

#ud = np.unique(dates)
#uh = np.unique(htM)

diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])

lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()

directPVplotting = np.zeros((lp,llat))
84/99:
a = 41
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/100: cyid
84/101:
a = 41
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/102: clat[a]
84/103: clat[a,srtid]
84/104:
a = 41
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        if m==0:
                            directPVplotting[m,k] = k
                        else:
                            directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/105: cmap2 = matplotlib.cm.jet
84/106: ticklabels2 = np.arange(0,69)
84/107: pv_levels2 = np.arange(0,69)
84/108:
a = 41
norm2 = plt.Normalize(0,68)
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        if m==0:
                            directPVplotting[m,k] = k
                        else:
                            directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap2, norm=norm2, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels2,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels2)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/109:
a = 41
norm2 = plt.Normalize(0,68)
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        if m<10:
                            directPVplotting[m,k] = k
                        else:
                            directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap2, norm=norm2, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels2,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels2)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/110:
a = 41
norm2 = plt.Normalize(0,68)
linecounterr = np.zeros(len(np.unique(rt[:,0])))
rrr = np.sort(np.unique(rt[:,0]))

for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        if m<10:
                            directPVplotting[m,k] = k
                        else:
                            directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines=0
        for q in range(0,len(rt[:,0])):           
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap2, norm=norm2, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines +=1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels2,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels2)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/111: clat[a]
84/112: clon[a]
84/113: rt[:,0]
84/114:
for fs in range(len(rt[:,0])):
    print(fs,rt[fs,0],clat[a,fs],clon[a,fs])
84/115:
for fs in range(len(rt[:,0])):
    print(fs,rt[fs,0],clat[a,srtid[fs]],clon[a,srtid[fs]])
84/116:
a=41
for t in ud[40:41]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        cyid = int(cycl.FLAG.values[0,clat[a,34],clon[a,34]])
        fdir = pt + lab2[labels[a]] + '/' + add + '/' + Month + '/' + str(cyid) + '/'
        if (os.path.isdir(pt+ lab2[labels[a]] + '/' + add + '/' + str(Month))==0):
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' +  str(Month))
            os.mkdir(pt + lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))
        elif(os.path.isdir(pt +  lab2[labels[a]] + '/' + add + '/' + str(Month) + '/' + str(cyid))==0):
            os.mkdir(pt +  lab2[labels[a]] + '/' + add + '/' +  str(Month) + '/' + str(cyid))
        htmp = h2M
        if(htmp<0):
            fname = fdir + 'vPVlines-' + str(cyid) + '-' + str(htmp*(-1)) + 'htozetamax.png'
        else:
            fname = fdir + 'vPVlines-' + str(cyid) + '+' + str(htmp) + 'htozetamax.png'
        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('test.png',dpi=300,bbox_inches="tight")
        plt.close()
84/117: DATES
84/118:
clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

lab = ['Allcyclones','Mediterranean','Extratropical-NonMediterranean','Tropical']
lab2 = ['Tropical','Extratropical-NonMediterranean','Mediterranean']
oi = np.array([])
for zz in range(-12,13,1):
    oi = np.append(oi,np.where(htM==zz))
oi = oi.astype(int)
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
clat = clat[oi]
clon = clon[oi]
84/119: np.where((htM==0) & (labels==2))
84/120: np.where((Hours==0) & (labels==2))
84/121: DATES[np.where((Hours==0) & (labels==2))]
85/1:
import numpy as np
from datetime import datetime, date, timedelta
85/2:
r = 6370

DisLon = np.linspace(0,2 * np.pi * r,901)
DisLat = np.linspace(0,0.5 * np.pi * r,226)

DisLon = DisLon - DisLon[450]
DisLat = DisLat- DisLat[113]

disy, disx = np.meshgrid(DisLon,DisLat)
r = np.sqrt(disx**2 + disy**2)
Latids, Lonids = np.where(r<dis)
Lonids = Lonids-451 #use 451 and 114 as there is a shift in the data set provided by roman
Latids = Latids-114
85/3: dis = 200
85/4:
r = 6370

DisLon = np.linspace(0,2 * np.pi * r,901)
DisLat = np.linspace(0,0.5 * np.pi * r,226)

DisLon = DisLon - DisLon[450]
DisLat = DisLat- DisLat[113]

disy, disx = np.meshgrid(DisLon,DisLat)
r = np.sqrt(disx**2 + disy**2)
Latids, Lonids = np.where(r<dis)
Lonids = Lonids-451 #use 451 and 114 as there is a shift in the data set provided by roman
Latids = Latids-114
85/5: DisLon
85/6: disx
85/7: disy
85/8: r
85/9: Latids, Lonids = np.where(r<dis)
85/10: Latids
85/11: Lonids
85/12: Lonids -= 451
85/13: Lonids
85/14: Latids -= 114
85/15: Latids
85/16:
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


dbase = '/atmosdyn2/ascherrmann/'
months = ['DEC17','JAN18','FEB18']

LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)

LATM = np.array([28,46])
LONM = np.array([-10,30])
ft = date.toordinal(date(1950,1,1))

dates = np.array([])
clat = np.array([])
clon = np.array([])
add = 'vorticitymature'
85/17:
r200_lonids, r200_latids = helper.radial_ids_around_center(200)

clat = np.zeros((len(r200_lonids)),dtype=int)
clon = np.zeros((len(r200_lonids)),dtype=int)
print(r200_lonids, r200_latids)
hourszeta = np.array([])
llat = len(clat)
zetal = np.zeros(llat)
labels = np.array([])
hourstoSLPmin = np.array([])

data = dict()
85/18:
for Month in months[0:1]:
    track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'

    d = np.loadtxt(track)
    IDs = np.unique(d[:,1])
85/19: IDs
85/20: IDs[73]
85/21:
for ids in IDs[72:73]:
        cappear, = np.where(d[:,1]==ids)
        if(len(cappear) >= 19):
            slpminid = cappear[np.where(d[cappear,6] == np.min(d[cappear,6]))]

            hourstoSLPmin = np.append(hourstoSLPmin, d[cappear,0]-d[slpminid,0])
            zeta = np.zeros(len(cappear))
            hours = np.zeros(len(cappear))
            for u in cappear:
                tmp = d[u]
                k = str(helper.datenum_to_datetime(ft+tmp[0]/24))
                Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
                if (np.any(dates==Date)==False):
                    data[Date] = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+Month+'/cdf/S'+Date, drop_variables=['PV','P','TH','THE','RH','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

                dates = np.append(dates,Date)
                hours[u-cappear[0]] = tmp[0]
      #### use latids for lon and lonids for lat to directly get the West-East orientation of the datapoint
#### does not work yet, tell someone about it
                addlon = r200_lonids + np.where(LON==np.round(tmp[2],1))[0][0]
                addlon[np.where((addlon-900)>0)] = addlon[np.where((addlon-900)>0)]-900
                clat = np.vstack((clat, r200_latids + np.where(LAT==np.round(tmp[3],1))[0][0]))
                clon = np.vstack((clon, addlon))

                SLP = data[Date].PS.values[0,0,clat[-1],clon[-1]]
                for e in range(llat):
                    P = helper.modellevel_to_pressure(SLP[e])
                    I = np.where(abs(P-850)==np.min(abs(P-850)))[0]
                    I = I[0].astype(int)
                    zetal[e] = data[Date].VORT.values[0,I,clat[-1,e],clon[-1,e]]
                zeta[u-cappear[0]] = np.mean(zetal)
            hours = hours - hours[np.where(zeta==np.max(zeta))]
            hourszeta = np.append(hourszeta,hours)
            if(d[cappear[0],-3]==0):
                    labels = np.append(labels,np.zeros(len(cappear))) #tropical cyclone
            elif( ((LATM[0]-d[slpminid,3])<0) & ((LATM[1]-d[slpminid,3])>0) & ((LONM[0]-d[slpminid,2])<0) &

((LONM[1]-d[slpminid,2])>0)):
                    labels = np.append(labels,np.zeros(len(cappear)) + 2) # mediterranean
            else:
                    labels = np.append(labels,np.zeros(len(cappear)) + 1)


            if((hours[0]>(-5)) | (hours[-1]<5)):
              for k in range(len(cappear)):
                labels = np.delete(labels,-1)
                hourszeta = np.delete(hourszeta,-1)
                dates = np.delete(dates,-1,0)
                hourstoSLPmin = np.delete(hourstoSLPmin,-1,0)
                clat = np.delete(clat,-1,axis=0)
                clon = np.delete(clon,-1,axis=0)
85/22:
clat = np.delete(clat,0,0)
clon = np.delete(clon,0,0)

datesort = np.argsort(dates)
dates = dates[datesort]
clat = clat[datesort]
clon = clon[datesort]
labels = labels[datesort]
hourszeta = hourszeta[datesort]
hourstoSLPmin = hourstoSLPmin[datesort]
85/23: add = 'test'
85/24:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/centerlatitude-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/centerlongitude-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')
85/25: dates
85/26: hourszeta
85/27: hourstoSLPmin
85/28: clat
85/29: clon
85/30: clataddlon = clat - r200_latids + r200_lonids
85/31: clonaddlat = con - r200_lonids + r200_latids
85/32: clonaddlat = clon - r200_lonids + r200_latids
85/33: clonaddlat
85/34: clonaddlat[0]
85/35: clonn = clon
85/36: clatn = clat
85/37:
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
85/38: idx
85/39: r
85/40: r[Lonids]
85/41: r[Lonids,0]
85/42: r[Lonids,Latids]
85/43: r[Lonids+451,Latids+114]
85/44: r[Latids+114,Lonids+451]
85/45: disy
85/46: disy[Latids+114,Lonids+451]
85/47: disy[clatn,clon]
85/48: disy[clatn,clonn]
85/49: clatn
85/50: disy
85/51: disy.shape
85/52: clonn
85/53: disy[clatn[0],clonn[0]]
85/54: idr
85/55: r
85/56: np.where(r<200)
85/57: idlatr, idlonr = np.where(r<200)
85/58: disx
85/59: disx[idlatr,idlonr]
85/60: disy[idlatr,idlonr]
85/61: distmp = disy
85/62: disy = disx
85/63: disx = disy
85/64: disx
85/65: disx = distmp
85/66: disx
85/67: disy
85/68: disy[idlatr,idlonr]
85/69: disx[idlatr,idlonr]
85/70: rwe = disy[idlatr,idlonr]
85/71: dates
85/72: labels
85/73: htM = hourszeta
85/74: oi, = np.where(htM==0)
85/75: oi
85/76:
DATES = dates[oi]
Hours = htM[oi]
labels = labels[oi]
85/77: DATES
85/78: clat
85/79: pclatn = clatn[oi]
85/80: pclonn = clonn[oi]
85/81: pclonn
85/82: pclat = clataddlon[oi]
85/83: pclon = clonaddlat[oi]
85/84: pclat
85/85: pclot
85/86: pclon
85/87: DATES
85/88: ud = np.unique(DATES)
85/89: ud
85/90: uh = np.arange(-12,13,1)
85/91:
diM = dict()
diT = dict()
diNM = dict()
compall = dict()

Plvl = np.arange(100,1001,25)
pressure = Plvl
lp = len(Plvl)
85/92: clat
85/93:
llat = len(clat[0])
llon = len(clon[0])

rt = np.zeros((llat,lp))
85/94: rwe
85/95:
for u in range(len(rt[:,0])):
         rt[u] = np.sort(rwe)[u]
85/96: rt
85/97: srtid=np.array([12,21,30,39,48, 5,13,22,31,40,49,57, 0,6,14,23,32,41,50,58,64, 1,7,15,24,33,42,51,59,65, 2,8,16,25,34,43,52,60,66, 3,9,17,26,35,44,53,61,67, 4,10,18,27,36,45,54,62,68, 11,19,28,37,46,55,63, 20,29,38,47,56])
85/98:
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
tprecalc = datetime.datetime.now()
85/99:
lines = 0

linewidth=2.3
alpha=1.
cmap,pv_levels,norm,ticklabels = PV_cmap2()

Mcounter = np.zeros(len(uh))
NMcounter = np.zeros(len(uh))
Tcounter = np.zeros(len(uh))
totcounter = np.zeros(len(uh))

for k in range(0, len(uh)):
    diT[uh[k]] = np.zeros((lp,llat))
    diM[uh[k]] = np.zeros((lp,llat))
    diNM[uh[k]] = np.zeros((lp,llat))
    compall[uh[k]] = np.zeros((lp,llat))
85/100: directPVplotting = np.zeros((lp,llat))
85/101: a = 0
85/102:
clat = pclatn
clon = pclonn
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('lonlonlatlat-unsrt.png',dpi=300,bbox_inches="tight")
        plt.close()
85/103:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
85/104:
clat = pclatn
clon = pclonn
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('lonlonlatlat-unsrt.png',dpi=300,bbox_inches="tight")
        plt.close()
85/105:
clat = pclat
clon = pclon
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,q])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('lonlatlatlon-unsrt.png',dpi=300,bbox_inches="tight")
        plt.close()
85/106:
clat = pclat
clon = pclon
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('lonlatlatlon-srt.png',dpi=300,bbox_inches="tight")
        plt.close()
85/107:
clat = pclatn
clon = pclonn
for t in ud:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    dur, = np.where(DATES==t)
    for n in range(0,len(dur)):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]

        h2M = Hours[a]
        hourid = np.where(uh==h2M)[0][0].astype(int)
        if(labels[a]==2):
            Mcounter[hourid] = Mcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diM[h2M][m,k] = diM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        elif(labels[a]==1):
            NMcounter[hourid] = NMcounter[hourid] +1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[k])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,k],clon[a,k]]
                        diNM[h2M][m,k] = diNM[h2M][m,k] + s.PV.values[0,I[0],clat[a,k],clon[a,k]]
        else:
            Tcounter[hourid] = Tcounter[hourid] + 1
            for m in range(0,lp):
                pressure = Plvl[m]
                for k in range(0,llat):
                        P = helper.modellevel_to_pressure(SLP[srtid[k]])
                        I, = np.where(abs(P-pressure)==np.min(abs(P-pressure)))
                        directPVplotting[m,k] = s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]
                        diT[h2M][m,k] = diT[h2M][m,k] + s.PV.values[0,I[0],clat[a,srtid[k]],clon[a,srtid[k]]]

        fig, ax = plt.subplots()
        lines = 0
        for q in range(0,len(rt[:,0])):
             if (rt[q,0]>rt[q-1,0]):
                 lines=0
             ll = np.floor(0.5 * len(np.asarray(np.where(rt[:,0]==rt[q,0])[0])))
             seg = helper.make_segments(rt[q]+2.6*lines-2.55*ll,Plvl)
             z=np.array(directPVplotting[:,srtid[q]])
             lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
             ax=plt.gca()
             ax.add_collection(lc)
             lines=lines+1
        ax.set_title(r'%d h to zeta max'%h2M)
        ax.invert_yaxis()
        ax.set_xticks(ticks=np.unique(np.round(rt[:,0])).astype(int))
        plt.xlim(-200,200)
        plt.ylim(1000,100)
        plt.xlabel('West-East distance from center [km]')
        plt.ylabel('pressure [hPa]')

        cbax = fig.add_axes([0, 0, 0.1, 0.1])
        cbar=plt.colorbar(lc, ticks=pv_levels,cax=cbax)
        func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
        fig.canvas.mpl_connect('draw_event', func)

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_xlabel('PVU',fontsize=10)
        cbar.ax.set_xticklabels(ticklabels)

        plt.savefig('lonlonlatlat-srt.png',dpi=300,bbox_inches="tight")
        plt.close()
85/108: d
85/109: pclatn
85/110: np.mean(pclatn)
85/111: DATES
85/112: LON
85/113: LON[88]
85/114: LAT[88]
85/115: pclonn
85/116: np.mean(pclonn)
85/117: np.min(pclonn)
85/118: np.max(pclonn)
85/119: LON[502]
85/120: LON[510]
85/121: cd /atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/
85/122: tlat = np.array([])
85/123: tlon = np.array([])
85/124: tp = np.array([])
85/125: clat
85/126: clon
85/127: SLP
85/128: sfile
85/129: s
85/130: SLP
85/131: help helper
85/132: help(helper)
86/1: import numpy as np
86/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
86/3:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'

disx = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disx.txt')
disy = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/disy.txt')

rr = np.sqrt(disx**2 + disy**2)
idx, idy = np.where(rr<200)
rwe = disx[idx,idy]


LAT = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lat.txt',dtype=int)

LON = np.loadtxt('/atmosdyn2/ascherrmann/003-2020-08-10-Mcases/Analyses-of-identified-ones/DEC17/73/' + '20171213_13' + '/lon.txt',dtype=int)


add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
86/4: np.where((dates=='20171214_02')&(labels==2))
86/5: a, = np.where((dates=='20171214_02')&(labels==2))
87/1: import numpy as np
87/2: import xrarray as xr
87/3: import xarray as xr
87/4:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper
87/5: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
87/6:
add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
87/7: tid, = np.where((dates=='20171214_02') & (labels==2))
87/8: tid
87/9: a =tid[0]
87/10:
for t in ud[tid]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
87/11:
for t in dates[tid]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
87/12:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
87/13:
for t in dates[tid]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]

    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
87/14: clat
87/15: llat = clat[a]
87/16: llon = clon[a]
87/17: plvl = np.arange(100,1001,25)
87/18: plvl = np.arange(500,926,25)
87/19:
pt = np.array([])
plat = np.array([])
plon = np.array([])
for n in range(0,1):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]
        pv = s.PV.values[0,:,clat[a],clon[a]]
        for k in range(len(clat[a])):
            P = helper.modellevel_to_pressure(SLP[k])
            pid, = np.where((P>500) & (P<926))
            for i in pid:
                if(pv[i,clat[a,k],clon[a,k]]>0.75):
                   pt = np.append(pt,P[i]) 
                   plat = np.append(plat,clat[a,k])
                   plon = np.append(plon,clon[a,k])
87/20: pv
87/21: pv .shape
87/22:
pt = np.array([])
plat = np.array([])
plon = np.array([])
pvstart = np.array([])
for n in range(0,1):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]
        pv = s.PV.values[0,:,clat[a],clon[a]]
        for k in range(len(clat[a])):
            P = helper.modellevel_to_pressure(SLP[k])
            pid, = np.where((P>500) & (P<926))
            for i in pid:
                if(pv[k,i]>0.75):
                   pt = np.append(pt,P[i]) 
                   plat = np.append(plat,clat[a,k])
                   plon = np.append(plon,clon[a,k])
                   pvstart = np.append(pvstart,pv[k,i])
87/23: pt
87/24: len(pt)
87/25: plat
87/26:
pt = np.array([])
plat = np.array([])
plon = np.array([])
pvstart = np.array([])
for n in range(0,1):
        latmin = clat[a,0]
        SLP = s.PS.values[0,0,clat[a],clon[a]]
        pv = s.PV.values[0,:,clat[a],clon[a]]
        for k in range(len(clat[a])):
            P = helper.modellevel_to_pressure(SLP[k])
            pid, = np.where((P>=500) & (P<=925))
            for i in pid:
                if(pv[k,i]>0.75):
                   pt = np.append(pt,P[i]) 
                   plat = np.append(plat,clat[a,k])
                   plon = np.append(plon,clon[a,k])
                   pvstart = np.append(pvstart,pv[k,i])
87/27: pt
87/28: len(pt)
87/29: pwd
87/30: sp = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
87/31: save = np.zeros((len(pt),3))
87/32: save[:,0] = plon
87/33: save[:,1] = plat
87/34: save[:,2] = pt
87/35: save
87/36: np.savetxt(sp + 'trajstart.txt',save,fmt='%d', delimiter=' ', newline='\n')
87/37: np.savetxt(sp + 'trajstart.txt',save,fmt='%f', delimiter=' ', newline='\n')
87/38: i
88/1: import numpy as np
88/2: Lat = np.round(np.linspace(0,90,226))
88/3: Lon = np.round(np.linspace(-180,180,901))
88/4: import os
88/5:
for f in os.listdir('./'):
    if f.endswith(".txt"):
        print(f)
88/6:
for f in os.listdir('./'):
    if f.endswith(".txt"):
        d = np.loadtxt(f)
        la = Lat[d[:,1].astype(int)]
        lo = Lon[d[:,0].astype(int)]
        d[:,1] = la
        d[:,0] = lo
        np.savetxt(f,d,fmt='%f', delimiter=' ', newline='\n')
88/7: d
88/8: d[:,0]
88/9: Lon = np.round(np.linspace(-180,180,901),2)
88/10: Lat = np.round(np.linspace(0,90,226),2)
88/11:
for f in os.listdir('./'):
    if f.endswith(".txt"):
        d = np.loadtxt(f)
        la = Lat[d[:,1].astype(int)]
        lo = Lon[d[:,0].astype(int)]
        d[:,1] = la
        d[:,0] = lo
        np.savetxt(f,d,fmt='%f', delimiter=' ', newline='\n')
88/12: d
88/13: d[:,0]
88/14: f
88/15: ls
88/16: rm trace.param
88/17:
for f in os.listdir('./'):
    if f.endswith(".txt"):
        d = np.loadtxt(f)
        la = Lat[d[:,1].astype(int)]
        lo = Lon[d[:,0].astype(int)]
        d[:,1] = la
        d[:,0] = lo
        np.savetxt(f,d,fmt='%f', delimiter=' ', newline='\n')
88/18: d
88/19: rm trastart-mature-201*.txt
89/1: import numpy as np
89/2: d = np.loadtxt('/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/traced-vars-20171203_00.txt')
89/3: d = np.loadtxt('/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/traced-vars-20171203_00.txt',skiprows=5)
89/4: d[0,0]
89/5: d[0,1]
89/6: np.where(d[:,2]<0)
89/7: np.where(d[:,3]<0)
89/8: d=np.delete(d, np.where(d[:,3]<0))
89/9: np.where(d[:,3]<0)
89/10: d
89/11: d = np.loadtxt('/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/traced-vars-20171203_00.txt',skiprows=5)
89/12: d=np.delete(d, np.where(d[:,3]<0),axis=0)
89/13: d
89/14: np.savetxt('test.txt',d,fmt='%f',delimiter=' ',newline='\n')
89/15: mv test.txt /atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/
89/16: cd /atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/
89/17: t = np.loadtxt('trajectories-mature-20171214_02.txt')
89/18: t = np.loadtxt('trajectories-mature-20171214_02.txt',skipwors=5)
89/19: t = np.loadtxt('trajectories-mature-20171214_02.txt',skiprows=5)
89/20: t.shape
89/21: np.where(t[:,3]<0)
89/22: t = np.delete(t,np.where(t[:,3]<0))
89/23: np.where(t[:,3]<0)
89/24: t = np.loadtxt('trajectories-mature-20171214_02.txt',skiprows=5)
89/25: t = np.delete(t,np.where(t[:,3]<0),axis=0)
89/26: t.shape
89/27: np.savetxt('test.txt',t,fmt='%f',delimiter=' ',newline='\n')
89/28: 52577/49
89/29: np.where(t[:,0]==(-48))
89/30: t[0:150]
89/31: np.where(t[:,0]==(-48))
89/32: np.arange(97-48,97)
89/33: test = np.array([])
89/34:
for k in  np.where(t[:,0]==(-48))[0]:
    test = np.append(test,range(k-48,k))
89/35: test
89/36: test = test.astype(int)
89/37: test
89/38: ls
89/39: F = open('trajectories-mature-20171214_02.txt')
89/40:
for i in range(5):
    line = next(F).strip()
    print(line)
89/41:
for i in range(5):
    line = next(F).strip()
    print(line)
89/42: F = open('trajectories-mature-20171214_02.txt')
89/43:
head = np.array([])
for i in range(5):
    line = next(F).strip()
    head.append(line)
    print(line)
89/44: F = open('trajectories-mature-20171214_02.txt')
89/45:
head = np.array([])
for i in range(5):
    line = next(F).strip()
    head = np.append(head,line)
    print(line)
89/46: head
89/47: F = open(test.txt)
89/48: F = open('test.txt')
89/49: F.write
89/50:
for l in range(N):
    F.write('%s\n'%head[l])
89/51: N = 5
89/52:
for l in range(N):
    F.write('%s\n'%head[l])
89/53: head
89/54: F = open('test.txt','rw')
89/55: F = open('test.txt','w')
89/56:
for l in range(N):
    F.write('%s\n'%head[l])
89/57: F
89/58: F.close()
89/59: less test.txt
89/60: import os
89/61:
traced = np.array([])
traj = np.array([])


for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
    elif(d.startswith('trajectories-mature')):
            traj = np.append(traj.d)
89/62:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
N = 5
traced = np.array([])
traj = np.array([])


for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
    elif(d.startswith('trajectories-mature')):
            traj = np.append(traj.d)
89/63:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
N = 5
traced = np.array([])
traj = np.array([])


for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
    elif(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
89/64: traj
89/65: traced
89/66: sort(traced)
89/67: np.sort(traced)
89/68: np.sort(traced)[0]
89/69: np.sort(traced)[1]
90/1:
import numpy as np
import os


p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
90/2:
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
90/3: traced = np.array([])
90/4:
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
90/5: traced = np.sort(traced)
90/6: traced
90/7: traced[0,17:27]
90/8: traced[0]
90/9: traced[0][17:27]
90/10: traced[0][14:24]
90/11: traced[0][12:23]
90/12: import helper
90/13: vars=helper.traced_vars()
90/14: vars
90/15: p
90/16: d = np.loadtxt(p + traced[0])
90/17: s = np.where(d[:,0]==0)[0]
90/18: s
90/19: d[0:48,0]
90/20: d[0:49,0]
90/21: np.cumsum(d[0:48,9:])
90/22: np.cumsum(d[0:48,9:],axis=0)
90/23: np.cumsum(d[0:48,9:],axis=0).shape
90/24: np.cumsum(d[0:48,9:],axis=1).shape
90/25: np.cumsum(d[0:48,9:],axis=1)
90/26: np.cumsum(d[0:4,9:],axis=1)
90/27: d[0:4,9:]
90/28: np.cumsum(d[0:4,9:],axis=0)
90/29: t = np.zeros(d.shape)
90/30: t[:,0:9] = d[:,0:9]
90/31: t
90/32: t[0]
90/33: t[:,9]
90/34: s
90/35:
for n in s:
    t[n:n+48,9:] = np.cumsum(d[n:n+48,9:],axis=0)
90/36:
for n in s:
    t[n+1:n+48,9:] = np.cumsum(d[n+1:n+48,9:],axis=0)
90/37: t[n+1:n+48,9:-2]
90/38: vars
90/39: np.where(vars=='PVRLS')
90/40: vars[12]
90/41: vars[17]
90/42: vars[16]
90/43: d
90/44: d[0:4,9]
90/45: d[0:4,9:]
90/46: np.cumsum(d[0:4,9:],axis=0)
90/47: np.cumsum(d[0:4,9:],axis=0)[::-1]
90/48: d
90/49: d[0:10,9]
90/50: d[48,9:]=0
90/51: d[48]
90/52: s
90/53: s[-1]
90/54: s[-1]+48
90/55: d.shape
90/56: d[s[-1]]
90/57: d[s[-1]+48]
90/58: d[s[-1]+47]
90/59: d[s[0]+47]
91/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
91/2: acc
91/3: acc[0][15:]
91/4: acc[0][16:-5]
91/5: acc[0][16:-4]
91/6: helper.traced_vars()
91/7:
LSid = 16
labs = helper.traced_vars()
PVRs = labs[9:]
PVRsum = np.array(['PVRTOT','PVRLS','PVRTURB','PVRCONV','PVRRAD'])

for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    di = dict()
    for k, el in enumerate(labs):
        di[el] = d[:,k]
    t = d[:,0]
    id47 = np.where(t==(-47))
    id0 = np.where(t==0)
    DPV = d[id0,5]-d[id47,5]

    APVTOT = np.sum(d[:,9:],axis=0)-d[:,LSid]
    APVLS = d[:,LSid]
    APVTURB = di['PVRTURBM'] + di['PVRTURBT']
    APVCONV = di['PVRCONVM'] + di['PVRCONVT']
    APVRAD = di['PVRSW'] + di['PVRLWH'] + di['PVRLWC']
    RES = APVTOT[id0] - DPV
91/8: d
91/9: np.sum(d[:,9:],axis=0)
91/10: np.sum(d[:,9:],axis=1)
91/11: np.sum(d[:,9:],axis=1).shape
91/12:
LSid = 16
labs = helper.traced_vars()
PVRs = labs[9:]
PVRsum = np.array(['PVRTOT','PVRLS','PVRTURB','PVRCONV','PVRRAD'])

for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    di = dict()
    for k, el in enumerate(labs):
        di[el] = d[:,k]
    t = d[:,0]
    id47 = np.where(t==(-47))
    id0 = np.where(t==0)
    DPV = d[id0,5]-d[id47,5]

    APVTOT = np.sum(d[:,9:],axis=1)-d[:,LSid]
    APVLS = d[:,LSid]
    APVTURB = di['PVRTURBM'] + di['PVRTURBT']
    APVCONV = di['PVRCONVM'] + di['PVRCONVT']
    APVRAD = di['PVRSW'] + di['PVRLWH'] + di['PVRLWC']
    RES = APVTOT[id0] - DPV
91/13: RES
91/14: fig, ax = plt.subplots()
91/15: import matplotlib
91/16: import matplotlib.pyplot as plt
91/17: fig, ax = plt.subplots()
91/18: ax.plot(t,APVLS,color='r',label='LS')
91/19: fig.show()
91/20: plt.close()
91/21:
fig, ax = plt.subplots()

    for si in id0:
        ax.plot(t[si:si+47],APVTOT[si:si+47],color='k')
        ax.plot(t[si:si+47],APVLS[si:si+47],color='r')
        ax.plot(t[si:si+47],APVTURB[si:si+47],color='lightblue')
        ax.plot(t[si:si+47],APVCONV[si:si+47],color='orange')
        ax.plot(t[si:si+47],APVRAD[si:si+47],color='magenta')
        ax.plot(t[si:si+47],di['PVRCOND'][si:si+47],color='cyan')
91/22:
fig, ax = plt.subplots()

for si in id0:
        ax.plot(t[si:si+47],APVTOT[si:si+47],color='k')
        ax.plot(t[si:si+47],APVLS[si:si+47],color='r')
        ax.plot(t[si:si+47],APVTURB[si:si+47],color='lightblue')
        ax.plot(t[si:si+47],APVCONV[si:si+47],color='orange')
        ax.plot(t[si:si+47],APVRAD[si:si+47],color='magenta')
        ax.plot(t[si:si+47],di['PVRCOND'][si:si+47],color='cyan')
91/23: id0
91/24: t
91/25: si:si+47
91/26: print(si:si+47)
91/27: print(t[sisi+47])
91/28: print(t[si:si+47])
91/29: t[si:]
91/30: si
91/31: id0
91/32:
id47 = np.where(t==(-47))[0]
id0 = np.where(t==0)[0]
91/33: print(t[si:si+47])
91/34:
for si in id0:
        ax.plot(t[si:si+47],APVTOT[si:si+47],color='k')
        ax.plot(t[si:si+47],APVLS[si:si+47],color='r')
        ax.plot(t[si:si+47],APVTURB[si:si+47],color='lightblue')
        ax.plot(t[si:si+47],APVCONV[si:si+47],color='orange')
        ax.plot(t[si:si+47],APVRAD[si:si+47],color='magenta')
        ax.plot(t[si:si+47],di['PVRCOND'][si:si+47],color='cyan')
91/35: fig.show()
91/36: APVRAD
91/37: APVRAD.reshape(-1,48)
91/38: APVRAD.reshape(-1,48).shape
91/39: np.mean(APVRAD.reshape(-1,48),axis=1)
91/40: np.mean(APVRAD.reshape(-1,48),axis=0)
91/41: np.mean(APVRAD.reshape(-1,48),axis=0).shape
91/42: d = np.loadtxt(p + traced[0]).reshape(-1,48)
91/43: d = np.loadtxt(p + e).reshape(-1,48)
91/44: d
91/45: d.shape
91/46: d = np.loadtxt(p + e)
91/47: t = d[:,0].reshape(-1,48)
91/48: t
91/49: id0 = np.where(t==0)[0]
91/50: id0
91/51: np.mean(t,axis=0)
92/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
labs = helper.traced_vars()
var='PV'
unit = 'PVU'
vid = np.where(labs==var)
ptitle = np.array(['800 hPa < P$_{-47}$', '600 < P$_{-47} <$800 hPa', '400 < P$_{-47} <$600 hPa',  'P$_{-47} <$400 hPa'])

for u, e in enumerate(acc):
    if u==0:
        d = np.loadtxt(p + e)
    else:
        d =np.vstack((d,np.loadtxt(p + e)))

di = dict()
for k, el in enumerate(labs):
    di[el] = d[:,k].reshape(-1,48)

t = d[:,0].reshape(-1,48)
92/2: di[var][47].shape
92/3: di[var].shape
92/4:
v_start = di[var][:,47]
v_end = di[var][:,0]

fig, axes = plt.subplots(5,3,sharex=True, sharey=False)
axes = axes.flatten()
fig.tight_layout()
92/5:
hh=47
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            h = ax.hist2d(v_start[idp],v_end[idp],bins=30)
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)
            print(h)
93/1: import numpy as np
93/2: np.arange(15)[::2]
93/3: np.arange(15)[2::2]
93/4: np.arange(15)[2::3]
93/5:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
labs = helper.traced_vars()
var='PV'
unit = 'PVU'
vid = np.where(labs==var)
ptitle = np.array(['800 hPa < P$_{-47}$', '600 < P$_{-47} <$800 hPa', '400 < P$_{-47} <$600 hPa',  'P$_{-47} <$400 hPa'])

for u, e in enumerate(acc):
    if u==0:
        d = np.loadtxt(p + e)
    else:
        d =np.vstack((d,np.loadtxt(p + e)))

di = dict()
for k, el in enumerate(labs):
    di[el] = d[:,k].reshape(-1,48)

t = d[:,0].reshape(-1,48)
v_start = di[var][:,47]
v_end = di[var][:,0]

fig, axes = plt.subplots(5,3,sharex=True, sharey=False)
axes = axes.flatten()
93/6:
hh=47
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            hq=0
            hq=ax.hist2d(v_start[idp],v_end[idp],bins=30)
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)


        ax.set_xlabel(xlab,fontsize=8)
        ax.set_ylabel(ylab,fontsize=8)
        ax.set_xlim(xlim)
93/7: fig.colorbar(hq,ax=[axes[2::3]])
93/8: hq
93/9: hq.type
93/10: type(hq)
93/11: plt.close('all')
93/12:
fig, axes = plt.subplots(5,3,sharex=True, sharey=False)
axes = axes.flatten()
93/13:
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            hq=0
            hq=ax.hist2d(v_start[idp],v_end[idp])
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)


        ax.set_xlabel(xlab,fontsize=8)
        ax.set_ylabel(ylab,fontsize=8)
        ax.set_xlim(xlim)
93/14: fig.colorbar(hq,ax=[axes[2::3]])
93/15: plt.close('all')
93/16:
fig, axes = plt.subplots(5,3,sharex=True, sharey=False)
axes = axes.flatten()
93/17:
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            h=ax.hist2d(v_start[idp],v_end[idp],bins=30,cmap='Reds')
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)


        ax.set_xlabel(xlab,fontsize=8)
        ax.set_ylabel(ylab,fontsize=8)
        ax.set_xlim(xlim)

fig.colorbar(h,ax=[axes[2::3]])
93/18: plt.close('all')
93/19:
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            h=ax.hist2d(v_start[idp],v_end[idp],bins=30,cmap='Reds')
            fig.colorbar(h,ax=[axes[2::3]])
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)
            

        ax.set_xlabel(xlab,fontsize=8)
        ax.set_ylabel(ylab,fontsize=8)
        ax.set_xlim(xlim)
93/20: plt.close()
93/21:
for q, ax in enumerate(axes):
        if q<3:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]>800)[0]
        elif q<6:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<800) & (d[:,3].reshape(-1,48)[:,hh]>600))[0]
        elif q<9:
            idp = np.where((d[:,3].reshape(-1,48)[:,hh]<600) & (d[:,3].reshape(-1,48)[:,hh]>400))[0]
        elif q<12:
            idp = np.where(d[:,3].reshape(-1,48)[:,hh]<400)[0]
        else:
            idp = np.arange(0,len(d[:,3].reshape(-1,48)))

        if (q%3)==0:
            ax.hist(v_start[idp],bins=30)
            ylab='counts'
            xlab=var+' start value [%s]'%unit
            xlim=np.array([-0.5,3])

        elif (q%3)==1:
            ax.hist(v_end[idp],bins=30)
            ylab='coutns'
            xlab=var + ' end value [%s]'%unit
            xlim=np.array([0.5,5])

        else:
            h=ax.hist2d(v_start[idp],v_end[idp],bins=30,cmap='Reds')
            fig.colorbar(h[3],ax=[axes[2::3]])
            ylab=var + ' end value [%s]' %unit
            xlab=var + ' start value [%s]' %unit
            xlim=np.array([-0.5,3])
            ylim=np.array([0.5,5])
            ax.set_ylim(ylim)
            

        ax.set_xlabel(xlab,fontsize=8)
        ax.set_ylabel(ylab,fontsize=8)
        ax.set_xlim(xlim)
93/22: plt.show()
93/23: fig.show()
93/24: plt.close()
94/1: import numpy as np
94/2: dates = np.loadtxt('dates-vorticitymature.txt')
94/3: labels = np.loadtxt('labels-vorticitymature.txt',dtype=int)
94/4: htzeta = np.loadtxt('htmaxzeta-vorticitymature.txt')
94/5: di = dict()
94/6:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
94/7:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
94/8:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
95/1:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
95/2: import numpy as np
95/3:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
95/4: htzeta = np.loadtxt('htmaxzeta-vorticitymature.txt')
95/5: dates = np.loadtxt('dates-vorticitymature.txt')
95/6: labels = np.loadtxt('labels-vorticitymature.txt',dtype=int)
95/7: di =dict()
95/8:
LSid = 16
labs = helper.traced_vars()
for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    di[date]=dict()
    for k, el in enumerate(labs):
        di[date][el] = d[:,k].reshape(-1,48)
95/9: di.keys()[0]
95/10: di.keys()
95/11: di.keys(0)
95/12: di.keys()
95/13:
for qw in di.keys():
    print(qw)
95/14: di.keys[0]
95/15: di.keys().0
95/16: di.keys().
95/17: di.keys().values
95/18: di.items()
95/19: di.items()[0]
95/20: l = di.keys()
95/21: l[0]
95/22: l
95/23: l = di.values()
95/24: l
95/25: l = di.items()
95/26: l
95/27: maturedates = np.array([])
95/28:
for qw in di.keys():
    maturedates = np.append(maturedates,qw)
95/29: maturedates
95/30: testid = np.where((dates==maturedates[1])& (labels==2))
95/31: testid
95/32: testid = np.where( (dates==maturedates[1]) & (htzeta==0))
95/33: testid
95/34: dates
95/35: dates = np.loadtxt('dates-vorticitymature.txt',dtype=str)
95/36: testid = np.where( (dates==maturedates[1]) & (htzeta==0))
95/37: testid
95/38: testid = np.where( (dates==maturedates[1]) & (htzeta==0) & (label==2))[0]
95/39: testid = np.where( (dates==maturedates[1]) & (htzeta==0) & (labels==2))[0]
95/40: testid
95/41: clat = np.loadtxt('centerlatitude-vorticitymature.txt',dtype=int)
95/42: clon = np.loadtxt('centerlongitude-vorticitymature.txt',dtype=int)
95/43: tmphtz = np.array([])
95/44: tmpid = np.array([])
95/45:
date = maturedate[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if hh<0:
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k))[0][0]
    if (tmpq):
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq])
        hh-=k
    else:
        break
95/46:
date = maturedate[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if hh<0:
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k))[0][0]
    if (tmpq>0):
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq])
        hh-=k
    else:
        break
95/47:
date = maturedate[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k))[0][0]
    if(tmpq>0):
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq])
        hh-=k
    else:
        break
95/48:
date = maturedate[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k))[0][0]
    print(tmpq)
    if(tmpq>0):
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq])
        hh-=k
    else:
        break
95/49:
date = maturedate[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
95/50:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,kk)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
95/51:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
95/52:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))
95/53: tmpq
95/54:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))
    print(tmpq)
95/55:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))
    print(Date)
95/56:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))
    hh-=1
    print(Date)
95/57:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))
    hh-=1
    print(tmpq)
95/58:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
    hh-=1
    if(tmpq>0):
         tmphtz = np.append(tmphtz,htzeta[tmpq])
         tmpid = np.append(tmpid,tmpq)
95/59:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]):
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/60: tmphtz
95/61:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))):
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/62: tmphtz
95/63: tmphtz = np.array([])
95/64: tmpid = np.array([])
95/65:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))):
        tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/66:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k))).size):
        tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/67:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
        tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/68: tmpid = np.array([])
95/69: tmphtz = np.array([])
95/70:
date = maturedates[1]
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
        tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
95/71: tmphtz
96/1:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

maturedates = np.array([])
for qw in di.keys():
     maturedates = np.append(maturedates,qw)
96/2: np.where((dates=='20171214_02'))
96/3: np.where((dates=='20171214_02')&(labels==2))
96/4: np.where((dates=='20171214_02')&(labels==2)&(htzeta==0))
96/5: date
96/6: date = maturedates[1]
96/7:
did=dict()

for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

maturedates = np.array([])
for qw in did.keys():
     maturedates = np.append(maturedates,qw)
96/8: labs = helper.traced_vars()
96/9:
for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

maturedates = np.array([])
for qw in did.keys():
     maturedates = np.append(maturedates,qw)
96/10: date = maturedates[1]
96/11:
yyyy = int(date[0:4])
MM = int(date[4:6])
DD = int(date[6:8])
hh = int(date[9:])
96/12:
tmpid = np.array([])
tmphtz = np.array([])
tmpdates = np.array([])
96/13:
for k in range(0,48):
    if (hh<0):
        hh=23
        DD-=1
    Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
    if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
        tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
        hh-=1
        tmphtz = np.append(tmphtz,htzeta[tmpq])
        tmpid = np.append(tmpid,tmpq)
        tmpdates = np.append(tmpdates,Date)
96/14: tmpdates
96/15: tmphtz
96/16:
did=dict()
dih=dict()
maturedates = np.array([])

for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

    tmpid = np.array([])
    tmphtz = np.array([])
    tmpdates = np.array([])

    maturedates = np.append(maturedates,date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmpdates = np.append(tmpdates,Date)
    dih[date] = tmpid
96/17: did
96/18: dih
96/19: date
96/20: dih[date] = tmpid.astype(int)
96/21: dih
96/22:
for tr,el in enumerate(dih[date]):
    print(np.mean(clat[tr]))
96/23:
for tr,el in enumerate(dih[date]):
    print(clat[el])
96/24:
for tr,el in enumerate(dih[date]):
    print(np.mean(clat[el]))
96/25:
for tr,el in enumerate(dih[date]):
    print(np.mean(clon[el]))
96/26:
dic=dict()
for u, e in enumerate(acc):
    date = e[16:-4]
    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
96/27: dic[:]['lon']
96/28: dic[date]['lon']
96/29: dit=dict()
96/30:
def month_days(yr):
    if yr%4==0:
        return np.array([31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])
    else:
        return np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])
96/31:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()
    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
96/32: dic
96/33: did[date]['lon']
96/34: dic[date]['lon']
96/35: dic[date]['lon'][-1] + helper.radial_ids_around_center(200)[0]
96/36: dih['h']
96/37: dih[date]['h']
96/38:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()
    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
96/39: dih[date]['h']
96/40: did[date]['lon']
96/41: did[date]['lat']
97/1:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)


did=dict() #data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
maturedates = np.array([])
97/2:
for u, e in enumerate(acc):
    date = e[16:-4]
    maturedates = np.append(maturedates,date)

    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

#for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date]['cycl'] = dict()
    dit[date]['env'] = dict()
97/3: dih[date]['h']
97/4: did[date]
97/5: did[date]['time]
97/6: did[date]['time']
97/7: did[date]['time'].shape
97/8: len(did[date]['time'].shape)
97/9: len(did[date]['time'])
97/10: len(did[date]['lon']).shape
97/11: did[date]['lon'].shape
97/12: did[date]['lon'][0][0]
97/13: did[date]['lon'][0,0]
97/14:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/15: dit[date]
97/16: dit[date][0]
97/17: dic[date]['lon'][e]
97/18: dic[date]['lon']
97/19: tmphtz
97/20: dit[date][:0,]
97/21: dit[date][:,0]
97/22: dit[date].shape
97/23: dit[date][0]
97/24: dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
97/25: dit[date].shape
97/26: dit[date]
97/27:
for e, h in enumerate(dih[date]['h']):
    print(e)
97/28: did[date]['lon'].shape
97/29: did[date]['lon'][:,0]
97/30: did[date]['lon'][0]
97/31: LON[tmplon]
97/32: LAT[tmplat]
97/33: dit['20171214_02']
97/34: dit['20171214_02'][:,0]
97/35: dit['20171214_02'][0]
97/36: tmplon
97/37: LON[tmplon]
97/38:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1]
        print(LON[dic[date]['lon'][e]],LAT[dic[date]['lat'][e]])
        for tr in range(len(did[date]['time'])):
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/39:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1]
        print(e,h,LON[dic[date]['lon'][e]],LAT[dic[date]['lat'][e]])
        for tr in range(len(did[date]['time'])):
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/40:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1]
        print(e,h,np.min(LON[tmplon]),np.max(LON[tmplon]),np.min(LAT[tmplat]),np.max(LAT[tmplat]))
        for tr in range(len(did[date]['time'])):
            print(did[date]['lon'][tr,e],did[date]['lat'][tr,e])
            sleep 10s
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/41: import time
97/42:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1]
        print(e,h,np.min(LON[tmplon]),np.max(LON[tmplon]),np.min(LAT[tmplat]),np.max(LAT[tmplat]))
        for tr in range(len(did[date]['time'])):
            print(did[date]['lon'][tr,e],did[date]['lat'][tr,e])
            
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        time.sleep(5)
97/43: clat.shape
97/44: np.mean(clat[2608])
97/45: LAT[int(np.mean(clat[2608]))]
97/46: LAT[int(np.mean(clat[2608]))+5]
97/47: LAT[int(np.mean(clat[2608]))+4]
97/48:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0] + 1
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1] + 1 
        print(e,h,np.min(LON[tmplon]),np.max(LON[tmplon]),np.min(LAT[tmplat]),np.max(LAT[tmplat]))
        for tr in range(len(did[date]['time'])):
                        
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/49: dit[date][:,0]
97/50:
date = '20171214_02'
for e, h in enumerate(dih[date]['h']):
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0] + 1
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1] + 1 
        print(e,h,np.min(LON[tmplon]),np.max(LON[tmplon]),np.min(LAT[tmplat]),np.max(LAT[tmplat]))
        for tr in range(len(did[date]['time'])):
                        
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
97/51: dit[date]
97/52: np.where(dit[date]==1)
97/53: dit[date][-1]
97/54: d
97/55: np.sum(d[:,9:],axis=1).reshape(-1,48)-(d[:,LSid]).reshape(-1,48)
97/56: LSid = 16
97/57: np.sum(d[:,9:],axis=1).reshape(-1,48)-(d[:,LSid]).reshape(-1,48)
97/58: (np.sum(d[:,9:],axis=1).reshape(-1,48)-(d[:,LSid]).reshape(-1,48)).shape
97/59: APVLS = (d[:,LSid]).reshape(-1,48)
97/60: APVLS
97/61: np.sum(np.array([1,2,3,4,5,6,7,8,9]))
97/62: np.sum(np.array([1,2,3,4,5,6,7,8,9]),where=np.array([0,0,0,0,1,0,0,0,0]))
97/63: np.sum(np.array([1,2,3,4,5,6,7,8,9]),where=np.array([0,0,0,0,1,0,0,0,0]).astype(bool))
97/64: dit
97/65: dit[date]
97/66: dit[date].astype(bool)
97/67: dipv=dict()
97/68: env='env'
97/69: cyc='cyc'
97/70: dipv[env]=dict()
97/71: dipv[cyc]=dict()
97/72: PVRsum = np.array(['PVRTOT','PVRLS','PVRTURB','PVRCONV','PVRRAD'])
97/73: ~dit[date].astype(bool)
97/74: (d[:,LSid]).reshape(-1,48)
97/75: np.sum(d[:,9:],axis=1).reshape(-1,48)
97/76: d[:,9:]
97/77: d[:,9:].shape
97/78: np.sum(d[:,9:],axis=1)
97/79: np.sum(d[:,9:],axis=1).shape
97/80: ls
97/81: np.cumsum(np.array([1,2,3,4,5,6,7,8,9]),where=np.array([0,0,0,0,1,0,0,0,0]).astype(bool))
98/1:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
### use traced-vars here, as the environmental and cyclonic splitting requires the rates and not the sumes
### the rates are summed later/below to create the accumulated values
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

LSid = 16

did=dict() #raw data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
dipv=dict()
env = 'env'
cyc = 'cyc'
dipv[env] = dict()
dipv[cyc] = dict()
maturedates = np.array([])
98/2:
for u, e in enumerate(acc):
    date = e[16:-4]
    maturedates = np.append(maturedates,date)

    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

#for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(200)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/3: ls *.txt
98/4:
for u, e in enumerate(acc):
    date = e[12:-4]
    maturedates = np.append(maturedates,date)

    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

#for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(200)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/5: date='20171214_02'
98/6: dit[date]
98/7: less traced-vars-20171214_02.txt
98/8: labs
98/9: dic[date]['lon']
98/10: dic[date]['lat']
98/11: yyyy
98/12: MM
98/13: DD
98/14: hh
98/15: dit
98/16:
acc = np.array([])
### use traced-vars here, as the environmental and cyclonic splitting requires the rates and not the sumes
### the rates are summed later/below to create the accumulated values
for d in os.listdir(p):
    if(d.startswith('accumu')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

LSid = 16

did=dict() #raw data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
dipv=dict()
env = 'env'
cyc = 'cyc'
dipv[env] = dict()
dipv[cyc] = dict()
maturedates = np.array([])
98/17:
for u, e in enumerate(acc):
    date=e[16:-4]
#    date = e[12:-4]
    maturedates = np.append(maturedates,date)

    d = np.loadtxt(p + e)
    did[date] = dict()
    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)

#for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(0))
            tmplat = np.append(tmplat,np.mean(0))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(200)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(200)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/18: dit
98/19:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,np.mean(0))
            tmplat = np.append(tmplat,np.mean(0))

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0] + 1
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1] + 1
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
98/20: dit
98/21: dit[date]
98/22: did[date]['lon']
98/23: tmplon
98/24: tmplat
98/25: dic[date]['lon']
98/26:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center(200)[0] + 1
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center(200)[1] + 1
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>=np.min(LON[tmplon]) ) & (did[date]['lon'][tr,e]<=np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>=np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<=np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/27: dit
98/28: date='20171214_02'
98/29: dit[date]
98/30: np.where(dit[date])
98/31: dit[date][0]
98/32: did[date][0]
98/33: did[date]
98/34: did[date]['lon'][0]
98/35: dic[date]['lon']
98/36: LON[dic[date]['lon']]
98/37: LON[dic[date]['lon']-4]
98/38: LON[dic[date]['lon']+4]
98/39: did[date]['lat'][0]
98/40: LAT[dic[date]['lat']+4]
98/41: LAT[dic[date]['lat']+4]
98/42: LAT[dic[date]['lat']-4]
98/43: did[date]['lon'][0][1]
98/44: did[date]['lat'][0][1]
98/45: LAT[dic[date]['lat']-4],LAT[dic[date]['lat']+4]
98/46: LON[dic[date]['lon']+4], LON[dic[date]['lon']-4]
98/47: helper.radial_ids_around_center_calc(200)
98/48: helper.radial_ids_around_center_calc(220)
98/49: helper.radial_ids_around_center_calc(230)
98/50:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(230)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(230)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon]),1) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/51:
for date in maturedates:

    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(230)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(230)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add smaller eq/ larger eq
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon])) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):
                dit[date][tr,e]=1
        dit[date] = dit[date].astype(bool)
98/52: dit['20171214_02']
98/53: help
98/54: help(numpy.cumsum)
98/55: help(np.cumsum)
98/56: dit[date] = dit[date].astype(int)
98/57: dit[date]
98/58: env
98/59: dipv[env]
98/60: dipv
98/61: dipv[date] = dipv
98/62: dipv[date]
98/63: dipv=dict()
98/64: dipv[date]=dict()
98/65: dipv[date][env]=dict()
98/66: dipv[date][cyc]=dict()
98/67: dipv[date][cyc]['APVLS'] = np.zeros(did[date]['APVLS'].shape)
98/68: labs
98/69: dipv[date][cyc]['APVLS'] = np.zeros(did[date]['PVRLS'].shape)
98/70: dipv[date][cyc]['APVLS']
98/71: dipv[date][cyc]['APVLS'][0:47] = np.cumsum(did[date]['PVRLS'][1:48] * dit[date],axis=0)[::-1]
98/72: did[date]['PVRLS'].shape
98/73: dipv[date][cyc]['APVLS'].shape
98/74: dipv[date][cyc]['APVLS'][0:47] = np.cumsum(did[date]['PVRLS'][:,1:48] * dit[date],axis=0)[::-1]
98/75: dipv[date][cyc]['APVLS'][0:47] = np.cumsum(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=0)[::-1]
98/76: dit[date].shape
98/77: did[date]['PVRLS'].shape
98/78: dipv[date][cyc]['APVLS'].shape
98/79: dipv[date][cyc]['APVLS'][:,0:47] = np.cumsum(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=0)[::-1]
98/80: dipv[date][cyc]['APVLS']
98/81: dipv[date][cyc]['APVLS'][:,0:47] = np.cumsum(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)[::-1]
98/82: dipv[date][cyc]['APVLS']
98/83: did[date]['PVRLS'][:,1:48]
98/84: did[date]['PVRLS'][:,1:48] * dit[date][:,1:48]
98/85: (did[date]['PVRLS'][:,1:48] * dit[date][:,1:48])[0]
98/86: np.cumsum((did[date]['PVRLS'][:,1:48] * dit[date][:,1:48])[0])
98/87: np.cumsum((did[date]['PVRLS'][:,1:48] * dit[date][:,1:48])[0])[::-1]
98/88: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48]))[0])
98/89: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48]))[0])[::-1]
98/90: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1))[0])[::-1]
98/91: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)),axis=0)[::-1]
98/92: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)),axis=1)[::-1]
98/93: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)),axis=1)
98/94: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)),axis=1)[::-1]
98/95: np.cumsum((np.flip(did[date]['PVRLS'][:,1:48] * dit[date][:,1:48],axis=1)),axis=1)[:,::-1]
98/96:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(len(traced2)):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
    for n in s2:
        print(n)
        #normally 49, but made mistake at the beginning
       # hour/the current PVR is not accounted for
        # write the revers cumsum into the hours, such that -1h contains the full
        # accumulated PV over the hours -48 to -2, i.e. up to this point.
        # and make -48h 0, as there is no accum PV before
98/97:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d2.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(len(traced2)):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
    for n in s2:
        print(n)
        #normally 49, but made mistake at the beginning
       # hour/the current PVR is not accounted for
        # write the revers cumsum into the hours, such that -1h contains the full
        # accumulated PV over the hours -48 to -2, i.e. up to this point.
        # and make -48h 0, as there is no accum PV before
98/98:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d2.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(1):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
    print(d2)
98/99:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d2.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(1):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
    print(d2.shape)
98/100:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d2.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(1):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
    print(d2[:,9:].shape)
98/101: \d2
98/102: d2
98/103: s
98/104: s2
98/105: d
98/106: d2
98/107: d2.shape
98/108:
for ut in range(10000):
    print(ut)
98/109: d2[0:47,9:]
98/110: d2[0:47,9:].shape
98/111: d2[0:47,9:][:,1]
98/112: d2[0:47,9:][:,1:3]
98/113: np.flip(d2[0:47,9:][:,1:3],axis=0)
98/114: np.cumsum(np.flip(d2[0:47,9:][:,1:3],axis=0),axis=0)
98/115: n
98/116: n=0
98/117: np.cumsum(d2[n+1:n+48,9:13],axis=0)
98/118: d2[n+1:n+48,9:13]
98/119: d2[n+1:n+48,9:11]
98/120: np.cumsum(d2[n+1:n+48,9:11],axis=0)
98/121: np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)
98/122: np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[:,::-1]
98/123: np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:]
98/124: d2
98/125: d2[n:n+47,9:]
98/126: d2[n:n+47,9:14]
98/127: tmpqr = d2[n:n+47,9:14]
98/128: d2[n:n+47,9:14]=np.cumsum(np.flip(d[n+1:n+48,9:14],axis=0),axis=0)[::-1,:]
98/129: d2[n:n+47,9:14]
98/130: tmpqr
98/131: n=48
98/132: d2[n:n+47,9:14]
98/133: tmpqr = d2[n:n+47,9:14]
98/134: d2[n:n+47,9:14]=np.cumsum(np.flip(d[n+1:n+48,9:14],axis=0),axis=0)[::-1,:]
98/135: d2[n:n+47,9:14]
98/136: tmpqr
98/137:
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced2 = np.array([])
nn = 'accumulated-PVR-'
for d2 in os.listdir(p):
    if(d2.startswith('traced-vars')):
            traced2 = np.append(traced2,d2)
traced2 = np.sort(traced2)

##PVRLS is the entry 16
LSid = 16

for k2 in range(1):
    date = traced2[k2][12:23]
    d2 = np.loadtxt(p + traced2[k2])
    s2 = np.where(d2[:,0]==0)[0]
98/138: n = 0
98/139: d2[n:n+47,9:11]
98/140: np.flip(d2[n:n+47,9:11])
98/141: np.flip(d2[n:n+47,9:11],axis=0)
98/142: np.cumsum(np.flip(d2[n:n+47,9:11],axis=0),axis=0)
98/143: np.cumsum(np.flip(d2[n:n+47,9:11],axis=0),axis=0)[::-1,:]
98/144: np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:]
98/145: tmpqr = np.zeros(np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape)
98/146: tmpqr
98/147: tmpqr = np.zeros(np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape+1)
98/148: tmpqr = np.zeros((np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[0]+1,np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[1]+1))
98/149: tmpqr.shape
98/150: tmpqr
98/151: tmpqr = np.zeros((np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[0]+1,np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[1]))
98/152: tmpqr
98/153: tmpqr[n:n+47,:] = np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:]
98/154: tmpqr
98/155: tmpqr2 = np.zeros((np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[0]+1,np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[1]))
98/156: tmpqr2 = np.zeros((np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[0]+1,np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:].shape[1]+2))
98/157: tmpqr2[n:n+47,:2] = np.cumsum(np.flip(d2[n+1:n+48,9:11],axis=0),axis=0)[::-1,:]
98/158: tmpqr2[n:n+47,2:] = np.cumsum(d2[n+1:n+48,9:11],axis=0)[::-1]
98/159: tmpqr2
98/160: dipv[date][cyc]['APVLS']
98/161: date='20171214_02'
98/162: dipv[date][cyc]['APVLS']
98/163: dipv
98/164: did[date]['PVRLS'].shape
98/165: did[date]['PVRLS'][0]
98/166: did[date]['PVRCOND'][0]
98/167: did[date]['PVRCOND'][0].shape
98/168: :q
98/169: less traced-vars-20171214_02.txt
98/170: dipv[date][cyc]['APVLS']
98/171: date='20180228_09'
98/172: dipv[date][cyc]['APVLS']
98/173: did[date]['PVRLS'].shape
98/174: did[date]['PVRLS']*dit[date]
98/175: np.flip(did[date]['PVRLS']*dit[date],axis=1)
98/176: np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1))
98/177: np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1),axis=1)
98/178: np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1),axis=0)
98/179: np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1),axis=1)
98/180: dit[date][0]
98/181: np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1),axis=1)[:,::-1]
98/182: dipv[date][cyc]['APVLS'] = np.cumsum(np.flip(did[date]['PVRLS']*dit[date],axis=1),axis=1)[:,::-1]
98/183: dipv[date][cyc]['APVLS']
98/184: dit[date][0]
98/185: ~dit[date][0]
98/186: (~(dit[date][0].astype(bool))).astype(int)
98/187: (~(dit[date].astype(bool))).astype(int)
99/1: import numpy as np
99/2: import os
99/3: start = ['clat-vort-','clon-vort-','dates-vort-','labels-vort-','htmaxzeta-vort-','htSLPmin-vort']
99/4: end=['DJF.txt','JJA.txt','MAM.txt','SON.txt']
99/5:
dt = [int,int,str,int,int,int]
for t, m in start:
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype-dt[t])
                    sdata = np.vstacke((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/6:
dt = [int,int,str,int,int,int]
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype-dt[t])
                    sdata = np.vstacke((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/7:
dt = [int,int,str,int,int,int]
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    sdata = np.vstacke((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/8:
dt = [int,int,str,int,int,int]
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    sdata = np.vstack((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/9:
dt = [int,int,str,int,int,int]
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                print(q,m)
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    sdata = np.vstack((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/10:
dt = [int,int,str,int,int,int]
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                print(q,m)
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    if (t>1):
                        sdata = np.append(sdata,tmp)
                    else:
                        sdata = np.vstack((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),delimiter=' ', newline='\n')
99/11:
dt = [int,int,str,int,int,int]
fmt = ['%d','%d','%s','%d','%d','%d']
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                print(q,m)
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    if (t>1):
                        sdata = np.append(sdata,tmp)
                    else:
                        sdata = np.vstack((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),fmt=fmt[t]delimiter=' ', newline='\n')
99/12:
dt = [int,int,str,int,int,int]
fmt = ['%d','%d','%s','%d','%d','%d']
for t, m in enumerate(start):
    save = m + 'entire-year.txt'
    for q,u in enumerate(end):
        for d in os.listdir('./'):
            if( (d.startswith(m))  & d.endswith(u)):
                print(q,m)
                if (q==0):
                    sdata = np.loadtxt(d,dtype=dt[t])
                else:
                    tmp = np.loadtxt(d,dtype=dt[t])
                    if (t>1):
                        sdata = np.append(sdata,tmp)
                    else:
                        sdata = np.vstack((sdata,tmp))
    np.savetxt(save,sdata.astype(dt[t]),fmt=fmt[t],delimiter=' ', newline='\n')
99/13: %save -r stacktxtfiles 1-99
99/14: ls -lrt
99/15: %save -r stacktxtfiles.py 1-99
99/16: ls -lrt
99/17: rm  stacktxtfiles.ipy
100/1: import sys
100/2: import numpy as np
100/3: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
100/4: import helper
100/5: q = helper.traced_vars()
100/6: q
100/7:
for k, el in enumerate(q[9:]):
    print(k,el)
100/8:
for k, el in enumerate(q):
    print(k,el)
100/9: np.array([0,7,8,12])/np.array([0,1,2,6])
100/10: q = np.array([0,7,8,12])/np.array([0,1,2,6])
100/11: q
100/12: q[q<0]
100/13: q[q==nan]
100/14: np.isnan(q)
100/15: q[np.isnan(q)]=0
100/16: q
100/17: labs=helper.traced_vars
100/18: labs
100/19: labs=helper.traced_vars()
100/20: labs
100/21: labs.append('APVTOT')
100/22: labs = np.append(labs,'APVTOT')
100/23: labs
100/24:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
### use traced-vars here, as the environmental and cyclonic splitting requires the rates and not the sumes
### the rates are summed later/below to create the accumulated values
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

LSid = 16

did=dict() #raw data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
dipv=dict()
dimean=dict()

envc = np.zeros(48)
cycc = np.zeros(48)

env = 'env'
cyc = 'cyc'

dimean[env]=dict()
dimean[cyc]=dict()
for u in labs[9:]
    dimean[env][u] = np.zeros(48)
    dimean[cyc][u] = np.zeros(48)
dimean[env]['APVTOT'] = np.zeros(48)
dimean[cyc]['APVTOT'] = np.zeros(48)

maturedates = np.array([])
t0= np.arange(-47,1,1)
100/25:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
### use traced-vars here, as the environmental and cyclonic splitting requires the rates and not the sumes
### the rates are summed later/below to create the accumulated values
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            acc = np.append(acc,d)
acc = np.sort(acc)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

LSid = 16

did=dict() #raw data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
dipv=dict()
dimean=dict()

envc = np.zeros(48)
cycc = np.zeros(48)

env = 'env'
cyc = 'cyc'

dimean[env]=dict()
dimean[cyc]=dict()
for u in labs[9:]:
    dimean[env][u] = np.zeros(48)
    dimean[cyc][u] = np.zeros(48)
dimean[env]['APVTOT'] = np.zeros(48)
dimean[cyc]['APVTOT'] = np.zeros(48)

maturedates = np.array([])
t0= np.arange(-47,1,1)
100/26:
for u, e in enumerate(acc):
    date=e[16:-4]
    maturedates = np.append(maturedates,date)
    d = np.loadtxt(p + e)
    did[date] = dict()
    dipv[date]=dict()
    dipv[date][env] = dict()
    dipv[date][cyc] = dict()

    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)
        dipv[date][env][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
        dipv[date][cyc][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
#for date in maturedates:
    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(230)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(230)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add 1 gridpoint and require the date to be truely grater/smaller
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon])) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):

                dit[date][tr,e]=1
    cycc += np.sum(dit[date],axis=0)
    envc += np.sum((~(dit[date].astype(bool))).astype(int),axis=0)

    for we,lab in enumerate(labs[9:]):
        dipv[date][cyc][lab] = np.cumsum(np.flip(did[date][lab]*dit[date],axis=1),axis=1)[:,::-1]
        dipv[date][env][lab] = np.cumsum(np.flip(did[date][lab]*(~(dit[date].astype(bool))).astype(int),axis=1),axis=1)[:,::-1]
        if we==0:
            dipv[date][cyc]['APVTOT'] = dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] = dipv[date][env][lab]
        else:
            dipv[date][cyc]['APVTOT'] += dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] += dipv[date][env][lab]
        dimean[cyc][lab] +=np.sum(dipv[date][cyc][lab],axis=0)
        dimean[env][lab] +=np.sum(dipv[date][env][lab],axis=0)

    dipv[date][cyc]['APVTOT'] -= dipv[date][cyc]['PVRLS']
    dipv[date][env]['APVTOT'] -= dipv[date][env]['PVRLS']
    dimean[cyc]['APVTOT'] += np.sum(dipv[date][cyc]['APVTOT'],axis=0)
    dimean[env]['APVTOT'] += np.sum(dipv[date][env]['APVTOT'],axis=0)
100/27:
for u, e in enumerate(acc):
    date=e[12:-4]
    maturedates = np.append(maturedates,date)
    d = np.loadtxt(p + e)
    did[date] = dict()
    dipv[date]=dict()
    dipv[date][env] = dict()
    dipv[date][cyc] = dict()

    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)
        dipv[date][env][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
        dipv[date][cyc][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
#for date in maturedates:
    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<0):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(230)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(230)[1]
        for tr in range(len(did[date]['time'])):
            ### if traj. pos is close to cyclone center (square of 400km side length around center)
            ### set entry = 1
            ### for safety add 1 gridpoint and require the date to be truely grater/smaller
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon])) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):

                dit[date][tr,e]=1
    cycc += np.sum(dit[date],axis=0)
    envc += np.sum((~(dit[date].astype(bool))).astype(int),axis=0)

    for we,lab in enumerate(labs[9:]):
        dipv[date][cyc][lab] = np.cumsum(np.flip(did[date][lab]*dit[date],axis=1),axis=1)[:,::-1]
        dipv[date][env][lab] = np.cumsum(np.flip(did[date][lab]*(~(dit[date].astype(bool))).astype(int),axis=1),axis=1)[:,::-1]
        if we==0:
            dipv[date][cyc]['APVTOT'] = dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] = dipv[date][env][lab]
        else:
            dipv[date][cyc]['APVTOT'] += dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] += dipv[date][env][lab]
        dimean[cyc][lab] +=np.sum(dipv[date][cyc][lab],axis=0)
        dimean[env][lab] +=np.sum(dipv[date][env][lab],axis=0)

    dipv[date][cyc]['APVTOT'] -= dipv[date][cyc]['PVRLS']
    dipv[date][env]['APVTOT'] -= dipv[date][env]['PVRLS']
    dimean[cyc]['APVTOT'] += np.sum(dipv[date][cyc]['APVTOT'],axis=0)
    dimean[env]['APVTOT'] += np.sum(dipv[date][env]['APVTOT'],axis=0)
100/28: dimean.item()
100/29: dimean.items()
100/30:
labs = np.append(labs,'APVTOT')
for u in labs[9:]:
    dimean[cyc][u] /= cycc[:]
    dimean[env][u] /= encc[:]
    dimean[cyc][u][np.isnan(dimean[cyc][u])]=0
    dimean[env][u][np.isnan(dimean[env][u])]=0
100/31:
for u in labs[9:]:
    dimean[cyc][u] /= cycc[:]
    dimean[env][u] /= encv[:]
    dimean[cyc][u][np.isnan(dimean[cyc][u])]=0
    dimean[env][u][np.isnan(dimean[env][u])]=0
100/32:
for u in labs[9:]:
    dimean[cyc][u] /= cycc[:]
    dimean[env][u] /= envc[:]
    dimean[cyc][u][np.isnan(dimean[cyc][u])]=0
    dimean[env][u][np.isnan(dimean[env][u])]=0
100/33: fig, ax = plt.subplots()
100/34: ax.plot(t,dimean[cyc]['APVTOT'],color='k',ls='-')
100/35: t0.shape
100/36: dimean[cyc]['APVTOT'].shape
100/37: d[:,0].reshape(-1,48)
100/38: t =d[:,0].reshape(-1,48)[0]
100/39: t
100/40: ax.plot(t,dimean[cyc]['APVTOT'],color='k',ls='-')
100/41: ax.plot(t,dimean[env]['APVTOT'],color='k',ls='--')
100/42: fig.show()
100/43: dimean[env]['APVTOT']
100/44: 0/0
100/45: 0./0.
100/46: cycc
100/47: envc
100/48: cycc-envc
100/49: np.inf
100/50: dimean[env]['APVTOT']==np.inf
100/51: plt.close()
100/52: fig, ax = plt.subplots()
100/53: labs
100/54: cl=['k','orange','green','blue','lightblue','magenta','grey','r']
100/55: pllab = ['APVTOT','PVRCONVT', 'PVRCONVM', 'PVRTURBT', 'PVRTURBM','APVRAD', 'PVRCOND','PVRLS']
100/56:
for date in maturedates:
    dipv[date][cyc]['APVRAD'] = dipv[date][cyc]['SW'] + dipv[date][cyc]['PVRLWC'] + dipv[date][cyc]['PVRLWH']
    dipv[date][env]['APVRAD'] = dipv[date][env]['SW'] + dipv[date][env]['PVRLWC'] + dipv[date][env]['PVRLWH']
100/57:
for date in maturedates:
    dipv[date][cyc]['APVRAD'] = dipv[date][cyc]['PVRSW'] + dipv[date][cyc]['PVRLWC'] + dipv[date][cyc]['PVRLWH']
    dipv[date][env]['APVRAD'] = dipv[date][env]['PVRSW'] + dipv[date][env]['PVRLWC'] + dipv[date][env]['PVRLWH']
100/58:
for wq, q in enumerate(pllab):
    ax.plot(t,dimean[cyc][q],color=cl[wq],ls='-')
    ax.plot(t,dimean[env][q],color=cl[wq],ls='--')
100/59:
for wq, q in enumerate(pllab[7:]):
    
    ax.plot(t,dimean[cyc][q],color=cl[wq+7],ls='-')
    ax.plot(t,dimean[env][q],color=cl[wq+7],ls='--')
100/60: fig.show()
100/61: date=
100/62: date
100/63: date='20171214_02'
100/64: fig, ax = plt.subplots()
100/65:
for wq, q in enumerate(pllab[7:]):
    
    ax.plot(t,dipv[date][cyc][q],color=cl[wq+7],ls='-')
    ax.plot(t,dipv[date][env][q],color=cl[wq+7],ls='--')
100/66:
for wq, q in enumerate(pllab[7:]):
    
    ax.plot(t,np.mean(dipv[date][cyc][q],axis=0),color=cl[wq+7],ls='-')
    ax.plot(t,np.mean(dipv[date][env][q],axis=0),color=cl[wq+7],ls='--')
100/67: fig.show()
100/68: labs
100/69: labs = np.append(labs,'APVRAD',-2)
100/70: labs = np.insert(labs,'APVRAD',-2)
100/71: labs = np.insert(labs,-2'APVRAD')
100/72: labs = np.insert(labs,-2,'APVRAD')
100/73: labs
100/74: plt.close('all')
100/75: fig, ax = plt.subplots()
100/76:
for wq, q in enumerate(pllab):
    
    ax.plot(t,np.mean(dipv[date][cyc][q],axis=0),color=cl[wq],ls='-')
    ax.plot(t,np.mean(dipv[date][env][q],axis=0),color=cl[wq],ls='--')
100/77: fig.show()
100/78: ax.legend()
100/79: pllab
100/80: cl
100/81: dipv[date][cyc]['APVTOT']
100/82: fig.show()
100/83: fig.show()
100/84: cl[0]='black'
100/85: plt.close()
100/86: fig, ax = plt.subplots()
100/87:
for wq, q in enumerate(pllab):
    ax.plot(t,np.mean(dipv[date][cyc][q],axis=0),color=cl[wq],ls='-')
    ax.plot(t,np.mean(dipv[date][env][q],axis=0),color=cl[wq],ls='--')
100/88: ax.legend()
100/89: fig.show()
100/90: fig.savefig('test.png',dpi=300)
100/91: ls
100/92: plt.close('all')
100/93: fig, ax = plt.subplots()
100/94: np.mean(dipv[date][cyc][q],axis=0)
100/95: np.mean(dipv[date][env][q],axis=0)
100/96: np.mean(dipv[date][env][q],axis=0)[::-1]
100/97: np.mean(dipv[date][env][q],axis=0)[1::-1]
100/98: np.mean(dipv[date][env][q],axis=0)[0::-1]
100/99: np.mean(dipv[date][env][q],axis=0)[:1:-1]
100/100: np.mean(dipv[date][env][q],axis=0)[:47]
100/101: np.mean(dipv[date][env][q],axis=0)[:47].shape
100/102: np.mean(dipv[date][env][q],axis=0).shape
100/103: np.mean(dipv[date][env][q],axis=0)[:48].shape
100/104: np.mean(dipv[date][env][q],axis=0)[:49].shape
100/105: np.mean(dipv[date][env][q],axis=0)[:46].shape
100/106: np.mean(dipv[date][env][q],axis=0)[:1:-1].shape
100/107: np.mean(dipv[date][env][q],axis=0).shape
100/108: np.mean(dipv[date][env][q],axis=0).shape
100/109: np.mean(dipv[date][env][q],axis=0)[:].shape
100/110: np.mean(dipv[date][env][q],axis=0)[:5].shape
100/111: np.arange(-47,1)
100/112: np.arange(-47,1).shape
100/113: np.arange(-47,1)[:47].shape
100/114: np.arange(-47,1)[:47]
100/115: np.arange(-47,1)[:4].shape
100/116: np.arange(-47,1)[:4:-1].shape
100/117: np.arange(-47,1)[:4:-1]
100/118: np.arange(-47,1)[:1:-1].shape
100/119: labs
100/120: t=np.arange(-47,1,1)[::-1]
100/121: t
100/122: di = dict()
100/123: di['env'] = np.array([4,5],[5,6])
100/124: di['env'] = np.array([4,5],[5,6],dtype=int)
100/125: di['env'] = np.array(([4,5],[5,6]),dtype=int)
100/126: di
100/127: di['env'] = np.vstack((di['env'],np.array(([5,6],[7,8]))))
100/128: di['env']
101/1:
import numpy as np
import sys
import os

sys.path.append('/atmosdyn2/ascherrmann/scripts/')

p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
traced = np.array([])
nn = 'accumulated-PVR-'
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            traced = np.append(traced,d)
traced = np.sort(traced)
101/2:
for k in range(1):
    date = traced[k][12:23]
    d = np.loadtxt(p + traced[k])
    s = np.where(d[:,0]==0)[0]
101/3: n=0
101/4: d[n:n+47]
101/5: d[n:n+48]
101/6: d[n:n+48,9:]
101/7: d[n:n+48,9:11]
101/8: d[n:n+48,9:12]
101/9: np.cumsum(np.flip(d[n+1:n+49,9:],axis=0),axis=0)[::-1,:]
101/10: np.cumsum(np.flip(d[n+1:n+49,9:,12],axis=0),axis=0)[::-1,:]
101/11: np.cumsum(np.flip(d[n+1:n+49,9:12],axis=0),axis=0)[::-1,:]
101/12: d[n:n+48,9:12]
101/13:
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
### use traced-vars here, as the environmental and cyclonic splitting requires the rates and not the sumes
### the rates are summed later/below to create the accumulated values
for d in os.listdir(p):
    if(d.startswith('traced-vars')):
            acc = np.append(acc,d)
acc = np.sort(acc)
acc2 = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc2 = np.append(acc2,d)
acc2 = np.sort(acc2)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vorticitymature'
labs = helper.traced_vars()

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
plabels = ['TOT','LS','TURBM','TURBT','CONVT','CONVM','RAD','COND']
clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

LSid = 16
cl=['k','orange','green','blue','lightblue','magenta','grey','r']
pllab = ['APVTOT','PVRCONVT', 'PVRCONVM', 'PVRTURBT', 'PVRTURBM','APVRAD','PVRCOND','PVRLS']
ptitle = np.array(['800 hPa < P$_{-47}$', '600 < P$_{-47} <$800 hPa', '400 < P$_{-47} <$600 hPa',  'P$_{-47} <$400 hPa'])

did=dict() #raw data
dih=dict() #help, hours 'h' to zetamax
dic=dict() #center, i.e. 'lat' and 'lon' of center
dit=dict() #trajectories contribution 'cycl', 'env'
dipv=dict()
dimean=dict()

v_start = np.array([])
v_end = np.array([])

envc = np.zeros(48)
cycc = np.zeros(48)

env = 'env'
cyc = 'cyc'
APVTOT = dict()
APVTOT[env] = dict()
APVTOT[cyc] = dict()
101/14:
hh=47
t=np.arange(-47,1,1)[::-1]
maturedates = np.array([])
for u, e in enumerate(acc):
    date=e[12:-4]
    maturedates = np.append(maturedates,date)
    d = np.loadtxt(p + e)
    d2 = np.loadtxt(p+acc2[u])
    did[date] = dict()
    dipv[date]=dict()
    dipv[date][env] = dict()
    dipv[date][cyc] = dict()

    for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)
        ### is the same so far
        dipv[date][env][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
        dipv[date][cyc][el] = np.zeros((d[:,k].reshape(-1,48)).shape)
#for date in maturedates:
    tmpid = np.array([])
    tmphtz = np.array([])
    tmplon= np.array([])
    tmplat= np.array([])

    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    dih[date]=dict()
    dic[date]=dict()
    dit[date]=dict()

    for k in range(0,48):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmphtz = np.append(tmphtz,htzeta[tmpq])
            tmpid = np.append(tmpid,tmpq)
            tmplon = np.append(tmplon,np.mean(clon[tmpq]))
            tmplat = np.append(tmplat,np.mean(clat[tmpq]))
        else:
            tmphtz = np.append(tmphtz,(-k))
            tmplon = np.append(tmplon,895)
            tmplat = np.append(tmplat,220)

    dih[date]['id'] = tmpid.astype(int)
    dih[date]['h'] = tmphtz
    dic[date]['lat'] = tmplat.astype(int)
    dic[date]['lon'] = tmplon.astype(int)
    dit[date] = np.zeros((len(did[date]['time']),len(did[date]['time'][0])))
    for e, h in enumerate(dih[date]['h']):
        #### helper.radial reduces indeces by 1, as there is an off set by 1 in the data set.
        #### the textdata already accounts for it and thus we have to get rid of the offset when adding
        #### radial ids here, therefore add 1 to the the ids whe.n using _center(200), or
        #### use new fuction _center_calc to consider true center therefore no more off set and correction here
        tmplon = dic[date]['lon'][e] + helper.radial_ids_around_center_calc(230)[0]
        tmplat = dic[date]['lat'][e] + helper.radial_ids_around_center_calc(230)[1]
        for tr in range(len(did[date]['time'])):
            if ((did[date]['lon'][tr,e]>np.min(LON[tmplon])) & (did[date]['lon'][tr,e]<np.max(LON[tmplon])) & (did[date]['lat'][tr,e]>np.min(LAT[tmplat])) &(did[date]['lat'][tr,e]<np.max(LAT[tmplat]))):

                dit[date][tr,e]=1
    APVTOT[cyc][date] = (np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*dit[date]
    APVTOT[env][date] = (np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*(~(dit[date].astype(bool))).astype(int)
    cycc += np.sum(dit[date],axis=0)
    envc += np.sum((~(dit[date].astype(bool))).astype(int),axis=0)

    for we,lab in enumerate(labs[9:]):
        dipv[date][cyc][lab][:,:47] = np.cumsum(np.flip(did[date][lab]*dit[date],axis=1),axis=1)[:,:0:-1]
        dipv[date][env][lab][:,:47] = np.cumsum(np.flip(did[date][lab]*(~(dit[date].astype(bool))).astype(int),axis=1),axis=1)[:,:0:-1]
        if we==0:
            dipv[date][cyc]['APVTOT'] = dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] = dipv[date][env][lab]
        else:
            dipv[date][cyc]['APVTOT'] += dipv[date][cyc][lab]
            dipv[date][env]['APVTOT'] += dipv[date][env][lab]
#        dimean[cyc][lab] +=np.sum(dipv[date][cyc][lab],axis=0)
#        dimean[env][lab] +=np.sum(dipv[date][env][lab],axis=0)
    dipv[date][cyc]['APVRAD'] = dipv[date][cyc]['PVRSW'] + dipv[date][cyc]['PVRLWC'] + dipv[date][cyc]['PVRLWH']
    dipv[date][env]['APVRAD'] = dipv[date][env]['PVRSW'] + dipv[date][env]['PVRLWC'] + dipv[date][env]['PVRLWH']
    dipv[date][cyc]['APVTOT'] -= dipv[date][cyc]['PVRLS']
    dipv[date][env]['APVTOT'] -= dipv[date][env]['PVRLS']
#    dimean[cyc]['APVTOT'] += np.sum(dipv[date][cyc]['APVTOT'],axis=0)
#    dimean[env]['APVTOT'] += np.sum(dipv[date][env]['APVTOT'],axis=0)
labs = np.append(labs,'APVTOT')
101/15: d2
101/16: aqc = (np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*dit[date]
101/17: aqe = (np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*(~(dit[date].astype(bool))).astype(int)
101/18: aqc
101/19: aqe = np.mean((np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*(~(dit[date].astype(bool))).astype(int),axies=0)
101/20: aqe = np.mean((np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*(~(dit[date].astype(bool))).astype(int),axis=0)
101/21: aqc = np.mean((np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48))*dit[date],axis=0)
101/22: aqc
101/23: aqe
101/24: dipv[date][cyc]
101/25: aqe
101/26: dipv[date][cyc]
101/27: dipv[date][cyc]['APVTOT'].shape
101/28: dit
101/29: dit[date]
101/30: dit[date].shape
101/31: d2
101/32: d2[9:].shape
101/33: d2[9:].reshape(-1,48)
101/34: d2[9:].reshape(-1,47)
101/35: d2[9:].reshape(-1,49)
101/36: d2[:,9:].reshape(-1,48)
101/37: d2[:,9:].reshape(-1,48).shape
101/38: d2.shape
101/39: d2[:,9:].shape
101/40: date
101/41: cd /atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/
101/42: wc -l trajectories-mature-20180228_09.txt
101/43: ls *.txt
101/44: d2.shape
101/45: d2[:,9:].reshape(-1,48)
101/46: d2[:,9:].reshape(-1,48).shape
101/47: np.sum(d2[:,9:],axis=1).reshape(-1,48)
101/48: np.sum(d2[:,9:],axis=1).reshape(-1,48).shape
101/49: d2[:,9].reshape(-1,48).shape
101/50: d
101/51: d.shape
101/52: d2.shape
101/53: test1 = d2[:,9].reshape(-1,48)
101/54: test1
101/55: test1 - np.cumsum(np.flip(did[date][labs[[9]]],axis=1),axis=1)[:,:0:-1]
101/56: np.cumsum(np.flip(did[date][labs[[9]]],axis=1),axis=1)[:,:0:-1]
101/57: np.cumsum(np.flip(did[date][labs[9]],axis=1),axis=1)[:,:0:-1]
101/58: test1 - np.cumsum(np.flip(did[date][labs[9]],axis=1),axis=1)[:,:0:-1]
101/59: test2 = np.zeros((461,48))
101/60: test2[:47] = np.cumsum(np.flip(did[date][labs[9]],axis=1),axis=1)[:,:0:-1]
101/61: np.cumsum(np.flip(did[date][labs[9]],axis=1),axis=1)[:,:0:-1].shape
101/62: test2[:,:47] = np.cumsum(np.flip(did[date][labs[9]],axis=1),axis=1)[:,:0:-1]
101/63: test1-test2
101/64: (test1-test2)[0]
101/65: d2 = np.loadtxt(p+acc2[u])
101/66: d2.shape
101/67: d2[46:49,0]
101/68: acc2
101/69: acc
101/70: u
101/71: e
101/72: el
101/73: d = np.loadtxt(p + acc[u])
101/74: d2 = np.loadtxt(p + acc2[u])
101/75: test = np.zeros(d[:48,9:12].shape)
101/76: d[:48]
101/77: test = np.zeros(d[:47,9:12].shape)
101/78: test = np.zeros(d[:48,9:12].shape)
101/79: d[48]
101/80: d[47]
101/81: test = np.zeros(d[:48,9:12].shape)
101/82: test[:47,:] = np.cumsum(np.flip(d[1:48,9:12],axis=0),axis=0)[::-1,:]
101/83: test
101/84: test2 = np.zeros(d[:48,9:12].shape)
101/85: pvtest = np.zeros(d[:48,9:12].shape)
101/86: pvtest = np.zeros((3,48))
101/87: test2 = np.sum(test,axis=1)
101/88: test2
101/89: d3 = d[:48,9:12].reshape(-1,48)
101/90: d3
101/91: d3 = np.cumsum(np.flip(d[:48,9:12].reshape(-1,48),axis=1),axis=1)[:,:0:-1]
101/92: d3
101/93: np.sum(d3,axis=0)
101/94: d = np.loadtxt(p + acc[u])
101/95: acc[u]
101/96:
did[date] = dict()
    dipv[date]=dict()
    dipv[date][env] = dict()
    dipv[date][cyc] = dict()
101/97:
did[date] = dict()
dipv[date]=dict()
dipv[date][env] = dict()
dipv[date][cyc] = dict()
101/98: date
101/99:
for k, el in enumerate(labs):
        did[date][el] = d[:,k]
101/100: labs
101/101: labs = helper.traced_vars()
101/102:
for k, el in enumerate(labs):
        did[date][el] = d[:,k]
101/103: did[date]
101/104: did[date][time].shape
101/105: did[date]['time'].shape
101/106:
for k, el in enumerate(labs):
        did[date][el] = d[:,k].reshape(-1,48)
101/107: did
101/108: did[date]['time'].shape
101/109: did[date]['time']
101/110: np.cumsum(np.flip(did[date]['time'],axis=1),axis=1)[:,:0:-1]
101/111: np.cumsum(np.flip(did[date]['time'],axis=1),axis=1)[:,:0:-1].shape
101/112: s
101/113:
dd = np.zeros(d[:,9:].shape)
for n in s:
        #normally 49, but made mistake at the beginning
        # n+1, as the first hour/the current PVR is not accounted for
        # write the revers cumsum into the hours, such that -1h contains the full
        # accumulated PV over the hours -48 to -2, i.e. up to this point.
        # and make -48h 0, as there is no accum PV before

        dd[n:n+47,9:] = np.cumsum(np.flip(d[n+1:n+48,9:],axis=0),axis=0)[::-1,:]
        #normally 48 but here 47 as deleted the -48 h
101/114: d.shape
101/115: d[:,9:].shape
101/116: dd.shape
101/117: np.cumsum(np.flip(d[n+1:n+48,9:],axis=0),axis=0)[::-1,:].shape
101/118: dd[n:n+47,9:].shape
101/119:
dd = np.zeros(d[:,9:].shape)
for n in s:
        #normally 49, but made mistake at the beginning
        # n+1, as the first hour/the current PVR is not accounted for
        # write the revers cumsum into the hours, such that -1h contains the full
        # accumulated PV over the hours -48 to -2, i.e. up to this point.
        # and make -48h 0, as there is no accum PV before

        dd[n:n+47,:] = np.cumsum(np.flip(d[n+1:n+48,9:],axis=0),axis=0)[::-1,:]
        #normally 48 but here 47 as deleted the -48 h
101/120: dd
101/121: accumulatedfield = dd
101/122: accumulatedfield.shape
101/123: acc0 = accumulatedfield[:,0].reshape(-1,48)
101/124: acc0
101/125: did[date]
101/126: did[date][labs[9]]
101/127: d[:,9]
101/128: d[:,9].reshape(-1,48)
101/129: did[date][labs[9]]-d[:,9].reshape(-1,48)
101/130: dd
101/131: dd.shape
101/132: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)
101/133: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)[:,:0:-1]
101/134: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)[:,:0:-2]
101/135: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)[:,:0:-1]
101/136: dd
101/137: dd[:,0]
101/138: dd[:,0].reshape(-1,48)
101/139: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)[:,:1:-1]
101/140: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)[:,:1:-2]
101/141: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1).shape
101/142: np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1)
101/143: dd[:,0].reshape(-1,48)
101/144: np.flip(np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1),axis=1)
101/145: np.flip(np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1),axis=1)[:,1:]
101/146: np.flip(np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1),axis=1)[:,1:].shape
101/147: dd[:,0].reshape(-1,48).shape
101/148: testqr = dd[:,0].reshape(-1,48)[0,:47]
101/149: testqr
101/150: testqr2 = np.flip(np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1),axis=1)[:,1:]
101/151: testqr2
101/152: testqr2 = np.flip(np.cumsum(np.flip(d[:,9].reshape(-1,48),axis=1),axis=1),axis=1)[0,1:]
101/153: testqr2
101/154: testqr2-testqr
101/155: for er, sie in enumerate(labs)
101/156:
d2 = np.loadtxt(p + 'accumulated-PVR-20180228_09.txt')
for er, sie in enumerate(labs):
    if er==0:
        tmpqs1 = np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
        tmpqs2 = np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48)
    else:     
        tmpqs1 += np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
101/157: labs
101/158:
d2 = np.loadtxt(p + 'accumulated-PVR-20180228_09.txt')
for er, sie in enumerate(labs):
    print(er)
    if er==0:
        tmpqs1 = np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
        tmpqs2 = np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48)
    else:     
        tmpqs1 += np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
101/159: d[:,27]
101/160:
d2 = np.loadtxt(p + 'accumulated-PVR-20180228_09.txt')
for er, sie in enumerate(labs[9:]):
    print(er)
    if er==0:
        tmpqs1 = np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
        tmpqs2 = np.sum(d2[:,9:],axis=1).reshape(-1,48)-(d2[:,LSid]).reshape(-1,48)
    else:     
        tmpqs1 += np.flip(np.cumsum(np.flip(d[:,er+9].reshape(-1,48),axis=1),axis=1),axis=1)
101/161: tmpqs1
101/162: tmpqs2
101/163: tmpqs2.shape
101/164: tmpqs1.shape
101/165: acc[u]
101/166: s
101/167: dit[date]
101/168: dit[date].shape
101/169: dit[date].flatten
101/170: print(dit[date].flatten)
101/171: print(dit[date].flatten())
101/172: print(dit[date].flatten().shape)
102/1: import numpy as np
102/2: d = np.zeros((10,10))
102/3:
for k,u in enumerate(range(len(d))):
    d[:,k] = np.arange(k*100,k*100+11)
102/4:
for k,u in enumerate(range(len(d))):
    d[:,k] = np.arange(k*100+1,k*100+11)
102/5: d
102/6: d[:,:]
102/7: np.flip(d[:,:])
102/8: np.flip(d[:,:],axis=0)
102/9: np.cumsum(d[:,:],axis=0)
102/10: d = d.astype(int)
102/11: np.cumsum(d[:,:],axis=0)
102/12: np.insert(d,0,np.flip(np.arange(-9,1)))
102/13: np.insert(d,0,np.flip(np.arange(-9,1)),axis=0)
102/14: d = np.insert(d,0,np.flip(np.arange(-9,1)),axis=0)
102/15: d
102/16: d[1:]
102/17: np.cumsum(np.flip(d[1:],axis=0),axis=0)
102/18: np.cumsum(np.flip(d[1:],axis=0),axis=0)[::-1,:]
102/19: np.delete(d,0)
102/20: np.delete(d,0,axis=0)
102/21: d = np.delete(d,0,axis=0)
102/22: np.insert(d,0,np.flip(np.arange(-9,1)),axis=1)
102/23: d = np.insert(d,0,np.flip(np.arange(-9,1)),axis=1)
102/24: np.cumsum(np.flip(d[:,1:],axis=0),axis=0)[::-1,:]
102/25: di = dict()
102/26:
d = np.zeros((10,10))
for k,u in enumerate(range(len(d)/2)):
    d[0:5,k] = np.arange(k*100+1,k*100+11)
    d[5:,k] = np.arange(k*1000+1,k*1000+11)
102/27:
d = np.zeros((10,10))
for k,u in enumerate(range(int(len(d)/2))):
    d[0:5,k] = np.arange(k*100+1,k*100+11)
    d[5:,k] = np.arange(k*1000+1,k*1000+11)
102/28: d[0:5,1]
102/29:
d = np.zeros((10,10))
for k,u in enumerate(range(int(len(d)/2))):
    d[0:5,k] = np.arange(k*100+1,k*100+6)
    d[5:,k] = np.arange(k*1000+1,k*1000+6)
102/30: d
102/31: d = d.astype(int)
102/32: d
102/33:
d = np.zeros((10,10))
for k,u in enumerate(range(len(d))):
    d[0:5,k] = np.arange(k*100+1,k*100+6)
    d[5:,k] = np.arange((k+1)*1000+1,(k+1)*1000+6)
102/34: d
102/35:
d = np.zeros((10,10),dtype=int)
for k,u in enumerate(range(len(d))):
    d[0:5,k] = np.arange(k*100+1,k*100+6)
    d[5:,k] = np.arange((k+1)*1000+1,(k+1)*1000+6)
102/36: d
102/37: d
102/38: d
102/39: d
102/40: d
102/41: d
102/42:
d = np.zeros((10,10),dtype=int)
for k,u in enumerate(range(len(d))):
    d[0:5,k] = np.arange(k*100+1,k*100+6)
    d[5:,k] = np.arange((k)*1000+1,(k)*1000+6)
102/43: d
102/44: d.reshape(-1,5)
102/45: d.reshape(-1,5,axis=0)
102/46: d.reshape(20,5)
102/47: d.reshape(-1,5)
102/48: d
102/49: d[:,0].reshape(-1,5)
102/50: dre = np.zeros((20,5))
102/51: di
102/52:
for i in range(len(d)):
    di[i] = d[:,i].reshape(-1,5)
102/53: di
102/54: dio = dict()
102/55: dc = d
102/56: dc
102/57: dc[:5,:] = np.cumsum(np.flip(d[:5,:],axis=0),axis=0)[:5:-1,:]
102/58: np.cumsum(np.flip(d[:5,:],axis=0),axis=0)[:5:-1,:]
102/59: np.cumsum(np.flip(d[:5,:],axis=0),axis=0)
102/60: np.cumsum(np.flip(d[:,:],axis=0),axis=0)
102/61: d
102/62: dc[:5,:] = np.cumsum(np.flip(d[:5,:],axis=0),axis=0)[::-1,:]
102/63: dc[5:,:] = np.cumsum(np.flip(d[5:,:],axis=0),axis=0)[::-1,:]
102/64: dc
102/65:
for i in range(len(d)):
    dio[i] = dc[:,i].reshape(-1,5)
102/66: dio
102/67: apv = dio[0]
102/68:
for i in range(1,len(d)):
    apc += dio[i]
102/69:
for i in range(1,len(d)):
    apv += dio[i]
102/70: apv
102/71: di
102/72: d
102/73: d
102/74: dc
102/75: dc
102/76: q
102/77: dio
102/78: di
102/79:
d = np.zeros((10,10),dtype=int)
for k,u in enumerate(range(len(d))):
     d[0:5,k] = np.arange(k*100+1,k*100+6)
     d[5:,k] = np.arange((k)*1000+1,(k)*1000+6)
102/80: d
102/81:
d = np.zeros((10,10),dtype=int)
for k,u in enumerate(range(len(d))):
     d[0:5,k] = np.arange(k*100+1,k*100+6)
     d[5:,k] = np.arange((k)*100+1,(k)*100+6)
102/82: d
102/83: dc = d
102/84: dc[:5,:] = np.cumsum(np.flip(d[:5,:],axis=0),axis=0)[::-1,:]
102/85: dc[5:,:] = np.cumsum(np.flip(d[5:,:],axis=0),axis=0)[::-1,:]
102/86: dc
102/87: dio = dict()
102/88: din = dict()
102/89:
do = dc
for i in range(len(dc)):
    dio[i] = do[:,i].reshape(-1,5)
102/90: dio
102/91: apvo = dio[0]
102/92:
for i in range(1,len(do)):
    apvo += dio[i]
102/93: apvo
102/94: dio
102/95: d
102/96: do
102/97: dc
104/1: import numpy as np
104/2: 1
104/3: [1]
105/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
acc = np.array([])
for d in os.listdir(p):
    if(d.startswith('accumulated-PVR-')):
            acc = np.append(acc,d)
acc = np.sort(acc)
LSid = 16
labs = helper.traced_vars()
PVRs = labs[9:]
PVRsum = np.array(['PVRTOT','PVRLS','PVRTURB','PVRCONV','PVRRAD'])
labels = ['TOT','LS','TURBM','TURBT','CONVT','CONVM','RAD','COND']
ptitle = np.array(['800 hPa < P$_{-47}$', '600 < P$_{-47} <$800 hPa', '400 < P$_{-47} <$600 hPa',  'P$_{-47} <$400 hPa'])
### INFO
### Trajetories start 200km around the center between 925 and 500 hPa if PV>0.75 PVU
###
hh=47


for u, e in enumerate(acc):
    date = e[16:-4]
    d = np.loadtxt(p + e)
    di = dict()
    for k, el in enumerate(labs):
        di[el] = d[:,k].reshape(-1,48)
105/2: labs
105/3: di['time']
105/4: di['P']
105/5: d[:,3]
105/6: d[:,9]
105/7: d[:,9][:48]
105/8: d[:,9][:47]
105/9: d[:,9][:49]
105/10: d[:,9][:48]
105/11: t = np.loadtxt('traced-vars-20180228_09.txt')
105/12: t[:,9][:48]
105/13: np.flip(np.cumsum(np.flip(t[:,9][:48])))
105/14: tmpt = t
105/15: tmpt.shape
105/16: tmpt = t[:,9]
105/17: tmpt
105/18: tmpt = t[:,9].reshape(-1,48)
105/19: tmpt
105/20: tmpt[0]
105/21: P = t[:,3].reshape(-1,48)
105/22: P
105/23: d
105/24: d[:,3]
105/25: P- d[:,3].reshape(-1,48)
105/26: np.where((P- d[:,3].reshape(-1,48))!=0)
105/27: labs
105/28: labs.shape
105/29: labs[3]
105/30: labs[9]
105/31: datadi = dict()
105/32:
for k, el in enumerate(labs):
    datadi[el] = t[:,k].reshape(-1,48)
105/33: datadi['P']
105/34: datadi['PVRCONVT']
105/35: np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][0:1],axis=1),axis=1),axis=1)
105/36: np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][0:1,1:],axis=1),axis=1),axis=1)
105/37: ditest = dict()
105/38:
for k, el in enumerate(labs):
    ditest[el] = np.flip(np.cumsum(np.flip(datadi['PVRCONVT'],axis=1),axis=1),axis=1)
105/39: titest['PVRCONVT']
105/40: ditest['PVRCONVT']
105/41:
for k, el in enumerate(labs):
    ditest[el] = np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][:,1:],axis=1),axis=1),axis=1)
105/42: ditest['PVRCONVT']
105/43:
tmp = np.zeros(ditest['P'].shape)
for k, el in enumerate(labs):
    tmp[:,:-1] += np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][:,1:],axis=1),axis=1),axis=1)
105/44:
tmp = np.zeros(ditest['P'].shape)
for k, el in enumerate(labs):
    tmp[:,:-2] += np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][:,1:],axis=1),axis=1),axis=1)
105/45:
ditest['P'].shape
tmp = np.zeros(ditest['P'].shape)
for k, el in enumerate(labs):
    tmp[:,:-1] += np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][:,1:],axis=1),axis=1),axis=1)
105/46:
ditest['P'].shape
tmp = np.zeros(ditest['P'].shape)
for k, el in enumerate(labs):
    tmp[:,:] += np.flip(np.cumsum(np.flip(datadi['PVRCONVT'][:,1:],axis=1),axis=1),axis=1)
105/47: ditest['P'].shape
105/48:
for el in labs:
    print(ditest[el].shape)
105/49: ditest['t']
105/50: ditest['time']
105/51:
for k, el in enumerate(labs[9:]):
    ditest[el] = np.zeros(datadi['time'].shape)
    ditest[el][:,-1] = np.flip(np.cumsum(np.flip(datadi[el],axis=1),axis=1),axis=1)
105/52:
for k, el in enumerate(labs[9:]):
    ditest[el] = np.zeros(datadi['time'].shape)
    ditest[el][:,-1] = np.flip(np.cumsum(np.flip(datadi[el][:,1:],axis=1),axis=1),axis=1)
105/53:
for k, el in enumerate(labs[9:]):
    ditest[el] = np.zeros(datadi['time'].shape)
#    ditest[el][:,-1] = np.flip(np.cumsum(np.flip(datadi[el][:,1:],axis=1),axis=1),axis=1)
105/54: datadi['time'].shape
105/55: np.flip(np.cumsum(np.flip(datadi[el][:,1:],axis=1),axis=1),axis=1).shape
105/56: ditest[el][:,-1].shape
105/57: ditest[el][:,:-1].shape
105/58:
for k, el in enumerate(labs[9:]):
    ditest[el] = np.zeros(datadi['time'].shape)
    ditest[el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[el][:,1:],axis=1),axis=1),axis=1)
105/59: ditest['PVRCONVT']
105/60: np.array([7,10],[5,9]) + np.array([7,10],[5,9])
105/61: np.array([7,10],[5,9],dtype=int) + np.array([7,10],[5,9],dtype=int)
105/62: np.array([[7,10],[5,9]],dtype=int) + np.array([[7,10],[5,9]],dtype=int)
105/63: ditest['LS']
105/64: ditest['PVRLS']
105/65: ditest['PVRCONVT'] + ditest['PVRLS']
105/66: ditest['PVRLS']
105/67: ditest['PVRCONVT']
105/68: APVTOT = np.sum(d[:,9:],axis=1).reshape(-1,48)-(d[:,LSid]).reshape(-1,48)
105/69: APVTOT
105/70: APVTOT.shape
105/71: ditest['PVRCONVT'].shape
105/72: apvtmp = ditest['PVRCONVT']
105/73:
for el in labs[10:]:
    apvtmp = apvtmp + ditest[el]
105/74: APVTOT-apvtmp
105/75: APVTOT-apvtmp+ditest['PVRLS']
106/1: k=500
106/2: range(k-48,k+1)
106/3: np.arange(-48,1)
106/4: range(-48,1)
106/5: import numpy
106/6: numpy.arange(-48,1)
106/7: numpy.arange(-48,1)[::-1]
106/8: tjstart = np.where(numpy.arange(-48,1)[::-1]==(-48))[0]
106/9: import numpy as np
106/10: tjstart = np.where(numpy.arange(-48,1)[::-1]==(-48))[0]
106/11: tjstart
106/12: sid = np.array([])
106/13:
for k in tjstart:
            sid= np.append(sid,range(k-48,k+1))
106/14: sid
107/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vort-entire-year'

clat = np.loadtxt(pt + 'centerlatitude-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'centerlongitude-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
107/2:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
107/3: MEDid = np.where(labels==2)[0]
107/4: MEDid
107/5: len(MEDid)
107/6: numpy.set_printoptions(threshold=sys.maxsize)
107/7: np.set_printoptions(threshold=sys.maxsize)
107/8: MEDid
107/9: MEDid[1:]-MEDid[:-1]
107/10: np.where((MEDid[1:]-MEDid[:-1])>60)
107/11: from random import randint
107/12: colors = np.array([])
107/13:
for i in range(27):
    colors = np.append(colors,'#%06X' %randint(0, 0xFFFFFF))
107/14: colors
107/15:
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

MEDid = np.where(labels==2)[0]
startids = np.array([0,np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1,len(MEDid)])
matureid = np.where((labels==2)&(htzeta==0))

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::48,2],d[::48,3],color=colors[q],marker='+',s=10)
    ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)
107/16:
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0,np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1,len(MEDid)]).astype(int)
matureid = np.where((labels==2)&(htzeta==0)).astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
107/17:
colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596'])
107/18:
p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)
107/19:
pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
107/20: MEDid = np.where(labels==2)[0].astype(int)
107/21: np.where((MEDid[1:]-MEDid[:-1])>60)[0]
107/22: np.array([0, np.where((MEDid[1:]-MEDid[:-1])>60)[0] ])
107/23: np.array([0, np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1 ])
107/24: np.array([0, np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1,len(MEDid) ])
107/25: np.array([0, np.asarray(np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1,len(MEDid)) ])
107/26:
for q,e in enumerate(np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1):
    print(e)
107/27:
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0)).astype(int)
107/28: matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)
107/29: startids
107/30:
for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::48,2],d[::48,3],color=colors[q],marker='+',s=10)
    ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)
107/31: plt.close('all')
107/32: len(startids)
107/33: MEDid[1:]-MEDid[:-1]
107/34: matureid
107/35: Medid-matureid[0]
107/36: MEDid-matureid[0]
107/37: MEDid-matureid[1]
107/38: MEDid-matureid[2]
107/39: htzeta[MEDid]
107/40: np.where((htzeta[1:]-htzeta[:-1])<0)
107/41: np.where((htzeta[1:]-htzeta[:-1])<-5)
107/42: np.where((htzeta[1:]-htzeta[:-1])>1)
107/43: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])>1)
107/44: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<-5)
107/45: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<-10)
107/46: len(np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<-10))
107/47: len(np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<-10)[0])
107/48: htzeta[MEDid]
107/49: dates[MEDid[np.where((htzeta[MEDid]<-40)| (htzeta[MEDid]>40))]]
107/50: MEDid[np.where((htzeta[MEDid]<-40)| (htzeta[MEDid]>40))]
107/51: dates[ 3696,  3702,  3715,  3718,  3725,  3737,  3745,  3751,  3759,3764,  3771,  3777, 7466]
107/52: dates[[3696,  3702,  3715,  3718,  3725,  3737,  3745,  3751,  3759,3764,  3771,  3777, 7466]]
107/53: datedec = '20171212_21'
107/54: np.where((labels==2)&(dates=datedec))
107/55: np.where((labels==2)&(dates==datedec))
107/56: clat[2315]
107/57: np.where((labels==2)&(dates=='20171212_22'))
107/58: clat[2317]
107/59: clon[2317]
107/60: clon[2315]
107/61: np.where((labels==2)&(dates=='20171212_23'))
107/62: clat[2335]
107/63: clat[2317:2335]
107/64: d
107/65: np.arange(0,481)[::48]
107/66: np.arange(0,481)[::49]
107/67: np.arange(0,481)[48::49]
107/68:
pltlat = np.linspace(0,90,226)#[60:181]
pltlon = np.linspace(-180,180,901)#[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3],color=colors[q],marker='+',s=10)
    ax.scatter(d[48::49,2],d[48,::49,3],color=colors[q],marker='o',s=5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
107/69: q
107/70: e
107/71: d = np.loadtxt(p + e)
107/72:
for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3],color=colors[q],marker='+',s=10)
    ax.scatter(d[48::49,2],d[48::49,3],color=colors[q],marker='o',s=5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
107/73: fig.show()
107/74: plt.close()
107/75:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3],color=colors[q],marker='+',s=10)
    ax.scatter(d[48::49,2],d[48::49,3],color=colors[q],marker='o',s=5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
107/76:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3],c='red',marker='+',s=100)
    ax.scatter(d[48::49,2],d[48::49,3],c='blue',marker='o',s=50)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
107/77:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
107/78:
for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3],c='red',marker='+',s=100)
    ax.scatter(d[48::49,2],d[48::49,3],c='blue',marker='o',s=50)
107/79: fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
107/80: plt.close('all')
107/81: plt.close('all')
107/82: plt.close('all')
107/83: plt.close('all')
107/84: plt.close('all')
107/85: fig.close()
107/86:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3])
    ax.scatter(d[48::49,2],d[48::49,3])
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

#lonticks=np.arange(minpltlonc, maxpltlonc,20)
#latticks=np.arange(minpltlatc, maxpltlatc,10)

#ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
#ax.set_yticks(latticks, crs=ccrs.PlateCarree());
#ax.set_xticklabels(labels=lonticks,fontsize=6)
#ax.set_yticklabels(labels=latticks,fontsize=6)

#ax.xaxis.set_major_formatter(LongitudeFormatter())
#ax.yaxis.set_major_formatter(LatitudeFormatter())

#ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
plt.close()
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
107/87:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3])
    ax.scatter(d[48::49,2],d[48::49,3])
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

#lonticks=np.arange(minpltlonc, maxpltlonc,20)
#latticks=np.arange(minpltlatc, maxpltlatc,10)

#ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
#ax.set_yticks(latticks, crs=ccrs.PlateCarree());
#ax.set_xticklabels(labels=lonticks,fontsize=6)
#ax.set_yticklabels(labels=latticks,fontsize=6)

#ax.xaxis.set_major_formatter(LongitudeFormatter())
#ax.yaxis.set_major_formatter(LatitudeFormatter())

#ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/88:
fig, axes = plt.subplots(1, 1)#, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
#ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,2],d[::49,3])
    ax.scatter(d[48::49,2],d[48::49,3])
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

#lonticks=np.arange(minpltlonc, maxpltlonc,20)
#latticks=np.arange(minpltlatc, maxpltlatc,10)

#ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
#ax.set_yticks(latticks, crs=ccrs.PlateCarree());
#ax.set_xticklabels(labels=lonticks,fontsize=6)
#ax.set_yticklabels(labels=latticks,fontsize=6)

#ax.xaxis.set_major_formatter(LongitudeFormatter())
#ax.yaxis.set_major_formatter(LatitudeFormatter())

#ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/89:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,1],d[::49,2],marker='+',c=col)
    ax.scatter(d[48::49,1],d[48::49,2],marker='o',c=col)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/90:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/91:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
#    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/92: d[:,0]
107/93:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/94:
pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/95:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()

for q,e in enumerate(traced):
    d = np.loadtxt(p + e)
    col=colors[q]
    #trackid = MEDid[startids[q]:startids[q+1]]
    #ax.plot(clon[trackid],clat[trackid],color=colors[q])
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    #ax.scatter(clon[matureid[q]],clat[matureid[q]],color=colors[q],marker='o',s=5)

lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'Mediclones-tracks-and-trajectory-start.png',dpi=300,bbox_inches="tight")
plt.close()
107/96: kqk = ['DEC17','JAN18','FEB18']
107/97: kqk[0]
107/98: kqk[0][0]
107/99: trajlat = 33.6
107/100: trajlon=14.4
107/101: centerlatt = 35.2
107/102: centerlon=19.6
107/103: df = np.sqrt((centerlon-trajlon)**2 + (centerlatt-trajlat)**2)
107/104: df
107/105: 200/2/np.pi/6370
107/106: 200/2/np.pi/6370*360
107/107: DISLON = np.linspace(0,2 * np.pi * r,901)
107/108: DISLON = np.linspace(0,2 * np.pi * 6370,901)
107/109: DISLON
107/110: np.linspace(0,360,901)
107/111: import helper
107/112: helper.traced_vars()
107/113: np.where(helper.traced_vars()=='PVRLS')
107/114: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-vort-entire-year.txt')
107/115: np.where(d==2)
107/116: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-vort-DJF.txt')
107/117: np.where(d==2)
107/118: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-vort-MAM.txt')
107/119: np.where(d==2)
107/120: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-vort-JJA.txt')
107/121: np.where(d==2)
107/122: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-vort-SON.txt')
107/123: np.where(d==2)
108/1: import numpy as np
108/2: import os
108/3:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)
108/4:
colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]
108/5: traced
108/6:
for q, e in enumerate(traced):
    print(q,e)
108/7: p
108/8: d = np.loadtxt(p+traced[0])
109/1: import numpy as np
109/2: np.any( np.array([47,12,-3,26,38,43])>20)
110/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
110/2:
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((MEDid[1:]-MEDid[:-1])>60)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[60:181]
pltlon = np.linspace(-180,180,901)[300:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
110/3:
for q, e in enumerate(traced):
    print(q,e)
110/4: p
110/5: pwd
111/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

MEDid = np.where(labels==2)[0].astype(int)
111/2: MEDid
111/3: MEDid.shape
111/4: MEDid[1:]-MEDid[:-1]
111/5: np.man(MEDid[1:]-MEDid[:-1])
111/6: np.max(MEDid[1:]-MEDid[:-1])
111/7: np.min(MEDid[1:]-MEDid[:-1])
111/8: numpy.set_printoptions(threshold=sys.maxsize)
111/9: np.set_printoptions(threshold=sys.maxsize)
111/10: MEDid[1:]-MEDid[:-1]
111/11: labels
111/12: htzeta
111/13: htzeta[MEDid]
111/14: labels[MEDid]
111/15: htzeta[MEDid]
111/16: htzeta[MEDid][1:]-htzeta[MEDid][:-1]
111/17: htzeta[MEDid][:-1]-htzeta[MEDid][1:]
111/18: htzeta[MEDid][1:]-htzeta[MEDid][:-1]
111/19: htzeta[MEDid]
111/20: htzeta[MEDid][1:]-htzeta[MEDid][:-1]
111/21: htzeta[MEDid]
111/22: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<0)
111/23: htzeta[MEDid][727]
111/24: htzeta[MEDid][:727]
111/25: htzeta[MEDid][:728]
111/26: htzeta[MEDid][:729]
111/27: htzeta[MEDid][:7240]
111/28: htzeta[MEDid][:740]
111/29: htzeta[MEDid][:750]
111/30: htzeta[MEDid][:751]
111/31: htzeta[MEDid][:760]
111/32: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<0)+1
111/33: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<0)[0]+1
111/34: htzeta[640:]
111/35: htzeta[MEDid][640:]
111/36: np.where((htzeta[MEDid][1:]-htzeta[MEDid][:-1])<0)[0]+1
112/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
MEDid = np.where(labels==2)[0].astype(int)
112/2: CYCids[MEDid]
112/3: np.set_printoptions(threshold=sys.maxsize)
112/4: CYCids[MEDid]
112/5: hrzeta[MEDid]
112/6: htzeta[MEDid]
112/7: np.where(CYCids[MEDid]==1)
112/8: np.where(CYCids[MEDid]==11)
112/9: htzeta[MEDid][260:270]
112/10: CYCids[MEDid]
112/11: CYCids[MEDid][1:]-CYCids[MEDid][-1]
112/12: CYCids[MEDid][1:]-CYCids[MEDid][:-1]
112/13: CYCids
112/14: labels
112/15: labels.shape
112/16: CYCids.shape
112/17: data = np.zeros((1965,7))
112/18: data[:,0]= labels
112/19: data[:,1]= CYCids
112/20: data[:,2]=htzeta
112/21: data
112/22: dates
112/23: data[:,3]=dates
112/24: data
112/25: data[:,3]=dates.astype(str)
112/26: data
112/27: data[:,3].astype(str)
112/28: htzeta
112/29: htzeta[MEDid]
113/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
113/2: labels
113/3: np.set_printoptions(threshold=sys.maxsize)
113/4: labels
113/5: MEDid
113/6: htzeta
113/7: CYCids
113/8: htzeta
113/9: cycIDs
113/10: CYCids
113/11: np.where(dates=='20180226_16')
113/12: CYCids[473]
113/13: np.where(CYCids==121)
113/14: LON[int(np.mean(clon,axis=1)[ np.where(CYCids==121)])]
113/15: LON=np.linspace(-180,180,901)
113/16: LON[int(np.mean(clon,axis=1)[ np.where(CYCids==121)])]
113/17: LON[np.mean(clon,axis=1)[ np.where(CYCids==121)].astype(int)]
113/18: np.where(dates=='20180308_23')
113/19: CYCids[503]
113/20: LON[np.mean(clon,axis=1)[ np.where(CYCids==40)].astype(int)]
113/21: clat = np.delete(clat,452,axis=0)
113/22: clon = np.delete(clon,452,axis=0)
113/23: dates = np.delete(dates,452,axis=0)
113/24: CYCids= np.delete(CYCids,452,axis=0)
113/25: CYCcids
113/26: CYCids
113/27: htzeta = np.delete(htzeta,452,axis=0)
113/28: SLPmin  = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-MED-vort-entire-year.txt')
113/29: SLPmin = np.delete(SLPmin,452,axis=0)
113/30: np.where(CYCids==40).astype(int)
113/31: np.where(CYCids==40)[0].astype(int)
113/32: clat = np.delete(clat,np.where(CYCids==40)[0].astype(int),axis=0)
113/33: clon = np.delete(clon,np.where(CYCids==40)[0].astype(int),axis=0)
113/34: htzeta = np.delete(htzeta,np.where(CYCids==40)[0].astype(int),axis=0)
113/35: SLPmin = np.delete(SLPmin,np.where(CYCids==40)[0].astype(int),axis=0)
113/36: dates = np.delete(dates,np.where(CYCids==40)[0].astype(int),axis=0)
113/37: labels = np.delte(labels,452,axis=0)
113/38: labels = np.delete(labels,452,axis=0)
113/39: labels = np.delete(labels,np.where(CYCids==40)[0].astype(int),axis=0)
113/40: houtstoSLPmin = SLPmin
113/41: CYCids= np.delete(CYCids,np.where(CYCids==40)[0].astype(int),axis=0)
113/42:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/43: houtstoSLPmin=SLPmin
113/44:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/45: hourstoSLPmin = SLPmin
113/46: hourstoSLPmin
113/47:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/48: hourszeta=htzeta
113/49:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/50: CYCIDS=CYCids
113/51:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/52: np.where(dates=='20180103_02')
113/53: LON[np.mean(clon,axis=1)[ np.where(CYCids==CYCids[154])].astype(int)]
113/54: LAT = np.linspace(0,90,226)
113/55: LAT[np.mean(clon,axis=1)[ np.where(CYCids==CYCids[154])].astype(int)]
113/56: LAT[np.mean(clat,axis=1)[ np.where(CYCids==CYCids[154])].astype(int)]
113/57: np.where(LAT[np.mean(clat,axis=1)]==48.4)
113/58: np.where(LAT[np.mean(clat,axis=1).astype(int)]==48.4)
113/59: LAT[np.mean(clat,axis=1).astype(int)]
113/60: np.where(np.round(LAT[np.mean(clat,axis=1).astype(int)],1)==48.4)
113/61: clat[148] = clat[149]
113/62: np.where(np.round(LAT[np.mean(clat,axis=1).astype(int)],1)==48.4)
113/63: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/64: np.where(dates=='20181211_22')
113/65: np.where(dates=='20181011_22')
113/66: CYCids[719]
113/67: htzeta[np.where(CYCids==CYCids[719]))
113/68: htzeta[np.where(CYCids==CYCids[719])]
113/69: np.where(CYCids==CYCids[719])
113/70: rm62 = np.array([693, 695, 697,698,700,702,705])
113/71: htzeta[np.where(CYCids==CYCids[719])+1]
113/72: htzeta[np.where(CYCids==CYCids[719])[0]+1]
113/73: htzeta[np.where(CYCids==CYCids[719])[0]+2]
113/74: np.where(CYCids==CYCids[719])
113/75: htzeta[np.where(CYCids==CYCids[719])[0]+2]
113/76: htzeta[np.where(CYCids==CYCids[719])]
113/77: CYCids= np.delete(CYCids,rm62,axis=0)
113/78: clat = np.delete(clat,rm62,axis=0)
113/79: clon = np.delete(clon,rm62,axis=0)
113/80: labels = np.delete(labels,rm62,axis=0)
113/81: htzeta = np.delete(htzeta,rm62,axis=0)
113/82: SLPmin = np.delete(SLPmin,rm62,axis=0)
113/83:
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
113/84: CYCids[719]
113/85: np.where(CYCids[719])
113/86: np.where(CYCids==CYCids[719])
113/87: CYCids[798]
113/88: np.where(CYCids==74)
113/89: np.where(CYCids==76)
113/90: np.where(np.where(CYCids==76)>700)
113/91: np.where(np.where(CYCids==76)[0]>700)
113/92: np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]
113/93: LAT(np.mean(clat,axis=0).astype(int)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]])
113/94: LAT(np.mean(clat,axis=1).astype(int)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]])
113/95: LAT(np.mean(clat,axis=1)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]])
113/96: LAT[np.mean(clat,axis=1)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]]]
113/97: LAT[(np.mean(clat,axis=1)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]]).astype(int)]
113/98: np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]
113/99: LAT[(np.mean(clat,axis=1)[np.where(CYCids==62)[0]]).astype(int)]
113/100: np.where(CYCids==62)[0]
113/101: np.where(CYCids==62)[0][60:]
113/102: LAT[(np.mean(clat,axis=1)[np.where(CYCids==62)[0]]).astype(int)][60:]
113/103: LAT[(np.mean(clat,axis=1)[np.where(CYCids==62)[0]]).astype(int)][80:]
113/104: LAT[(np.mean(clat,axis=1)[np.where(CYCids==62)[0]]).astype(int)][90:]
113/105: np.where(CYCids==62)[0][90:]
113/106: sw62to76 = np.array([787,790,792,794,796])
113/107: sw76to62 = np.array([800,801,803,805,807])
113/108: np.where(dates=='20181007_12')
113/109: CYCids[600]
113/110: np.where(CYCids==44)
113/111: htzeta[np.where(CYCids==44)]
113/112: np.where(dates=='20181011_22')
113/113: LAT[(np.mean(clat,axis=1)[np.where(CYCids==62)[0]]).astype(int)]
113/114: LON[(np.mean(clon,axis=1)[np.where(CYCids==62)[0]]).astype(int)]
113/115: htzeta[np.where(CYCids==62)]
113/116: htzeta[np.where(CYCids==62)][:15]
113/117: np.where(CYCids==62)[:15]
113/118: np.where(CYCids==62)[0][:15]
113/119: np.where(CYCids==44)[0][60:]
113/120: htzeta[np.where(CYCids==44)[0][60:]]
113/121: np.mean(clat[785:810],axis=1)
113/122: LAT[(np.mean(clat,axis=1)[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]]).astype(int)]
113/123: np.where(np.where(CYCids==76)[0]>700)
113/124: np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]
113/125: htzeta[np.where(CYCids==76)[0][np.where(np.where(CYCids==76)[0]>700)]]
113/126: sw62to76
113/127: sw72to62
113/128: sw76to62
113/129:
for l  in range(len(sw62to76)):
    clat[sw76to62[l]] = clat[sw62to76[l]]
    clon[sw76to62[l]] = clon[sw62to76[l]]
    CYCids[sw76to62[l]] = CYCids[sw62to76[l]]
    htzeta[sw76to62[l]] = htzeta[sw62to76[l]]
    SLPmin[sw76to62[l]] = SLPmin[sw62to76[l]]
113/130: rm= np.arange(680,706,1)
113/131: clon = np.delete(clon,rm,axis=0)
113/132: clat = np.delete(clat,rm,axis=0)
113/133: labels = np.delete(labels,rm,axis=0)
113/134: dates = np.delete(dates,rm62,axis=0)
113/135: dates = np.delete(dates,rm,axis=0)
113/136: dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
113/137: dates = np.delete(dates,rm,axis=0)
113/138: CYCids= np.delete(CYCids,rm,axis=0)
113/139: htzeta = np.delete(htzeta,rm,axis=0)
113/140: SLPmin = np.delete(SLPmin,rm,axis=0)
113/141: hourszeta = htzeta
113/142: hourstoSLPmin = SLPmin
113/143: CYCIDS = CYCids
113/144:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
113/145:
MEDid = np.where(labels==2)[0].astype(int)
#startids=np.array([0,26,73, 142, 168, 197, 224, 269, 288, 331, 393, 452, 484, 530, 576, 599,640,728,903,922,951,972])
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[70:181]
pltlon = np.linspace(-180,180,901)[420:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
113/146:
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
for q, e in enumerate(traced):
    q = q #+ 10
    d = np.loadtxt(p + e)
    col=colors[q]
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(LON[np.mean(clon,axis=1).astype(int)[trackid]],LAT[np.mean(clat,axis=1).astype(int)[trackid]],color=col)
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    legendd = np.append(legendd,dates[matureid[q]])
#    ax.text(d[::49,1],d[::49,2],'%d'%q)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    ax.scatter(LON[int(np.mean(clon[matureid[q]]))],LAT[int(np.mean(clat[matureid[q]]))],color=col,marker='o',s=0.3)
    ax.scatter(LON[int(np.mean(clon[startids[q]]))],LAT[int(np.mean(clat[startids[q]]))],color=col,marker='d',s=10.)

lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
ax.legend(legendd,fontsize=4)
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'test.png',dpi=300,bbox_inches="tight")
plt.close()
113/147:
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
113/148: np.where(dates=='20181007_12')
113/149: CYCids[600]
113/150: np.where(CYCids==44)
113/151: rm = np.arange(680,706)
113/152: clat = np.delete(clat,rm,axis=0)
113/153: clon = np.delete(clon,rm,axis=0)
113/154: CYCids= np.delete(CYCids,rm,axis=0)
113/155: dates = np.delete(dates,rm,axis=0)
113/156: htzeta = np.delete(htzeta,rm,axis=0)
113/157: labels = np.delete(labels,rm,axis=0)
113/158:
MEDid = np.where(labels==2)[0].astype(int)
#startids=np.array([0,26,73, 142, 168, 197, 224, 269, 288, 331, 393, 452, 484, 530, 576, 599,640,728,903,922,951,972])
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[70:181]
pltlon = np.linspace(-180,180,901)[420:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
for q, e in enumerate(traced):
    q = q #+ 10
    d = np.loadtxt(p + e)
    col=colors[q]
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(LON[np.mean(clon,axis=1).astype(int)[trackid]],LAT[np.mean(clat,axis=1).astype(int)[trackid]],color=col)
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    legendd = np.append(legendd,dates[matureid[q]])
#    ax.text(d[::49,1],d[::49,2],'%d'%q)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    ax.scatter(LON[int(np.mean(clon[matureid[q]]))],LAT[int(np.mean(clat[matureid[q]]))],color=col,marker='o',s=0.3)
    ax.scatter(LON[int(np.mean(clon[startids[q]]))],LAT[int(np.mean(clat[startids[q]]))],color=col,marker='d',s=10.)

lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
113/159:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
ax.legend(legendd,fontsize=4)
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'test.png',dpi=300,bbox_inches="tight")
plt.close()
113/160: hourszeta = htzeta
113/161:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
113/162: np.where(dates=='20171011_22')
113/163: np.where(dates=='20181011_22')
113/164: np.where(CYCids==CYCids[693])
113/165: htzeta[np.where(CYCids==CYCids[693])]
113/166: np.where(CYCids==CYCids[693])[0][70:]
113/167: htzeta[np.where(CYCids==CYCids[693])][70:]
113/168: rm = np.arange(758,772,1)
113/169: clon = np.delete(clon,rm,axis=0)
113/170: clat = np.delete(clat,rm,axis=0)
113/171: htzeta = np.delete(htzeta,rm,axis=0)
113/172: dates = np.delete(dates,rm,axis=0)
113/173: labels = np.delete(labels,rm,axis=0)
113/174: CYCids= np.delete(CYCids,rm,axis=0)
113/175:
MEDid = np.where(labels==2)[0].astype(int)
#startids=np.array([0,26,73, 142, 168, 197, 224, 269, 288, 331, 393, 452, 484, 530, 576, 599,640,728,903,922,951,972])
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[70:181]
pltlon = np.linspace(-180,180,901)[420:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
for q, e in enumerate(traced):
    q = q #+ 10
    d = np.loadtxt(p + e)
    col=colors[q]
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(LON[np.mean(clon,axis=1).astype(int)[trackid]],LAT[np.mean(clat,axis=1).astype(int)[trackid]],color=col)
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    legendd = np.append(legendd,dates[matureid[q]])
#    ax.text(d[::49,1],d[::49,2],'%d'%q)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    ax.scatter(LON[int(np.mean(clon[matureid[q]]))],LAT[int(np.mean(clat[matureid[q]]))],color=col,marker='o',s=0.3)
    ax.scatter(LON[int(np.mean(clon[startids[q]]))],LAT[int(np.mean(clat[startids[q]]))],color=col,marker='d',s=10.)

lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
ax.legend(legendd,fontsize=4)
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'test.png',dpi=300,bbox_inches="tight")
plt.close()
113/176: np.where(CYCids==76)
113/177: htzeta[np.where(CYCids==76)]
113/178: htzeta[np.where(CYCids==76)][20:]
113/179: htzeta[np.where(CYCids==76)][24:]
113/180: np.where(CYCids==76)[24:]
113/181: np.where(CYCids==76)[0][24:]
113/182: rm = np.arange(759,768)
113/183: clat = np.delete(clat,rm,axis=0)
113/184: clon = np.delete(clon,rm,axis=0)
113/185: dates = np.delete(dates,rm,axis=0)
113/186: labels = np.delete(labels,rm,axis=0)
113/187: htzeta = np.delete(htzeta,rm,axis=0)
113/188: CYCids= np.delete(CYCids,rm,axis=0)
113/189:
MEDid = np.where(labels==2)[0].astype(int)
#startids=np.array([0,26,73, 142, 168, 197, 224, 269, 288, 331, 393, 452, 484, 530, 576, 599,640,728,903,922,951,972])
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pltlat = np.linspace(0,90,226)[70:181]
pltlon = np.linspace(-180,180,901)[420:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
for q, e in enumerate(traced):
    q = q #+ 10
    d = np.loadtxt(p + e)
    col=colors[q]
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(LON[np.mean(clon,axis=1).astype(int)[trackid]],LAT[np.mean(clat,axis=1).astype(int)[trackid]],color=col)
    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    legendd = np.append(legendd,dates[matureid[q]])
#    ax.text(d[::49,1],d[::49,2],'%d'%q)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    ax.scatter(LON[int(np.mean(clon[matureid[q]]))],LAT[int(np.mean(clat[matureid[q]]))],color=col,marker='o',s=0.3)
    ax.scatter(LON[int(np.mean(clon[startids[q]]))],LAT[int(np.mean(clat[startids[q]]))],color=col,marker='d',s=10.)

lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
ax.legend(legendd,fontsize=4)
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'test.png',dpi=300,bbox_inches="tight")
plt.close()
113/190: hourszeta = htzeta
113/191:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htSLPmin-' + add + '.txt',hourstoSLPmin.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',hourszeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCIDS.astype(int), fmt='%i', delimiter=' ',newline='\n')
114/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
114/2: np.where(CYCids==62)
114/3: np.where(CYCids==76)
114/4: np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1
114/5: MEDid = np.where(labels==2)[0].astype(int)
114/6: np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1
114/7: CYCids[MEDid][1:]-CYCids[MEDid][:-1]
114/8: CYCids
114/9: CYCids[772]
114/10: CYCids[773]
114/11: CYCids[774]
114/12: CYCids[776]
114/13: CYCids[775]
114/14: CYCids[770:]
114/15: rm = np.array([774,775,777,779,781])
114/16: CYCids[rm]
114/17: clat = np.delete(clat,rm,axis=0)
114/18: clon = np.delete(clon,rm,axis=0)
114/19: dates = np.delete(dates,rm,axis=0)
114/20: labels = np.delete(labels,rm,axis=0)
114/21: htzeta = np.delete(htzeta,rm,axis=0)
114/22: CYCids= np.delete(CYCids,rm,axis=0)
114/23: :q
114/24:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',htzeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCids.astype(int), fmt='%i', delimiter=' ',newline='\n')
114/25: np.where(CYCids==62)
114/26: np.linspace(0,90,226)[np.mean(clat,axis=0)[np.where(CYCids==62)].astype(int)]
114/27: np.linspace(0,90,226)[np.mean(clat,axis=1)[np.where(CYCids==62)].astype(int)]
114/28: CYCids[[np.where(CYCids==62)]]
114/29: [np.where(CYCids==62)]
114/30: np.where(dates==20181011_22')
114/31: np.where(dates=='20181011_22')
114/32: CYCids[693]
114/33: CYCids[758:772]=76
114/34:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',dates.astype(str), fmt='%s', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/labels-' + add + '.txt',labels.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',htzeta.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-' +add + '.txt', CYCids.astype(int), fmt='%i', delimiter=' ',newline='\n')
115/1: from datetime import datetime, date, timedelta
115/2: datetime.toordinal()
115/3: help(datetime.toordinal)
115/4: datetime.toordinal('20180101_00')
115/5: import numpy as np
115/6: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-MED-vort-entire-year.txt')
115/7: d
115/8: d = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-MED-vort-entire-year.txt')
115/9: np.where(d==0)
115/10: k = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-MED-vort-entire-year.txt')
115/11: k[np.where(d==0)]
115/12: k = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-MED-vort-entire-year.txt')
115/13: k[np.where(d==0)]
115/14: da = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year.txt)
115/15: da = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year.txt')
115/16: da[np.where(d==0)]
115/17: da = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year.txt',dtype=str)
115/18: da[np.where(d==0)]
115/19: k[np.where(d==0)]
115/20: dates[np.where(k==76)]
115/21: da[np.where(k==76)]
115/22: np.where(k==73)
115/23: t = np.array([1, 2,3,4,5,6,7,8,23,0])
115/24: np.where((t[1:]-t[:-1])==(1 | (-23)))
115/25: t[1:]-t[:-1]
115/26: np.where((t[1:]-t[:-1])!=(1 | (-23)))
115/27: np.where((t[1:]-t[:-1])!=(1 || (-23)))
115/28: np.where((t[1:]-t[:-1])!=(1 or (-23)))
115/29: da
115/30: da[np.where(k==76)]
115/31: da[1:][9:].astype(int)-da[:-1][9:].astype(int)
115/32: I =np.where(k==76) [0]
115/33: I
115/34: da[I][1:][9:].astype(int)-da[I][:-1][9:].astype(int)
115/35: da[I]
115/36: da[I][1:]
115/37: da[I][1:][9:]
115/38: da[I][1:,9:]
115/39: da[I][1:]
115/40: da[1:]
115/41: da[I]
115/42: da[I][0]
115/43: da[I][0][9:]
115/44: da[I][:][9:]
115/45: da[I][:,0]
115/46: da[I][1:]
115/47: da[I]
115/48: da[I][1:]
115/49: da[I][1:][0]
115/50: da[I][1:][0][9:]
115/51: da[I][1:][:][9:]
115/52: da[I][1:][9:]
115/53: da[I]
115/54: da[I][0]
115/55: da[I][0][9]
115/56: da[I][1:][9]
115/57: (da[I][1:]-da[I][:-1])[9]
115/58: da[I]
115/59: da[I][0]
115/60: da[I][0][9:]
115/61:
for q in range(len(da[I])-2):
    if ((da[I][q+1][9:].astype(int)-da[I][q][9:].astype(int))!= (1 or (-23))):
        print(q)
115/62:
for q in range(len(da[I])-2):
    if ((int(da[I][q+1][9:])-int(da[I][q][9:]))!= (1 or (-23))):
        print(q)
115/63:
for q in range(len(da[I])-2):
    print(int(da[I][q+1][9:])-int(da[I][q][9:]))
    if ((int(da[I][q+1][9:])-int(da[I][q][9:]))!= (1 or (-23))):
       print(test)
115/64:
for q in range(len(da[I])-2):
    print(int(da[I][q+1][9:])-int(da[I][q][9:]))
    if ((int(da[I][q+1][9:])-int(da[I][q][9:]))!= (1 or (-23))):
       print('test')
115/65: da[I]
115/66: pwd
116/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


#p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
p = '/atmosdyn2/ascherrmann/006-year-traj/12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)
fsl=4
LSid = 16
labs = helper.traced_vars()
cl=['k','orange','green','lightblue','magenta','blue','red']
pllegend = ['cyc','env','TOT','CONVT + TURBT', 'CONVM', 'TURBM','RAD','COND','LS']
plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRCOND','PVRLS']
ptitle = np.array(['800 hPa < P$_{-48}$', '600 < P$_{-48} <$800 hPa', '400 < P$_{-48} <$600 hPa',  'P$_{-48} <$400 hPa'])
linestyle = ['-',':']

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
rdis = 1000
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)
### INFO
### Trajetories start 200km around the center between 925 and 500 hPa if PV>0.75 PVU
###
wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()
H = 48
xlim = np.array([-1*H,0])
xlim = xlim - 12
pressure_stack = np.zeros(H+1)
116/2:
for txt in traced:
    date=txt[-15:-4]
#    date=txt[12:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here
    dipv[date][env]=dict()
    dipv[date][cyc]=dict()

    tt = np.loadtxt(p + txt)
117/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


#p = '/atmosdyn2/ascherrmann/005-trajetories-DEC17-73/maturestage/'
p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)
fsl=4
LSid = 16
labs = helper.traced_vars()
cl=['k','orange','green','lightblue','magenta','blue','red']
pllegend = ['cyc','env','TOT','CONVT + TURBT', 'CONVM', 'TURBM','RAD','COND','LS']
plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRCOND','PVRLS']
ptitle = np.array(['800 hPa < P$_{-48}$', '600 < P$_{-48} <$800 hPa', '400 < P$_{-48} <$600 hPa',  'P$_{-48} <$400 hPa'])
linestyle = ['-',':']

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
rdis = 100
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)
### INFO
### Trajetories start 200km around the center between 925 and 500 hPa if PV>0.75 PVU
###
wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()
H = 48
xlim = np.array([-1*H,0])
ylim = np.array([-0.3,0.5])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
117/2:
for txt in traced:
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here
    dipv[date][env]=dict()
    dipv[date][cyc]=dict()

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    tmpclon= np.array([])
    tmpclat= np.array([])

    ### follow cyclone backwards to find its center
    dit[date] = dict()
    dit[date][env] = np.zeros(datadi[date]['time'].shape)
    dit[date][cyc] = np.zeros(datadi[date]['time'].shape)

    for k in range(0,H+1):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        if(np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0].size):
            tmpq = np.where((dates==Date) & (labels==2) & (htzeta==(-k)))[0][0]
            hh-=1
            tmpclon = np.append(tmpclon,np.mean(clon[tmpq]))
            tmpclat = np.append(tmpclat,np.mean(clat[tmpq]))
        else:
            ### use boundary position that no traj should be near it
            tmpclon = np.append(tmpclon,860)
            tmpclat = np.append(tmpclat,200)
    ### check every hours every trajecttory whether it is close to the center ###
    for e, h in enumerate(datadi[date]['time'][0,:]):
        tmplon = tmpclon[e].astype(int)# + helper.radial_ids_around_center_calc(rdis)[0].astype(int)
        tmplat = tmpclat[e].astype(int)# + helper.radial_ids_around_center_calc(rdis)[1].astype(int)
        ### center lon and latitude
        CLON = LON[tmplon]#.astype(int)]
        CLAT = LAT[tmplat]#.astype(int)]

        ### 30.10.2020 radial distance instead of square
        ### if traj is in circle of 200km set cyc entry to 0, else env entry 1
        for tr in range(len(datadi[date]['time'])):
            if ( np.sqrt( (CLON-datadi[date]['lon'][tr,e])**2 + (CLAT-datadi[date]['lat'][tr,e])**2) <=  deltaLONLAT):
            ###
                dit[date][cyc][tr,e]=1
            else:
                dit[date][env][tr,e]=1
    for key in split:
        for k, el in enumerate(labs[9:]):
            dipv[date][key][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][key][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:]*dit[date][key][:,1:],axis=1),axis=1),axis=1)

        dipv[date][key]['APVTOT'] = -1 * dipv[date][key]['PVRLS']
        for el in labs[9:]:
            dipv[date][key]['APVTOT'] += dipv[date][key][el]

        dipv[date][key]['APVRAD'] = dipv[date][key]['PVRSW'] + dipv[date][key]['PVRLWH'] + dipv[date][key]['PVRLWC']
        dipv[date][key]['PVR-T'] = dipv[date][key]['PVRTURBT'] + dipv[date][key]['PVRCONVT']

        for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[key][el] = dipv[date][key][el]
            else:
                meandi[key][el] = np.concatenate((meandi[key][el], dipv[date][key][el]),axis=0)
    wql=10
    pressure_stack = np.vstack((pressure_stack,datadi[date]['P']))
117/3:
pressure_stack=np.delete(pressure_stack,0,axis=0)

ditstack = dict()
for key in split:
    for k,txt in enumerate(traced):
        date=txt[12:-4]
        if k==0:
            ditstack[key] = dit[date][key]
        else:
            ditstack[key] = np.concatenate((ditstack[key],dit[date][key]),axis=0)
117/4:
fig, axes = plt.subplots(2,2,sharex=True, sharey=True)
plt.subplots_adjust(left=0.15,bottom=None,top=None,right=None,hspace=0.2,wspace=0.1)
axes = axes.flatten()
117/5:
for q, ax in enumerate(axes):
    idp = np.array([])
    for kl in range(0,49):
        if q==0:
            idp = np.append(idp,np.where(pressure_stack[:,kl]>800)[0])
         elif q==1:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600))[0])
         elif q==2:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400))[0])
         else:
            idp = np.append(idp,np.where(pressure_stack[:,kl]<400)[0])
117/7:
for q, ax in enumerate(axes):
    idp = np.array([])
    for kl in range(0,49):
         if q==0:
            idp = np.append(idp,np.where(pressure_stack[:,kl]>800)[0])
         elif q==1:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600))[0])
         elif q==2:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400))[0])
         else:
            idp = np.append(idp,np.where(pressure_stack[:,kl]<400)[0])
117/8: idp
117/9:
for q, ax in enumerate(axes):
    idp = np.array([])
    for kl in range(0,49):
         if q==0:
            idp = np.append(idp,np.where(pressure_stack[:,kl]>800))
         elif q==1:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600)))
         elif q==2:
            idp = np.append(idp,np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400)))
         else:
            idp = np.append(idp,np.where(pressure_stack[:,kl]<400))
117/10: idp
117/11: idp.shape
117/12: pressure_stack.shape
117/13:
for q, ax in enumerate(axes):
    idp = []
    for kl in range(0,49):
         if q==0:
            idp.append(np.where(pressure_stack[:,kl]>800))
         elif q==1:
            idp.append(np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600)))
         elif q==2:
            idp.append(np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400)))
         else:
            idp.append(np.where(pressure_stack[:,kl]<400))
117/14: idp
117/15: idp[0]
117/16: idp[1]
117/17: idp[4]
117/18: idp.shape
117/19:
for q, ax in enumerate(axes):
    idp = []
    for kl in range(0,49):
         if q==0:
            idp.append(np.where(pressure_stack[:,kl]>800)[0])
         elif q==1:
            idp.append(np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600))[0])
         elif q==2:
            idp.append(np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400))[0])
         else:
            idp.append(np.where(pressure_stack[:,kl]<400)[0])
117/20: idp
117/21: len(idp)
117/22: idp[0]
117/23: idp[49]
117/24: idp[48]
117/25: idp[48].shape
117/26:
fig, axes = plt.subplots(2,2,sharex=True, sharey=True)
plt.subplots_adjust(left=0.15,bottom=None,top=None,right=None,hspace=0.2,wspace=0.1)
axes = axes.flatten()
gax = fig.add_subplot(111, frameon=False)
gax.set_xticks(ticks=[])
gax.set_yticks(ticks=[])
titles = 'pressure-regime-' + 'PV-contribution'
for q, ax in enumerate(axes):
    idp = []
    for kl in range(0,49):
         if q==0:
            idp.append(np.where(pressure_stack[:,kl]>800)[0])
         elif q==1:
            idp.append(np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600))[0])
         elif q==2:
            idp.append(np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400))[0])
         else:
            idp.append(np.where(pressure_stack[:,kl]<400)[0])
    for wt, ru in enumerate(plotvars):
#            sq=np.sum(ditstack[env][idp] + ditstack[cyc][idp],axis=0)
            sq=np.sum(ditstack[env]+ ditstack[cyc],axis=0)
            meantmp = np.array([])
            stdtmp = np.array([])
            for xx in range(len(sq)):
                if sq[xx]>0:
                    meantmp = np.append(meantmp,np.sum(meandi[key][ru][idp[xx],xx])/sq[xx])
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum( (meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/sq[xx]))
                else:
                    meantmp = np.append(meantmp,0)
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum((meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/1))
            ax.plot(t,meantmp,color=cl[wt],label=pllegend[wt],ls=linestyle[pl])
#            ax.fill_between(t,meantmp-stdtmp,meantmp+stdtmp,color=cl[wt],alpha=0.2)
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)
    ax.set_title(ptitle[q],fontsize=8)
    ax.set_xticks(ticks=np.arange(-48,1,6))
    ax.tick_params(labelright=False,right=True)
axes[1].legend(pllegend,fontsize=fsl,loc='upper left')
fig.text(0.5,0.94, titles ,ha='center',fontsize=12)
fig.text(0.5, 0.04, 'time until mature stage [h]',ha='center')
fig.text(0.04,0.5, 'accumulated PV [PVU]',va='center',rotation='vertical')
name = 'accumulated-composite-pressure-contribution-' + 'mean-wrt-alltrajectories-' + str(rdis) +  '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
plt.close()
117/27:
plt.close('all')
t = np.flip(np.arange(-48,1))
fig, axes = plt.subplots(2,2,sharex=True, sharey=True)
plt.subplots_adjust(left=0.15,bottom=None,top=None,right=None,hspace=0.2,wspace=0.1)
axes = axes.flatten()
gax = fig.add_subplot(111, frameon=False)
gax.set_xticks(ticks=[])
gax.set_yticks(ticks=[])
titles = 'pressure-regime-' + 'PV-contribution'
for q, ax in enumerate(axes):
    idp = []
    for kl in range(0,49):
         if q==0:
            idp.append(np.where(pressure_stack[:,kl]>800)[0])
         elif q==1:
            idp.append(np.where((pressure_stack[:,kl]<800) & (pressure_stack[:,kl]>600))[0])
         elif q==2:
            idp.append(np.where((pressure_stack[:,kl]<600) & (pressure_stack[:,kl]>400))[0])
         else:
            idp.append(np.where(pressure_stack[:,kl]<400)[0])
    for wt, ru in enumerate(plotvars):
#            sq=np.sum(ditstack[env][idp] + ditstack[cyc][idp],axis=0)
            sq=np.sum(ditstack[env]+ ditstack[cyc],axis=0)
            meantmp = np.array([])
            stdtmp = np.array([])
            for xx in range(len(sq)):
                if sq[xx]>0:
                    meantmp = np.append(meantmp,np.sum(meandi[key][ru][idp[xx],xx])/sq[xx])
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum( (meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/sq[xx]))
                else:
                    meantmp = np.append(meantmp,0)
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum((meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/1))
            ax.plot(t,meantmp,color=cl[wt],label=pllegend[wt],ls=linestyle[pl])
#            ax.fill_between(t,meantmp-stdtmp,meantmp+stdtmp,color=cl[wt],alpha=0.2)
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)
    ax.set_title(ptitle[q],fontsize=8)
    ax.set_xticks(ticks=np.arange(-48,1,6))
    ax.tick_params(labelright=False,right=True)
axes[1].legend(pllegend,fontsize=fsl,loc='upper left')
fig.text(0.5,0.94, titles ,ha='center',fontsize=12)
fig.text(0.5, 0.04, 'time until mature stage [h]',ha='center')
fig.text(0.04,0.5, 'accumulated PV [PVU]',va='center',rotation='vertical')
name = 'accumulated-composite-pressure-contribution-' + 'mean-wrt-alltrajectories-' + str(rdis) +  '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
plt.close()
117/28: plt.close()
117/29:
fig, axes = plt.subplots(2,2,sharex=True, sharey=True)
plt.subplots_adjust(left=0.15,bottom=None,top=None,right=None,hspace=0.2,wspace=0.1)
axes = axes.flatten()
gax = fig.add_subplot(111, frameon=False)
gax.set_xticks(ticks=[])
gax.set_yticks(ticks=[])
titles = 'pressure-regime-' + 'PV-contribution'
for pl, key in enumerate(split):
    for q, ax in enumerate(axes):
        ax.plot([],[],marker=None,ls='-',color='black')
        ax.plot([],[],marker=None,ls=':',color='black')
        idp = []
        for kl in range(0,49):
         if q==0:
             idp.append(np.where((ditstack[key][:,kl] * pressure_stack[:,kl])>800)[0])
         elif q==1:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl])<800) & ((ditstack[key][:,kl] *pressure_stack[:,kl])>600))[0])
         elif q==2:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl])<600) & ((ditstack[key][:,kl] *pressure_stack[:,kl])>400))[0])
         else:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl)]<400) & (ditstack[key][:,kl]==1) )[0])

        for wt, ru in enumerate(plotvars):
#            sq=np.sum(ditstack[env][idp] + ditstack[cyc][idp],axis=0)
            sq=np.sum(ditstack[env]+ ditstack[cyc],axis=0)
            meantmp = np.array([])
            stdtmp = np.array([])
            for xx in range(len(sq)):
                if sq[xx]>0:
                    meantmp = np.append(meantmp,np.sum(meandi[key][ru][idp[xx],xx])/sq[xx])
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum( (meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/sq[xx]))
                else:
                    meantmp = np.append(meantmp,0)
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum((meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/1))
            ax.plot(t,meantmp,color=cl[wt],label=pllegend[wt],ls=linestyle[pl])
#            ax.fill_between(t,meantmp-stdtmp,meantmp+stdtmp,color=cl[wt],alpha=0.2)
        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
        ax.set_title(ptitle[q],fontsize=8)
        ax.set_xticks(ticks=np.arange(-48,1,6))
        ax.tick_params(labelright=False,right=True)
axes[1].legend(pllegend,fontsize=fsl,loc='upper left')
fig.text(0.5,0.94, titles ,ha='center',fontsize=12)
fig.text(0.5, 0.04, 'time until mature stage [h]',ha='center')
fig.text(0.04,0.5, 'accumulated PV [PVU]',va='center',rotation='vertical')
name = 'accumulated-composite-pressure-contribution-' + 'mean-wrt-alltrajectories-' + str(rdis) +  '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
plt.close()
117/30: plt.close()
117/31:
fig, axes = plt.subplots(2,2,sharex=True, sharey=True)
plt.subplots_adjust(left=0.15,bottom=None,top=None,right=None,hspace=0.2,wspace=0.1)
axes = axes.flatten()
gax = fig.add_subplot(111, frameon=False)
gax.set_xticks(ticks=[])
gax.set_yticks(ticks=[])
titles = 'pressure-regime-' + 'PV-contribution'
for pl, key in enumerate(split):
    for q, ax in enumerate(axes):
        ax.plot([],[],marker=None,ls='-',color='black')
        ax.plot([],[],marker=None,ls=':',color='black')
        idp = []
        for kl in range(0,49):
         if q==0:
             idp.append(np.where((ditstack[key][:,kl] * pressure_stack[:,kl])>800)[0])
         elif q==1:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl])<800) & ((ditstack[key][:,kl] *pressure_stack[:,kl])>600))[0])
         elif q==2:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl])<600) & ((ditstack[key][:,kl] *pressure_stack[:,kl])>400))[0])
         else:
            idp.append(np.where(((ditstack[key][:,kl] *pressure_stack[:,kl])<400) & (ditstack[key][:,kl]==1) )[0])

        for wt, ru in enumerate(plotvars):
#            sq=np.sum(ditstack[env][idp] + ditstack[cyc][idp],axis=0)
            sq=np.sum(ditstack[env]+ ditstack[cyc],axis=0)
            meantmp = np.array([])
            stdtmp = np.array([])
            for xx in range(len(sq)):
                if sq[xx]>0:
                    meantmp = np.append(meantmp,np.sum(meandi[key][ru][idp[xx],xx])/sq[xx])
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum( (meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/sq[xx]))
                else:
                    meantmp = np.append(meantmp,0)
                    stdtmp = np.append(stdtmp,np.sqrt(np.sum((meandi[key][ru][idp[xx],xx]-meantmp[-1])**2 )/1))
            ax.plot(t,meantmp,color=cl[wt],label=pllegend[wt],ls=linestyle[pl])
#            ax.fill_between(t,meantmp-stdtmp,meantmp+stdtmp,color=cl[wt],alpha=0.2)
        ax.set_xlim(xlim)
        ax.set_ylim(ylim)
        ax.set_title(ptitle[q],fontsize=8)
        ax.set_xticks(ticks=np.arange(-48,1,6))
        ax.tick_params(labelright=False,right=True)
axes[1].legend(pllegend,fontsize=fsl,loc='upper left')
fig.text(0.5,0.94, titles ,ha='center',fontsize=12)
fig.text(0.5, 0.04, 'time until mature stage [h]',ha='center')
fig.text(0.04,0.5, 'accumulated PV [PVU]',va='center',rotation='vertical')
name = 'accumulated-composite-pressure-contribution-' + 'mean-wrt-alltrajectories-' + str(rdis) +  '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
plt.close()
118/1: import numpy as np
118/2: add = 'ET-vort-entire-year'
118/3: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
118/4:
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
118/5:
add = 'MED-vort-entire-year'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
118/6: cyids = np.loadtxt('cycIDs-MED-vort-entire-year.txt',dtype=int)
118/7: cyids[np.where(dates=='20181015_23')]
118/8: np.where(cyids==76)
118/9: np.mean(clat[758:825])
118/10: np.mean(clat[758:825],axis=1)
118/11: np.mean(clon[758:825],axis=1)
119/1: import numpy as np
119/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
119/3:
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year2'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
119/4:
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
119/5: MEDid = np.where(labels==2)[0].astype(int)
119/6:
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
119/7: len(MEDid)
119/8: len(dates)
119/9: dates[-1]
119/10: CYCids[np.where(dates=='20180103_02')]
119/11: np.mean(clat[np.where(CYCids==17)],axis=1)
119/12: np.mean(clon[np.where(CYCids==17)],axis=1)
119/13: htzeta[np.where(CYCids==17)]
119/14: htzeta[np.where(CYCids==73)]
119/15: np.where(CYCids==17 & htzeta==-6)
119/16: np.where((CYCids==17) & (htzeta==-6))
119/17: clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
119/18: clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])).astype(int)
119/19: clat[148]
119/20: np.mean(clat[np.where(CYCids==17)],axis=1)
119/21: clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
119/22: np.mean(clon[np.where(CYCids==17)],axis=1)
119/23: np.where(dates=='20180308_23')
119/24: CYCids[536]
119/25: CYCids[692]
119/26: datesMAM = np.loadtxt('dates-MED-vort-MAM.txt',dtype=str)
119/27: datesMAM
119/28: np.where(datesMAM=='20180308_23')
119/29: np.where(dates=='20180308_23')
119/30: np.where(dates=='20180308_22')
119/31: np.where(dates=='20180314_11')
119/32: np.where(dates=='20180317_02')
119/33: np.where(dates=='20180417_02')
119/34: np.where(dates=='20180422_03')
119/35: CYCids[655:900]
119/36: CYCids[673:900]
119/37: CYCids[672:900]
119/38: CYCids[673:900]
119/39: CYCids[672:900]
119/40: CYCids[672:840]
119/41: CYCids[672:831]
119/42: CYCids[672:829]
119/43: CYCids[672:830]
119/44: np.delete(np.array([7,8,9,10],np.arange(0,2)))
119/45: np.delete(np.array([7,8,9,10]),np.arange(0,2))
119/46: np.delete(np.array([7,8,9,10]),np.arange(1,3))
119/47: delids = np.arange(673,829)
119/48: CYCids[delids]
119/49: np.delete(clat,delids)
119/50: np.delete(clat,delids,axis=0)
119/51: dates
119/52: dates = np.delete(dates,delids)
119/53: htzeta = np.delete(htzeta,delids)
119/54: clat = np.delete(clat,delids,axis=0)
119/55: clon = np.delete(clon,delids,axis=0)
119/56: CYCids = np.delete(CYCids,delids)
119/57: labels = np.delete(labels,delids)
119/58:
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
matureid = np.where((labels==2)&(htzeta==0))[0].astype(int)

colors = np.array(['#5F0458', '#A5BF65', '#C589D7', '#C360DB', '#C887B1', '#15A1C0',
       '#D0AF0C', '#EC4BEB', '#D647CA', '#8A3724', '#DE6067', '#B0AE27',
       '#87F134', '#859C82', '#A1FCD4', '#4612F7', '#22888C', '#94223C',
       '#DB3396', '#835255', '#061522', '#B1A8F7', '#E34CC2', '#0A48CB',
       '#EE086B', '#C4D5C2', '#D99596','#4712F7'])

p = '/atmosdyn2/ascherrmann/006-year-traj/'
119/59:
pltlat = np.linspace(0,90,226)[50:150]
pltlon = np.linspace(-180,180,901)[440:601]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)
119/60:
for q in range(len(startids[10:20])):#enumerate(traced[:]):
#    d = np.loadtxt(p + e)
    col=colors[q+10]
    q=q+10
    trackid = MEDid[startids[q]:startids[q+1]]
    ax.plot(LON[np.mean(clon,axis=1).astype(int)[trackid]],LAT[np.mean(clat,axis=1).astype(int)[trackid]],color=col)
#    ax.scatter(d[::49,1],d[::49,2],c=col,marker='+',s=0.5)
    legendd = np.append(legendd,dates[matureid[q]])
#    ax.text(d[::49,1],d[::49,2],'%d'%q)
#    ax.scatter(d[48::49,1],d[48::49,2],c=col,marker='x',s=0.5)
    ax.scatter(LON[int(np.mean(clon[matureid[q]]))],LAT[int(np.mean(clat[matureid[q]]))],color=col,marker='o',s=25.)
    ax.scatter(LON[int(np.mean(clon[startids[q]]))],LAT[int(np.mean(clat[startids[q]]))],color=col,marker='+',s=25.)
119/61:
lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
ax.legend(legendd,fontsize=4)
ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
fig.savefig(p + 'cyclone-tracks.png',dpi=300,bbox_inches="tight")
plt.close()
119/62: CYCids[np.where(dates=='20180308_23')]
119/63: np.where(CYCids==40)
119/64: delids = np.where(CYCids==40)
119/65:
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
119/66: CYCids[np.where(dates=='20180226_20')]
119/67: CYCids[np.where(dates=='20180228_09')]
119/68: CYCids[np.where(dates=='20180222_17')]
119/69: CYCids[np.where(dates=='20180308_23')]
119/70: CYCids[np.where(dates=='20180226_26')]
119/71: CYCids[np.where(dates=='20180226_20')]
119/72: np.where(CYCids==121)
119/73: clat[np.where(CYCids==121)]
119/74: np.mean(clat[np.where(CYCids==121)],axis=1)
119/75: np.mean(clon[np.where(CYCids==121)],axis=1)
119/76: htzeta[np.where(CYCids==121)]
119/77: np.where(CYCids==121)
119/78: delids=np.arange(452,456)
119/79:
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
119/80: np.where(dates=='20181007_12')
119/81: CYCids[np.where(dates=='20181007_12')]
119/82: dates[np.where(CYCids==44)]
119/83: np.where(dates=='20181011_02')
119/84: np.where(dates=='20181010_19')
119/85: htzeta[np.where(CYCids==44)]
119/86: CYCids
119/87: CYCids[700:]
119/88: CYCids[800:]
119/89: CYCids[900:]
119/90: CYCids[1000:]
119/91: CYCids[980:]
119/92: CYCids[985:]
119/93: CYCids[989:]
119/94: CYCids[988:]
119/95: CYCids[989:]
119/96: CYCids[989:len(CYCids)]
119/97: delids = np.arange(989,len(CYCids))
119/98: np.where(dates=='20181007_12')
119/99:
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
119/100: htzeta[700:]
119/101: np.where(dates=='20181010_19')
119/102: htzeta[np.where(CYCids==44)]
119/103: np.where(CYCids==62)
119/104: htzeta[np.where(CYCids==62)]
119/105: np.mean[clat[np.where(CYCids==62)],axis=1]
119/106: np.mean(clat[np.where(CYCids==62)],axis=1)
119/107: np.mean(clat[np.where(CYCids==44)],axis=1)
119/108: htzeta[np.where(CYCids==44)]
119/109: np.where(CYCids==62)
119/110: np.where(htzeta[np.where(CYCids==44)]<-10)
119/111: np.where((htzeta<-10)&(CYCids==44))
119/112: id44belongto62 = np.where((htzeta<-10)&(CYCids==44))[0]
119/113: htzeta[np.where(CYCids==62)]
119/114: htzeta[np.where(CYCids==76)]
119/115: id62belongto76 = np.where((htzeta>80)&(CYCids==62))[0]
119/116: id62belongto76
119/117: id44
119/118: id44belongto62
119/119: clattmp = clat[id44belongto62]
119/120: clattmp
119/121: htzeta[np.where(CYCids==62)]
119/122: htzeta[np.where(CYCids==44)]
119/123: htzeta[np.where(CYCids==62)]
119/124: htzeta[np.where(CYCids==76)]
119/125: id44t62 = np.where((htzeta<-10)&(CYCids==44))
119/126: id62t44 = np.where((htzeta>80)&(CYCids==62))
119/127: id62t76 = np.where((htzeta<-20)&(CYCids==62))
119/128: id62t76 = np.where((htzeta>70)&(CYCids==75))
119/129: datestmp = dates[id44t62]
119/130: clontmp = clon[id44t62]
119/131: clattmp = clat[id44t62]
119/132: htzetatmp = htzeta[id44t62]
119/133: labels
119/134: dates4462 = dates[id44t62]
119/135: clon4462 = clon[id44t62]
119/136: clat4462 = clat[id44t62]
119/137: htzeta4462 = htzeta[id44t62]
119/138: htzeta6244 = htzeta[id62t44]
119/139: clon6244 = clon[id62t44]
119/140: clat6244 = clat[id62t44]
119/141: dates6244 = dates[id62t44]
119/142: dates6276 = dates[id62t76]
119/143: clon6276 = clon[id62t76]
119/144: clat6276 = clat[id62t76]
119/145: htzeta6276 = htzeta[id62t76]
119/146: htzeta7662 = htzeta[id76t62]
119/147: id62t76 = np.where((htzeta<-20)&(CYCids==62))
119/148: id76t62 = np.where((htzeta>70)&(CYCids==76))
119/149: dates6276 = dates[id62t76]
119/150: clon6276 = clon[id62t76]
119/151: clat6276 = clat[id62t76]
119/152: htzeta6276 = htzeta[id62t76]
119/153: htzeta7662 = htzeta[id76t62]
119/154: clon7662 = clon[id76t62]
119/155: clat7662 = clat[id76t62]
119/156: dates7662 = dates[id76t62]
119/157: np.insert(np.array([5,6,7,8],1,1))
119/158: np.insert(np.array([5,6,7,8]),1,1)
119/159: np.insert(np.array([5,6,7,8]),2,1)
119/160: np.insert(np.array([5,6,7,8]),2,np.array([1,2]))
119/161: clat6276
119/162: np.insert(clat6276,1,clat7662,axis=0)
119/163: np.insert(clat6276,0,clat7662,axis=0)
119/164: np.delete(htzeta,id44t62)
119/165: np.delete(htzeta,id44t62)[:700]
119/166: htzeta[700:]
119/167: np.delete(htzeta,id44t62)[700:]
119/168: np.concatenate(id44t62,id62t44)
119/169: np.concatenate((id44t62,id62t44))
119/170: np.concatenate((id44t62,id62t44),axis=None)
119/171: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[700:]
119/172: htzeta6244
119/173: htzeta4462
119/174: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[711]
119/175: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[716]
119/176: np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),715,1)[715]
119/177: htzeta = np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))
119/178: htzeta = np.insert(htzeta,715,np.concatenate((htzeta6244,htzeta4462),axis=None))
119/179: np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None))[800:]
119/180: np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None))[815:]
119/181: np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None))[822:]
119/182: np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None))[823:]
119/183: np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None))[822:]
119/184: np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((htzeta7662,htzeta6276),axis=None))
119/185: np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((htzeta7662,htzeta6276),axis=None))[822:]
119/186: htzeta = np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((htzeta7662,htzeta6276),axis=None))
119/187:
clon = np.insert(np.delete(clon,np.concatenate((id44t62,id62t44),axis=None)),715,np.concatenate((clon6244,clon4462),axis=None))
clon = np.insert(np.delete(clon,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((clon7662,clon6276),axis=None))
119/188:
clat = np.insert(np.delete(clat,np.concatenate((id44t62,id62t44),axis=None)),715,np.concatenate((clat6244,clat4462),axis=None))
clat = np.insert(np.delete(clat,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((clat7662,clat6276),axis=None))
119/189: len(clat)
119/190: clat
119/191: clat.reshape(-1,69)
119/192: clat.reshape(-1,68)
119/193:
dates = np.insert(np.delete(dates,np.concatenate((id44t62,id62t44),axis=None)),715,np.concatenate((dates6244,dates4462),axis=None))
dates = np.insert(np.delete(dates,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((dates7662,dates6276),axis=None))
119/194: %save -r removebadtrack.py
119/195: %save -r removebadtrack.py 1-999
119/196: pwd
120/1: add = 'test'
120/2: add[-1]
120/3: add[-1]=3
120/4: add[-1]=3
121/1:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year2'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
delids = np.arange(673,829)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

delids = np.where(CYCids==40)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids=np.arange(452,456)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids = np.arange(989,len(CYCids))
dates = np.delete(dates,delids)
121/2:
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
121/3:
id44t62 = np.where((htzeta<-10)&(CYCids==44))
id62t44 = np.where((htzeta>80)&(CYCids==62))
id62t76 = np.where((htzeta<-20)&(CYCids==62))
id76t62 = np.where((htzeta>70)&(CYCids==76))

dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]
htzeta6244 = htzeta[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]
dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
htzeta7662 = htzeta[id76t62]
clon7662 = clon[id76t62]
clat7662 = clat[id76t62]
dates7662 = dates[id76t62]
122/1:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year2'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
delids = np.arange(673,829)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

delids = np.where(CYCids==40)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids=np.arange(452,456)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids = np.arange(989,len(CYCids))
dates = np.delete(dates,delids)
122/2:
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
122/3:
id44t62 = np.where((htzeta<-10)&(CYCids==44))
id62t44 = np.where((htzeta>80)&(CYCids==62))
id62t76 = np.where((htzeta<-20)&(CYCids==62))
id76t62 = np.where((htzeta>70)&(CYCids==76))

dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]
htzeta6244 = htzeta[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]
dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
htzeta7662 = htzeta[id76t62]
clon7662 = clon[id76t62]
clat7662 = clat[id76t62]
dates7662 = dates[id76t62]
122/4: htzeta[700:]
122/5:
htzeta = np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),715,np.concatenate((htzeta6244,htzeta4462),axis=None))
htzeta = np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),822,np.concatenate((htzeta7662,htzeta6276),axis=None))
122/6: htzeta[700:]
122/7:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year2'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
delids = np.arange(673,829)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

delids = np.where(CYCids==40)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids=np.arange(452,456)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids = np.arange(989,len(CYCids))
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

id44t62 = np.where((htzeta<-10)&(CYCids==44))
id62t44 = np.where((htzeta>80)&(CYCids==62))
id62t76 = np.where((htzeta<-20)&(CYCids==62))
id76t62 = np.where((htzeta>70)&(CYCids==76))

CYCids44t62 = CYCids[id44t62]
dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]

htzeta6244 = htzeta[id62t44]
CYCids6244 = CYCids[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]

dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
CYCids6276 = CYCids[id62t76]
122/8:
htzeta = np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),716,np.concatenate((htzeta6244,htzeta4462),axis=None))
htzeta = np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),823,np.concatenate((htzeta7662,htzeta6276),axis=None))
122/9: htzeta[700:]
122/10: CYCids[700]
122/11: CYCids[700:]
122/12: CYCids[750:]
122/13: CYCids[820:]
122/14: CYCids[826:]
122/15: CYCids[828:]
122/16: htzeta[828:]
122/17: clon[828]
122/18: np.mean(clon[828:],axis=1)
122/19:
clon = np.insert(np.delete(clon,np.concatenate((id44t62,id62t44),axis=None),axis=0),716,np.concatenate((clon6244,clon4462),axis=0),axis=0)
clon = np.insert(np.delete(clon,np.concatenate((id62t76,id76t62),axis=None),axis=0),823,np.concatenate((clon7662,clon6276),axis=0),axis=0)

clat = np.insert(np.delete(clat,np.concatenate((id44t62,id62t44),axis=None),axis=0),716,np.concatenate((clat6244,clat4462),axis=0),axis=0)
clat = np.insert(np.delete(clat,np.concatenate((id62t76,id76t62),axis=None),axis=0),823,np.concatenate((clat7662,clat6276),axis=0),axis=0)
122/20: np.mean(clon[828:],axis=1)
122/21:
CYCids = np.insert(np.delete(CYCids,np.concatenate((id44t62,id62t44),axis=None)),716,np.concatenate((CYCids6244,CYCids4462),axis=None))
CYCids = np.insert(np.delete(CYCids,np.concatenate((id62t76,id76t62),axis=None)),823,np.concatenate((CYCids7662,CYCids6276),axis=None))
122/22:
CYCids44t62 = CYCids[id44t62]
dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]

htzeta6244 = htzeta[id62t44]
CYCids6244 = CYCids[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]

dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
CYCids6276 = CYCids[id62t76]

htzeta7662 = htzeta[id76t62]
clon7662 = clon[id76t62]
clat7662 = clat[id76t62]
dates7662 = dates[id76t62]
CYCids7662 = CYCids[id76t62]
122/23:
CYCids = np.insert(np.delete(CYCids,np.concatenate((id44t62,id62t44),axis=None)),716,np.concatenate((CYCids6244,CYCids4462),axis=None))
CYCids = np.insert(np.delete(CYCids,np.concatenate((id62t76,id76t62),axis=None)),823,np.concatenate((CYCids7662,CYCids6276),axis=None))
122/24:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year2'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
MEDid = np.where(labels==2)[0].astype(int)
startids = np.array([0],dtype=int)
for q,e in enumerate(np.where((CYCids[MEDid][1:]-CYCids[MEDid][:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(MEDid))
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
delids = np.arange(673,829)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

delids = np.where(CYCids==40)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids=np.arange(452,456)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
delids = np.arange(989,len(CYCids))
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)

id44t62 = np.where((htzeta<-10)&(CYCids==44))
id62t44 = np.where((htzeta>80)&(CYCids==62))
id62t76 = np.where((htzeta<-20)&(CYCids==62))
id76t62 = np.where((htzeta>70)&(CYCids==76))

CYCids4462 = CYCids[id44t62]
dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]

htzeta6244 = htzeta[id62t44]
CYCids6244 = CYCids[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]

dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
CYCids6276 = CYCids[id62t76]
122/25: CYCids[700:]
122/26:

htzeta = np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),716,np.concatenate((htzeta6244,htzeta4462),axis=None))
htzeta = np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),823,np.concatenate((htzeta7662,htzeta6276),axis=None))
clon = np.insert(np.delete(clon,np.concatenate((id44t62,id62t44),axis=None),axis=0),716,np.concatenate((clon6244,clon4462),axis=0),axis=0)
clon = np.insert(np.delete(clon,np.concatenate((id62t76,id76t62),axis=None),axis=0),823,np.concatenate((clon7662,clon6276),axis=0),axis=0)

clat = np.insert(np.delete(clat,np.concatenate((id44t62,id62t44),axis=None),axis=0),716,np.concatenate((clat6244,clat4462),axis=0),axis=0)
clat = np.insert(np.delete(clat,np.concatenate((id62t76,id76t62),axis=None),axis=0),823,np.concatenate((clat7662,clat6276),axis=0),axis=0)
dates = np.insert(np.delete(dates,np.concatenate((id44t62,id62t44),axis=None)),716,np.concatenate((dates6244,dates4462),axis=None))
dates = np.insert(np.delete(dates,np.concatenate((id62t76,id76t62),axis=None)),823,np.concatenate((dates7662,dates6276),axis=None))
122/27: htzeta[700:]
122/28: htzeta[716:]
122/29: htzeta[723:]
122/30: htzeta[722:]
122/31: CYCids[722:]
123/1:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year4'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
123/2: htzeta
123/3: clat[148]
123/4: np.mean(clat[145:149],axis=1)
123/5: htzeta[145:149]
123/6: htzeta[:300]
123/7: np.mean(clat[:300],axis=1)
123/8: dates[np.where(htzeta==0)]
123/9: len(dates[np.where(htzeta==0)])
123/10:
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
123/11: delids = np.arange(673,829)
123/12: dates[np.where(np.delete(htzeta,delids)==0)]
123/13: CYCids[300:]
123/14: CYCids[:300]
123/15: CYCids[np.where(dates=='20180308_23')]
123/16: np.where(CYCids==40)
123/17: CYCids[500:]
123/18: len(CYCids)
123/19:
import numpy as np
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year4'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)
123/20: clat[148]
123/21:
clat[148] = (clat[148]-np.mean(clat[148]) + np.mean(clat[149])).astype(int)
clon[148] = (clon[148]-np.mean(clon[148]) + np.mean(clon[149])/2 + np.mean(clon[147])/2).astype(int)
123/22: dates[np.where(htzeta==0)]
123/23: len(dates[np.where(htzeta==0)])
123/24:
delids = np.where(CYCids==40)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
123/25: np.mean(clat[420:500],axis=1)
123/26: dates[np.where(htzeta==0)]
123/27: np.where(CYCids==CYCids[np.where(dates=='20180226_16')])
123/28: np.mean(clat[np.where(CYCids==CYCids[np.where(dates=='20180226_16')])],axis=1)
123/29:
delids=np.arange(452,456)
dates = np.delete(dates,delids)
htzeta = np.delete(htzeta,delids)
clat = np.delete(clat,delids,axis=0)
clon = np.delete(clon,delids,axis=0)
CYCids = np.delete(CYCids,delids)
labels = np.delete(labels,delids)
123/30: htzeta[np.where((htzeta<-10)&(CYCids==44))]
123/31: np.where((htzeta<-10)&(CYCids==44))
123/32: np.where((htzeta>80)&(CYCids==62))
123/33: htzeta[660:]
123/34: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))
123/35:
id44t62 = np.where((htzeta<-10)&(CYCids==44))
id62t44 = np.where((htzeta>80)&(CYCids==62))
id62t76 = np.where((htzeta<-20)&(CYCids==62))
id76t62 = np.where((htzeta>70)&(CYCids==76))
123/36:
CYCids4462 = CYCids[id44t62]
dates4462 = dates[id44t62]
clon4462 = clon[id44t62]
clat4462 = clat[id44t62]
htzeta4462 = htzeta[id44t62]

htzeta6244 = htzeta[id62t44]
CYCids6244 = CYCids[id62t44]
clon6244 = clon[id62t44]
clat6244 = clat[id62t44]
dates6244 = dates[id62t44]

dates6276 = dates[id62t76]
clon6276 = clon[id62t76]
clat6276 = clat[id62t76]
htzeta6276 = htzeta[id62t76]
CYCids6276 = CYCids[id62t76]

htzeta7662 = htzeta[id76t62]
clon7662 = clon[id76t62]
clat7662 = clat[id76t62]
dates7662 = dates[id76t62]
CYCids7662 = CYCids[id76t62]
123/37: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))
123/38: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[660:]
123/39: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[680:]
123/40: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[683:]
123/41: ins1 = 683
123/42: np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),ins1,np.concatenate((htzeta6244,htzeta4462),axis=None))
123/43: np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None))[790:]
123/44: np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),ins1,np.concatenate((htzeta6244,htzeta4462),axis=None))[790:]
123/45: htzeta = np.insert(np.delete(htzeta,np.concatenate((id44t62,id62t44),axis=None)),ins1,np.concatenate((htzeta6244,htzeta4462),axis=None))
123/46: ins2 = 790
123/47: np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),ins2,np.concatenate((htzeta7662,htzeta6276),axis=None))[660:]
123/48: htzeta[660:]
123/49: htzeta[780:]
123/50: np.insert(np.delete(htzeta,np.concatenate((id62t76,id76t62),axis=None)),ins2,np.concatenate((htzeta7662,htzeta6276),axis=None))[780:]
124/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt


p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

radii = np.arange(0,2100,100)
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'
globalpercentage = np.array([])

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
124/2: lis = dict()
124/3: np.where(htzeta[1:]<htzeta[:-1])
124/4: ids = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)
124/5: ids
124/6: htzeta[ids]
125/1:
if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[:,1])
125/3:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
125/4:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
125/5: dbase='/atmosdyn2/ascherrmann/'
125/6:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
125/7: fig.savefig('tropicaltracks.png',dpi=300,bbox_inches="tight")
125/8: pwd
125/9:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        if ( (np.any(np.where((d[cappear,2]>(-50)))[0] == (np.where(d[cappear,2]<-40)[0]) ))):
           ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
125/10: plt.show()
126/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
126/2:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18']:#,'MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
126/3: dbase = '/atmosdyn2/ascherrmann/'
126/4:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18']:#,'MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
126/5: plt.show()
127/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
127/2: dbase = '/atmosdyn2/ascherrmann/'
127/3:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['MAR18','APR18','MAY18']:#,'JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/4: plt.show
127/5: plt.show()
127/6: plt.close()
127/7:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/8: plt.show()
127/9: plt.close()
127/10:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/11: plt.show()
127/12: plt.close()
127/13:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=2)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/14: plt.show()
127/15:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/16: plt.show()
127/17:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=4)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/18: plt.show()
127/19:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/20: plt.show()
127/21: plt.close('all')
127/22:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:#,'SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/23: plt.show()
127/24:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/25: plt.show()
127/26:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        if ((ids==10)|(ids==108)|(ids==75)|(ids==184)|(ids==174)):
        cappear, = np.where((d[:,1]==ids))
        ax.plot(d[cappear,2],d[cappear,3])
        legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/27:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['SEP18','OCT18','NOV18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        if ((ids==10)|(ids==108)|(ids==75)|(ids==184)|(ids==174)):
         cappear, = np.where((d[:,1]==ids))
         ax.plot(d[cappear,2],d[cappear,3])
         legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/28: plt.show()
127/29:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['JUN18','JUL18','AUG18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        if ((ids==85)|(ids==191)|(ids==96)|(ids==9)|(ids==155)):
         cappear, = np.where((d[:,1]==ids))
         ax.plot(d[cappear,2],d[cappear,3])
         legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
127/30: plt.show()
128/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
128/2: dbase = '/atmosdyn2/ascherrmann/'
128/3: from datetime import datetime, date, timedelta
128/4: ft = date.toordinal(date(1950,1,1))
128/5:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['AUG18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==0),1])
    for ids in IDs:
        if (ids==9):
         cappear, = np.where((d[:,1]==ids))
         print(len(cappear))
         ax.plot(d[cappear,2],d[cappear,3])
         legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
129/1: import numpy as np
129/2: zeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zetaTRO-vort-JJA.txt')
129/3: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-TRO-vort-JJA.txt')
129/4: 4 + 9
129/5: len(ids)
129/6: np.where(ids==9)
129/7: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-TRO-vort-JJA.txt',dtype=str)
129/8: zeta
129/9: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-TRO-vort-MAM.txt')
129/10: np.where((ids==9)&(htzeta==0))
129/11: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-TRO-vort-JJA.txt')
129/12: np.where((ids==9)&(htzeta==0))
129/13: dates[1540]
129/14: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-TRO-vort-SON.txt')
129/15: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-TRO-vort-SON.txt',dtype=str)
129/16: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-TRO-vort-SON.txt')
129/17: dates[np.where((ids==10)&(htzeta==0))]
128/6:
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax=axes
ax.coastlines()
legend = np.array([])
legendd = np.array([])
LON = np.linspace(-180,180,901)
LAT = np.linspace(0,90,226)

pltlat = np.linspace(0,90,226)[0:100]
pltlon = np.linspace(-180,180,901)[0:901]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]

for Month in ['DEC17','JAN18','FEB18']:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==1),1])
    for ids in IDs:
         cappear, = np.where((d[:,1]==ids))
         
         ax.plot(d[cappear,2],d[cappear,3])
         legend=np.append(legend,ids)
lonticks=np.arange(minpltlonc, maxpltlonc,10)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=6)
ax.set_yticklabels(labels=latticks,fontsize=6)
ax.legend(legend,fontsize=6)
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
128/7: plt.show()
130/1: plt.close('all')
130/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os

#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
130/3: plt.close('all')
131/1: import numpy as np
131/2: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-ET-vort-SON.txt')
131/3: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-ET-vort-SON.txt',dtype=str)
131/4: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-SON.txt')
131/5: dates[np.where((htzeta==0) & (ids==169))]
131/6: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-JJA.txt')
131/7: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-ET-vort-JJA.txt',dtype=str)
131/8: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-ET-vort-JJA.txt')
131/9: dates[np.where((htzeta==0) & (ids==86))]
131/10: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-ET-vort-MAM.txt')
131/11: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-ET-vort-MAM.txt',dtype=str)
131/12: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-MAM.txt')
131/13: dates[np.where((htzeta==0) & (ids==186))]
131/14: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-FEB.txt')
131/15: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-DJF.txt')
131/16: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-ET-vort-DJF.txt',dtype=str)
131/17: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-ET-vort-DJF.txt')
131/18: dates[np.where((htzeta==0) & (ids==137))]
132/1: import numpy as np
132/2: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-ET-vort-JJA.txt')
132/3: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-JJA.txt')
132/4: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-ET-vort-JJA.txt',dtype=str)
132/5: dates[np.where((htzeta==0) & (ids==86))]
134/1: import numpy as np
134/2: dates = np.loadtxt('dates-TROentire-year.txt')
134/3: dates = np.loadtxt('dates-TROentire-year.txt',dtype=str)
134/4: np.where(dates=='20180302_11')
134/5: da = np.loadtxt('dates-TRO-vort-DJF.txt',dtype=str)
134/6: np.where(da=='20180302_11')
135/1: import numpy as np
135/2: dates = np.loadtxt('dates-ET-vort-entire-year.txt')
135/3: ids = cycids('cycIDs-ET-vort-entire-year.txt')
135/4: ids = np.loadtxt('cycIDs-ET-vort-entire-year.txt')
135/5: dates = np.loadtxt('dates-ET-vort-entire-year.txt',dtype=str)
135/6: np.where(ids==86)
135/7: np.where((ids==86) & (dates==20180815_19))
135/8: np.where((dates==20180815_19))
135/9: np.where((ids==86) & (dates=='20180815_19'))
135/10: dates = np.loadtxt('dates-TROentire-year.txt',dtype=str)
135/11: ids = np.loadtxt('cycIDs-TROentire-year.txt')
135/12: np.where((ids==9) & (dates=='20180804_20'))
135/13: np.where(ids==9)
135/14: np.where(ids==10)
135/15: np.where((ids==10) & (dates=='20180915_15'))
135/16: np.where((ids==10) & (dates=='20180915_15'))[0][1:]-np.where((ids==10) & (dates=='20180915_15'))[0][:-1]
135/17: np.where((ids==10) & (dates=='20180915_15'))[0][1:]
135/18: np.where((ids==10) & (dates=='20180915_15'))[0]
135/19: np.where(ids==10)[0][1:]-np.where(ids==10)[0][:-1]
135/20: htzeta = np.loadtxt('htmaxzeta-ET-vort-entire-year.txt')
135/21: htzeta[np.where(ids==10)]
135/22: dates[np.where(ids==10)]
135/23: htzeta = np.loadtxt('htmaxzeta-ET-vort-SON.txt')
135/24: ids = np.loadtxt('cycIDs-TRO-vort-SON.txt')
135/25: htzeta[np.where(ids==10)]
136/1: import numpy as np
136/2: start = ['clat-','clon-','dates-','labels-','htmaxzeta-','htSLPmin-','cycIDs-','zeta']
136/3: add = 'ETTROP'
136/4:
for Month in months:
    if Month == 'DEC17':
        track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
        d = np.loadtxt(track)
    else:
        track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
        d = np.loadtxt(track,skiprows=1)
    IDs = np.unique(d[np.where(d[:,-3]==1),1])
    for ids in IDs:
#        if ( (os.path.isdir(pt + 'Tropical/' + add +'/' + Month + '/' + str(int(ids))  + '/')) | (os.path.isdir(pt + 'Extratropical-NonMediterranean/' + add +'/' + Month + '/' + str(int(ids))  + '/')) | (os.path.isdir(pt + 'Mediterranean/' + add +'/' + Month + '/' + str(int(ids))  + '/'))):
          cap, = np.where(d[:,1]==int(ids))
          if ((d[cap[0],3]>35) & (d[cap[0],2]>(-55)) & (d[cap[0],2]<(-46)) & (d[cap[0],3]<65)):
            print(Month,ids)
            leg = np.append(leg,ids)
            lon = d[cap,2]
            lat = d[cap,3]
            if( (np.any(lon<(-175))) & (np.any(lon>175))):
                ax.scatter(lon,lat,s=0.5)
            else:
                ax.plot(lon,lat)
136/5: dates = np.array('20180302_11','20180804_20','20180815_19','20180915_15')
136/6: dates = np.array(['20180302_11','20180804_20','20180815_19','20180915_15'])
136/7:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
for date in dates:
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + date[2:4]
    if Month == 'DEC17':
         track = dbase + '002-2020-08-05-Identify-DJF1718-medcyclones/' + Month  + '/TRACKED_CYCLONES'
         d = np.loadtxt(track)
     else:
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
136/9:
from datetime import datetime, date, timedelta
import helper

ft = date.toordinal(date(1950,1,1))
LAT = np.linspace(0,90,226)
LON = np.linspace(-180,180,901)
rlon,lat = helper.radial_ids_around_center(500)
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
ids = np.array([137,9,86,10])
clat = dict()
clon = dict()
htzeta = dict()
dato = dict()
for date in dates:
    clat[date] = np.array([])
    clon[date] = np.array([])
    htzeta[date] = np.array([])
    dato[date] = np.array([])
for q,date in enumerate(dates):
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + date[2:4]
    if Month == 'MAR18':
         Month = 'FEB18'
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    else:
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    cap = np.where(d[:,1]==ids[q])[0]
    for e,k in enumerate(cap):
        idlat = int(np.where(np.round(LAT,1)==np.round(d[k,3],1))[0][0])
        idlon = int(np.where(np.round(LON,1)==np.round(d[k,2],1))[0][0])
        if e==0:
            clat[date] = np.zeros(len(rlon))
            clon[date] = np.zeros(len(rlon))
        else:
            clat[date] = np.vstack((clat[date],idlat + rlat))
            clon[date] = np.vstack((clon[date],idlon + rlon))
        w = str(helper.datenum_to_datetime(ft+d[k,0]/24))
        dato[date] = np.append(dato[date],(w[0:4] + w[5:7] + w[8:10] + '_' + w[11:13]))
    htzeta[date] = np.cumsum(np.ones(len(dato[date])))-np.cumsum(np.ones(len(dato[date])))[np.where(dato[date]==date)]
136/10:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from datetime import datetime, date, timedelta
import helper

ft = date.toordinal(date(1950,1,1))
LAT = np.linspace(0,90,226)
LON = np.linspace(-180,180,901)
rlon,lat = helper.radial_ids_around_center(500)
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
ids = np.array([137,9,86,10])
clat = dict()
clon = dict()
htzeta = dict()
dato = dict()
for date in dates:
    clat[date] = np.array([])
    clon[date] = np.array([])
    htzeta[date] = np.array([])
    dato[date] = np.array([])
for q,date in enumerate(dates):
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + date[2:4]
    if Month == 'MAR18':
         Month = 'FEB18'
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    else:
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    cap = np.where(d[:,1]==ids[q])[0]
    for e,k in enumerate(cap):
        idlat = int(np.where(np.round(LAT,1)==np.round(d[k,3],1))[0][0])
        idlon = int(np.where(np.round(LON,1)==np.round(d[k,2],1))[0][0])
        if e==0:
            clat[date] = np.zeros(len(rlon))
            clon[date] = np.zeros(len(rlon))
        else:
            clat[date] = np.vstack((clat[date],idlat + rlat))
            clon[date] = np.vstack((clon[date],idlon + rlon))
        w = str(helper.datenum_to_datetime(ft+d[k,0]/24))
        dato[date] = np.append(dato[date],(w[0:4] + w[5:7] + w[8:10] + '_' + w[11:13]))
    htzeta[date] = np.cumsum(np.ones(len(dato[date])))-np.cumsum(np.ones(len(dato[date])))[np.where(dato[date]==date)]
136/11:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from datetime import datetime, date, timedelta
import helper

ft = date.toordinal(date(1950,1,1))
LAT = np.linspace(0,90,226)
LON = np.linspace(-180,180,901)
rlon,rlat = helper.radial_ids_around_center(500)
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)
ids = np.array([137,9,86,10])
clat = dict()
clon = dict()
htzeta = dict()
dato = dict()
for date in dates:
    clat[date] = np.array([])
    clon[date] = np.array([])
    htzeta[date] = np.array([])
    dato[date] = np.array([])
for q,date in enumerate(dates):
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + date[2:4]
    if Month == 'MAR18':
         Month = 'FEB18'
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    else:
         track = '/atmosdyn/atroman/phd/' + Month + '/cyclones/TRACKED_CYCLONES'
         d = np.loadtxt(track,skiprows=1)
    cap = np.where(d[:,1]==ids[q])[0]
    for e,k in enumerate(cap):
        idlat = int(np.where(np.round(LAT,1)==np.round(d[k,3],1))[0][0])
        idlon = int(np.where(np.round(LON,1)==np.round(d[k,2],1))[0][0])
        if e==0:
            clat[date] = np.zeros(len(rlon))
            clon[date] = np.zeros(len(rlon))
        else:
            clat[date] = np.vstack((clat[date],idlat + rlat))
            clon[date] = np.vstack((clon[date],idlon + rlon))
        w = str(helper.datenum_to_datetime(ft+d[k,0]/24))
        dato[date] = np.append(dato[date],(w[0:4] + w[5:7] + w[8:10] + '_' + w[11:13]))
    htzeta[date] = np.cumsum(np.ones(len(dato[date])))-np.cumsum(np.ones(len(dato[date])))[np.where(dato[date]==date)]
136/12: htzeta[date]
136/13:
for date in dates:
    clon[date] = np.delete(clon[date],0,axis=0)
    clat[date] = np.delete(clat[date],0,axis=0)
136/14: clon[date]
136/15: CLON = clon[dates[0]]
136/16: CLAT = clat[dates[0]]
136/17:
DATE = dato[dates[0]]
HTzeta = htzeta[dates[0]]
for date in dates[1:]:
    CLON = np.vstack((CLON,clon[date]))
    CLAT = np.vstack((CLAT,clat[date]))
    DATE = np.append(DATE,dato[date])
    HTzeta = np.append(HTzeta,htzeta[date])
136/18: add
136/19: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-' + add + '.txt',DATE.astype(str), fmt='%s', delimiter=' ',newline='\n')
136/20: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',CLAT.astype(int), fmt='%i', delimiter=' ',newline='\n')
136/21: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',CLON.astype(int), fmt='%i', delimiter=' ',newline='\n')
136/22: np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-' + add + '.txt',HTzeta.astype(int), fmt='%i', delimiter=' ',newline='\n')
136/23: %save -r ettropical-data.py 1-999
136/24: add
136/25: pwd
136/26: ls ../
138/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
138/2:
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d[-15:-4])
138/3: p = '/atmosdyn2/ascherrmann/006-year-traj/'
138/4:
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d[-15:-4])
138/5: traced
138/6:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'
138/7: htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
138/8: cycids = np.loadtxt(pt + 'cycIDS-' + add + '.txt',dtype=int)
138/9: cycids = np.loadtxt(pt + 'cycIDs-MED-vort-entire-year3.txt',dtype=int)
138/10: cycids[np.where(htzeta==0)]
138/11: import helper
138/12:
p = '/atmosdyn2/ascherrmann/006-year-traj/'
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            dates = np.append(dates,d[-15:-4])
138/13: ids = helper.MED_cyclones_date_to_id(dates)
138/14: ids
138/15: ids = helper.MED_cyclones_date_to_id(dates[10:15])
138/16: ids = helper.MED_cyclones_date_to_id(dates[0])
138/17: ids
138/18: ids = helper.MED_cyclones_date_to_id(dates[5])
138/19: ids
138/20:
varS = np.array(['PV','THE'])
varP = np.array(['Q'])
138/21: np.append(varS,varP)
139/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
#cartopy
import helper
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
import argparse
import os

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/006-year-traj/'
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            dates = np.append(dates,d[-15:-4])
dates = np.sort(dates)
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
plevels=np.arange(960,1041,5)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

Clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
Clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
Dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

pv_cmap,pv_levels,pvnorm,pvticklabels=PV_cmap2()
varS = np.array(['PV','THE'])
varP = np.array(['Q'])

Var = dict()

labels = np.array(['PV',r'$\theta_e$','RH'])
units = np.array(['[PVU]','[K]',r'[%]'])
levels = np.array([pv_levels,np.arange(280,345,2),np.arange(0,105,5)])
ticklabels = np.array([pvticklabels,np.arange(280,345,6),np.arange(0,105,5)])
cmaps = np.array([pv_cmap,matplotlib.cm.seismic,matplotlib.cm.YlGnBu])
norms = np.array([pvnorm,plt.Normalize(np.min(levels[1]),np.max(levels[1])),plt.Normalize(np.min(levels[2]),np.max(levels[2]))])

slicelevels = np.array([900,850,800,500,300])
139/2:
for var in np.append(varS,'RH'):
    if(os.path.isdir(p + var + '/')==0):
        os.mkdir(p + var + '/')
    for lv in slicelevels:
        if(os.path.isdir(p + var + '/'+ str(lv) + '/')==0):
            os.mkdir(p + var + '/'  + str(lv) + '/')
path = p
139/3:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int)
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int)

    ran=int(np.min(np.where(np.linspace(0,2*np.pi*6370,901)>1600)))
    latu = np.arange(clat-ran,clat+ran+1,1)
    lonu = np.arange(clon-ran,clon+ran+1,1)
    minlatc = np.min(latu)
    minlonc = np.min(lonu)
    print(lonu,latu)

    pltlat =np.linspace(0,90,226)[latu]
    pltlon = np.linspace(-180,180,901)[lonu]
    minlatc = np.min(latu)
    maxlatc = np.max(latu)
    minpltlatc = pltlat[0]
    maxpltlatc = pltlat[-1]
    minlonc = np.min(lonu)
    maxlonc = np.max(lonu)
    minpltlonc = pltlon[0]
    maxpltlonc = pltlon[-1]


    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    s_file = ana_path+'/'+'S'+date
    p_file = ana_path+'/'+'P'+date
    s = xr.open_dataset(s_file,drop_variables=['P','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(p_file,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    for var in varS:
        Var[var] = np.zeros((len(latu),len(lonu)))
    for var in varP:
        Var[var] = np.zeros((len(latu),len(lonu)))
    T = np.zeros((len(lonu),len(latu)))
    U = np.zeros((len(lonu),len(latu)))
    V = np.zeros((len(lonu),len(latu)))
    SLP = np.zeros((len(lonu),len(latu)))
    for pres in slicelevels[:1]:
        for e in latu:
            for r in lonu:
                SLP[e-minlatc,r-minlonc] = p.SLP.values[0,0,e,r]
                P = helper.modellevel_to_pressure(SLP[e-minlatc,r-minlonc])
                I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
                for var in varS:
                    atr = getattr(s,var)
                    Var[var][e-minlatc,r-minlonc] = atr.values[0,I,e,r]
                for var in varP:
                    atr = getattr(p,var)
                    Var[var][e-minlatc,r-minlonc] = atr.values[0,I,e,r]
                    T[e-minlatc,r-minlonc] = p.T.values[0,I,e,r]
                    V[e-minlatc,r-minlonc] = p.V.values[0,I,e,r]
                    U[e-minlatc,r-minlonc] = p.U.values[0,I,e,r]

        Var[var] = Var[var]/(helper.qs(T,pres*100)) * 100.
139/4:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((0.7,0.2),0.2,0.1,alpha=1.,color='white')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/5: pres
139/6:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            ax.Rectangle((0.7,0.2),0.2,0.1,alpha=1.,color='white')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/7:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((0.7,0.2),0.2,0.1,alpha=1.,color='black')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/8:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((7,40),0.2,0.1,alpha=1.,color='black')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/9:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((7,40),5,5,alpha=1.,color='black')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/10:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((7,40),5,5,alpha=1.,color='black')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',facecolor='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/11:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            plt.Rectangle((0.065,0.225),0.5,0.5,facecolor='black')
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/12: import matplotlib.patches as patches
139/13:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((7,40),100,100,edgecolor='none',facecolor='k')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='axes')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/14:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-5,minpltlatc+0.5),5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,0.065,0.225,10,r'10 m s$^{-1}$', labelpos='N',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/15:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-5,minpltlatc+0.5),5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-5,minpltlatc+0.5,10,r'10 m s$^{-1}$', labelpos='E',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/16:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-7,minpltlatc+0.5),5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-5,minpltlatc+0.9,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/17:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-4,minpltlatc+0.9,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/18:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-1,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/19:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-1,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data',fontsize=8)

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/20:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data',fontproperties(size=8))

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/21:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data',size=8)

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/22:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/23: props = dict()
139/24: props['size'] = 8
139/25:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.5),5.5,1.5,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.2,10,r'10 m s$^{-1}$', labelpos='W',coordinates='data',props)

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/26:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.25),5.5,2,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.,10,r'10 m s$^{-1}$', labelpos='S',coordinates='data',props)

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/27:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-6,minpltlatc+0.25),5.5,2,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc,minpltlatc+1.,10,r'10 m s$^{-1}$', labelpos='S',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
139/28:
for q,var in enumerate(np.append(varS,varP)):
            fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
            ax=axes
            ax.coastlines()

            lonticks=np.arange(minpltlonc, maxpltlonc,5)
            latticks=np.arange(minpltlatc, maxpltlatc,5)

            ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
            ax.set_yticks(latticks, crs=ccrs.PlateCarree());
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.set_yticklabels(labels=latticks,fontsize=10)

            ax.xaxis.set_major_formatter(LongitudeFormatter())
            ax.yaxis.set_major_formatter(LatitudeFormatter())

            ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())

            h=ax.contourf(pltlon,pltlat,Var[var],levels=levels[q],cmap=cmaps[q],extend='both',norm=norms[q])

            h2=ax.contour(pltlon,pltlat,SLP,levels=plevels,colors='slategrey',animated=True,linewidths=1, alpha=1)
            plt.clabel(h2, inline=1, fontsize=6, fmt='%1.0f')
            rect = patches.Rectangle((maxpltlonc-5.75,minpltlatc+0.25),5.5,2,edgecolor='none',facecolor='white')
            ax.add_patch(rect)
            qv=ax.quiver(pltlon[::2],pltlat[::2],U[::2,::2],V[::2,::2],units='width',color='black')
            qk=ax.quiverkey(qv,maxpltlonc-2.8775,minpltlatc+2.,10,r'10 m s$^{-1}$', labelpos='S',coordinates='data')

            cbax = fig.add_axes([0, 0, 0.1, 0.1])
            cbar=plt.colorbar(h, ticks=ticklabels[q],cax=cbax)
            func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
            fig.canvas.mpl_connect('draw_event', func)
            cbar.ax.tick_params(labelsize=10)
            cbar.ax.set_xlabel(var + ' '  + units[q],fontsize=10)
            cbar.ax.set_xticklabels(ticklabels[q])
            if var=='Q':
                var = 'RH'
            figname = path + var + '/' + str(pres) + '/' + var + '-at-'+ str(pres)+ 'hPa-' + date + '.png'
            fig.savefig(figname,dpi=300,bbox_inches="tight")
            plt.close()
142/1: import numpy as np
142/2: dates = np.loadtxt('../004-composite-analysis/dates-MED-vort-entire-year3.txt',dtype=str)
142/3: clat = np.loadtxt('../004-composite-analysis/clat-MED-vort-entire-year3.txt',dtype=int)
142/4: clon = np.loadtxt('../004-composite-analysis/clon-MED-vort-entire-year3.txt',dtype=int)
142/5: LAT = np.linspace(0,90,226)
142/6: LON = np.linspace(-180,180,901)
142/7: np.where(dates=='20180209_15')
142/8: LAT[clat[280]]
142/9: np.mean(LAT[clat[280]])
142/10: np.mean(LON[clat[280]])
142/11: np.mean(LON[clon[280]])
142/12: clat[280]
142/13: clat[280]-1
142/14: np.mean(LAT[clat[280]-1])
142/15: clat[280] = clat[280]-1
142/16: clon[280]
142/17: np.mean(LON[clon[280]-10])
142/18: clon[280] = clon[280]-10
142/19: add='MED-vort-entrire-year3'
142/20:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')
142/21: ls -lrt ../004-composite-analysis/*.txt
142/22: clat-MED-vort-entire-year3.txt
142/23: clat-MED-vort-entrire-year3.txt
142/24:
for k:
    clat-MED-vort-entire-year3.txt
142/25:
for k:
    clat-MED-vort-entire-year3.txt
142/26: add='MED-vort-entire-year3'
142/27:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')
142/28: rm ../004-composite-analysis/clat-MED-vort-entrire-year3.txt ../004-composite-analysis/clon-MED-vort-entrire-year3.txt
142/29: ls -lrt ../004-composite-analysis/*.txt
143/1:
import numpy as np
import xarray as xr
import datetime
import os

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
import helper

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.collections as mcoll
143/2:
add = 'MED-vort-entire-year3'
#add = 'ET-vort-entire-year'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
143/3:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
143/4:
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
#htM = np.loadtxt(pt + 'htSLPmin' + add + '.txt', dtype=int)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
143/5: np.where(htM==0)
143/6:
for t in dates[np.where(htM==0)]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]
    if ((yyyy==2018)&(MM==12)):
        Month = 'NOV18'
    if((MM==2)& (DD<4)):
        Month = 'JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    pfile = ana_path + 'P' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(p_file,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
    
    a = np.where(dates==t)[0]
    SLP = s.PS.values[0,0,clat[a],clon[a]]
    slp = p.SLP.values[0,0,clat[a],clon[a]]
    print(SLP-slp)
143/7:
for t in dates[np.where(htM==0)]:
    yyyy = int(t[0:4])
    MM = int(t[4:6])
    DD = int(t[6:8])
    hh = int(t[9:])
    monthid, = np.where(MONTHSN==MM)
    Month = MONTHS[monthid[0]] + t[2:4]
    if ((yyyy==2018)&(MM==12)):
        Month = 'NOV18'
    if((MM==2)& (DD<4)):
        Month = 'JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
    sfile = ana_path + 'S' + t
    p_file = ana_path + 'P' + t
    cycl = xr.open_dataset('/net/thermo/atmosdyn/atroman/phd/'+ Month + '/cyclones/CY' + t + '.nc',drop_variables=['CENTRES','WFRONTS','CFRONTS','BBFRONTS'])

    s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(p_file,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
    
    a = np.where(dates==t)[0]
    SLP = s.PS.values[0,0,clat[a],clon[a]]
    slp = p.SLP.values[0,0,clat[a],clon[a]]
    print(SLP-slp)
144/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
144/2:
p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)
144/3:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
144/4: rdis = 400
144/5:
traced = np.array([])
traj = np.array([])
H = 48

for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
    elif(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)
traced = np.sort(traced)
traj = np.sort(traj)
144/6: np.where(trj[:][-15:-4]=='20171214_02')
144/7: np.where(traj[:][-15:-4]=='20171214_02')
144/8: traj
144/9: traj[:][1]
144/10: traj[:][:1]
144/11: traj[:][:,1]
144/12: traj[:,1]
144/13: f = p + traj[1]
144/14: d = np.loadtxt(f,skiprows=0)
144/15: d
144/16: f = p + traced[1]
144/17: d = np.loadtxt(f,skiprows=0)
144/18: d
144/19: tralon = d[:,1].reshape(-1,48)
144/20: tralon = d[:,1].reshape(-1,49)
144/21: tralat = d[:,2].reshape(-1,49)
144/22: time = d[:,0].reshape(-1,49)
144/23: dates[:100]
144/24: np.where(dates=='20171212_21')
144/25: np.where(dates=='20171214_19')
144/26: ids = np.arange(26,73,1)
144/27: htzeta[ids]
144/28: ids = np.arrange(26,57,1)
144/29: ids = np.arange(26,57,1)
144/30: htzeta[ids]
144/31: ids = np.arange(26,56,1)
144/32: htzeta[ids]
144/33: LON = np.linspace(-180,180,901)
144/34: LAT = np.linspace(0,90,226)
144/35: clat2 = np.mean(clat[ids],axis=1)
144/36: clat2
144/37: clat2 = np.mean(clat[ids],axis=1).astype(int)
144/38: clon2 = np.mean(clon[ids],axis=1).astype(int)
144/39: fig, axes = plt.subplots()
144/40: ax = axes
144/41: ax.scatter(0,0,color='r',marker='o')
144/42: import matplotlib.patches as patch
144/43: dlon = LON[clon2] - tralon
144/44: dlon = LON[clon2] - tralon[:,:30]
144/45: dlon
144/46: LON[np.flip(clon2)] - tralon[:,:30]
144/47: (LON[np.flip(clon2)] - tralon[:,:30])[:,0]
144/48: dlon = LON[np.flip(clon2)] - tralon[:,:30]
144/49: dlat = LAT[np.flip(clat2)] - tralat[:,:30]
144/50: import helper
144/51:
def convert_lon_lat_dis_to_radial_dis(deltalatlon):
    return (deltalatlon/360 * 2 * np.pi * 6370)
144/52: dx = convert_lon_lat_dis_to_radial_dis(dlon)
144/53: dy = convert_lon_lat_dis_to_radial_dis(dlat)
144/54: ax.plot(dx,dy)
144/55: fig.show()
144/56: plt.close('all')
144/57: fig, axes = plt.subplots()
144/58: ax = axes
144/59:
for q in range(len(dx)):
    ax.plot(dx[q],dy[q])
144/60: fig.show()
144/61: fig, ax = plt.subplots()
144/62: clon2
144/63: np.insert(clon2,0,np.ones(18)*495)
144/64: len(np.insert(clon2,0,np.ones(18)*495))
144/65: len(np.insert(clon2,0,np.ones(19)*495))
144/66: clon2 = np.insert(clon2,0,np.ones(18)*clon[0])
144/67: clon2 = np.insert(clon2,0,np.ones(18)*clon2[0])
144/68: clat2 = np.insert(clat2,0,np.ones(19)*clat2[0])
144/69: clon2 = np.insert(clon2,0,np.ones(1)*clon2[0])
144/70: dlon = LON[np.flip(clon2)] - tralon[:,:]
144/71: dlat = LAT[np.flip(clat2)] - tralat[:,:]
144/72: dx = convert_lon_lat_dis_to_radial_dis(dlon)
144/73: dy = convert_lon_lat_dis_to_radial_dis(dlat)
144/74:
for q in range(len(dx)):
    ax.plot(dx[q],dy[q])
144/75: fig.show()
144/76: fig, ax = plt.subplots()
144/77:
for q in range(len(dx)/2):
    ax.plot(dx[q],dy[q])
144/78:
for q in range(int(len(dx)/2)):
    ax.plot(dx[q],dy[q])
144/79: fig.show()
144/80:
for q in range(int(len(dx)/2)):
    ax.plot(dx[q],dy[q])
144/81: plt.close('all')
144/82:
for q in range(int(len(dx)/10)):
    ax.plot(dx[q + q * 10],dy[q + q * 10 ])
144/83:
for q in range(int(len(dx)/10)):
    ax.plot(dx[q * 10],dy[q * 10 ])
144/84: fig.show()
144/85: a = 25
144/86: fig, ax = plt.subplots()
144/87:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/88: fig.show()
144/89: a = 100
144/90: fig, ax = plt.subplots()
144/91:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/92: fig.show()
144/93: patch.Circle((0,0),200,color='r',linestyle='-')
144/94: patch.Circle((0,0),400,color='b',linestyle='--')
144/95: plt.close('all')
144/96: fig, ax = plt.subplots()
144/97:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/98: patch.Circle((0,0),200,color='r',linestyle='-')
144/99: patch.Circle((0,0),400,color='b',linestyle='--')
144/100: fig.show()
144/101: circ2 = patch.Circle((0,0),400,color='b',linestyle='--')
144/102: circ1 = patch.Circle((0,0),200,color='r',linestyle='-')
144/103: ax.add_patch(circ1)
144/104: ax.add_patch(circ2)
144/105: plt.close('all')
144/106: plt.close('all')
144/107: fig, ax = plt.subplots()
144/108:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/109: circ1 = patch.Circle((0,0),200,color='r',linestyle='-')
144/110: circ2 = patch.Circle((0,0),400,color='b',linestyle='--')
144/111: ax.add_patch(circ2)
144/112: ax.add_patch(circ1)
144/113: fig.show()
144/114: plt.close('all')
144/115: fig, ax = plt.subplots()
144/116:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/117: circ2 = patch.Circle((0,0),400,ec='k',linestyle='--',fc=None)
144/118: circ1 = patch.Circle((0,0),200,ec='r',linestyle='-',fc=None)
144/119: fig.show()
144/120: plt.close('all')
144/121: fig, ax = plt.subplots()
144/122:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/123: circ1 = patch.Circle((0,0),200,ec='r',linestyle='-',fc=None)
144/124: circ2 = patch.Circle((0,0),400,ec='k',linestyle='--',fc=None)
144/125: ax.add_patch(circ1)
144/126: ax.add_patch(circ2)
144/127: fig.show()
144/128: plt.close('all')
144/129: fig, ax = plt.subplots()
144/130:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/131: circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--')
144/132: circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None')
144/133: ax.add_patch(circ2)
144/134: ax.add_patch(circ1)
144/135: fig.show()
144/136: fig.show()
144/137: circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=2.)
144/138: circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=2.)
144/139: ax.add_patch(circ1)
144/140: ax.add_patch(circ2)
144/141: plt.show()
144/142: fig.show()
144/143: plt.close('all')
144/144: fig, ax = plt.subplots()
144/145: plt.close('all')
144/146: fig, ax = plt.subplots()
144/147:
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
144/148: circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=2.)
144/149: circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=2.)
144/150: ax.add_patch(circ2)
144/151: ax.add_patch(circ1)
144/152: fig.show()
144/153: plt.close('all')
144/154:
fig, ax = plt.subplots()
a = 100
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

ax.add_patch(circ1)
ax.add_patch(circ2)

ax.set_xlim(-1000,1000)
ax.set_ylim(-1000,1000)
144/155: fig.show()
144/156:
fig, ax = plt.subplots()
a = 1
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

ax.add_patch(circ1)
ax.add_patch(circ2)

ax.set_xlim(-1000,1000)
ax.set_ylim(-1000,1000)
144/157: fig.show()
144/158: plt.close('all')
144/159:
fig, ax = plt.subplots()
a = 1
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

ax.add_patch(circ1)
ax.add_patch(circ2)

ax.set_xlim(-1000,1000)
ax.set_ylim(-1000,1000)
144/160:
ax.set_xticklabels(fontsize=8)
ax.set_yticklabels(fontsize=8)
144/161:
ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=8)
ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=8)
144/162: fig.show()
144/163: plt.close('all')
144/164:
fig, ax = plt.subplots()
a = 1
for q in range(int(len(dx)/a)):
    ax.plot(dx[q * a],dy[q * a ])
circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

ax.add_patch(circ1)
ax.add_patch(circ2)

ax.set_xlim(-1000,1000)
ax.set_ylim(-1000,1000)
ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
144/165: fig.show()
144/166: pvr = np.zeros(tralon.shape)
144/167: labs = helper.traced_vars()
144/168: pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
144/169: d
144/170: pvr -= d[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
144/171:
for z in labs[9:]:
    pvr +=d[:,np.where(labs==z)].reshape(-1,H+1)
144/172: pvr
144/173: tralon
144/174: tlon = tralon
144/175: tlat = tralat
144/176:
fig, ax = plt.subplots()
cmap = matplotlib.cm.YlGnBu
norm = plt.Normalize(-0.3,0.3)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.3,0.31,0.1)
for q in range(len(tlon[0])):
    seg = helper.make_segments(tlon[q,:],tlat[q,:])
    z = pvr[q,:]
    lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
    ax=plt.gca()
    ax.add_collection(lc)
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)
144/177:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
144/178: import matplotlib.collections as mcoll
144/179:
fig, ax = plt.subplots()
cmap = matplotlib.cm.YlGnBu
norm = plt.Normalize(-0.3,0.3)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.3,0.31,0.1)
for q in range(len(tlon[0])):
    seg = helper.make_segments(tlon[q,:],tlat[q,:])
    z = pvr[q,:]
    lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
    ax=plt.gca()
    ax.add_collection(lc)
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)
144/180:
fig, ax = plt.subplots()
cmap = matplotlib.cm.YlGnBu
norm = plt.Normalize(-0.3,0.3)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.3,0.31,0.1)
ticklabels=pvr_levels
for q in range(len(tlon[0])):
    seg = helper.make_segments(tlon[q,:],tlat[q,:])
    z = pvr[q,:]
    lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
    ax=plt.gca()
    ax.add_collection(lc)
    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)
144/181: fig.show()
144/182: plt.show()
145/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch


p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
CYCids = np.loadtxt(pt + 'cycIDs-' + add + '.txt', dtype=int)

for q,e in enumerate(np.where((CYCids[1:]-CYCids[:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(CYCids))
matureid = np.where(htzeta==0)[0].astype(int)

rdis = 400
labs = helper.traced_vars()
traced = np.array([])
traj = np.array([])
H = 48
a = 100
145/2:
startids = np.array([])
for q,e in enumerate(np.where((CYCids[1:]-CYCids[:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(CYCids))
matureid = np.where(htzeta==0)[0].astype(int)

rdis = 400
labs = helper.traced_vars()
traced = np.array([])
traj = np.array([])
H = 48
a = 100

for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)


cmap = matplotlib.cm.YlGnBu
norm = plt.Normalize(-0.3,0.3)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.3,0.31,0.1)
ticklabels=pvr_levels
145/3: plt.close('all')
145/4:
for t in traced[1:2]:
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tlon[0])):
         seg = helper.make_segments(tlon[q,:],tlat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/5: matureids = np.where(htzeta==0)[0].astype(int)
145/6:
for t in traced[1:2]:
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tlon[0])):
         seg = helper.make_segments(tlon[q,:],tlat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/7: ids
145/8: matureids
145/9: startids
145/10: q
145/11:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tlon[0])):
         seg = helper.make_segments(tlon[q,:],tlat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)
145/12: ids
145/13: q
145/14: data
145/15: tralon
145/16: pvr
145/17: startids[q]
145/18:
startids = np.array([0])
for q,e in enumerate(np.where((CYCids[1:]-CYCids[:-1])!=0)[0]+1):
    startids = np.append(startids,e)
startids = np.append(startids,len(CYCids))
matureids = np.where(htzeta==0)[0].astype(int)
145/19:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tlon[0])):
         seg = helper.make_segments(tlon[q,:],tlat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/20:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(tralon[q,:],tralat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/21:
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
145/22:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(tralon[q,:],tralat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=14)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=14)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/23: plt.close('all')
145/24:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(tralon[q,:],tralat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)

#    ax.set_xlim(-1000,1000)
#    ax.set_ylim(-1000,1000)
#    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
#    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    plt.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/25:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(tralon[q,:],tralat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    plt.xlim(-1000,1000)
    plt.ylim(-1000,1000)
#    ax.set_xlim(-1000,1000)
#    ax.set_ylim(-1000,1000)
#    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
#    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/26:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(tralon[q,:],tralat[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
#    plt.xlim(-1000,1000)
#    plt.ylim(-1000,1000)
#    ax.set_xlim(-1000,1000)
#    ax.set_ylim(-1000,1000)
#    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
#    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/27: dx
145/28:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
#    plt.xlim(-1000,1000)
#    plt.ylim(-1000,1000)
#    ax.set_xlim(-1000,1000)
#    ax.set_ylim(-1000,1000)
#    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
#    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/29:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/30: a = 20
145/31:
cmap = matplotlib.cm.seismic
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.5,0.51,0.1)
ticklabels=pvr_levels
145/32:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/33:
cmap = matplotlib.cm.jet
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
pvr_levels = np.arange(-0.5,0.51,0.1)
ticklabels=pvr_levels
145/34:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/35:
def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', maplist, cmap.N)
    bounds = np.linspace(minval, maxval, nlevels)
    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)
    return newmap, norm
145/36:
cmap = matplotlib.cm.seismic

maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)

cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/37:
def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', maplist, cmap.N)
    bounds = np.linspace(minval, maxval, nlevels)
    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)
    return newmap, norm
145/38:
cmap = matplotlib.cm.seismic

maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)

cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/39:
def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', maplist, cmap.N)
    bounds = np.linspace(minval, maxval, nlevels)
    norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)
    return newmap, norm
145/40:
cmap = matplotlib.cm.seismic

maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)

cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/41:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/42:
cmap = plt.cm.jet

maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)

cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
norm = plt.Normalize(-0.5,0.5)
alpha=1.
linewidth=1.
ticklabels=pvr_levels


for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cvar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
#    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)
    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/43:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
#    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)
    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)


    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/44:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)

#cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
#norm = plt.Normalize(-0.5,0.5)
cmap = ListedColormap('jet')
norm = BoundaryNorm(pvr_levels,cmap.N)

alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/45:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
#    cbar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/46:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)
#cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
#norm = plt.Normalize(-0.5,0.5)
cmap = ListedColormap(['jet'])
norm = BoundaryNorm(pvr_levels,cmap.N)
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/47:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
#    cbar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/48:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)
#cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
#norm = plt.Normalize(-0.5,0.5)
cmap = plt.cm.jet
cmaplist = [cmap(i) for i in range(cmap.N)]
maps = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)
cmap = ListedColormap(maps)

norm = BoundaryNorm(pvr_levels,len(pvr_level))
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/49:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)
#cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
#norm = plt.Normalize(-0.5,0.5)
cmap = plt.cm.jet
cmaplist = [cmap(i) for i in range(cmap.N)]
#maps = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)
cmap = ListedColormap(cmaplist)

norm = BoundaryNorm(pvr_levels,len(pvr_level))
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/50:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)
#cmap, norm = colbar(cmap,minv,maxv,len(pvr_levels))
#norm = plt.Normalize(-0.5,0.5)
cmap = plt.cm.jet
cmaplist = [cmap(i) for i in range(cmap.N)]
#maps = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)
cmap = ListedColormap(cmaplist)

norm = BoundaryNorm(pvr_levels,len(pvr_levels))
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/51:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
#    cbar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/52:
cmap = plt.cm.jet
cmaplist = [cmap(i) for i in range(cmap.N)]
#maps = matplotlib.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)
cmap = ListedColormap(cmaplist)

norm = BoundaryNorm(pvr_levels,cmap.N)
alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/53:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
#    cbar = plt.colorbar.ColorbarBase(cbax,cmap=cmap,norm=norm,spacing='proportional',ticks=ticklabels,boundaries=pvr_levels,format='%.1f')
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/54:
def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(cmaplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm
145/55:
maxv = 0.5
minv =-0.5
pvr_levels = np.arange(minv,maxv,0.1)
cmap = plt.cm.seismic
cmap,norm = colbar(cmap,minv,maxv,len(pvr_levels))

alpha=1.
linewidth=1.
ticklabels=pvr_levels
145/56:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
145/57:
ap = plt.cm.seismic
cmap ,norm = colbar(ap,minv,maxv,len(pvr_levels))
145/58:
for q,t in enumerate(traced[:2]):
    data = np.loadtxt(p + t)
    tralon = data[:,1].reshape(-1,H+1)
    tralat = data[:,2].reshape(-1,H+1)
    pvr = np.zeros(tralon.shape)
    pvr -= data[:,np.where(labs=='PVRLS')].reshape(-1,H+1)
    for z in labs[9:]:
        pvr +=data[:,np.where(labs==z)].reshape(-1,H+1)

    ids = np.arange(startids[q],matureids[q]+1,1)
    clat2 = np.mean(clat[ids],axis=1).astype(int)
    clon2 = np.mean(clon[ids],axis=1).astype(int)

    ll = np.min(htzeta[ids]) + H

    clon2 = np.insert(clon2,0,np.ones(ll)*clon2[0])
    clat2 = np.insert(clat2,0,np.ones(ll)*clat2[0])

    dlon = LON[np.flip(clon2)] - tralon[:,:]
    dlat = LAT[np.flip(clat2)] - tralat[:,:]

    dx = helper.convert_lon_lat_dis_to_radial_dis(dlon)
    dy = helper.convert_lon_lat_dis_to_radial_dis(dlat)

    fig, ax = plt.subplots()

    for q in range(len(tralon[0])):
         seg = helper.make_segments(dx[q,:],dy[q,:])
         z = pvr[q,:]
         lc = mcoll.LineCollection(seg, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)
         ax=plt.gca()
         ax.add_collection(lc)
    ax.set_xlim(-1000,1000)
    ax.set_ylim(-1000,1000)
    ax.set_xticklabels(labels=np.arange(-1000,1001,250),fontsize=10)
    ax.set_yticklabels(labels=np.arange(-1000,1001,250),fontsize=10)

    cbax = fig.add_axes([0, 0, 0.1, 0.1])
    cbar=plt.colorbar(lc, ticks=pvr_levels,cax=cbax)

    func=resize_colorbar_vert(cbax, ax, pad=0.05, size=0.03)
    fig.canvas.mpl_connect('draw_event', func)

    cbar.ax.tick_params(labelsize=10)
    cbar.ax.set_xlabel('PVR [PVU/h]',fontsize=10)
    cbar.ax.set_xticklabels(ticklabels)

    circ2 = patch.Circle((0,0),400,edgecolor='k',facecolor='none',linestyle='--',linewidth=3.,zorder=10.)
    circ1 = patch.Circle((0,0),200,edgecolor='r',linestyle='-',facecolor='None',linewidth=3.,zorder=10.)

    ax.add_patch(circ1)
    ax.add_patch(circ2)

    figname = p + 'traj-color-test.png'
    fig.savefig(figname,dpi=300,bbox_inches="tight")

    plt.close('all')
146/1:
import numpy as np
import xarray as xr
import os
import argparse
import matplotlib
import matplotlib.pyplot as plt
146/2:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/006-year-traj/'
path=p
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            dates = np.append(dates,d[-15:-4])
dates = np.sort(dates)
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
plevels=np.arange(970,1022,3)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

Clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
Clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
Dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

rdis=200

varS = np.array(['PV','TH','THE'])
varP = np.array(['T'])
di = dict()
di2= dict()
tmp = dict()
146/3:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(p_file,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/4:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
146/5:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(p_file,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/6:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/7:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = tmp.values[0,:,clat,clon]
        di2[q] = np.array([])
    tmp = dict()
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/8: di['TH']
146/9: di['TH'].shape
146/10: s.TH.values[0,:].shape
146/11: s.TH.values[0,:,clat,clon].shape
146/12: s.TH.values[0,0,clat,clon].shape
146/13: s.TH.values[0,1,clat,clon].shape
146/14: s.TH.values[0,1:3,clat,clon].shape
146/15: np.flip(di['TH']).shape
146/16: np.transpose(di['TH']).shape
146/17: np.transpose(di['TH'])
146/18: P
146/19:
for date in dates[:1]
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])
    tmp = dict()
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/20:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])
    tmp = dict()
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/21:
for date in dates[:1]:
    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[q] = np.array([])
    di2['THEstar'] = np.array([])
    tmp = dict()
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmp[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[q][I,e])

        for q in np.append(varS,varP):
                di2[q] = np.append(di2[q],np.mean(tmp[q]))
        di2['THEstar'] = np.append(di2['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/22: fig, ax = plt.subplots(1,3,sharey=True)
146/23: pltvar = np.append(varS,varP,'THEstar')
146/24: pltvar = np.append(np.append(varS,varP),'THEstar')
146/25: pltvar
146/26: pltvar = np.append(varS,'THEstar')
146/27: pltvar
146/28:  fig, ax = plt.subplots(1,2,sharey=True)
146/29: ax[0].plt(np.arange(100,1001,25),di2['PV'],color='k')
146/30: ax[0].plot(np.arange(100,1001,25),di2['PV'],color='k')
146/31:
for q in pltvar[1:]:
    ax[1].plot(np.arange(100,1001,25),di2[q])
146/32: fig.show()
146/33: plt.close()
146/34: fig, ax = plt.subplots(1,2,sharey=True)
146/35: ax[0].plot(di2['PV'],np.arange(100,1001,25),color='k')
146/36:
for q in pltvar[1:]:
    ax[1].plot(di2[q],np.arange(100,1001,25))
146/37: fig.show()
146/38: ax[0].invert_yaxis()
146/39: plt.close()
146/40: fig, ax = plt.subplots(1,2,sharey=True)
146/41: ax[0].plot(di2['PV'],np.arange(100,1001,25),color='k')
146/42: ax[0].invert_yaxis()
146/43:
for q in pltvar[1:]:
    ax[1].plot(di2[q],np.arange(100,1001,25))
146/44: fig.show()
146/45: plt.close()
146/46:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/006-year-traj/'
path=p
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            dates = np.append(dates,d[-15:-4])
dates = np.sort(dates)
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
plevels=np.arange(970,1022,3)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

Clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
Clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
Dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

rdis=200

varS = np.array(['PV','TH','THE'])
varP = np.array(['T'])
di = dict()
di2= dict()
tmpd = dict()
146/47:
for date in dates:
    di[date] = dict()
    di2[date] = dict()

    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmp[q] = np.append(tmp[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmp[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmp['TH'],tmp['T'],pres)))
146/48:
di = dict()
di2= dict()
tmpd = dict()

for date in dates:
    di[date] = dict()
    di2[date] = dict()

    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
146/49:
for date in dates:
    di[date] = dict()
    di2[date] = dict()

    ID = helper.MED_cyclones_date_to_id(date)
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    clat = (np.mean(Clat[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[1]
    clon = (np.mean(Clon[np.where(Dates==date)])).astype(int) + helper.radial_ids_around_center_calc(rdis)[0]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
146/50:
pltvar = np.append(varS,'THEstar')
col = np.array(['grey','red','midnightblue'])
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='k')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

ax[0].invert_yaxis()
ax[0].set_xlim(-1,10)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/51: fig.show()
146/52: ax[0].invert_yaxis()
146/53: fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/54: di2[date]['PV'].shape
146/55: 900/25
146/56: di2[date]['PV']
146/57: plt.close('all')
146/58:
pltvar = np.append(varS,'THEstar')
col = np.array(['grey','red','midnightblue'])
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

lvls = dict()
av = dict()

for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array()
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for var in np.append(varS,'THEstar'):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))

ax[0].plot(av['PV'],np.arange(100,1001,25),color='k',linewidth=2.)

ax[0].set_xlim(-1,10)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/59: plt.close()
146/60:
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

lvls = dict()
av = dict()

for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for var in np.append(varS,'THEstar'):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))

ax[0].plot(av['PV'],np.arange(100,1001,25),color='k',linewidth=2.)

ax[0].set_xlim(-1,10)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/61: fig.show()
146/62: plt.close()
146/63:
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

lvls = dict()
av = dict()

for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for var in np.append(varS,'THEstar'):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))

ax[0].plot(av['PV'],np.arange(100,1001,25),color='k',linewidth=2.)
ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xlim(-1,10)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/64: fig.show()
146/65: plt.close()
146/66:
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

lvls = dict()
av = dict()

for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for var in np.append(varS,'THEstar'):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))

ax[0].plot(av['PV'],np.arange(100,1001,25),color='k',linewidth=2.)
ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xlim(-1,10)
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=6)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/67: fig.show()
146/68: plt.close()
146/69:
fig, ax = plt.subplots(1,2,sharey=True)

for date in dates:
    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[1:]):
        ax[1].plot(di2[date][q],np.arange(100,1001,25),color=col[w])

lvls = dict()
av = dict()

for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for var in np.append(varS,'THEstar'):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))

ax[0].plot(av['PV'],np.arange(100,1001,25),color='k',linewidth=2.)
ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xlim(-1,10)
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=8)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')
ax[0].set_xlabel('PV [PVU]')
ax[1].set_xlim(280,420)
ax[1].set_xlabel(r'$\theta$ [K]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/70: fig.show()
146/71:
fig, ax = plt.subplots(1,4,sharey=True)

for date in dates:
#    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[:]):
        ax[w].plot(di2[date][q],np.arange(100,1001,25),color='grey')

lvls = dict()
av = dict()
xlims = np.array([-1,10],[280,420],[280,420],[280,420])
xlab = np.array(['PV [PVU]',r'$\theta$ [K]',r'$\theta_e$ [K]',r'$\theta_e^{*}$ [K]'])
for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for e,var in enumerate(np.append(varS,'THEstar')):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))
    ax[e].plot(av[var],np.arange(100,1001,25),color='k',linewidth=2.)
    ax[e].set_xlim(xlims[e])
    ax[e].set_xlabel(xlab[e])

ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=8)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/72:
fig, ax = plt.subplots(1,4,sharey=True)

for date in dates:
#    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[:]):
        ax[w].plot(di2[date][q],np.arange(100,1001,25),color='grey')

lvls = dict()
av = dict()
xlims = np.array([[-1,10],[280,420],[280,420],[280,420]])
xlab = np.array(['PV [PVU]',r'$\theta$ [K]',r'$\theta_e$ [K]',r'$\theta_e^{*}$ [K]'])
for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for e,var in enumerate(np.append(varS,'THEstar')):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))
    ax[e].plot(av[var],np.arange(100,1001,25),color='k',linewidth=2.)
    ax[e].set_xlim(xlims[e])
    ax[e].set_xlabel(xlab[e])

ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=8)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/73: plt.show()
146/74: plt.close('all')
146/75:
fig, ax = plt.subplots(1,4,sharey=True)
print(fig.size)
146/76:
fig, ax = plt.subplots(1,4,sharey=True,figsize=(10,6))
for date in dates:
#    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[:]):
        ax[w].plot(di2[date][q],np.arange(100,1001,25),color='grey')

lvls = dict()
av = dict()
xlims = np.array([[-1,10],[280,420],[280,420],[280,420]])
xlab = np.array(['PV [PVU]',r'$\theta$ [K]',r'$\theta_e$ [K]',r'$\theta_e^{*}$ [K]'])
for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for e,var in enumerate(np.append(varS,'THEstar')):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))
    ax[e].plot(av[var],np.arange(100,1001,25),color='k',linewidth=2.)
    ax[e].set_xlim(xlims[e])
    ax[e].set_xlabel(xlab[e])

ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=8)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/77: plt.show()
146/78: plt.close('all')
146/79:
fig, ax = plt.subplots(1,4,sharey=True,figsize=(8,6))
for date in dates:
#    ax[0].plot(di2[date]['PV'],np.arange(100,1001,25),color='grey')
    for w,q in enumerate(pltvar[:]):
        ax[w].plot(di2[date][q],np.arange(100,1001,25),color='grey')

lvls = dict()
av = dict()
xlims = np.array([[-1,10],[280,420],[280,420],[280,420]])
xlab = np.array(['PV [PVU]',r'$\theta$ [K]',r'$\theta_e$ [K]',r'$\theta_e^{*}$ [K]'])
for q,pres in enumerate(np.arange(100,1001,25)):
    lvls[pres] = dict()
    for var in np.append(varS,'THEstar'):
        av[var] = np.array([])
        lvls[pres][var] = np.array([])
        for date in dates:
            lvls[pres][var] = np.append(lvls[pres][var],di2[date][var][q])

for e,var in enumerate(np.append(varS,'THEstar')):
    for q,pres in enumerate(np.arange(100,1001,25)):
        av[var] = np.append(av[var],np.mean(lvls[pres][var]))
    ax[e].plot(av[var],np.arange(100,1001,25),color='k',linewidth=2.)
    ax[e].set_xlim(xlims[e])
    ax[e].set_xlabel(xlab[e])

ax[0].axvline(0,color='grey',linestyle='-')
ax[0].set_xticks(ticks=np.arange(-1,11))
ax[0].set_xticklabels(labels=np.arange(-1,11),fontsize=8)
ax[0].set_ylim(100,1000)
ax[0].set_ylabel('pressure [hPa]')

ax[0].invert_yaxis()

fig.savefig(path + 'vertical-averages.png',dpi=300,bbox_inches="tight")
146/80: fig.show()
146/81: plt.close('all')
147/1: import numpy as np
147/2: LAT = np.linspace(0,90,226)
147/3: LON = np.linspace(-180,180,901)
147/4: np.where((LON>-4.1) & (LON<36.1))
147/5: np.where((LAT>27.9) & (LAT<48.1))
148/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
148/2:
p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)
fsl=4
LSid = 16
labs = helper.traced_vars()
cl=['k','orange','green','dodgerblue','blue','red']
pllegend = ['cyc','env','TOT','CONVT + TURBT, |CONV|>|TURB|','TURBT + CONVT, |TURB|>|CONV|', 'CONVM', 'TURBM','RAD','LS']
plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRLS']
ptitle = np.array(['800 hPa < P$_{-48}$', '600 < P$_{-48} <$ 800 hPa', '400 < P$_{-48} <$ 600 hPa',  'P$_{-48} <$ 400 hPa'])
linestyle = ['-',':']

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
labels = np.loadtxt(pt + 'labels-' + add + '.txt',dtype=int)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zeta'+ add + '.txt',dtype=float)

#rdis = int(args.rdis)
#deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)
### INFO
### Trajetories start 200km around the center between 925 and 500 hPa if PV>0.75 PVU
###
wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
H = 48
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
148/3:
ylim2 = np.array([-0.3,0.5])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
cmap = ListedColormap(['saddlebrown','orange'])
norm = BoundaryNorm([0, 0.5, 1], cmap.N)

matureid = np.where(htzeta==0)[0]
relvortmature = relvort[matureid]
148/4:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:]axis=1),axis=1),axis=1)

        dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

        dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
        dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'][:,0])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/6:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:]axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

        dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
        dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'][:,0])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/8:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:]axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

    dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
    dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'][:,0])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/9:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:],axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

    dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
    dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'][:,0])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/10: dipv[date]['deltaPV']
148/11: dipv[date]['deltaPV'].shape
148/12: abs(dipv[date]['deltaPV'])
148/13: np.where(abs(dipv[date]['deltaPV'])<0.2)
148/14:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:],axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

    dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
    dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/15: fig.show()
148/16: plt.close()
148/17:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:],axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

    dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
    dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(abs(dipv[date]['deltaPV'])<0.2)[0])/len(dipv[date]['deltaPV'])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [-5,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/18: fig.show()
148/19: plt.close()
148/20:
fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.9]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/21: fig.show()
148/22: plt.close()
148/23:
for uyt, txt in enumerate(traced):
    date=txt[-15:-4]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[date]=dict() #raw data
    dipv[date]=dict()    #accumulated pv is saved here

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)

    for k, el in enumerate(labs[9:]):
            dipv[date][el] = np.zeros(datadi[date]['time'].shape)
            dipv[date][el][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date][el][:,1:],axis=1),axis=1),axis=1)

    dipv[date]['APVTOT'] = -1 * dipv[date]['PVRLS']
    for el in labs[9:]:
            dipv[date]['APVTOT'] += dipv[date][el]

    dipv[date]['APVRAD'] = dipv[date]['PVRSW'] + dipv[date]['PVRLWH'] + dipv[date]['PVRLWC']
    dipv[date]['PVR-T'] = dipv[date]['PVRTURBT'] + dipv[date]['PVRCONVT']

    for el in np.append(labs[9:],['APVTOT','APVRAD','PVR-T']):
            if wql==0:
                meandi[el] = dipv[date][el]
            else:
                meandi[el] = np.concatenate((meandi[el], dipv[date][el]),axis=0)
        ### PLOTTING
    t = datadi[date]['time'][0]
    titles= 'PV-contribution'

    dipv[date]['deltaPV'] = datadi[date]['PV'][:,0]-datadi[date]['PV'][:,-1]
    dipv[date]['con-per'] = len(np.where(dipv[date]['deltaPV']<0.2)[0])/len(dipv[date]['deltaPV'])

per = np.array([])
for k in dipv.keys():
    per = np.append(per,dipv[k]['con-per'])

fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [-5,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/24: fig.show()
148/25:
fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/26: fig.show()
148/27: plt.close()
148/28:
for w,k in enumerate(dipv.keys()):
    print(w,k)
148/29:
fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
ax.scatter(relvortmature[21],per[21],color='red',marker='x')
ax.scatter(relvortmature[20],per[20],color='blue',marker='x')
ax.scatter(relvortmature[15],per[15],color='purple',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/30: fig.show()
148/31: plt.close()
148/32: plt.close('all')
148/33:
fig, ax = plt.subplots()
ax.scatter(relvortmature,per,color='black',marker='x')
ax.scatter(relvortmature[3],per[3],color='red',marker='x')
ax.scatter(relvortmature[4],per[4],color='blue',marker='x')
ax.scatter(relvortmature[7],per[7],color='purple',marker='x')
ax.scatter(relvortmature[15],per[15],color='orange',marker='x')
xlim = [0.9,1.8]
ylim = [0,1]
ax.set_xlim(xlim)
ax.set_ylim(ylim)
ax.set_xlabel(r'relative vorticity [$\times 10^{-4}$ s $^{-1}$]')
ax.set_ylabel(r'number of traj with mainly conserved PV [%]')
ax.tick_params(labelright=False,right=True)
name = 'conserved-PV-percentage' + '.png'
fig.savefig(p + name,dpi=300,bbox_inches="tight")
148/34: fig.show()
148/35: relvortmature
148/36: np.max(relvortmature)
148/37: plt.close('all')
149/1: import numpy as np
149/2: a = np.array([3,4,5])
149/3: np.where(a==4)
149/4: np.where(a==4).size
149/5: np.where(a==4)[0].size
149/6: ~np.where(a==4)[0].size
149/7: ~(np.where(a==4)[0].size)
149/8: ~(np.where(a==9)[0].size)
149/9: np.where(a==9)[0].size
150/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
#dypy
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython


import pickle
import netCDF4
import numpy as np
import math
import dypy.netcdf as nc
150/2:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/006-year-traj/'
path=p
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            dates = np.append(dates,d[-15:-4])
dates = np.sort(dates)
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
plevels=np.arange(970,1022,3)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

Clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
Clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
Dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)

pv_cmap,pv_levels,pvnorm,pvticklabels=PV_cmap2()
varS = np.array(['PV','THE'])
varP = np.array(['Q'])

for var in np.append(varS,'RH'):
    if(os.path.isdir(p + var + '/')==0):
        os.mkdir(p + var + '/')
    elif (os.path.isdir(p+var+'/'+'vertical/')==0):
        os.mkdir(p+var+'/'+'vertical/')

Var = dict()

labels = np.array(['PV',r'$\theta_e$','RH'])
units = np.array(['[PVU]','[K]',r'[%]'])
levels = np.array([pv_levels,np.arange(280,346,2),np.arange(0,105,5)])
ticklabels = np.array([pvticklabels,np.arange(280,346,6),np.arange(0,105,5)])
cmaps = np.array([pv_cmap,matplotlib.cm.bwr,matplotlib.cm.YlGnBu])
norms = np.array([pvnorm,plt.Normalize(np.min(levels[1]),np.max(levels[1])),plt.Normalize(np.min(levels[2]),np.max(levels[2]))])
150/3:
for date in dates:
   ID = helper.MED_cyclones_date_to_id(date)
   yyyy = int(date[0:4])
   MM = int(date[4:6])
   DD = int(date[6:8])
   hh = int(date[9:])

   for w in range(3,25,3):
    hh -=w
    if (hh<0):
            hh+=24
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]

    date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    if (np.where(Dates==date)[0].size==0):
        continue
    print(date,w)
150/4:
for date in dates:
   print(date)
   ID = helper.MED_cyclones_date_to_id(date)
   yyyy = int(date[0:4])
   MM = int(date[4:6])
   DD = int(date[6:8])
   hh = int(date[9:])

   for w in range(3,25,3):
    hh -=w
    if (hh<0):
            hh+=24
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]

    date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    if (np.where(Dates==date)[0].size==0):
        continue
    print(date,w)
150/5:
for date in dates:
   print(date)
   ID = helper.MED_cyclones_date_to_id(date)
   yyyy = int(date[0:4])
   MM = int(date[4:6])
   DD = int(date[6:8])
   hh = int(date[9:])

   for w in range(3,25,3):
    hh -=3
    if (hh<0):
            hh+=24
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]

    date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)

    monthn = int(date[4:6])
    monthid, = np.where(MONTHSN==monthn)
    month = MONTHS[monthid[0]] + date[2:4]
    if month=='DEC18':
        month='NOV18'
    if ((MM==2) & (DD<4)):
        month='JAN18'
    ana_path='/net/thermo/atmosdyn/atroman/phd/'+ month +'/cdf/'

    if (np.where(Dates==date)[0].size==0):
        continue
    print(date,w)
151/1: import numpy as np
151/2:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
151/3: d = np.loadtxt('/atmosdyn/atroman/phd/FEB18/cyclones/TRACKED_CYCLONES')
151/4: d = np.loadtxt('/atmosdyn/atroman/phd/FEB18/cyclones/TRACKED_CYCLONES',skiprows=1)
151/5: dates = str(helper.datenum_to_datetime(ft+d[:,0]/24))
151/6: from datetime import datetime, date, timedelta
151/7: ft = date.toordinal(date(1950,1,1))
151/8: dates = str(helper.datenum_to_datetime(ft+d[:,0]/24))
151/9: dates = (helper.datenum_to_datetime(ft+d[:,0]/24)).astype(str)
151/10: dates = helper.datenum_to_datetime(ft+d[:,0]/24)
151/11: d
151/12: d[:,0]
151/13:
for t in d[:,0]:
    k = str(helper.datenum_to_datetime(ft+t/24))
    date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
    if (date=='20180209_15'):
        print(t)
151/14:
for q,t in enumerate(d[:,0]):
    k = str(helper.datenum_to_datetime(ft+t/24))
    date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
    if (date=='20180209_15'):
        print(t,d[q,1])
151/15: print(helper.MED_cyclones_date_to_id('20180209_15'))
151/16:
for q,t in enumerate(d[:,0]):
    k = str(helper.datenum_to_datetime(ft+t/24))
    date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
    if (date=='20180209_15'):
        print(t,d[q,1],d[q,2],d[q,3])
151/17: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-ET-vort-entire-year3.txt')
151/18: ids = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-MED-vort-entire-year3.txt')
151/19: np.unique(ids)
151/20: :w
151/21: ids
151/22: ids[np.where((ids[1:]-ids[:-1])!=0)[0] + 1]
151/23: np.append(14.,ids[np.where((ids[1:]-ids[:-1])!=0)[0] + 1])
151/24: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year3.txt',dtpe=str)
151/25: dates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year3.txt',dtype=str)
151/26: clat =  np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-MED-vort-entire-year3.txt')
151/27: clon =  np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-MED-vort-entire-year3.txt')
151/28: np.where(dates=='20180209_15')
151/29: clat[280] = clat[280] + 2
151/30: clon[280] = clon[280] + 11
151/31:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')
151/32: add= 'MED-vort-entire-year3
151/33: add= 'MED-vort-entire-year3'
151/34:
np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-' + add + '.txt',clat.astype(int), fmt='%i', delimiter=' ',newline='\n')

np.savetxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-' + add + '.txt',clon.astype(int), fmt='%i', delimiter=' ',newline='\n')
151/35: relvort = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zeta'+ add + '.txt',dtype=float)
151/36: htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
151/37: pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
151/38: htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
151/39: relvort[np.where(htzeta==0)]
152/1: import numpy as np.
152/2: import numpy as np
152/3:
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
152/4: ap = plt.cm.seismic
152/5: newcol = matplotlib.get_cmap('seismic',8)
152/6: matplotlib.get_cmap
152/7: newcol = matplotlib.cm.get_cmap('seismic',8)
152/8: newcol
152/9: newcol = matplotlib.cm.get_cmap('seismic',256)
152/10: newcol = newcol(np.linspace(0, 1, 256))
152/11: grey = np.array([0.5,0.5,0.5,1])
152/12: ap
152/13: ap.shape
152/14: ap.type
152/15: print(ap)
152/16: cmap ,norm = colbar(ap,minv,maxv,len(pvr_levels))
152/17:
def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm
152/18: cmap ,norm = colbar(ap,minv,maxv,len(pvr_levels))
152/19:
maxv = 0.61
minv =-0.6
pvr_levels = np.arange(minv,maxv,0.15)

ap = plt.cm.seismic
#ap = plt.cm.YlGnBu
cmap ,norm = colbar(ap,minv,maxv,len(pvr_levels))
152/20: cmap
152/21: print(cmap)
152/22: cmap.values
152/23: cmap.colors
152/24: cmap.colors.shape
152/25: cmap.colors[0]
152/26: cmap.colors[100]
152/27: len(cmap.colors)
152/28: 76+64
152/29: len(cmap.colors[100])
152/30: cmap.color[100] = (0.5, 0.5, 0.5, 1.0)
152/31: cmap.colors[100] = (0.5, 0.5, 0.5, 1.0)
152/32: ap.colors
152/33: ap
152/34: cmap
152/35: ap.shape
152/36: len(cmap.colors)
153/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from scipy.stats.stats import pearsonr
import xarray as xr
153/2:
p = '/atmosdyn2/ascherrmann/006-year-traj/'#12h-premature-trajectories/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zeta'+ add + '.txt',dtype=float)
labs = helper.traced_vars()
traced = np.array([])
traj = np.array([])
H = 48
a = 1

for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

Clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
Clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
Dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htzeta = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
153/3: hdata = np.loadtxt('/atmosdyn2/ascherrmann/006-year-traj/PV-gt--0.75PVU-percentages.txt',dtype=float)
153/4: hdata = np.loadtxt('/atmosdyn2/ascherrmann/006-year-traj/PV-gt-0.75PVU-percentages.txt',dtype=float)
153/5: hdata
154/1: import numpy as np
154/2: d = np.loadtxt('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609',skiprows=4)
154/3: d[:,0]
154/4: len(d[:,0])
154/5: np.where(d[1:,0]-d[:-1,0]!=1)
154/6: np.linspace(0,90,226)[70:121]
154/7: np.linspace(-180,180,901)[440:541]
154/8: londom = np.array([-5.,2.,27.,37])
154/9: latbon = np.array([42.,46.,40.])
154/10: test = np.array([[5,6,7],[7,8,9,10]])
154/11: test
154/12: test[0]
154/13: test = np.array([np.array([5,6,7]),np.array([7,8,9,10])])
154/14: test[0]
154/15: np.min(test)
154/16: np.min(test[:])
154/17: np.min(test[:,0])
154/18: np.min(test[0])
154/19: np.where(d[1:,0]-d[:-1,0]!=1)
154/20: d[0:14]
154/21: d[0:15]
154/22:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>100:
            break
        print(l)
154/23:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>100:
            break
        if l=='\n':
            print(l)
154/24:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if '\n' in l:
            print(l)
154/25:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if '\n' in l:
            print(l)
        a+=1
154/26:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if '\n\n' in l:
            print(l)
        a+=1
154/27:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if '\n\n' in l:
            print(l)
            print(a)
        a+=1
154/28:
with open ('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if '\n'== l:
            print(l)
            print(a)
        a+=1
154/29:
with open('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609') as f:
    a = 0
    for l in f:
        if a>20:
            break
        if l=="\n":
            print(l)
            print(a)
        a+=1
154/30: f
154/31: f = open('/net/thermo/atmosdyn/michaesp/mincl.era-5/tracks/fi_198609','r')
154/32: lines = f.readlines()
154/33:
for l in lines:
    if l=="\n":
        print('empty')
154/34:
for l in lines[:10]:
        print(l)
154/35:
for l in lines[:2]:
        print(l)
154/36:
for l in lines[:2]:
    if '\n\n\ in l:
        print(l)
154/37:
for l in lines[:2]:
    if '\n\n' in l:
        print(l)
154/38:
for l in lines[:10]:
    if '\n\n' in l:
        print(l)
154/39: d
154/40: f.close()
154/41: ids = np.where((d[1:,0]-d[:-1,0)!=1])[0] + 1
154/42: ids = np.where((d[1:,0]-d[:-1,0])!=1)[0] + 1
154/43: ids = np.append(0,np.where((d[1:,0]-d[:-1,0])!=1)[0] + 1)
154/44: ids = np.append(ids,len(d[:,0]))
154/45:
array = np.array([])
for k,i in enumerate(ids[:2]):
    array = np.append(array,np.array(d[i:ids[k+1]]))
154/46: arrau
154/47: array
154/48:
array = np.array([])
for k,i in enumerate(ids[:2]):
    array = np.append(array,np.array(d[i:ids[k+1],0]))
154/49: array
154/50:
array = []
for k,i in enumerate(ids[:2]):
    array.append(np.array(d[i:ids[k+1],0]))
154/51: array
154/52: array[0]
154/53:
array = np.array([])
for k,i in enumerate(ids[:2]):
    array = np.append(array,np.array([d[i:ids[k+1],0]]))
154/54: array
154/55:
array = np.array([])
for k,i in enumerate(ids[:2]):
    array = np.append(array,[np.array([d[i:ids[k+1],0]])])
154/56: array
154/57:
array = []
for k,i in enumerate(ids[:2]):
    array.append(np.array(d[i:ids[k+1],0]))
154/58: array
154/59:
array = []
for k,i in enumerate(ids[:10]):
    array.append(np.array(d[i:ids[k+1],0]))
154/60: array
154/61:
fdate = 'fi_198609'
array = []
SLP = []
lon = []
lat = []
dates = []
for k,i in enumerate(ids[:10]):
    array.append(np.array(d[i:ids[k+1],0]))
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
154/62: SLP
154/63: array
154/64: array/24
154/65:
fdate = 'fi_198609'
array = []
SLP = []
lon = []
lat = []
dates = []
for k,i in enumerate(ids[:10]):
    array.append(np.array(d[i:ids[k+1],0]))
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    dates.append(np.array(str(fdate[-6:]) + '%02d'%int(np.floor(d[i:ids[k+1],0]/24)) + '%02d' %int(d[i:ids[k+1],0]%24) ))
154/66:
fdate = 'fi_198609'
array = []
SLP = []
lon = []
lat = []
dates = []
for k,i in enumerate(ids[:10]):
    array.append(np.array(d[i:ids[k+1],0]))
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    dates.append(np.array(str(fdate[-6:]) + '%02d'%(np.floor(d[i:ids[k+1],0]/24)).astype(int) + '%02d' %(d[i:ids[k+1],0]%24).astype(int) ))
154/67: d[i:ids[k+1],0]
154/68: d[i:ids[k+1],0] + 1
154/69: d[i:ids[k+1],0].astype(str)
154/70: '09' + d[i:ids[k+1],0].astype(str)
154/71: d[i:ids[k+1],0].astype(int).astype(str)
154/72: dates
154/73:
tmp = np.array([])
for u,v in enumerate(d[i:ids[k+1],0]):
    tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '%02d'%(v%24).astype(int))
dates.append(tmp)
154/74: dates
154/75:
tmp = np.array([])
for u,v in enumerate(d[i:ids[k+1],0]):
    tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
dates.append(tmp)
154/76: dates
154/77:
fdate = 'fi_198609'
array = []
SLP = []
lon = []
lat = []
dates = []
for k,i in enumerate(ids[:10]):
    array.append(np.array(d[i:ids[k+1],0]))
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    tmp = np.array([])
    for u,v in enumerate(d[i:ids[k+1],0]):
        tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
    dates.append(tmp)
154/78: dates
154/79:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
ID = []
for k,i in enumerate(ids[]):
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    ID.append(np.array(d[i:ids[k+1],-1]))
    tmp = np.array([])
    for u,v in enumerate(d[i:ids[k+1],0]):
        tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
    dates.append(tmp)
154/80:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
ID = []
for k,i in enumerate(ids[:]):
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    ID.append(np.array(d[i:ids[k+1],-1]))
    tmp = np.array([])
    for u,v in enumerate(d[i:ids[k+1],0]):
        tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
    dates.append(tmp)
154/81:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
ID = []
for k,i in enumerate(ids[:-1]):
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    ID.append(np.array(d[i:ids[k+1],-1]))
    tmp = np.array([])
    for u,v in enumerate(d[i:ids[k+1],0]):
        tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
    dates.append(tmp)
154/82: dates
154/83:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
ID = []
for k,i in enumerate(ids[:1]):
    SLPtmp = d[i:ids[k+1],3]
    
    SLP.append(np.array(d[i:ids[k+1],3]))
    lon.append(np.array(d[i:ids[k+1],1]))
    lat.append(np.array(d[i:ids[k+1],2]))
    ID.append(np.array(d[i:ids[k+1],-1]))
    tmp = np.array([])
    for u,v in enumerate(d[i:ids[k+1],0]):
        tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
    dates.append(tmp)
154/84: SLPtmp
154/85: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0]]
154/86: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0][0]]
154/87: lon
154/88: lon[0]
154/89: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0]]
154/90: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0]][0]
154/91: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0][0]]
154/92: lon[0][np.where(SLPtmp==np.min(SLPtmp))[0][-1]]
154/93: loncheck = lon[0][np.where(SLPtmp==np.min(SLPtmp))[0][-1]]
154/94:
if ((loncheck>londom[0]) & (loncheck<londom[-1])):
    print('test')
else:
    print('nope')
154/95:
if ((loncheck>londom[0]) & (loncheck<londom[-1])):
    print('test')
else:
    latcheck = d[i:ids[k+1],2]
154/96: latcheck
154/97:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:100]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in londom[:-1]:
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/98: londom
154/99:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:100]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/100: dates
154/101: lon
154/102: lat
154/103: SLP
154/104:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[100:1000]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/105:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[100:150]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/106:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:100]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/107:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/108:
fdate = 'fi_198609'
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:-1]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
     dates.append(tmp)
154/109: dates
154/110: SLP
154/111: len(dates)
154/112: dates
154/113: import sys
154/114: sys.path.append('/atmosdyn2/ascherrmann/scripts/')_
154/115: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
154/116: import helper
154/117: fdate
154/118: year = int(fdate[-6:-2])
154/119: month = int(fdate[-2:])-1
154/120: days = helper.month_days(year)[month]
154/121: days
154/122:
fdate = 'fi_198609'
year = int(fdate[-6:-2])
month = int(fdate[-2:])-1
days = helper.month_days(year)[month]
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
for k,i in enumerate(ids[:-1]):
    indomain = 0
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]
    lonmin = d[i:ids[k+1],1][SLPmin]
    if ((lonmin>=londom[0]) & (lonmin<=londom[-1])):
        latmin = d[i:ids[k+1],2][SLPmin]
        for b,o in enumerate(londom[:-1]):
            if ((lonmin>=o) & (lonmin<=londom[b+1]) & (latmin>=30) & (latmin<=latbon[b])):
                indomain=1
    if indomain==1:
     SLP.append(np.array(d[i:ids[k+1],3]))
     lon.append(np.array(d[i:ids[k+1],1]))
     lat.append(np.array(d[i:ids[k+1],2]))
     ID.append(np.array(d[i:ids[k+1],-1]))
     hourstoSLPmin.append(np.array(d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]))
     tmp = np.array([])
     for u,v in enumerate(d[i:ids[k+1],0]):
         if(np.floor(v/24).astype(int)>days):
             tmp = np.append(tmp,fdate[-6:-2] + str(int(fdate[-2:]) + 1) + '%02d'%(np.floor(v/24).astype(int)-30) + '_%02d'%(v%24).astype(int))
             if ((int(fdate[-2:]) + 1)>12):
                 tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + str(int(fdate[-2:]) + 1 - 12) + '%02d'%(np.floor(v/24).astype(int)-30) + '_%02d'%(v%24).astype(int))
         else:
             tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
         
     dates.append(tmp)
154/123: dates
154/124: lon
154/125: lat
154/126: lo
154/127: lon
154/128: lon[-1]
154/129: lat[-1]
154/130: hourstoSLPmin[-1]
154/131: import os
154/132: trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
154/133:
tracks = np.array([])
for d in os.listdir(p):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
        tracks = np.append(tracks,d)
154/134:
tracks = np.array([])
for d in os.listdir(p):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)
154/135:
tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)
154/136: tracks
154/137: tracks = np.sort(tracks)
154/138: tracks
154/139: SLP
154/140: import pickle
154/141: f = open('SLP-test.txt',"wb")
154/142: pickle.dump(SLPmin,f)
154/143: f.close()
154/144: f = open('SLP-test.txt',"rb")
154/145: ltest = pickle.load(f)
154/146: ltest
154/147: SLPmin
154/148: SLP
154/149: f = open('SLP-test.txt',"wb")
154/150: pickle.dump(SLP,f)
154/151: f.close()
154/152: f = open('SLP-test.txt',"rb")
154/153: ltest = pickle.load(f)
154/154: ltest
154/155: ltest[0]
154/156: ltest[-1]
154/157: SLP
154/158: eval("SLP")
154/159: eval("lon")
156/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from scipy.stats.stats import pearsonr
import pickle
156/2:
pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt(pt + 'zeta' + add + '.txt',dtype=float)
156/3: maturestage = np.where(htM==0)[0]
156/4: Pintervals = np.array([])
156/5: Pintervals = np.array([[np.arange(700,925.5,12.5)],[np.arange(100,550.1,25)],[np.arange(550,700.1,15)]])
156/6: Pintervals
156/7: Pival = [np.arange(700,925.5,12.5),np.arange(100,550.1,25),np.arange(550,700.1,15)]
156/8: Pival
156/9: Pival[0]
156/10: Pival[0][0]
157/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from scipy.stats.stats import pearsonr
import pickle

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt(pt + 'zeta' + add + '.txt',dtype=float)

clat3 = np.mean(clat,axis=1).astype(int)
clon3 = np.mean(clon,axis=1).astype(int)

maturestage = np.where(htM==0)[0]

Pintervals = [np.arange(100,550.1,25),np.arange(550,700.1,15),np.arange(700,925.5,12.5)]

maturelon = np.mean(clon[maturestage],axis=1)
maturelat = np.mean(clat[maturestage],axis=1)
alldates = []

monthdays = helper.month_days(2018)

for date in dates[maturestage]:
    tmpdates = np.array([])
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])+2
    if(DD>monthdays[MM-1]):
        DD-=monthdays[MM-1]
    hh = int(date[9:])
    for k in range(1,96):
        hh-=1
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=monthdays[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        tmpdates = np.append(tmpdates,Date)

    alldates.append(np.flip(tmpdates))
157/2: alldates
157/3: len(alldates)
157/4: vi /atmosdyn2/ascherrmann/scripts/trajectories/Get-Mature-time-PV-anomalies.py
157/5: less /atmosdyn2/ascherrmann/scripts/trajectories/Get-Mature-time-PV-anomalies.py
157/6:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from scipy.stats.stats import pearsonr
import pickle
import os


pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

clat = np.loadtxt(pt + 'clat-' + add + '.txt',dtype=int)
clon = np.loadtxt(pt + 'clon-' + add + '.txt',dtype=int)
dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt(pt + 'zeta' + add + '.txt',dtype=float)

maturestage = np.where(htM==0)[0]
Pintervals = [np.arange(100,550.1,25),np.arange(550,700.1,15),np.arange(700,925.5,12.5)]

maturelon = np.mean(clon[maturestage],axis=1)
maturelat = np.mean(clat[maturestage],axis=1)
radano = [200, 200, 1000]


alldates = []
monthdays = helper.month_days(2018)

for date in dates[maturestage]:
    tmpdates = np.array([])
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])+2
    if(DD>monthdays[MM-1]):
        DD-=monthdays[MM-1]
    hh = int(date[9:])
    for k in range(1,96):
        hh-=1
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=monthdays[int(MM)-1]
        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)
        tmpdates = np.append(tmpdates,Date)

    alldates.append(np.flip(tmpdates))


relvort = relvort[maturestage]

MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

sp = '/atmosdyn2/ascherrmann/006-year-traj/'
Lat = np.round(np.linspace(0,90,226),2)
Lon = np.round(np.linspace(-180,180,901),2)
157/7:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()
for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()

    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, date in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook,astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[i,l]

                            if(np.any(dates[maturestage])==date):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[i,l]
157/8:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()

for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()
    layercounter[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, date in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook,astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[i,l]

                            if(np.any(dates[maturestage])==date):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[i,l]
157/9:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()

for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()
    layercounter[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, t in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook,astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[i,l]

                            if(np.any(dates[maturestage])==t):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[i,l]
157/10:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()

for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()
    layercounter[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, t in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook.astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[i,l]

                            if(np.any(dates[maturestage])==t):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[i,l]
157/11:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()

for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()
    layercounter[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, t in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook.astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[l,i]

                            if(np.any(dates[maturestage])==t):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[l,i]
157/12: t
157/13: dates[maturestage]
157/14: np.any(dates[maturestage]==t)
157/15:
anomaly = dict()
climav = dict()
mature = dict()
layercounter = dict()
daycounter = np.zeros(len(alldates))
layerano = dict()

for y in range(len(alldates)):

    anomaly[dates[maturestage[y]]] = dict()
    climav[dates[maturestage[y]]] = dict()
    mature[dates[maturestage[y]]] = dict()
    layerano[dates[maturestage[y]]] = dict()
    layercounter[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        anomaly[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        climav[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        mature[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))
        layercounter[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi]-1))
        layerano[dates[maturestage[y]]][pi] = np.zeros((len(helper.radial_ids_around_center_calc(radano[pi])[1]),len(Pintervals[pi])-1))

    for x, t in enumerate(alldates[y]):

        yyyy = int(t[0:4])
        MM = int(t[4:6])
        DD = int(t[6:8])
        hh = int(t[9:])
        monthid, = np.where(MONTHSN==MM)
        Month = MONTHS[monthid[0]] + t[2:4]

        if ((yyyy==2018)&(MM==12)):
            Month = 'NOV18'
        if ((MM==2) & (DD<4)):
            Month = 'JAN18'

        ana_path='/net/thermo/atmosdyn/atroman/phd/'+ Month +'/cdf/'
        sfile = ana_path + 'S' + t

        if (os.path.isfile(sfile)):

            s = xr.open_dataset(sfile, drop_variables=['P','TH','THE','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])
            daycounter[y] += 1
            latc = maturelat[y]
            lonc = maturelon[y]

            for pi in range(len(Pintervals)):

                latlook = latc + helper.radial_ids_around_center_calc(radano[pi])[1]
                latlook = latlook.astype(int)
                lonlook = lonc+ helper.radial_ids_around_center_calc(radano[pi])[0]
                lonlook = lonlook.astype(int)
                PS = s.PS.values[0,0,latlook,lonlook]
                pv = s.PV.values[0,:,latlook,lonlook]

                for l in range(len(latlook)):

                    P = helper.modellevel_to_pressure(PS[l])
                    for m,n in enumerate(Pintervals[pi][:-1]):

                        pid =  helper.where_greater_smaller(P,n,Pintervals[pi][m+1])
                        layercounter[dates[maturestage[y]]][pi][m] += len(pid)

                        for i in pid:

                            climav[dates[maturestage[y]]][pi][l,m] += pv[l,i]

                            if(np.any(dates[maturestage]==t)):

                                mature[dates[maturestage[y]]][pi][l,m] += pv[l,i]
157/16:
layerav = dict()
for y in range(len(alldates)):

    layerav[dates[maturestage[y]]] = dict()
    for pi in range(len(Pintervals)):

        layerav[dates[maturestage[y]]][pi] = np.zeros(len(Pintervals[pi])-1)
        for m,n in enumerate(Pintervals[pi][:-1]):

            layerav[dates[maturestage[y]]][pi][m] = np.sum(climav[dates[maturestage[y]]][pi][:,m])/layercounter[dates[maturestage[y]]][pi][m]
        for l in range(len(latlook)):
            for m,n in enumerate(Pintervals[pi][:-1]):

                ### this gives the climatology and anomaly at every point
                climav[dates[maturestage[y]]][pi][l,m] /= layercounter[dates[maturestage[y]]][pi][m]
                anomaly[dates[maturestage[y]]][pi][l,m] = mature[dates[maturestage[y]]][pi][l,m] - climav[dates[maturestage[y]]][pi][l,m]
                layerano[dates[maturestage[y]]][pi][l,m]= mature[dates[maturestage[y]]][pi][l,m] - layerav[dates[maturestage[y]]][pi][m]


f = open(sp + 'mature-stages-pv-4day-dict.txt',"wb")
pickle.dump(mature,f)
f.close()

f = open(sp + 'pv-layer-anomaly-4day-dict.txt',"wb")
pickle.dump(layerano,f)
f.close()

f = open(sp + 'pv-point-anomaly-4day-dict.txt',"wb")
pickle.dump(anomaly,f)
f.close()

f = open(sp + 'climav-4day-dict.txt',"wb")
pickle.dump(climav,f)
f.close()

f = open(sp + 'daycounter-4day-dict.txt',"wb")
pickle.dump(daycounter,f)
f.close()
157/17: y
157/18: pi
157/19: m
157/20: l
158/1:
import numpy as np
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import os
import pickle
158/2: trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
158/3:
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
158/4:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper as h
import colorbars
import os
import pickle
#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib

#cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
158/5: tracks = np.loadtxt(trackpath + 'fi_201609',skiprows=4)
158/6:
ids = np.append(0,np.where((d[1:,0]-d[:-1,0])!=1)[0] + 1)
ids = np.append(ids,len(d[:,0]))
158/7: d = tracks
158/8:
ids = np.append(0,np.where((d[1:,0]-d[:-1,0])!=1)[0] + 1)
ids = np.append(ids,len(d[:,0]))
158/9:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>24):
        ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
158/10: p = '/atmosdyn2/ascherrmann/009-ERA-5/'
158/11: fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/12: :q
158/13: plt.close()
158/14:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>24):
        if (d[i:ids[k+1],2]>0):
            if((d[i:ids[k+1],1]>-160) & (d[i:ids[k+1],1]<160)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/15:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>24):
        if (d[i:ids[k+1],2][0]>0):
            if((d[i:ids[k+1],1][0]>-160) & (d[i:ids[k+1],1][0]<160)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/16:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>24):
        if (d[i:ids[k+1],2][0]>0):
            if((d[i:ids[k+1],1][0]>-140) & (d[i:ids[k+1],1][0]<140)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/17:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>24):
        if (d[i:ids[k+1],2][0]>0):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/18:
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>49):
        if (d[i:ids[k+1],2][0]>0):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/19:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>49):
        if (d[i:ids[k+1],2][0]>0):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/20: counter
158/21:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>49):  
        if (d[i:ids[k+1],2][0]>0):
          if(np.min(d[i:ids[k+1],3])<995):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/22: counter
158/23:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>49):  
        if (d[i:ids[k+1],2][0]>0):
          if(np.min(d[i:ids[k+1],3])<1000):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/24: counter
158/25:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>36):  
        if (d[i:ids[k+1],2][0]>0):
          if(np.min(d[i:ids[k+1],3])<1000):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/26: counter
158/27:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):  
        if (d[i:ids[k+1],2][0]>0):
          if(np.min(d[i:ids[k+1],3])<1000):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
counter
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/28:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):  
        if (d[i:ids[k+1],2][0]>0):
          if(np.min(d[i:ids[k+1],3])<1000):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
print(counter)
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/29:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):
          if(np.min(d[i:ids[k+1],3])<1000):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
print(counter)
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/30:
counter = 0
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):
          if(np.min(d[i:ids[k+1],3])<995):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
print(counter)
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/31:
counter = 0
matureid = np.array([])
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):
          if(np.min(d[i:ids[k+1],3])<995):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
                matureid = np.append(matureid,np.arange(i,ids[k+1])[np.where(d[i:ids[k+1],3]==np.min(d[i:ids[k+1],3]))])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/32: matureid
158/33: len(matureid)
158/34:
counter = 0
matureid = np.array([])
fig,ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k,i in enumerate(ids[:-1]):
    if (len(d[i:ids[k+1],1])>48):
          if(np.min(d[i:ids[k+1],3])<995):
            if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                counter +=1
                matureid = np.append(matureid,np.arange(i,ids[k+1])[np.where(d[i:ids[k+1],3]==np.min(d[i:ids[k+1],3]))[0][-1]])
fig.savefig(p + 'sep2016.png',dpi=300,bbox_inches="tight")
158/35: len(matureid)
158/36: maturedates = []
158/37: SLPs = []
158/38: lons = []
158/39: lats = []
158/40: ID = []
158/41: plt.close('all')
158/42:
matureid = np.array([])
for k,i in enumerate(ids[:-1]):
     if (len(d[i:ids[k+1],1])>48):
           if(np.min(d[i:ids[k+1],3])<995):
             if((d[i:ids[k+1],1][0]>-120) & (d[i:ids[k+1],1][0]<120)):
                 ax.plot(d[i:ids[k+1],1],d[i:ids[k+1],2])
                 matureid = np.append(matureid,np.arange(i,ids[k+1])[np.where(d[i:ids[k+1],3]==np.min(d[i:ids[k+1],3]))[0][-1]]).astype(int)
158/43: matureid
158/44: SLPs = d[matureid,3]
158/45: SLPs
158/46: lonst = d[matureid,1]
158/47: lats = d[matureid,2]
158/48:
fdate = '201609'
for u,v in enumerate(d[matureid,0]):
    if(np.floor(v/24).astype(int)>30):
        maturedates = np.append(maturedates,fdate[-6:-2] + str(int(fdate[-2:]) + 1) + '%02d'%(np.floor(v/24).astype(int)-30) + '_%02d'%(v%24).astype(int))
    else:
         maturedates = np.append(maturedates,str(fdate[-6:]) + '%02d'%np.floor(v/24).astype(int) + '_%02d'%(v%24).astype(int))
158/49: maturedates
158/50: ID = d[matureid,-1]
158/51: ID
158/52: ID = d[matureid,-1].astype(int)
158/53: lon
158/54: lonts
158/55: lons
158/56: lons = d[matureid,1]
158/57: lats = d[matureid,2]
158/58: SLP = d[matureid,3]
158/59: maturedates
158/60: p
158/61: np.savetxt(p + 'manos-test-dates.txt',maturedates.astype(str),fmt='%s',delimiter=' ', newline='\n')
158/62: data = np.zeros((len(SLP),5))
158/63: data[:,0] = lons
158/64: data[:,1] = lats
158/65: data[:,2] = SLP
158/66: data[:,3] = ID
158/67: data[:,4] = matureid
158/68: data
158/69: np.savetxt(p + 'manos-test-data.txt',data.astype(float),fmt='%.8e',delimiter=' ', newline='\n')
158/70: %save -r get-test-data.py 1-999
159/1: import numpy as np
159/2: import xarray as xr
159/3: path = '/atmosdyn2/era5/cdf/2016/09/'
159/4: P = xr.open_dataset(path+'P20160901_13')
159/5: P
159/6: LON = np.linspace(-180,180,721)
159/7: LON = np.linspace(-180,179.5,720)
159/8: LAT = np.linspace(-90,90,361)
159/9: LON
159/10: LAT
159/11: LON[np.where((LON>=-120) & (LON<=30))[0]]
159/12: len(LON[np.where((LON>=-120) & (LON<=30))[0]])
159/13: LAT[np.where((LAT>=-20) & (LAT<=90))[0]]
159/14: len(LAT[np.where((LAT>=-20) & (LAT<=90))[0]])
159/15: P.PS.values
159/16: P.PS.values.shape
159/17: P.PS.values[:].shape
159/18: P.PS.values[:,20,20].shape
159/19: P.PS.values[:,20,20]
159/20: P.PS.values[:,np.where((LAT>=-20) & (LAT<=90))[0],20]
159/21: P.PS.values[:,np.where((LAT>=-20) & (LAT<=90))[0],np.where((LON>=-120) & (LON<=30))[0]]
159/22: P.PS.shape
159/23: P.PS.valuesshape
159/24: P.PS.values.shape
159/25: P.PS.values
159/26: P.PS.values[:,20,20]
159/27: P.PS.values[:,20,20][0]
159/28: for k in np.where((LAT>=-20) & (LAT<=90))[0]
159/29: newPS = np.array([])
159/30: newPS = np.append(newPS,np.zeros((len(np.where((LAT>=-20) & (LAT<=90))[0]),len(np.where((LON>=-120) & (LON<=30))[0]))))
159/31: newPS.shape
159/32: np.zeros((len(np.where((LAT>=-20) & (LAT<=90))[0]),len(np.where((LON>=-120) & (LON<=30))[0])))
159/33: np.zeros((len(np.where((LAT>=-20) & (LAT<=90))[0]),len(np.where((LON>=-120) & (LON<=30))[0]))).shape
159/34: newPS[0]
159/35: newPS = np.array([])
159/36: newPS[0]
159/37: a = np.zeros((len(np.where((LAT>=-20) & (LAT<=90))[0]),len(np.where((LON>=-120) & (LON<=30))[0])))
159/38: newPS
159/39: newPS = np.append(newPS,a)
159/40: newPS
159/41: newPS = np.zers((1,a))
159/42: newPS = np.zeros((1,a))
159/43: newPS = np.zeros((1,len(np.where((LAT>=-20) & (LAT<=90))[0]),len(np.where((LON>=-120) & (LON<=30))[0])))
159/44: newPS
159/45: newPS.shape
159/46: newPS[0]
159/47: newPS[:,20,20]
159/48:

for k in np.where((LAT>=-20) & (LAT<=90))[0]:
    for l in np.where((LON>=-120) & (LON<=30))[0]:

        
        k
159/49: newPS[0,20,20]
159/50:
for m,k in enumerate(np.where((LAT>=-20) & (LAT<=90))[0]):
    for n,l in enumerate(np.where((LON>=-120) & (LON<=30))[0]):
        newPS[0,m,n] = P.PS.values[0,k,l]
159/51: newPS
159/52: nPS = xr.Dataset({"test": (("PS"),newPS)},coords={"lon": LON[np.where((LON>=-120) & (LON<=30))[0]], "lat": LAT[np.where((LAT>=-20) & (LAT<=90))[0]]},)
159/53: nPS = xr.Dataset({"test": (("PS"),newPS)},coords={"lon": LON[np.where((LON>=-120) & (LON<=30))[0]], "lat": LAT[np.where((LAT>=-20) & (LAT<=90))[0]]})
159/54: nPS = xr.Dataset({"PS": (("time","lon","lat"),newPS)},coords={"time":[0],"lon": LON[np.where((LON>=-120) & (LON<=30))[0]], "lat": LAT[np.where((LAT>=-20) & (LAT<=90))[0]]})
159/55: nPS = xr.Dataset({"PS": (("time","lon","lat"),newPS)},coords={"time":[0],"lat": LAT[np.where((LAT>=-20) & (LAT<=90))[0]],"lon": LON[np.where((LON>=-120) & (LON<=30))[0]]})
159/56: nPS = xr.Dataset({"newPS": (("time","lon","lat"),newPS)},coords={"time":[0],"lat": LAT[np.where((LAT>=-20) & (LAT<=90))[0]],"lon": LON[np.where((LON>=-120) & (LON<=30))[0]]})
159/57: %save -r cropPSdown.py 1-999
160/1: import numpy as np
160/2: import pickle
160/3: f = open('ID-1980.txt',"rb")
160/4: ID = pickle.load(f)
160/5: f.close()
160/6: ID
160/7: ID[0]
160/8: len(ID)
160/9: np.where(len(ID[:])>24)
160/10: np.where(len(ID[0,:])>24)
160/11:
for k in range(len(ID)):
    if len(ID[k])>24:
        print(k)
160/12: f = open("SLP-1979.txt")
160/13: f = open("SLP-1979.txt","rb")
160/14: SLP = pickle.load(f)
160/15: f.close()
160/16:
for k in range(len(ID)):
    if ((len(ID[k])>24) & (np.min(SLP[k])<1000)):
        print(k)
160/17:
for k in range(len(ID)):
    print(np.min(SLP[k]))
    if ((len(ID[k])>24) & (np.min(SLP[k])<1000)):
        print(k)
160/18:
for k in range(len(ID)):
    print(np.min(SLP[k]),np.max(SLP[k]))
    if ((len(ID[k])>24) & (np.min(SLP[k])<1000)):
        print(k)
160/19:
for k in range(len(ID)):
    print(np.min(SLP[k]),np.max(SLP[k]))
    if ((len(ID[k])>24) & ((np.min(SLP[k])-np.max(SLP[k]))>5)):
        print(k)
160/20:
for k in range(len(ID)):
    print(len(ID[k]),np.min(SLP[k]),np.max(SLP[k]))
    if ((len(ID[k])>24) & ((np.min(SLP[k])-np.max(SLP[k]))>5)):
        print(k)
160/21: ID = []
160/22:
SLP = []
        lon = []
        lat = []
        dates = []
        hourstoSLPmin = []
        ID = []
160/23:
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
160/24: savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-']
160/25: tmp = dict()
160/26:
fin = dict()
for x in saving:
    fin[x] = []
for k in range(1979,2020):
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/27:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/28: fin['ID']
160/29: fin['ID-']
160/30:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/31: fin
160/32:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/33:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  print(tmp['ID-'])
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/34:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  print(tmp['ID-'])
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/35:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      print(l)
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/36:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      print(tmp['SLP-'][l])
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/37:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      print(np.min(tmp['SLP-'][l]))
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/38:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      print(np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))
      if ((len(tmp['ID-'][l])>12) & ((np.min(tmp['SLP-'][l])-np.max(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/39:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5)):
          print('yes')
          for x in savings:
              fin[x].append(tmp[x][l])
160/40: fin
160/41: fin['dates-']
160/42: fin['dates-'][0]
160/43:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/44: len(fin['ID-'])
160/45:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/46: len(fin['ID-'])
160/47:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<995)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/48: len(fin['ID-'])
160/49:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/50: len(fin['ID-'])
160/51: import matplotlib
160/52:
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
160/53: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
160/54: ax=axes
160/55: ax.coastlines()
160/56:
pltlat = np.linspace(0,90,226)[70:121]
pltlon = np.linspace(-180,180,901)[440:541]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]
160/57:
for k in range(len(fin['ID-'])):
    ax.plot(fin['lon-'][k],fin['lat-'][k])
160/58: fig.show()
160/59: fig.close()
160/60: plt.close('all')
160/61:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    if k%12==11:
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
160/62: fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
160/63:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    if k%12==11:
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
        plt.close('all')
160/64: fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
160/65: plt.close('all')
160/66: ls -lrt *.png
160/67:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    if k%12==11:
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
        plt.close('all')
160/68: fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
160/69: plt.close('all')
160/70:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    mit = np.where(fin['SLP-'][k]==np.min(fin['SLP-'][k]))[0][-1]
    ax.scatter(fin['lon-'][k][mit],fin['lat-'][k][mit])
    if ((k%12==11) | (k==len(fin['ID-'])-1)):
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
        plt.close('all')
160/71:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
        dlon = tmp['lon-'][l][1:]-tmp['lon-'][l][:-1]
        dlat = tmp['lat-'][l][1:]-tmp['lat-'][l][:-1]
        
        r = np.sqrt(dlon**2 + dlat**2)
        if (~np.any(r>3.5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/72: len(fin['ID-'])
160/73:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    mit = np.where(fin['SLP-'][k]==np.min(fin['SLP-'][k]))[0][-1]
    ax.scatter(fin['lon-'][k][mit],fin['lat-'][k][mit])
    if ((k%12==11) | (k==len(fin['ID-'])-1)):
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
        plt.close('all')
160/74:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
        dlon = tmp['lon-'][l][1:]-tmp['lon-'][l][:-1]
        dlat = tmp['lat-'][l][1:]-tmp['lat-'][l][:-1]
        
        r = np.sqrt(dlon**2 + dlat**2)
        if (~np.any(r>4)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/75: len(fin['ID-'])
160/76:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
        dlon = tmp['lon-'][l][1:]-tmp['lon-'][l][:-1]
        dlat = tmp['lat-'][l][1:]-tmp['lat-'][l][:-1]
        
        r = np.sqrt(dlon**2 + dlat**2)
        if (~np.any(r>5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/77: len(fin['ID-'])
160/78:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2020):
  tmp = dict()
  for x in savings:
    f = open(x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1000)):
        dlon = tmp['lon-'][l][1:]-tmp['lon-'][l][:-1]
        dlat = tmp['lat-'][l][1:]-tmp['lat-'][l][:-1]
        
        r = np.sqrt(dlon**2 + dlat**2)
        if (~np.any(r>4.5)):
          for x in savings:
              fin[x].append(tmp[x][l])
160/79: len(fin['ID-'])
160/80:
a =0
for k in range(len(fin['ID-'])):
    if k%12==0:
        a +=1
        fig, ax= plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
        
    ax.plot(fin['lon-'][k],fin['lat-'][k])
    mit = np.where(fin['SLP-'][k]==np.min(fin['SLP-'][k]))[0][-1]
    ax.scatter(fin['lon-'][k][mit],fin['lat-'][k][mit])
    if ((k%12==11) | (k==len(fin['ID-'])-1)):
        lonticks=np.arange(minpltlonc, maxpltlonc,5)
        latticks=np.arange(minpltlatc, maxpltlatc,5)

        ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
        ax.set_yticks(latticks, crs=ccrs.PlateCarree());
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)

        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
        
        fig.savefig('further-sel-tracks-%02d.png'%a,dpi=300,bbox_inches="tight")
        plt.close('all')
160/81:
for x in savings:
    f = open(x + 'furthersel.txt',"wb")
    pickle.dump(f,fin[x])
    f.close()
160/82:
for x in savings:
    f = open(x + 'furthersel.txt',"wb")
    pickle.dump(fin[x],f)
    f.close()
160/83: fin[x]
160/84: savings
160/85: ls -lrt *.txt
160/86: savings[0][:-4]
160/87: savings[0][:4]
160/88: savings[0][:3]
160/89: savings[0][:-1]
160/90: test1 = []
160/91: test2 = []
160/92: var = [test1,test2]
160/93: var[0] = np.zeros(100)
160/94: test1
160/95: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/further-select.py 1-999
161/1: import numpy as np
161/2: import pickle
161/3: f = open('../dates-2008.txt',"wb")
161/4: dates = pickle.load(f)
161/5: f = open('../dates-2008.txt',"rb")
161/6: dates = pickle.load(f)
161/7: less ../dates-2008.txt
162/1: import numpy as np
162/2: import pickle
162/3: f = open("dates-2008","rb")
162/4: f = open("dates-2008.txt","rb")
162/5: dates = pickle.load(f)
162/6: f.close()
162/7: dates
163/1: import numpy as np
163/2: np.floor(724/24)
163/3: fdate = 'fi_198004'
163/4: np.floor(617.0/24)
163/5: 617%24
164/1:
import numpy as np
import sys
import os
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'

name = 'traend-'
164/2:
for d in os.listdir(p):
  if (d.startswith('trastart-mature')):
      date = d[-25:-14]
      print(date)
164/3: ls -lrt *.txt
164/4:
for d in os.listdir(p):
  if (d.startswith('trastart-mature')):
      date = d[16:26]
      print(date)
164/5:
for d in os.listdir(p):
  if (d.startswith('trastart-mature')):
      date = d[16:27]
      print(date)
165/1: import numpy as np
165/2: import pickle
165/3: f = open('dates-Manos.txt','rb')
165/4: dates = pickle.load(f0)
165/5: dates = pickle.load(f)
165/6: f.close()
165/7: dates
166/1: import numpy as np
166/2: import pickle
166/3: f = open('dates-Manos.txt','rb')
166/4: dates = pickle.load(f)
166/5: f.close()
166/6: dates
166/7: ls traced-vars-201609*
166/8: rm traced-vars-20160903_12-ID-496648.txt
166/9: rm trajectories-mature-20160903_12-ID-496648.txt
166/10: import sys
166/11: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
166/12: import helper
166/13: labs = helper.traced_vars_ERA5()
166/14: labs
167/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle

parser = argparse.ArgumentParser(description="plot accumulated average PV gain that is associated with the cyclone and the environment")
parser.add_argument('rdis',default='',type=int,help='distance from center in km that should be considered as cyclonic')
args = parser.parse_args()

p = '/atmosdyn2/ascherrmann/009-ERA-5/'

traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

fsl=4

f = open(p + 'lats-Manos.txt','rb')
clat = pickle.load(f)
f.close()

f = open(p + 'lons-Manos.txt','rb')
clon = pickle.load(f)
f.close()

f = open(p + 'dates-Manos.txt','rb')
dates = pickle.load(f)
f.close()

labs = helper.traced_vars_ERA5()


#cl=['k','orange','green','dodgerblue','blue','red']
#pllegend = ['cyc','env','TOT','CONVT + TURBT, |CONV|>|TURB|','TURBT + CONVT, |TURB|>|CONV|', 'CONVM', 'TURBM','RAD','LS']
#plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRLS']

ptitle = np.array(['700 hPa < P$_{0}$', 'P$_{0} <$ 700 hPa', '400 < P$_{-48} <$ 600 hPa',  'P$_{-48} <$ 400 hPa'])
linestyle = ['-',':']

LON=np.linspace(-120,30,301)
LAT=np.linspace(-20,90,221)

rdis = int(args.rdis)
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

### INFO
### Trajetories start 200km around the center between 925 and 600 hPa if PV>0.6 PVU
###

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]
167/2:
datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 47
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,0.5])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
167/3:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
167/4:
p = '/atmosdyn2/ascherrmann/009-ERA-5/'

traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

fsl=4

f = open(p + 'lats-Manos.txt','rb')
clat = pickle.load(f)
f.close()

f = open(p + 'lons-Manos.txt','rb')
clon = pickle.load(f)
f.close()

f = open(p + 'dates-Manos.txt','rb')
dates = pickle.load(f)
f.close()

labs = helper.traced_vars_ERA5()


#cl=['k','orange','green','dodgerblue','blue','red']
#pllegend = ['cyc','env','TOT','CONVT + TURBT, |CONV|>|TURB|','TURBT + CONVT, |TURB|>|CONV|', 'CONVM', 'TURBM','RAD','LS']
#plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRLS']

ptitle = np.array(['700 hPa < P$_{0}$', 'P$_{0} <$ 700 hPa', '400 < P$_{-48} <$ 600 hPa',  'P$_{-48} <$ 400 hPa'])
linestyle = ['-',':']

LON=np.linspace(-120,30,301)
LAT=np.linspace(-20,90,221)

rdis = int(args.rdis)
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

### INFO
### Trajetories start 200km around the center between 925 and 600 hPa if PV>0.6 PVU
###

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]
167/5:
p = '/atmosdyn2/ascherrmann/009-ERA-5/'

traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

fsl=4

f = open(p + 'lats-Manos.txt','rb')
clat = pickle.load(f)
f.close()

f = open(p + 'lons-Manos.txt','rb')
clon = pickle.load(f)
f.close()

f = open(p + 'dates-Manos.txt','rb')
dates = pickle.load(f)
f.close()

labs = helper.traced_vars_ERA5()


#cl=['k','orange','green','dodgerblue','blue','red']
#pllegend = ['cyc','env','TOT','CONVT + TURBT, |CONV|>|TURB|','TURBT + CONVT, |TURB|>|CONV|', 'CONVM', 'TURBM','RAD','LS']
#plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRLS']

ptitle = np.array(['700 hPa < P$_{0}$', 'P$_{0} <$ 700 hPa', '400 < P$_{-48} <$ 600 hPa',  'P$_{-48} <$ 400 hPa'])
linestyle = ['-',':']

LON=np.linspace(-120,30,301)
LAT=np.linspace(-20,90,221)
167/6: rdis=400
167/7:
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

### INFO
### Trajetories start 200km around the center between 925 and 600 hPa if PV>0.6 PVU
###

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]
167/8:
datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 47
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,0.5])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
167/9:
for uyt, txt in enumerate(traced[:1]):
    cycID=txt[-10:-4]
    date=txt[-25:-14]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[cycID]=dict() #raw data
    dipv[cycID]=dict()    #accumulated pv is saved here
    dipv[cycID][env]=dict()
    dipv[cycID][cyc]=dict()

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[cycID][el] = tt[:,k].reshape(-1,H+1)

    tmpclon= np.array([])
    tmpclat= np.array([])

    ### follow cyclone backwards to find its center
    dit[cycID] = dict()
    dit[cycID][env] = np.zeros(datadi[cycID]['time'].shape)
    dit[cycID][cyc] = np.zeros(datadi[cycID]['time'].shape)

    for k in range(0,H+1):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]

        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)


        if(np.where((dates[uyt]==Date))[0].size):
            tmpq = np.where((dates[uyt]==Date))[0][0]
            hh-=1
            tmpclon = np.append(tmpclon,np.mean(clon[uyt][tmpq]))
            tmpclat = np.append(tmpclat,np.mean(clat[uyt][tmpq]))
        else:
            ### use boundary position that no traj should be near it
            tmpclon = np.append(tmpclon,300)
            tmpclat = np.append(tmpclat,0)
    for e, h in enumerate(datadi[cycID]['time'][0,:]):
        tmplon = tmpclon[e].astype(int)
        tmplat = tmpclat[e].astype(int)
        ### center lon and latitude
        CLON = LON[tmplon]
        CLAT = LAT[tmplat]

        ### 30.10.2020 radial distance instead of square
        ### if traj is in circle of 200km set cyc entry to 0, else env entry 1
        for tr in range(len(datadi[cycID]['time'])):
            if ( np.sqrt( (CLON-datadi[cycID]['lon'][tr,e])**2 + (CLAT-datadi[cycID]['lat'][tr,e])**2) <=  deltaLONLAT):
            ###
                dit[cycID][cyc][tr,e]=1
            else:
                dit[cycID][env][tr,e]=1
    deltaPV = np.zeros(datadi[cycID]['time'].shape)
    deltaPV[:,1:] = datadi[cycID]['PV'][:,:-1]-datadi[cycID]['PV'][:,1:]
167/10: deltaPV
167/11: datadi[cycID]['PV']
167/12: less Manos-test/traced-vars-20160904_10-ID-496748.txt
168/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
168/2:
p = '/atmosdyn2/ascherrmann/009-ERA-5/'

traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('traced-vars-')):
            traced = np.append(traced,d)
traced = np.sort(traced)

fsl=4

f = open(p + 'lats-Manos.txt','rb')
clat = pickle.load(f)
f.close()

f = open(p + 'lons-Manos.txt','rb')
clon = pickle.load(f)
f.close()

f = open(p + 'dates-Manos.txt','rb')
dates = pickle.load(f)
f.close()

labs = helper.traced_vars_ERA5()


#cl=['k','orange','green','dodgerblue','blue','red']
#pllegend = ['cyc','env','TOT','CONVT + TURBT, |CONV|>|TURB|','TURBT + CONVT, |TURB|>|CONV|', 'CONVM', 'TURBM','RAD','LS']
#plotvars = ['APVTOT','PVR-T','PVRCONVM','PVRTURBM','APVRAD','PVRLS']

ptitle = np.array(['700 hPa < P$_{0}$', 'P$_{0} <$ 700 hPa', '400 < P$_{-48} <$ 600 hPa',  'P$_{-48} <$ 400 hPa'])
linestyle = ['-',':']

LON=np.linspace(-120,30,301)
LAT=np.linspace(-20,90,221)

rdis = int(args.rdis)
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

### INFO
### Trajetories start 200km around the center between 925 and 600 hPa if PV>0.6 PVU
###

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]
168/3: rdis = 400
168/4:
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

### INFO
### Trajetories start 200km around the center between 925 and 600 hPa if PV>0.6 PVU
###

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 47
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,0.5])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
168/5:
for uyt, txt in enumerate(traced[:1]):
    cycID=txt[-10:-4]
    date=txt[-25:-14]
    yyyy = int(date[0:4])
    MM = int(date[4:6])
    DD = int(date[6:8])
    hh = int(date[9:])

    datadi[cycID]=dict() #raw data
    dipv[cycID]=dict()    #accumulated pv is saved here
    dipv[cycID][env]=dict()
    dipv[cycID][cyc]=dict()

    tt = np.loadtxt(p + txt)
    for k, el in enumerate(labs):
        datadi[cycID][el] = tt[:,k].reshape(-1,H+1)

    tmpclon= np.array([])
    tmpclat= np.array([])

    ### follow cyclone backwards to find its center
    dit[cycID] = dict()
    dit[cycID][env] = np.zeros(datadi[cycID]['time'].shape)
    dit[cycID][cyc] = np.zeros(datadi[cycID]['time'].shape)

    for k in range(0,H+1):
        if (hh<0):
            hh=23
            DD-=1
            if(DD<1):
                MM-=1
                DD=helper.month_days(yyyy)[int(MM)-1]

        Date=str(yyyy)+'%02d%02d_%02d'%(MM,DD,hh)


        if(np.where((dates[uyt]==Date))[0].size):
            tmpq = np.where((dates[uyt]==Date))[0][0]
            hh-=1
            tmpclon = np.append(tmpclon,np.mean(clon[uyt][tmpq]))
            tmpclat = np.append(tmpclat,np.mean(clat[uyt][tmpq]))
        else:
            ### use boundary position that no traj should be near it
            tmpclon = np.append(tmpclon,300)
            tmpclat = np.append(tmpclat,0)
    ### check every hours every trajecttory whether it is close to the center ###


    for e, h in enumerate(datadi[cycID]['time'][0,:]):
        tmplon = tmpclon[e].astype(int)
        tmplat = tmpclat[e].astype(int)
        ### center lon and latitude
        CLON = LON[tmplon]
        CLAT = LAT[tmplat]

        ### 30.10.2020 radial distance instead of square
        ### if traj is in circle of 200km set cyc entry to 0, else env entry 1
        for tr in range(len(datadi[cycID]['time'])):
            if ( np.sqrt( (CLON-datadi[cycID]['lon'][tr,e])**2 + (CLAT-datadi[cycID]['lat'][tr,e])**2) <=  deltaLONLAT):
            ###
                dit[cycID][cyc][tr,e]=1
            else:
                dit[cycID][env][tr,e]=1
168/6: datadi[cycID]['PV']
168/7: datadi[cycID]['PV'][:,1:]
168/8: datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:]
168/9: deltaPV
168/10: deltaPV = np.zeros(datadi[cycID]['time'].shape)
168/11: deltaPV[:,1:-1:] = datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:]
168/12: deltaPV
168/13: cycID
169/1: import numpy as np
169/2: import os
169/3:
test = np.array([])
for d in os.listdir('./'):
    if (d.startswith('trastart-mature')):
        test = np.append(test,d)
169/4: test = np.sort(test)
169/5:
for k in test[:1]:
    d = np.loadtxt(k)
    data = np.zeros((len(d[:,0]),4))
    data[:,1:] = d
169/6: data
169/7:
for k in test[:]:
    d = np.loadtxt(k)
    data = np.zeros((len(d[:,0]),4))
    data[:,1:] = d
    np.savetxt(d,data,fmt='%f',delimiter=' ',newline='\n')
169/8:
for k in test[:]:
    d = np.loadtxt(k)
    data = np.zeros((len(d[:,0]),4))
    data[:,1:] = d
    np.savetxt(k,data,fmt='%f',delimiter=' ',newline='\n')
169/9: k
169/10: d
169/11: d.shape
168/14: deltaPV
168/15: np.flip(np.cumsum(np.flip(deltaPV[:,1:-1]*dit[cycID][key][:,2:],axis=1),axis=1),axis=1)
168/16: deltaPV[:,1:-1:] = np.flip(np.cumsum(np.flip(datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:])))
168/17: deltaPV = np.zeros(datadi[cycID]['time'].shape)
168/18: deltaPV[:,1:-1:] = np.flip(np.cumsum(np.flip(datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:])))
168/19: deltaPV[:,1:-1] = np.flip(np.cumsum(np.flip(datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:])))
168/20: np.flip(np.cumsum(np.flip(datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:])))
168/21: deltaPV[:,1:-1] = np.flip(np.cumsum(np.flip(datadi[cycID]['PV'][:,1:-1]-datadi[cycID]['PV'][:,2:],axis=1),axis=1),axis=1)
168/22: deltaPV
170/1: import numpy as np
170/2: import pickle
170/3: p = '/atmosdyn2/ascherrmann/009-ERA-5/'
170/4:
f = open(p + 'dates-Manos.txt','rb')
dates = pickle.load(f)
f.close()
170/5: len(dates)
170/6: dates[:][-1]
170/7: dates[0:-1][-1]
170/8: dates[0:-1]
171/1: 1.5%0.5
171/2: import numpy as np
171/3: np.round(59.8,1)
171/4: np.round(59.8,0)
172/1: import numpy as np
172/2: import pickle
172/3: f = open('SLP-2005.txt',"rb")
172/4: SLP = pickle.load(f)
172/5: f.close()
172/6: f = open('dates-2005.txt',"rb")
172/7: dates = pickle.load(f)
172/8: f.close()
172/9: len(dates)
172/10:
for i in dates:
    for j in i:
        if int(j[4:6])==12:
            print(i)
            continue
172/11:
for i in dates:
    for j in i:
        if int(j[4:6])==12:
            if int(j[6:8])==5:
                print(i)
                break
172/12:
for i in dates:
    for j in i:
        if int(j[4:6])==12:
            if int(j[6:8])==5:
                print(i)
172/13:
for i in dates:
    for j in i:
        if int(j[4:6])==12:
            if int(j[6:8])==15:
                print(i)
172/14:
for i in dates:
    if i[0] =='20051212_10':
                print(i)
172/15: SLP
172/16:
for k,i in enumerate(dates):
    if i[0] =='20051212_10':
                print(i)
                print(SLP[k])
172/17: import matplotlib
172/18: f = open('lats-2005.txt',"rb")
172/19: f = open('lat-2005.txt',"rb")
172/20: lats = pickle.load(f)
172/21: f.close()
172/22: f = open('lon-2005.txt',"rb")
172/23: lons = pickle.load(f)
172/24: f.close()
172/25:
for k,i in enumerate(dates):
    if i[0] =='20051212_10':
                print(i)
                print(SLP[k])
                mlat = lats[k]
                mlon = lons[k]
172/26: fig, ax = plt.subplots()
172/27: from matplotlib import pyplot as plt
172/28: fig, ax = plt.subplots()
172/29: ax.plot(mlon,mlat)
172/30: fig.show()
172/31: plt.close('all')
172/32: fig, ax = plt.subplots()
172/33:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from colormaps import PV_cmap2
172/34: ax.coastlines()
172/35: plt.close('all')
172/36:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
172/37: ax.plot(mlon,mlat)
172/38: fig.show()
172/39: plt.close()
172/40: ls *ID*
172/41: ls *ID*Manos*.txt
172/42: ls *Manos*.txt
172/43: f = open('ID-2005.txt',"rb")
172/44: ID = pickle.load(f)
172/45: f.close()
172/46:
for k,i in enumerate(dates):
    if i[0] =='20051212_10':
                print(i)
                print(SLP[k])
                mlat = lats[k]
                mlon = lons[k]
                mID = ID[k]
172/47: ID
172/48: mID
172/49: ls *350393*
172/50: f = open('ID-2018.txt',"rb")
172/51: ID = pickle.load(f)
172/52: f.close()
172/53: f = open('lon-2018.txt',"rb")
172/54: lon = pickle.load(f)
172/55: f.close()
172/56: f = open('lat-2018.txt',"rb")
172/57: lat = pickle.load(f)
172/58: f.close()
172/59: f = open('SLP-2018.txt',"rb")
172/60: SLP = pickle.load(f)
172/61: f.close()
172/62: f = open('SLP-2005.txt',"rb")
172/63: SLP = pickle.load(f)
172/64: f.close()
172/65:
for k,i in enumerate(dates):
    if i[0] =='20051212_10':
                print(i)
                print(SLP[k])
                mlat = lats[k]
                mlon = lons[k]
                mID = ID[k]
                mSLP = SLP[k]
172/66:
for k,i in enumerate(dates):
    if i[0] =='20051212_10':
                mlat = lats[k]
                mlon = lons[k]
                mID = ID[k]
                mSLP = SLP[k]
                mdates = i
172/67: np.where(mSLP==np.min(mSLP))[0]
172/68: mdata = np.zeros((43,4))
172/69: mdata[:,0] = mlon[:43]
172/70: mdata[:,1] = mlat[:43]
172/71: mdata[:,2] = mSLP[:43]
172/72: mdata[:,3] = mdates
172/73: mdata[:,3] = mdates[:43]
172/74: mdata
172/75: mdata[:,3] = mID[:43]
172/76: mID
172/77:
mID = np.array([350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393., 350393., 350393., 350393., 350393., 350393., 350393.,
       350393.])
172/78: mdata[:,3] = mID[:43]
172/79: mdates[42]
172/80: np.savetxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/medicane-data-20051214_04.txt',mdata,fmt='%f',delimiter=' ',newline='\n')
172/81: f = open('SLP-2018.txt',"rb")
172/82: SLP = pickle.load(f)
172/83: f.close()
172/84: lat
172/85: len(ID)
172/86: len(lat)
172/87: len(SLP)
172/88: len(lon)
172/89: f = open('dates-2018.txt',"rb")
172/90: dates = pickle.load(f)
172/91: f.close()
172/92:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='12':
            if j[6:8] =='28':
                print(i)
                zlat = lats[k]
                zlon = lons[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/93:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='12':
            if j[6:8] =='28':
                print(i)
                zlat = lat[k]
                zlon = lon[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/94:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='12':
            if j[6:8] =='29':
                print(i)
                zlat = lat[k]
                zlon = lon[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/95:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='12':
            if j[6:8] =='28':
                print(i,k)
                zlat = lat[k]
                zlon = lon[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/96: k
172/97: i
172/98: plt.close('all')
172/99:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
172/100: ax.plot(zlon,zlat)
172/101: fig.show()
172/102: plt.close('all')
172/103: zlat
172/104: zlon
172/105:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='12':
            if j[6:8] =='31':
                print(i,k)
                zlat = lat[k]
                zlon = lon[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/106:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
172/107: ax.plot(zlon,zlat)
172/108: fig.show()
172/109:
for k,i in enumerate(dates):
    for j in i:
        if j[4:6]=='09':
            if j[6:8] =='28':
                print(i,k)
                zlat = lat[k]
                zlon = lon[k]
                zID = ID[k]
                zSLP = SLP[k]
                zdates = i
172/110:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
172/111: ax.plot(zlon,zlat)
172/112: fig.show()
172/113: np.where(zSLP==np.min(zSLP))
172/114: zdata = np.zeros((27,4))
172/115: zdata[:,0] = lon[:28]
172/116: zdata = np.zeros((28,4))
172/117: zdata[:,0] = lon[:28]
172/118: lon
172/119: zdata[:,0] = zlon[:28]
172/120: zdata[:,1] = zlat[:28]
172/121: zdata[:,2] = zSLP[:28]
172/122: zdata[:,3] = zID[:28]
172/123: zdates[28]
172/124: np.savetxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/medicane-zorbas-data-20180928_05.txt',zdata,fmt='%f',delimiter=' ',newline='\n')
173/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from matplotlib import cm
from scipy.stats.stats import pearsonr
import pickle

pt = '/atmosdyn2/ascherrmann/004-composite-analysis/'
add = 'MED-vort-entire-year3'

dates = np.loadtxt(pt + 'dates-' + add + '.txt',dtype=str)
htM = np.loadtxt(pt + 'htmaxzeta-' + add + '.txt', dtype=int)
relvort = np.loadtxt(pt + 'zeta' + add + '.txt',dtype=float)

maturestage = np.where(htM==0)[0]
relvort = relvort[maturestage]


sp = '/atmosdyn2/ascherrmann/006-year-traj/'
Lat = np.round(np.linspace(0,90,226),2)
Lon = np.round(np.linspace(-180,180,901),2)

pvival = np.array([-100,0.2,0.5,0.75,100])

anomaly = dict()
mature = dict()
layercounter = dict()
cycc =0

pinvals = np.arange(700,925.1,12.5)
plvlcounter = dict()




f = open(sp + 'mature-stages-pv-dict.txt',"rb")
mature = pickle.load(f)
f.close()
f = open(sp + 'pv-anomaly-dict.txt',"rb")
anomaly = pickle.load(f)
f.close()
f = open(sp + 'layer-count-dict.txt',"rb")
closecounter = pickle.load(f)
f.close()
f = open(sp + 'gridpv-dict.txt',"rb")
gridpv = pickle.load(f)
f.close()

f = open(sp + 'gridano-dict.txt',"rb")
gridano = pickle.load(f)
f.close()
173/2: gridano
173/3: Pintervals = np.append(np.append(np.arange(100,550,25),np.arange(550,700,15)),np.arange(700,925.1,12.5))
173/4:
clat = helper.radial_ids_around_center_calc(200)[1]
totanomaly = np.zeros(len(dates[maturestage]))
totPV = np.zeros(len(dates[maturestage]))
realano=np.zeros(len(dates[maturestage]))
for k,t in enumerate(dates[maturestage]):
    for l in range(len(clat)):
        for m in range(len(pinvals)-1):
            totPV[k] += mature[t][l,m]
            totanomaly[k] += anomaly[t][l,m]
            realano[k] += np.sum(gridano[t][invals[m]])
173/5:
clat = helper.radial_ids_around_center_calc(200)[1]
totanomaly = np.zeros(len(dates[maturestage]))
totPV = np.zeros(len(dates[maturestage]))
realano=np.zeros(len(dates[maturestage]))
for k,t in enumerate(dates[maturestage]):
    for l in range(len(clat)):
        for m in range(len(pinvals)-1):
            totPV[k] += mature[t][l,m]
            totanomaly[k] += anomaly[t][l,m]
            realano[k] += np.sum(gridano[t][pinvals[m]])
173/6:
order = np.argsort(relvort)
relvort2 = relvort[order]
totPV = totPV[order]
totanomaly = totanomaly[order]
173/7: realano = realano[order]
173/8:
fig, ax = plt.subplots()

ax.plot(relvort2,totPV,color='k')
ax.plot(relvort2,totanomaly,color='r')
ax.plot(relvort2,realano,color='g')
ax.set_xlabel(r'rel. vort. [$\times 10^{-4}$ s$^{-1}$]')
ax.set_ylabel('sumed PV [PVU]')

fig.savefig(sp + 'low-level-anomaly-pv.png',dpi=300,box_inches="tight")
plt.close('all')
173/9:
clat = helper.radial_ids_around_center_calc(200)[1]
totanomaly = np.zeros(len(dates[maturestage]))
totPV = np.zeros(len(dates[maturestage]))
realano=np.zeros(len(dates[maturestage]))
for k,t in enumerate(dates[maturestage]):
    for l in range(len(clat)):
        for m in range(len(pinvals)-1):
            totPV[k] += mature[t][l,m]
            totanomaly[k] += anomaly[t][l,m]
    for m in range(len(pinvals)-1):
        realano[k] += np.sum(gridano[t][pinvals[m]])
173/10:
fig, ax = plt.subplots()

ax.plot(relvort2,totPV,color='k')
ax.plot(relvort2,totanomaly,color='r')
ax.plot(relvort2,realano,color='g')
ax.set_xlabel(r'rel. vort. [$\times 10^{-4}$ s$^{-1}$]')
ax.set_ylabel('sumed PV [PVU]')

fig.savefig(sp + 'low-level-anomaly-pv.png',dpi=300,box_inches="tight")
plt.close('all')
173/11: realano = realano[order]
173/12:
fig, ax = plt.subplots()

ax.plot(relvort2,totPV,color='k')
ax.plot(relvort2,totanomaly,color='r')
ax.plot(relvort2,realano,color='g')
ax.set_xlabel(r'rel. vort. [$\times 10^{-4}$ s$^{-1}$]')
ax.set_ylabel('sumed PV [PVU]')

fig.savefig(sp + 'low-level-anomaly-pv.png',dpi=300,box_inches="tight")
plt.close('all')
173/13: gridano
173/14: gridpv
174/1: import numpy as np
174/2: import xarray as xr
174/3: oro = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
174/4: oro
174/5: oro.ZB
174/6: oro.ZB.values
174/7: oro.ZB.values.shape
174/8: oro.LSM.values.shape
174/9: oro.LSM.values
174/10: oro.LSM.values[0,0,0]
174/11: oro.LSM.values[0,0,181]
174/12: oro.ZB.values[0,0,181]
175/1: import numpy as np
175/2: np.linspace(-180,180,721)
175/3: np.linspace(-180,180,901)
175/4: from scipy.interpolate import RegularGridInterpolator
175/5:
def regrid(data, x, y):
    m= np.max(data.shape[0],data.shape[1])
    yy = np.linspace(0,1/m,data.shape[0])
    xx = np.linspace(0,1/m,data.shape[1])
    intf = RegularGridInterpolator((yy,xx),data)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))
175/6: import xarray as xr
175/7: data = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
175/8: z = data.ZB.values[0,0]
175/9: z
175/10: z.shape
175/11: nxew = 901
175/12: xnew = 901
175/13: ynew=226
175/14: z.shape
175/15: z = data.ZB.values[0,0,180:,:]
175/16: z.shape
175/17: data
175/18: np.linspace(-90,90,361)[180:]
175/19: z.shape
175/20: znew = regrid(z,xnew,ynew)
175/21: data.shape
175/22:
def regrid(oldd, x, y):
    m= np.max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),data)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))
175/23: znew = regrid(z,xnew,ynew)
175/24:
def regrid(oldd, x, y):
    print(oldd)
    m= np.max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),data)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))
175/25: znew = regrid(z,xnew,ynew)
175/26:
def regrid(oldd, x, y):
    print(oldd)
    m= max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),data)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))
175/27: znew = regrid(z,xnew,ynew)
175/28:
def regrid(oldd, x, y):
    print(oldd)
    m= max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),oldd)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))
175/29: znew = regrid(z,xnew,ynew)
175/30: znew
175/31: znew.shape
175/32: z
175/33: z = data.ZB.values[0,0,180:,:]
175/34: z
175/35: np.max(z,axis=1)
175/36: np.max(znew,axis=1)
175/37: import matplotlib
175/38: from matplotlib import pyplot as plt
175/39:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
#cartopy
import helper
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
175/40: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
175/41: ax = axes
175/42: ax.coastlines(zorder=0)
175/43: ax.contourf(np.linspace(-180,180,901),np.linspace(0,90,226),znew,levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/44: ax.contourf(np.linspace(-180,180,901),np.linspace(0,90,226),np.transpose(znew),levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/45: plt.show()
175/46: plt.close('all')
175/47: znew = regrid(z,ynew,xnew)
175/48: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
175/49: ax = axes
175/50: ax.contourf(np.linspace(-180,180,901),np.linspace(0,90,226),np.transpose(znew),levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/51: ax.coastlines(zorder=0)
175/52: ax.contourf(np.linspace(-180,180,901),np.linspace(0,90,226),znew,levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/53: fig.show()
175/54: plt.close('all')
175/55: fig, axes = plt.subplots(2, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
175/56: ax = axes[1]
175/57: ax.coastlines(zorder=0)
175/58: ax.contourf(np.linspace(-180,180,901),np.linspace(0,90,226),znew,levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/59: ax = axes[0]
175/60: ax.coastlines(zorder=0)
175/61: ax.contourf(np.linspace(-180,180,721),np.linspace(0,90,181),z,levels=np.arange(-300,6001,500),cmap=matplotlib.cm.jet,extend='both',norm=plt.Normalize(np.min(z),np.max(z),len(np.arange(-300,6001,500))))
175/62: fig.show()
175/63: import pickle
175/64: f = open('/atmosdyn2/ascherrmann/convert-ERA5-ZB-oro-to-IFS-resolution.txt',"wb")
175/65: pickle.dump(znew,f)
175/66: f.close()
175/67: land = data.LSM.values[0,0,180:,:]
175/68: newland = regrid(land,ynew,xnew)
175/69: newland[np.where((newland>0)&(newland<1))]
175/70: newland[np.where((newland>0)&(newland<1))] = np.round(newland[np.where((newland>0)&(newland<1))],0)
175/71: newland[np.where((newland>0)&(newland<1))]
175/72: f = open('/atmosdyn2/ascherrmann/convert-ERA5-LSM-to-IFS-resolution.txt',"wb")
175/73: pickle.dump(newland,f)
175/74: f.close()
175/75: import ecco_v4_py as ecco
175/76: dataset = xr.open_dataset('/atmosdyn/atroman/phd/FEB18/cdf/P20180210_10').load()
175/77: dataset
175/78: newdata.lat
175/79: dataset.lat
175/80: dataset.Coordinates
175/81: dataset.
175/82: dataset
175/83: cp
175/84: cp /atmosdyn/atroman/phd/FEB18/cdf/P20180210_10 .
175/85: ls
175/86: znew
175/87: landnew
175/88: newland
175/89: ds = xr.Dataset(data_vars=dict(bound=(['x','y','time'],znew)),coords=dict(lon=(['x','y'],np.linspace(-180,180,901))))
175/90:
ds = xr.Dataset(data_vars=dict(bound=(['x','y','time'],znew)),
coords=dict(
lon=(['x','y'],np.linspace(-180,180,901)),
lat=(['x','y'],np.linspace(0,90,226)),
time=10
))
175/91: ds
175/92:
ds = xr.Dataset(data_vars=dict(bound=(['x','y','time'],znew)),
coords=dict(
lon=(['x','y'],np.linspace(-180,180,901)),
lat=(['x','y'],np.linspace(0,90,226)),
time=10
))
175/93: ds
175/94:
ds = xr.Dataset(data_vars=dict(znew=(['x','y','time'],znew)),
coords=dict(
lon=(['x','y'],np.linspace(-180,180,901)),
lat=(['x','y'],np.linspace(0,90,226)),
time=10.
))
175/95:
ds = xr.Dataset(data_vars=dict(znew=(['x','y'],znew)),
coords=dict(
lon=(['x','y'],np.linspace(-180,180,901)),
lat=(['x','y'],np.linspace(0,90,226)),
))
175/96: ds
175/97:
ds = xr.Dataset(data_vars=dict(znew=(['x','y'],znew)),
coords=dict(
lon=(['x','y'],np.meshgrid(np.linspace(-180,180,901),np.linspace(0,90,226))[1]),
lat=(['x','y'],np.meshgrid(np.linspace(-180,180,901),np.linspace(0,90,226))[0]),
))
175/98: ds
175/99: ds.znew
175/100: ds.znew.values
175/101: ds.znew.values.shape
175/102: dataset
175/103: ds
175/104: ds
175/105:
ds = xr.Dataset(data_vars=dict(znew=(['time','lev2','lat','lon'],znew)),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
time=(['time'],np.array([0]))
))
175/106: ds
175/107:
ds = xr.Dataset(data_vars=dict(znew=(['lat','lon'],znew)),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
))
175/108: ds
175/109: ds.znew.values.shape
175/110:
ds = xr.Dataset(data_vars=dict(znew=(['lat','lon'],znew),newland=(['lat','lon'],newland)),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
))
175/111: ds
175/112:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],znew),OL=(['lat','lon'],newland)),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
))
175/113: ds
175/114:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],znew.astype(float32)),OL=(['lat','lon'],newland.astype(float32))),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
))
175/115:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],np.float32(znew)),OL=(['lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.linspace(-180,180,901)),
lat=(['lat'],np.linspace(0,90,226)),
))
175/116: ds
175/117:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],np.float32(znew)),OL=(['lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
175/118: ds
175/119: ds.to_netcdf('test123',mode='w')
175/120: pwd
175/121: %save -r saveboundarylayer-interpolation.py 1-999
176/1:
import numpy as np
from scipy.interpolate import RegularGridInterpolator
import xarray as xr
data = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
z = data.ZB.values[0,0,180:,:]
def regrid(oldd, x, y):
    m= max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),oldd)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))

znew = regrid(z,xnew,ynew)
176/2: xnew=226
176/3: ynew=901
176/4:
import numpy as np
from scipy.interpolate import RegularGridInterpolator
import xarray as xr
data = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
z = data.ZB.values[0,0,180:,:]
def regrid(oldd, x, y):
    m= max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),oldd)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))

znew = regrid(z,xnew,ynew)
176/5: znew.shape
176/6: import xarray as xr
176/7: dataset = xr.open_dataset('/atmosdyn/atroman/phd/FEB18/cdf/P20180210_10')
176/8: dataset
176/9: dataset.data_vars
176/10: dataset.Q.values
176/11: dataset.Q.values.shape
176/12: dataset.data_vars
176/13: dataset.coords
176/14: dataset.coords.time
176/15: dataset.coords[0]
176/16: dataset.coords
176/17: dataset.coords[time]
176/18: dataset.coords
176/19: dataset.time
176/20: ds
176/21:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],np.float32(znew)),OL=(['lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
176/22:
land = data.LSM.values[0,0,180:,:]
newland = regrid(land,ynew,xnew)
newland[np.where((newland>0)&(newland<1))] = np.round(newland[np.where((newland>0)&(newland<1))],0)
176/23:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],np.float32(znew)),OL=(['lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
176/24: ds
176/25: newland = regrid(land,xnew,ynew)
176/26:
ds = xr.Dataset(data_vars=dict(ZB=(['lat','lon'],np.float32(znew)),OL=(['lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
176/27: ds
176/28: dataset
176/29: dataset.attributes
176/30: dataset.attre
176/31: dataset.attr
176/32: dataset.attrs
176/33: test = xr.load_dataset('/atmosdyn/atroman/phd/FEB18/cdf/P20180210_10')
176/34: test
176/35: test.Q
176/36: dataset
176/37: dataset.PS.values[:,0,0,0]
176/38: dataset.PS.values.shape
176/39: dataset.PS.values
176/40: ds
176/41:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],np.float32(znew)),OL=(['time','lev2','lat','lon'],np.float32(newland))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
176/42:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
176/43: ds
176/44: ds.ZB.values.shape
176/45: pwd
176/46: ls
176/47: ds.to_netcdf('P20180210_10',mode='a')
176/48: newds = xr.open_dataset('P20180210_10')
176/49: newds
176/50: oro = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
176/51: oro
176/52: ds.to_netcdf('OROIFS',mode='w')
176/53: ls
176/54: %save -r saveboundarylayer-interpolation.py 1-999
177/1:
xnew=226
ynew=901
import numpy as np
from scipy.interpolate import RegularGridInterpolator
import xarray as xr
data = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
z = data.ZB.values[0,0,180:,:]
def regrid(oldd, x, y):
    m= max(oldd.shape[0],oldd.shape[1])
    yy = np.linspace(0,1/m,oldd.shape[0])
    xx = np.linspace(0,1/m,oldd.shape[1])
    intf = RegularGridInterpolator((yy,xx),oldd)
    yv,xv = np.meshgrid(np.linspace(0,1/m,y),np.linspace(0,1/m,x))
    return intf((xv,yv))

znew = regrid(z,xnew,ynew)
dataset = xr.open_dataset('/atmosdyn/atroman/phd/FEB18/cdf/P20180210_10')
land = data.LSM.values[0,0,180:,:]
newland = regrid(land,xnew,ynew)
newland[np.where((newland>0)&(newland<1))] = np.round(newland[np.where((newland>0)&(newland<1))],0)
177/2: dataset
177/3: dataset.PS
177/4: dataset.tevr
177/5: dataset
177/6: ds
177/7: dataset.shape
177/8: dataset[0]
177/9: dataset['PS']
177/10: dataset['PS'].attrs
177/11: dataset['PS'].attrs['long_name']
177/12:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
))
177/13: ds
177/14: xarray.Dataarray
177/15: xr.DataArray
177/16:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict
(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
)
attrs=dict
(center='European Center for Medium-Range Weather Forecasts'
)
)
177/17:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
)
attrs=dict(
center='European Center for Medium-Range Weather Forecasts'
)
)
177/18:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
),
attrs=dict(
center='European Center for Medium-Range Weather Forecasts'
)
)
177/19: ds
177/20: dataset['PS'].attrs['long_name']
177/21: dataset['PS'].attrs
177/22: dataset.attrs
177/23:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict
(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
)
attrs=dict
(center='European Center for Medium-Range Weather Forecasts',
    long_name='Local surface height, boundary layer',
    units='m',
    level=1.0,
    xmin=-180.0,
    xmax=180.0,
    xstag=0.0,
    ymin=0.0,
    ymax=90,
    ystag=0,
    zmin=1050,
    zmax=0.0,
    zstag=-0.5,
    missing_data=-999.99
)
)
177/24:
ds = xr.Dataset(data_vars=dict(ZB=(['time','lev2','lat','lon'],
np.array( [ np.array( [ np.float32(znew) ]) ])),OL=(['time','lev2','lat','lon'],np.array([np.array([np.float32(newland)])]))),
coords=dict
(
lon=(['lon'],np.float32(np.linspace(-180,180,901))),
lat=(['lat'],np.float32(np.linspace(0,90,226))),
),
attrs=dict
(center='European Center for Medium-Range Weather Forecasts',
    long_name='Local surface height, boundary layer',
    units='m',
    level=1.0,
    xmin=-180.0,
    xmax=180.0,
    xstag=0.0,
    ymin=0.0,
    ymax=90,
    ystag=0,
    zmin=1050,
    zmax=0.0,
    zstag=-0.5,
    missing_data=-999.99
)
)
177/25: ds
177/26: ds.ZB
177/27: dataset.PS
177/28: dataset['PS']
177/29: dataset['ZB']=dataset['PS']
177/30: dataset['ZB']
177/31: dataset['ZB'].attrs
177/32: dataset['ZB'].attrs['long_name']
177/33: dataset['ZB'].attrs['long_name']='Local surface height, boundary layer'
177/34: dataset['ZB'].attrs['units']='m'
177/35: dataset['ZB'].values = np.array( [ np.array( [ np.float32(znew) ]) ])
177/36: dataset['OL']=dataset['PS']
177/37: dataset['OL'].values = np.array( [ np.array( [ np.float32(newland) ]) ])
177/38: dataset['OL'].attrs['units']='binary'
177/39: dataset['OL'].attrs['long_name']='Land sea mask'
177/40: dataset.to_netcdf('IFSOROTEST',mode='w')
177/41: dataset.drop('Q')
177/42: dataset.drop(['RWC','LWC'])
177/43: ds = dataset.drop(['Q','IWC','SWC',RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti,'tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/44: ds = dataset.drop(['Q','IWC','SWC',RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix'])#,'tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti,'tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/45: ds = dataset.drop(['Q','IWC','SWC',RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix'])
177/46: ds = dataset.drop(['Q','IWC','SWC','RWC'])
177/47: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti,'tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/48: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw'])#,'tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti,'tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/49: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/50: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/51: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts'])#,'tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/52: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tvf','tevc'])#,'tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/53: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw'])#,'tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/54: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw'])#,'tlw','tmix','tconv','tcond','tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/55: dataset
177/56: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond'])#,'tdep','tvf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/57: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])
177/58: ds
177/59: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','PS','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','udotconv','vdotconv','udotmix','vdotmix','tls','tce','trime'])
177/60: ds
177/61: ds.to_netcdf('IFSORO','w')
177/62: %save -r saveboundarylayer-interpolation.py 1-999
178/1: import numpy as np
178/2: d = np.loadtxt('/atmosdyn/atroman/phd/FEB18/cyclones/TRACKED_CYCLONES')
178/3: d = np.loadtxt('/atmosdyn/atroman/phd/FEB18/cyclones/TRACKED_CYCLONES',skiprows=1)
178/4: IDS = np.unique(d[:,1])
178/5:
for ids in IDS[:1]:
    cappear=np.where(d[:,1]==ids)
    hours = np.zeros(len(cappear))
    for wr,u in enumerate(cappear):
        tmp = d[u]
        hours[wr] = tmp[0]
    print(hours)
178/6:
for ids in IDS[:1]:
    cappear=np.where(d[:,1]==ids)[0]
    hours = np.zeros(len(cappear))
    for wr,u in enumerate(cappear):
        tmp = d[u]
        hours[wr] = tmp[0]
    print(hours)
179/1: import numpy as np
179/2: import pikcle
179/3: import pickle
179/4: f = open('/atmosdyn2/ascherrmann/010-IFS/data/APR18/All-CYC-entire-yearAPR18.txt','rb')
179/5: data = pickle.load(f)
179/6: f.close()
179/7: data
179/8: data.dates
179/9: data.APR18
179/10: data.keys
179/11: data.keys()
179/12: data['APR18']
179/13: data['APR18'].keys()
179/14:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
#cartopy
import helper
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
179/15:
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
fig, ax = plt.subplots(1,1,subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k in data['APR18'].keys():
    lat = np.array([])
    lon = np.array([])
    for u in range(len(data['APR18'][k]['clat'])):
        lat = np.append(lat,np.mean(data['APR18'][k]['clat'][u]).astype(int))
        lon = np.append(lon,np.mean(data['APR18'][k]['clon'][u]).astype(int))
    ax.plot(LON[lon],LAT[lat])
179/16: lon
179/17:
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
fig, ax = plt.subplots(1,1,subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for k in data['APR18'].keys():
    lat = np.array([])
    lon = np.array([])
    for u in range(len(data['APR18'][k]['clat'])):
        lat = np.append(lat,np.mean(data['APR18'][k]['clat'][u]))
        lon = np.append(lon,np.mean(data['APR18'][k]['clon'][u]))
    ax.plot(LON[lon.astype(int)],LAT[lat.astype(int)])
179/18: fig.show()
180/1: import numpy as np
180/2: import pickle
180/3: ls
180/4: cd /atmosdyn2/ascherrmann/010-IFS/data/
180/5: ls
180/6: import os
180/7: os.listdir()
180/8: rm nohup.out
180/9:
for k in os.listdir():
    cd k
180/10:
for k in os.listdir():
    os.changedir(k)
    print(k)
    os.changedir('../')
180/11:
for k in os.listdir():
    os.chdir(k)
    print(k)
    os.chdir('../')
180/12: fulldata = dict()
180/13:
for k in os.listdir():
    f = open(k + '/All-CYC-entire-year' + k + '.txt','rb')
    tmp = pickle.load(f)
    f.close()
    fulldata[k] = tmp[k]
180/14: k
180/15: fulldata[k].keys()
180/16:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
#raphaels modules
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2

import matplotlib
#cartopy
import helper
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
for k in fulldata.keys():
    for l in fulldata[k].keys():
        lat = np.array([])
        lon = np.array([])
        for n in range(len(fulldata[k][l]['clat'])):
            lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
            lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
        axes.plot(lon,lat)
180/17: fig.show()
180/18: plt.close('all')
180/19: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
180/20: ax.coastlines()
180/21: axes.coastlines()
180/22:
for k in fulldata.keys():
    for l in fulldata[k].keys():
        lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/23:
for k in fulldata.keys():
    for l in fulldata[k].keys():
         lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/24: fig.show()
180/25: plt.close('all')
180/26: fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
180/27: axes.coastlines()
180/28:
for k in fulldata.keys():
    for l in fulldata[k].keys():
        if fulldata[k][l]['label']==2:
         lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/29: fig.show()
180/30:
counter=0
for k in fulldata.keys():
    for l in fulldata[k].keys():
        if fulldata[k][l]['label']==2:
         counter+=1
         lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/31: counter
180/32: fig.show()
180/33:
counter=0
plt.close('all')
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
axes.coastlines()
for k in fulldata.keys():
    for l in fulldata[k].keys():
        if fulldata[k][l]['label']==0:
         counter+=1
         lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/34: fig.show()
180/35:
counter=0
plt.close('all')
fig, axes = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
axes.coastlines()
for k in fulldata.keys():
    for l in fulldata[k].keys():
        if fulldata[k][l]['label']==1:
         counter+=1
         lat = np.array([])
         lon = np.array([])
         for n in range(len(fulldata[k][l]['clat'])):
             lat = np.append(lat,LAT[np.mean(fulldata[k][l]['clat'][n]).astype(int)])
             lon = np.append(lon,LON[np.mean(fulldata[k][l]['clon'][n]).astype(int)])
         axes.plot(lon,lat)
180/36: fig.show()
180/37: ls
180/38: f = open('All-CYC-entire-year.txt','wb')
180/39: pickle.dump(fulldata,f)
180/40: f.close()
180/41: MONTHS = ['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18']
180/42: MOT='NOV18'
180/43: np.where(MONTHS==MOT)[0][0]
180/44: np.where(MONTHS==MOT)[0]
180/45: np.where(MONTHS==MOT)
180/46: MONTHS = np.array(['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18'])
180/47: np.where(MONTHS==MOT)
180/48: np.where(MONTHS==MOT)[0]
180/49: np.where(MONTHS==MOT)[0][0]
180/50: np.where(MONTHS==MOT)[0][0]+1
180/51: MONTHN = np.append(12,np.arange(1,12))
180/52: MONTHN[np.where(MONTHS==MOT)[0][0]+1]
180/53: MONTHN[np.where(MONTHS==MOT)[0][0]]
180/54: MONTHN[np.where(MONTHS==MOT)[0][0]]
180/55: counter
180/56: less /atmosdyn2/ascherrmann/scripts/helper.py
181/1: import xarray as xr
181/2: import numpy as np
181/3: data = xr.open_dataset('/net/litho/atmosdyn/wernlih/ace/cdf/ORO')
181/4: dataset = xr.open_dataset('/atmosdyn/era5/cdf/2000/05/P20000510_10')
181/5: dataset
181/6: data
181/7: data.ZB.values
181/8: data.ZB.values.shape
181/9: dataset.U
181/10: dataset.V
181/11: dataset.PS
181/12: dataset['ZB'] = dataset['PS']
181/13: dataset['OL'] = dataset['PS']
181/14: dataset['OL'].values = data.LSM.values
181/15: test = np.array([np.array([np.zeros(361,721)])])
181/16: test = np.array([np.array([np.zeros((361,721))])])
181/17: test[0,0,:,:-1] = data.LSM.values
181/18: data.LSM.values.shape
181/19: data.ZB.values.shape
181/20: dataset['OL'].values = data.LSM.values[0,:,:,:-1]
181/21: dataset['ZB'].values = data.ZB.values[0,:,:,:-1]
181/22: dataset.OL
181/23: dataset.OL.attr
181/24: dataset.OL.attrs
181/25: dataset.OL.attrs['long_name'] = 'Land sea mask'
181/26: dataset.OL.attrs['units'] = 'binary'
181/27: dataset.ZB.attrs['units'] = 'm'
181/28: dataset.ZB.attrs['long_name'] = 'Local height'
181/29: dataset
181/30: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','CC','T','U','V','OMEGA','SLP','LSP','CP','SF','SSHF','SLHF',])
181/31: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','T','U','V','OMEGA','SLP','LSP','CP','SF','SSHF','SLHF'])
181/32: datset
181/33: dataset
181/34: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','T','U','V','OMEGA','LSP','CP','SF','SSHF','SLHF'])
181/35: ds
181/36: ds.BLH.values
181/37: ds.BLH
181/38: np.max(ds.BLH.values[0])
181/39: np.min(ds.BLH.values[0])
181/40: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','T','U','V','OMEGA','SLP','LSP','CP','SF','SSHF','SLHF','BLH'])
181/41: ds = dataset.drop(['Q','IWC','SWC','RWC','LWC','T','U','V','OMEGA','LSP','CP','SF','SSHF','SLHF','BLH'])
181/42: ds.to_netcdf('ERA5ORO',mode='w')
181/43: ls
182/1: import numpy as np
182/2: np.round(5.87,2)
182/3: np.round(5.87,1)
182/4: np.round(5.5,1)
182/5: np.round(5.54,1)
182/6: np.round(5.55,1)
183/1: import numpy as np
183/2: import xarray as xr
184/1: import xarray as xr
184/2: import numpy as np
184/3: dsS = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/S19790310_10')
184/4: dsS
185/1: import numpy as np
185/2: import xarray as xr
185/3: dsS = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/S19790310_10')
185/4: ds = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/ORO')
185/5: ds
185/6: dsn = ds.drop('PS')
185/7: dsn
185/8: dsn.to_netcdf('RO',mode='w')
185/9: nr = xr.open_dataset('/atmosdyn/era5/const/ERA5CONST.nc')
185/10: nr
185/11: nr.Z
185/12: ds.ZB
185/13: ds.LSM
185/14: nr.LSM
185/15: ds.ZB
185/16: dsn
185/17: nr
185/18: dsn = ds.drop(['PS','hyai','hybi','hyam','hybm'])
185/19: dsn
185/20: nr
185/21: dsn.to_netcdf('NORO',mode='w')
185/22: ls
186/1: import numpy as np
186/2: iport pickle
186/3: import pickle
186/4: f = open('All-CYC-entire-year.txt','rb')
186/5: gd = pickle.load(f)
186/6: f.close()
186/7: gd
186/8: gd.keys()
186/9: gd.DEC17.keys()
186/10: gd['DEC17'].keys()
186/11: gd['DEC17'][11.0].keys()
186/12: gd['DEC17'][11.0]['clat']
186/13: gd['DEC17'][11.0]['clat'][7]
186/14: gd['DEC17'][11.0]['dates'][7]
187/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
187/2: dates.keys()
187/3: var[0].keys()
187/4: SLP
187/5: SLP.shape
187/6: SLP[0]
187/7: ID
187/8:
for k in SLP:
    print(np.mean(SLP[k]))
187/9:
for k in SLP:
    print(np.mean(k))
187/10:
for k in ID:
        print(np.mean(k))
188/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import pickle
188/2: CT = 'MED'
188/3: rdis=400
188/4:
pl = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
pll = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'
p = '/atmosdyn2/ascherrmann/006-year-traj/'

traj = np.array([])
for d in os.listdir(pl):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array()
for d in os.listdir(pll):
    if(d.startswith('traend-')):
        MON = np.append(MON,d[-9:-4])
188/5:
pl = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
pll = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'
p = '/atmosdyn2/ascherrmann/006-year-traj/'

traj = np.array([])
for d in os.listdir(pl):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(pll):
    if(d.startswith('traend-')):
        MON = np.append(MON,d[-9:-4])
188/6: MON
188/7: traj
188/8: np.sort(traj)
188/9:
f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year.txt','rb')
td = pickle.load(f)
f.close()
188/10: td.keys()
188/11: td.DEC17.keys()
188/12: td['DEC17'].keys()
188/13: td['DEC17'].[11.0].keys()
188/14: td['DEC17'][11.0].keys()
188/15: td['DEC17'][11.0]['clat']
188/16: td['DEC17'][11.0]['hzeta']
188/17: td['DEC17'][11]['hzeta']
188/18: labs
188/19: labs = helper.traced_varsIFS()
188/20: labs = helper.traced_vars_IFS()
188/21: lbs
188/22: labs
189/1: import pickle
189/2: f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year.txt','rb')
189/3: d  = pickle.load(f)
189/4: f.close()
189/5: d.keys()
189/6: u = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-entire-year3.txt')
189/7: import numpy as np
189/8: u = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-entire-year3.txt')
189/9: u = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year3.txt')
189/10: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-MED-vort-entire-year3.txt')
189/11: clat = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-MED-vort-entire-year3.txt')
189/12: clon = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-MED-vort-entire-year3.txt')
189/13: zeta = = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zeta-MED-vort-entire-year3.txt')
189/14: zeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zeta-MED-vort-entire-year3.txt')
189/15: zeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zetaMED-vort-entire-year3.txt')
189/16: tracks = np.loadtxt('/atmosdyn/atroman/phd/DEC17/cyclones/TRACKED_CYCLONES')
189/17: tracks = np.loadtxt('/atmosdyn/atroman/phd/DEC17/cyclones/TRACKED_CYCLONES',skiprows=1)
189/18: tracks[0,:]
189/19: less /atmosdyn/atroman/phd/DEC17/cyclones/TRACKED_CYCLONES
189/20: SLP = tracks[np.where(tracks[:,1]==14)[0]]
189/21: SLP = tracks[np.where(tracks[:,1]==14)[0],6]
189/22: htSLP = tracks[np.where(tracks[:,1]==14)[0],1]
189/23: htSLP = htSLP - htSLP[np.where(SLP==np.min(SLP)[0][-1])]
189/24: htSLP = htSLP - htSLP[np.where(SLP==np.min(SLP))[0][-1]]
189/25: htSLP
189/26: SLP
189/27: htzeta
189/28: htzeta = htzeta[np.where(tracks[:,1]==14)[0]]
189/29: zeta = zeta[np.where(tracks[:,1]==14)[0]]
189/30: clat = clat[np.where(tracks[:,1]==14)[0]]
189/31: clon = clon[np.where(tracks[:,1]==14)[0]]
189/32: htzeta
189/33: d
189/34: tracks
189/35: clat = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clat-MED-vort-entire-year3.txt')
189/36: clon = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/clon-MED-vort-entire-year3.txt')
189/37: htzeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/htmaxzeta-MED-vort-entire-year3.txt')
189/38: zeta = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/zetaMED-vort-entire-year3.txt')
189/39: ndates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year3.txt')
189/40: SLP
189/41: tracks = np.loadtxt('/atmosdyn/atroman/phd/DEC17/cyclones/TRACKED_CYCLONES',skiprows=1)
189/42: tracks[np.where(tracks[:,1]==14)[0]]
189/43: ls append/
189/44: ID = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/cycIDs-MED-vort-entire-year3.txt')
189/45: loc = np.where((ID==14) & (ndates=='20171203_00'))[0]
189/46: ID
189/47: ID.shape
189/48: ndates.shape
189/49: np.where(ID==14)[0]
189/50: loc = np.where(ID==14)[0]
189/51: zeta = zeta[loc]
189/52: htzeta = htzeta[loc]
189/53: htzeta
189/54: clat = clat[loc]
189/55: clon = clon[loc]
189/56: SLP
189/57: SLP.shape
189/58: htzeta.shape
189/59: htSLP
189/60: htSLP = tracks[np.where(tracks[:,1]==14)[0],0]
189/61: htSLP.shape
189/62: htSLP
189/63: np.where(SLP==np.min(SLP))[0]
189/64: htSLP = htSLP- htSLP[np.where(SLP==np.min(SLP))[0]]
189/65: htSLP
189/66: label=2
189/67: d['DEC17']/keys()
189/68: d['DEC17'].keys()
189/69: d['DEC17'][11].keys()
189/70: clat
189/71: d['DEC17'][11]['clat']
189/72: d['DEC17'][14]['clat']=clat
189/73: d['DEC17'][14]=dict()
189/74: d['DEC17'][14]['clat']=clat
189/75: d['DEC17'][14]['clon']=clon
189/76: d['DEC17'][14]['zeta']=zeta
189/77: d['DEC17'][14]['hzeta']=htzeta
189/78: d['DEC17'][14]['SLP']=SLP
189/79: d['DEC17'][14]['hSLP']=htSLP
189/80: dates
189/81: ndates
189/82: ndates = np.loadtxt('/atmosdyn2/ascherrmann/004-composite-analysis/dates-MED-vort-entire-year3.txt',dtype=str)
189/83: ndates=ndates[loc]
189/84: ndates
189/85: d['DEC17'][14]['dates']=ndates
189/86: d['DEC17'][14]['label']=label
189/87: f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year.txt','wb')
189/88: pickle.dump(d,f)
189/89: f.close()
189/90: mv append/trajectories-mature-20171203_00-ID-000014.txt use/
189/91: mv append/traend-20171203_00-ID-000014DEC17.txt .
189/92: ls
189/93: ls
190/1: import pickle
190/2: import numpy as np
190/3: f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/further-sel2-tracks')
190/4: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/
190/5: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/data
190/6: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/traj/
190/7: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/data/furthersel2.txt
190/8: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/furthersel2.txt
190/9: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/traj/furthersel2.txt
190/10: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/data/furthersel2.txt
190/11: ex
191/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
191/2: SLp.shape
191/3: SLP.shape
191/4: len(SLP)
191/5: SLP[0]
191/6: SLP[1].shape
191/7: SLP[0].shape
191/8: SLP[1].shape
191/9: SLP[5].shape
191/10: ID[0]
191/11: ID[1]
191/12: ID[2]
192/1:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
192/2:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
192/3:
for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
192/4: var = []
192/5:
for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
192/6: var = [SLP, lon, lat, ID, hourstoSLPmin, dates]
192/7:
for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
192/8: SLP
192/9: len(SLP)
192/10:
maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    if len(dates[l][ids])==11:
        if(np.round(lat[l][ids],1)%0.5!=0):
            lat[l][ids] = np.round(lat[l][ids],0)
        if(np.round(lon[l][ids],1)%0.5!=0):
            lon[l][ids] = np.round(lon[l][ids],0)

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
192/11: dates[l][ids]
193/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
193/2: lat
194/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
194/2: len(ID)
194/3: print(ID[:100][0])
194/4: print(ID[0:100][0])
194/5: print(ID[0][0])
194/6: print(ID[1][0])
194/7:
maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    ##check correct date format
    if len(dates[l][ids])==11:
    ##
        if(np.round(lat[l][ids],1)%0.5!=0):
            lat[l][ids] = np.round(lat[l][ids],0)
        if(np.round(lon[l][ids],1)%0.5!=0):
            lon[l][ids] = np.round(lon[l][ids],0)

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
194/8:
for k,t in enumerate(maturedates[:20]):
    print(ID[k],t)
194/9:
for k,t in enumerate(maturedates[:20]):
    print(ID[k][0],t)
194/10:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel2.txt',"rb")
    var.append(pickle.load(f))
    f.close()

IDAPV = var[3]
194/11: len(IDAPV)
194/12:
for k,t in enumerate(maturedates[:20]):
    print(ID[k][0],IDAPV[k][0],t)
194/13:
for k,t in enumerate(maturedates[:20]):
    print(int(ID[k][0]),IDAPV[k][0],t)
194/14: IDS
194/15:
traj = np.array([])
IDS = np.array([])

for d in os.listdir(pload):
    if(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
            IDS = np.append(IDS,d[-10:-4])
194/16: import os
194/17:
traj = np.array([])
IDS = np.array([])

for d in os.listdir(pload):
    if(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
            IDS = np.append(IDS,d[-10:-4])
194/18: IDS
194/19:
for k,t in enumerate(maturedates[:20]):
    print(int(ID[k][0]),IDAPV[k][0],IDS[k],t)
194/20:
for k,t in enumerate(maturedates[:20]):
    print(int(ID[k][0]),IDAPV[k][0],IDS[k],t,traj[k][-25:-14])
194/21: IDS
194/22: ID
194/23: IDS
194/24:
newID = np.array([])
for l in ID:
    newID = np.append(newID,l[0])
194/25: newID
194/26: order = np.argsort(IDS)
194/27: order
194/28: len(order)
194/29: len(IDS)
194/30: order[:100]
194/31: IDS[order]
194/32: IDS[order[:100]]
194/33: len(IDS)
194/34: len(ID)
194/35: ID
194/36: newID
194/37: len(newID)
194/38: order2 = np.argsort(newID)
194/39: newID[order2[:100])
194/40: newID[order2[:100]]
194/41: len(traj)
195/1: import numpy as np
195/2: import pickle
195/3: f = open('PV-data-MEDdPSP-100-ZB-800.txt','rb')
195/4: data = pickle.load(f)
195/5: f.close()
195/6: data.keys()
195/7: oro = data['oro']
195/8: oro.keys()
195/9: oro['20171203_00-014'].keys()
195/10: oro['20171203_00-014']['cyc']['APVTOT'].shape
195/11:
datadi = data['dawdata']
for date in oro.keys():
    meantmp = np.array([])
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env'])"
195/12:
datadi = data['dawdata']
for date in oro.keys():
    meantmp = np.array([])
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
    if (meantmp[0]>0.4):
        print(date)
195/13:
datadi = data['rawdata']
for date in oro.keys():
    meantmp = np.array([])
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
    if (meantmp[0]>0.4):
        print(date)
195/14:
for date in oro.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.4):
            print(date)
195/15:
for date in oro.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
195/16:
for date in oro.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.5):
            print(date)
195/17:
for date in oro.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.2):
            print(date)
195/18:
for date in oro.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
195/19:
f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year.txt','rb')
td = pickle.load(f)
f.close()
195/20: td.keys()
195/21:
for ul, date in enumerate(oro.keys():)
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mon'][ul])
195/22:
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mon'][ul])
195/23: data.keys()
195/24:
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mons'][ul],data['ids'][ul])
195/25:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
195/26: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
195/27: ax.coastlines()
195/28:
LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)
195/29: tr['DEC17'][11.]['clat']
195/30: track
195/31: td['DEC17'][11]['clat']
195/32:
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mons'][ul],data['ids'][ul])
            mon = data['mons'][ul]
            ids = data['ids'][ul]
            lat = LAT[np.mean(td[mon][ids]['clat'],axis=1).astype(int)]
            lon = LON[np.mean(td[mon][ids]['clon'],axis=1).astype(int)]
            ax.plot(lon,lat)
195/33: fig.show()
195/34: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
195/35:
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=-10)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mons'][ul],data['ids'][ul])
            mon = data['mons'][ul]
            ids = data['ids'][ul]
            lat = LAT[np.mean(td[mon][ids]['clat'],axis=1).astype(int)]
            lon = LON[np.mean(td[mon][ids]['clon'],axis=1).astype(int)]
            ax.plot(lon,lat)
195/36: fig.show()
195/37:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=0.6)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mons'][ul],data['ids'][ul])
            mon = data['mons'][ul]
            ids = data['ids'][ul]
            lat = LAT[np.mean(td[mon][ids]['clat'],axis=1).astype(int)]
            lon = LON[np.mean(td[mon][ids]['clon'],axis=1).astype(int)]
            ax.plot(lon,lat)
195/38:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
for ul, date in enumerate(oro.keys()):
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    sq = np.ones(49)*len(idp)
    for pl, key in enumerate(['cyc','env']):
        for wt, ru in enumerate(['APVTOT']):
            meantmp = np.array([])
            for xx in range(len(sq)):
                meantmp = np.append(meantmp,np.sum(oro[date][key][ru][idp,xx]/sq[xx]))
        if (meantmp[0]>0.3):
            print(date)
            print(data['mons'][ul],data['ids'][ul])
            mon = data['mons'][ul]
            ids = data['ids'][ul]
            lat = LAT[np.mean(td[mon][ids]['clat'],axis=1).astype(int)]
            lon = LON[np.mean(td[mon][ids]['clon'],axis=1).astype(int)]
            ax.plot(lon,lat)
195/39: plt.show()
195/40: %save -r high-oro-graphic-cyclones.py 1-999
196/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle


CT = 'ETA'

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
plload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'

traj = np.array([])
for d in os.listdir(pload):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(plload):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)

MON = np.sort(MON)
traj = np.sort(traj)

radii = np.arange(0,2100,200)

globalpercentage = np.array([])

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

labs = helper.traced_vars_IFS()
env = 'env'
cyc = 'cyc'
split=[cyc,env]
datadi = dict()
H = 48

f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year.txt','rb')
td = pickle.load(f)
f.close()
196/2:
for uyt, txt in enumerate(traj):

    date=txt[-25:-14]
    idtmp=int(date[-10:-4])
    montmp = MON[uyt][-9:-4]

    date=date+'-%03d'%idtmp

    datadi[date]=dict()
    tt = np.loadtxt(pload + txt)

    for k, el in enumerate(labs):
        datadi[date][el] = tt[:,k].reshape(-1,H+1)
197/1: import pickle
197/2: import numpy as np
197/3:
Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
197/4:
p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.round(np.linspace(-90,90,361),1)
Lon = np.round(np.linspace(-180,180,721),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel2.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
197/5: SLP.shape
197/6: SLP[0]
197/7: ID[0]
197/8: lon[0]
197/9: trackdata = dict()
197/10:
for l,k in enumerate(ID):
    ids = np.mean(k)
    trackdata[ids] = dict()
    trackdata[ids]['lat'] = lat[l]
    trackdata[ids]['lon'] = lon[l]
    trackdata[ids]['SLP'] = SLP[l]
    trackdata[ids]['htSLP'] = hourstoSLPmin[l]
197/11: ids
197/12: f = open('trackdata-ERA5.txt','wb')
197/13: pickle.dump(trackdata,f)
197/14: f.close()
197/15: ls
197/16: pwd
198/1: import numpy as np
198/2:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
198/3: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
198/4: ax.coastlines()
198/5:
minpltlonc = -120
minpltlatc = 0
maxpltlatc = 90
maxpltlonc = 100

lonticks=np.arange(minpltlonc, maxpltlonc,20)
latticks=np.arange(minpltlatc, maxpltlatc,10)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree())
198/6: ax.axvline(-105,ymin=15,ymax=90,color='k')
198/7: ax.axvline(90,ymin=60,ymax=90,color='k')
198/8: ax.axvline(40,ymin=0,ymax=60,color='k')
198/9: ax.axvline(-75,ymin=0,ymax=15,color='k')
198/10: ax.axhline(15,xmin=-105,xmax=-75,color='k')
198/11: ax.axhline(0,xmin=-75,xmax=40,color='k')
198/12: ax.axhline(60,xmin=40,xmax=90,color='k')
198/13: fig.show()
198/14: plt.close('all')
198/15: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
198/16: ax.coastlines()
198/17: ax.plot([-105,-105],[15,90],color='grey')
198/18: ax.plot([-105,-75],[15,15],color='grey')
198/19: ax.plot([-75,-75],[0,15],color='grey')
198/20: ax.plot([-75,40],[0,0],color='grey')
198/21: ax.plot([40,40],[0,60],color='grey')
198/22: ax.plot([40,90],[60,60],color='grey')
198/23: ax.plot([90,90],[60,90],color='grey')
198/24: fig.show()
198/25: ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
198/26: ax.set_yticks(latticks, crs=ccrs.PlateCarree())
198/27: ax.set_xlim(-120,100)
198/28: ax.set_ylim(-10,90)
198/29: ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
198/30: fig.savefig('Atlantic-box.png',dpi=300,bbox_inches="tight")
198/31: pwd
198/32: :q
198/33: plt.close()
198/34: minpltlonc=-5
198/35: minpltlatc=-30
198/36: minpltlatc=30
198/37: maxpltlatc=50
198/38: maxpltlonc=40
198/39: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
198/40: ax.coastlines()
198/41: ax.plot([-1.6,33],[33,33],color='grey')
198/42: ax.plot([-1.6,33],[45,45],color='grey')
198/43: ax.plot([-1.6,-1.6],[33,45],color='grey')
198/44: ax.plot([33,33],[33,45],color='grey')
198/45: ax.set_yticks(latticks, crs=ccrs.PlateCarree())
198/46: ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
198/47:  ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
198/48: fig.savefig('MED-box.png',dpi=300,bbox_inches="tight")
198/49: plt.close('all')
199/1: import pickle
199/2: f = open('../trackdata-ERA5.txt','rb')
199/3: td = pickle.load(f)
199/4: td.keys()
199/5: td[541749.0].keys()
200/1: import pickle
200/2: import numpy as np
200/3: MONTHS = np.array(['DEC17','JAN18','FEB18','MAR18','APR18','MAY18','JUN18','JUL18','AUG18','SEP18','OCT18','NOV18'])
200/4: f = open('DEC17/All-CYC-entire-year-NEWDEC17.txt','rb')
200/5: d = pickle.load(f)
200/6: f.close()
200/7: d.keys()
200/8: d['DEC17']
200/9: d['DEC17'].keys()
200/10:
for k in MONTHS[1:]:
    f = open(k + '/All-CYC-entire-year-NEW'+ k + '.txt','rb')
    tmp = pickle.load(f)
    f.close()
    d[k] = tmp[k]
200/11: d.keys()
200/12: f = open('All-CYC-entire-year-NEW.txt','wb')
200/13: pickle.dump(d,f)
200/14: f.close()
200/15: ls
201/1: import pickle
201/2: f = open('SLP-furthersel.txt','rb')
201/3: SLP = pickle.load(f)
201/4: f.close()
201/5: SLP.keys()
201/6: len(SLP)
201/7: f = open('SLP-furthersel.txt','rb')
201/8: SLP = pickle.load(f)
201/9: f.close()
201/10: len(SLP)
201/11: f = open('SLP-furthersel.txt','rb')
201/12: SLP = pickle.load(f)
201/13: f.close()
201/14: len(SLP)
201/15: f = open('SLP-furthersel.txt','rb')
201/16: SLP = pickle.load(f)
201/17: f.close()
201/18: len(SLP)
201/19: 4239-1588
202/1: 2651/4
202/2: 2651/8
202/3: 2651/6
203/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

CT = 'MED'

f = open(pload + 'PV-data-' + CT + 'dPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()
203/2: datadi = data['rawdata']
203/3:
for q in data['highORO'][1:]:
    PS = datadi[q]['PS']
    P = datadi[q]['P']
203/4: PSP = PS-P
203/5: np.where(PSP<0)
203/6: PSP[np.where(PSP<0)]
203/7: data['dipv'][q][np.where(PSP<0)]
203/8: data['dipv'][q]['env'][np.where(PSP<0)]
203/9: data['dipv'][q]['env']['APVTOT'][np.where(PSP<0)]
203/10:
PV = datadi[q]['PV'][array([ 652,  675,  853, 1058, 1099, 1100, 1264, 1266, 1268, 1273, 1273,
        1274, 1275, 1276, 1286, 1286, 1287, 1288, 1289, 1291, 1291, 1291,
        1294, 1296, 1300, 1300, 1300, 1302, 1334, 1335, 1335, 1366, 1366,
        1478, 1480, 1482, 1514, 1532, 1535, 1539, 1543, 1559, 1567, 1569,
        1643, 1665, 1666, 1666, 1667, 1670]),0]
203/11:
PV = datadi[q]['PV'][np.array([ 652,  675,  853, 1058, 1099, 1100, 1264, 1266, 1268, 1273, 1273,
        1274, 1275, 1276, 1286, 1286, 1287, 1288, 1289, 1291, 1291, 1291,
        1294, 1296, 1300, 1300, 1300, 1302, 1334, 1335, 1335, 1366, 1366,
        1478, 1480, 1482, 1514, 1532, 1535, 1539, 1543, 1559, 1567, 1569,
        1643, 1665, 1666, 1666, 1667, 1670]),0]
203/12: PV
204/1: import numpy as np
204/2:
LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)
204/3: lat = 35.76
204/4: lon = 5.93
204/5: lo = LON-lon
204/6: la = LAT - lat
204/7: np.where((lo==np.min(lo))& (la = np.min(la)) )
204/8: np.where((lo==np.min(lo))& (la==np.min(la)) )
204/9: np.where((lo==np.min(lo)))
204/10: np.where((abs(lo)==np.min(abs(lo))))
204/11: LON[465]
204/12: np.where((abs(la)==np.min(abs(la))))
204/13: LAT[89]
204/14:
def find_nearest_grid_point(lon,lat):

    dlon = LON-lon
    dlat = LAT-lat

    lonid = np.where(abs(dlon)==np.min(abs(dlon)))[0][0]
    latid = np.where(abs(dlat)==np.min(abs(dlat)))[0][0]

    return lonid,latid
204/15: find_nearest_grid_point(lon,lat)
204/16: lonid,latid = find_nearest_grid_point(lon,lat)
204/17: lonid
204/18: latid
204/19: ls /atmosdyn2/ascherrmann/010-IFS/traj/MED/use/*.txt
204/20: less /atmosdyn2/ascherrmann/scripts/help.
204/21: less /atmosdyn2/ascherrmann/scripts/helper.py
204/22: np.zeros((LON.shape,LAT.shape))
204/23: np.zeros((LON.size,LAT.size))
204/24: np.zeros((LON.size,LAT.size)).shape
204/25: np.wher(np.zeros((LON.size,LAT.size))==0)
204/26: np.where(np.zeros((LON.size,LAT.size))==0)
204/27:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'

f = open('PV-data-' + CT + 'dPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
204/28: CT ='MED'
204/29:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'

f = open('PV-data-' + CT + 'dPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
204/30:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'

f = open(pload+'PV-data-' + CT + 'dPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
204/31: import pickle
204/32:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'

f = open(pload+'PV-data-' + CT + 'dPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
204/33: datadi.keys()
204/34: datadi.keys()[:1]
204/35: enumerate(datadi.keys())
204/36: k = enumerate(datadi.keys())
204/37: k
204/38:
for q,date in enumerate(datadi.keys())[:5]:
    print(q)
204/39:
for q,date in enumerate(datadi.keys()):
    print(q)
    if(q>5):
        break
205/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
205/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
205/3: HourstoSLPmin = var[4]
205/4: len(Slp)
205/5: ID
205/6: import os
206/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
206/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
HourstoSLPmin = var[4]
206/3: ls use/ |wc -l
206/4:
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
206/5: for d in os.listdir('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/')
206/6:
for d in os.listdir('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'):
    if (d.startswith('trajectories-mature')):
        ids = int(d[-10:-4])
        print(d)
        if (np.any(avaID==ids)):
            continue
        #else:
            #os.remove(d)
            
        break
206/7:
for d in os.listdir('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'):
    if (d.startswith('trajectories-mature')):
        ids = int(d[-10:-4])
        
        if (np.any(avaID==ids)):
            continue
        else:
            add = d[-25:]
            os.remove('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/' + d)
            os.remove('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/' + 'trastart-mature-' + add)
206/8: ls use/ |wc -l
206/9: len(avaID)
206/10: dates = var[5]
206/11: len(dates)
206/12: maturedates = np.array([])
206/13:
for k in range(len(ID)):
    loc = np.where(hourstoSLPmin==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])
206/14:
for k in range(len(ID)):
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])
206/15: len(maturedates)
206/16: ls use/trajectories-mature*.txt |wc -l
206/17: en = np.array([])
206/18: end = np.array([])
206/19: ent = np.array([])
206/20:
for d in os.listdir('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'):
    if (d.startswith('trajectories-mature')):
        ent = np.append(ent,d[-25:])
206/21:
for k in range(len(ID)):
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
206/22: len(end)
206/23: len(ent)
206/24: pos = np.zeros(len(end))
206/25:
for k in ent:
    pos[np.where(end==k)[0][0]] +=1
206/26:
for k in ent:
    pos[np.where(end==k)[0]] =1
206/27: np.where(pos!=1)
206/28: pos = np.zeros(len(end))
206/29:
for k in ent:
    pos[np.where(end==k)[0]] +=1
206/30: np.where(pos==0)
206/31: np.where(pos>1)
206/32: end[   0, 1513, 1631, 2246, 3231, 3960]
206/33: end[np.where(pos==0)[0])
206/34: end[np.where(pos==0)[0]]
206/35: dates[1513]
206/36: dates[np.where(pos==0)[0]]
206/37: dates[1631]
206/38: dates[1631][::2]
206/39: dates[1631][1::2]
206/40: rmid = [0,1513, 1631, 2246, 3231, 3960]
206/41: savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-']
206/42:
for j in rmid:
    for k in range(len(savings)):
        del var[k][j]
206/43: len(var[-1])
206/44: end = np.array([])
206/45:
for j in rmid:
    for k in range(len(savings)):
        del eval(savings[k][:-1])[j]
206/46: len (SLP)
206/47: len(var[-1])
206/48: len(var[0])
206/49:
for k in len(var):
    print(len(var[k]))
206/50:
for k in range(len(var)):
    print(len(var[k]))
206/51: :q
206/52:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
206/53:
for k in range(len(var)):
    print(len(var[k]))
206/54: lon = var[1]
206/55: lat = var[2]
206/56: dates
206/57: hourstoSLPmin.size
206/58: len(hourstoSLPmin)
206/59:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    eval(savings[u]) = pickle.load(f)
    f.close()
206/60:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    eval(savings[u][:-1]) = pickle.load(f)
    f.close()
206/61:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    eval(x[:-1]) = pickle.load(f)
    f.close()
206/62:
for k in range(len(var)):
    print(len(var[k]))
206/63: SLP = var[0]
206/64: lon = var[1]
206/65: lat = var[2]
206/66: ID = var[3]
206/67: hourstoSLPmin = var[4]
206/68: dates = var[5]
206/69: len(end)
206/70: len(ent)
206/71: end
206/72:
for k in range(len(ID)):
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
206/73: len(end)
206/74: end[np.where(pos==0)]
206/75: np.where(ID==957094)
206/76: np.max(ID)
206/77: np.max(avaID)
206/78: np.where(maturedates=='19790101_20')
206/79:
for k in range(len(var)):
    print(len(var[k]))
206/80: rmids
206/81: rmid
206/82: rmid = [0,1512,1629,2243,3227,3955]
206/83:
for k in range(len(var)):
    for i in rmid:
        del var[k][i]
206/84:
for k in range(len(var)):
    print(len(var[k]))
206/85: SLP = var[0]
206/86: lon = var[1]
206/87: lat = var[2]
206/88: savings
206/89: ID = var[3]
206/90: hourstoSLPmin = var[4]
206/91: dates = var[5]
206/92: ls use/traje* |wc -l
206/93:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"wb")
    pickle.dump(x[:-1],f)
    f.close()
206/94: %save -r remove-bad-ids.py 1-999
207/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
207/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
207/3: len(var[0])
207/4:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
207/5: len(var[0])
207/6:
SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))

maturedates = np.array([])
for k in range(len(ID)):
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])

end = np.array([])
ent = np.array([])
for d in os.listdir('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'):
    if (d.startswith('trajectories-mature')):
        ent = np.append(ent,d[-25:])

for k in range(len(ID)):
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])

pos = np.zeros(len(end))
for k in ent:
    pos[np.where(end==k)[0]] =1

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
207/7: np.where(pos==0)
207/8:
rmid = [0,1512,1629,2243,3227,3955]
for k in range(len(var)):
    for i in rmid:
        del var[k][i]


SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
207/9: len(SLP)
207/10: pload
207/11:
for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"wb")
    pickle.dump(eval(x[:-1]),f)
    f.close()
207/12:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
207/13: len(var[0])
208/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
208/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
HourstoSLPmin = var[4]

SLPminid = np.array([])
for kl in hourstoSLPmin[:]:
    SLPminid = np.append(SLPminid,np.where(kl==0)[0][0])

dates = var[5]
208/3:
traj = np.array([])
IDS = np.array([])

for d in os.listdir(pload):
    if(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
            IDS = np.append(IDS,int(d[-10:-4]))
208/4:
for uyt, txt in enumerate(traj[:100]):

    cycID = int(txt[-10:-4])
    print(cycID-ID[uyt][0])
208/5:
for k in ID[:20]:
    print(k[0])
208/6: traj[:20]
208/7: np.sort(traj)[:20]
208/8:
for uyt, txt in enumerate(np.sort(traj)[:100]):

    cycID = int(txt[-10:-4])
    print(cycID-ID[uyt][0])
208/9:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])
    SLPminid = np.append(SLPminid,loc)
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
208/10:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])

for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])
    SLPminid = np.append(SLPminid,loc)
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
208/11:
traj = np.array([])

for d in os.listdir(pload):
    if(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
208/12:
for uyt, txt in enumerate(traj[:]):
    cycID = txt[-10:-4]
    idsave = np.append(idsave,cycID)

    date=txt[-25:-14]
    lfd = txt[-25:]
    uyt = np.where(end==lfd)[0]
    if (uyt.size==0):
        print('not avail')
208/13:
for uyt, txt in enumerate(traj[:]):
    cycID = txt[-10:-4]

    date=txt[-25:-14]
    lfd = txt[-25:]
    uyt = np.where(end==lfd)[0]
    if (uyt.size==0):
        print('not avail')
210/1: import pickle
210/2: import numpy as np
210/3: f = open('lon-furthersel.txt','rb')
210/4: lon = pickle.load(f)
210/5: f.close()
210/6: len(lon)
210/7: pwd
210/8: ls use/*data*.txt
211/1: import numpy as np
211/2: import pickle
211/3: pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
211/4:
f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()
211/5: dipv = PVdata['dipv']
211/6: adv = np.array([])
211/7: cyclonic = np.array([])
211/8: environmental = np.array([])
211/9:
both = np.array([])
for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp]
    env = dipv[k]['env'][idp]
    tot = cyc + env
    if np.mean(tot/PVend)>0.4:
        if(np.mean(cyc/env)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (np.mean(cyc/env)<0.8):
            environmental = np.append(environmental)
        else:
            both = np.append(both,k)
    else:
        adv = np.append(adv,k)
211/10:
both = np.array([])
for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp][:,0]
    env = dipv[k]['env'][idp][:,0]
    tot = cyc + env
    if np.mean(tot/PVend)>0.4:
        if(np.mean(cyc/env)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (np.mean(cyc/env)<0.8):
            environmental = np.append(environmental)
        else:
            both = np.append(both,k)
    else:
        adv = np.append(adv,k)
211/11:
both = np.array([])
for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    if np.mean(tot/PVend)>0.4:
        if(np.mean(cyc/env)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (np.mean(cyc/env)<0.8):
            environmental = np.append(environmental)
        else:
            both = np.append(both,k)
    else:
        adv = np.append(adv,k)
211/12:
both = np.array([])
for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    if np.mean(tot/PVend)>0.4:
        if(np.mean(cyc/env)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (np.mean(cyc/env)<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
    else:
        adv = np.append(adv,k)
211/13: len(cyclonic)
211/14: len(environmental)
211/15: len(both)
211/16: len(adv)
211/17: len(adv) + len(environmental) + len(both) + len(cyclonic)
211/18:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
   
        if(np.mean(cyc/env)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (np.mean(cyc/env)<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
            
      elif((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
    else:
        adv = np.append(adv,k)
211/19: len(cyclonic)
211/20: len(adv)
211/21: len(both)
211/22: len(environmental)
211/23:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
        
        elif(cycm/envm>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (cycm/envm<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
          
      elif((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
          
      else:
          adv = np.append(adv)
    else:
        adv = np.append(adv,k)
211/24:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
        elif (cycm/envm>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (cycm/envm<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
          
      elif ((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
          
      else:
          adv = np.append(adv)
    else:
        adv = np.append(adv,k)
211/25:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
        if ((cycm/envm)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (cycm/envm<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
          
      elif ((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
          
      else:
          adv = np.append(adv)
    else:
        adv = np.append(adv,k)
211/26:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
        if ((cycm/envm)>1.2):
            cyclonic = np.append(cyclonic,k)
        elif (cycm/envm<0.8):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
          
      elif ((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
          
      else:
          adv = np.append(adv,k)
    else:
        adv = np.append(adv,k)
211/27: len(adv)
211/28: len(cyclonic)
211/29: len(environmental)
211/30: len(both)
211/31:
both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

for k in dipv.keys():
    idp = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    PVend = PVdata['rawdata'][k]['PV'][idp,0]
    cyc = dipv[k]['cyc'][idp,0]
    env = dipv[k]['env'][idp,0]
    tot = cyc + env
    cycm = np.mean(cyc)
    envm = np.mean(env)
    
    if np.mean(tot/PVend)>0.4:
        
      if((envm>0) & (cycm>0)):
        if ((cycm/envm)>1.3):
            cyclonic = np.append(cyclonic,k)
        elif (envm/cycm>1.3):
            environmental = np.append(environmental,k)
        else:
            both = np.append(both,k)
          
      elif ((envm<0) & (cycm<0)):
          adv = np.append(adv,k)
          
      elif((cycm<0) & (envm>0)):
          environmental = np.append(environmental,k)
          
      elif((cycm>0) & (envm<0)):
          cyclonic = np.append(cyclonic,k)
          
      else:
          adv = np.append(adv,k)
    else:
        adv = np.append(adv,k)
211/32: len(both)
211/33: len(environmental)
211/34: len(cyclonic)
211/35: len(adv)
211/36: %save -r cyc-env-adv-cyclones.py 1-999
212/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle
212/2:
f = open(pload + 'local-cyclonic-PV-percentage.txt','rb')
local = pickle.load(f)
f.close()
212/3: pload = './'
212/4:
f = open(pload + 'local-cyclonic-PV-percentage.txt','rb')
local = pickle.load(f)
f.close()
212/5: local.keys()
212/6: gperc = np.array([])
212/7: radii = np.arange(0,2100,100)
212/8: gperc = np.zeros(radii.shape)
212/9: gperc
212/10:
for k in local.keys():
    for q,l in enumerate(radii):
        gperc[q] += local[k][l]
212/11: k
212/12: l
212/13:
for k in local.keys():
    for q,l in enumerate(radii[1:]):
        gperc[q+1] += local[k][l]
212/14: local[k]
212/15: local['545850']
213/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle
213/2: pload = './'
213/3:
f = open(pload + 'local-cyclonic-PV-percentage.txt','rb')
local = pickle.load(f)
f.close()
213/4: local['545850']
213/5: enumerate(local.keys())
213/6: q = enumerate(local.keys())
213/7: q
213/8: q[:10]
213/9: local.keys()
213/10: local['957160']
213/11:
f = open(pload + 'local-cyclonic-PV-percentage.txt','rb')
local = pickle.load(f)
f.close()
213/12: local['002426']
214/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle
214/2:
f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW.txt','rb')
pd = pickle.load(f)
f.close()
214/3: pd
214/4: pd.keys()
214/5: pd['DEC17'].keys()
214/6: pd['DEC17'][73]
215/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from scipy.stats.stats import pearsonr
import pickle


pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
215/2: Clon[0]
216/1:
import numpy as np
import xarray as xr
import os
import argparse
import matplotlib
import matplotlib.pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import cm
import pickle


MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
path=p
dates = np.array([])
for d in os.listdir(p):
    if(d.startswith('trajectories-mature-')):
            dates = np.append(dates,d[-25:-14])

dates = np.sort(dates)

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

f = open(p[:-13] + 'data/All-CYC-entire-year-NEW.txt','rb')
PVdata = pickle.load(f)
f.close()
216/2: PVdata.keys()
216/3: PVdata['DEC17'][11]
216/4: PVdata['DEC17'][11].keys()
216/5:
MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
MONTHSN = np.arange(1,13,1)

p = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
path=p
dates = np.array([])
ids = np.array([])
for d in os.listdir(p):
    if(d.startswith('trajectories-mature-')):
            dates = np.append(dates,d[-25:-14])

dates = np.sort(dates)

MON = np.array([])
for d in os.listdir(p[:-4]):
    if(d.startswith('traend-')):
        MON = np.append(MON)
MON = np.sort(MON)

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

f = open(p[:-13] + 'data/All-CYC-entire-year-NEW.txt','rb')
PVdata = pickle.load(f)
f.close()

rdis=200

varS = np.array(['PV','TH','THE'])
varP = np.array(['T'])
di = dict()
di2= dict()
tmpd = dict()
216/6:
MON = np.array([])
for d in os.listdir(p[:-4]):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)
MON = np.sort(MON)

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

f = open(p[:-13] + 'data/All-CYC-entire-year-NEW.txt','rb')
PVdata = pickle.load(f)
f.close()

rdis=200

varS = np.array(['PV','TH','THE'])
varP = np.array(['T'])
di = dict()
di2= dict()
tmpd = dict()
216/7:
for q,date in enumreate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = MON[q][-16:-10]
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    clat = PVdata[mon][ID]['clat']
    clon = PVdata[mon][ID]['clon']

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/8:
for q,date in enumerate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = MON[q][-16:-10]
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    clat = PVdata[mon][ID]['clat']
    clon = PVdata[mon][ID]['clon']

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/9:
for q,date in enumerate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = MON[q][-16:-10].astype(int)
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    clat = PVdata[mon][ID]['clat']
    clon = PVdata[mon][ID]['clon']

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/10:
for q,date in enumerate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = int(MON[q][-16:-10])
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    clat = PVdata[mon][ID]['clat']
    clon = PVdata[mon][ID]['clon']

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/11:
di = dict()
di2= dict()
tmpd = dict()
216/12:
for q,date in enumerate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = int(MON[q][-16:-10])
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    mat = np.where(PVdata[mon][ID]['dates']==date)[0][0]

    clat = PVdata[mon][ID]['clat'][mat]
    clon = PVdata[mon][ID]['clon'][mat]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/13: ls /atmosdyn2/ascherrmann/010-IFS/data-
216/14: ls /atmosdyn2/ascherrmann/010-IFS/data/
216/15: ls /atmosdyn2/ascherrmann/010-IFS/data/MAR18/
216/16:
for q,date in enumerate(dates):

    di[date] = dict()
    di2[date] = dict()
    mon = MON[q][-9:-4]
    ID = int(MON[q][-16:-10])
    ana_path='/atmosdyn2/ascherrmann/010-IFS/data/' + mon + '/'

    mat = np.where(PVdata[mon][ID]['dates']==date)[0][0]

    clat = PVdata[mon][ID]['clat'][mat]
    clon = PVdata[mon][ID]['clon'][mat]

    sfile = ana_path + 'S' + date
    pfile = ana_path + 'P' + date

    s = xr.open_dataset(sfile, drop_variables=['P','RH','VORT','PVRCONVT','PVRCONVM','PVRTURBT','PVRTURBM','PVRLS','PVRCOND','PVRSW','PVRLWH','PVRLWC','PVRDEP','PVREVC','PVREVR','PVRSUBI','PVRSUBS','PVRMELTI','PVRMELTS','PVRFRZ','PVRRIME','PVRBF'])

    p = xr.open_dataset(pfile,drop_variables=['SWC', 'RWC', 'IWC', 'LWC','PS','CC','OMEGA','tsw','tlw','tmix','tconv','tcond','tdep','tbf','tevc','tsubi','tevr','tsubs','tmelti','tmelts','tfrz','trime','udotconv','vdotconv','udotmix','vdotmix','tls','tce'])

    PS = s.PS.values[0,0,clat,clon]
    for q in varS:
        tmp = getattr(s,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    for q in varP:
        tmp = getattr(p,q)
        di[date][q] = np.transpose(tmp.values[0,:,clat,clon])
        di2[date][q] = np.array([])

    di2[date]['THEstar'] = np.array([])
    for pres in np.arange(100,1001,25):
        for q in np.append(varS,varP):
            tmpd[q] = np.array([])
        for e in range(len(clat)):
            P = helper.modellevel_to_pressure(PS[e])
            I = (np.where(abs(P-pres)==np.min(abs(P-pres)))[0][0]).astype(int)
            for q in np.append(varS,varP):
                tmpd[q] = np.append(tmpd[q],di[date][q][I,e])

        for q in np.append(varS,varP):
                di2[date][q] = np.append(di2[date][q],np.mean(tmpd[q]))
        di2[date]['THEstar'] = np.append(di2[date]['THEstar'],np.mean(helper.theta_star(tmpd['TH'],tmpd['T'],pres)))
216/17: ls /atmosdyn2/ascherrmann/010-IFS/data/MAR18/S20180303_09
216/18: ls '/atmosdyn2/ascherrmann/010-IFS/data/MAR18/S20180303_09'
217/1: import xarray as xr
217/2: s = '/atmosdyn2/ascherrmann/010-IFS/data/MAR18/S20180303_09'
217/3: sf = xr.open_dataset(s)
217/4: s = '/atmosdyn2/ascherrmann/010-IFS/data/MAR18/S20180303_08'
217/5: sf = xr.open_dataset(s)
217/6: s = '/atmosdyn2/ascherrmann/010-IFS/data/DEC17S20171214_02'
217/7: sf = xr.open_dataset(s)
217/8: s = '/atmosdyn2/ascherrmann/010-IFS/data/DEC17/S20171214_02'
217/9: sf = xr.open_dataset(s)
217/10: sf
218/1: import numpy as np
218/2: import pickle
218/3: pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'
218/4: f = open(pload + 'process-di.txt','rb')
218/5: f = open(pload + 'process-di.txt','rb')
218/6: pload = '/atmosdyn2/ascherrmann/010-IFS/data/DEC17/'
218/7: f = open(pload + 'process-di.txt','rb')
218/8: prodi = pickle.load(f)
218/9: f.close()
218/10: prodi.keys()
218/11: prodi['20171203_00-014']
218/12: np.where(prodi['20171203_00-014']!=0)
219/1: import pickle
219/2: pload = '/atmosdyn2/ascherrmann/010-IFS/data/DEC17/'
219/3: f = open(pload + 'process-di.txt','rb')
219/4: prodi = pickle.load(f)
219/5: f.close()
219/6: prodi.keys()
219/7: prodi['20171203_00-014'].keys()
219/8: prodi['20171203_00-014']['102-475']
219/9:
LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)
219/10: import numpy as np
219/11:
LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)
219/12: for
219/13:
promap = dict()
for date in prodi.keys():
    for ll in prodi[date].keys():
        if ll not in promap.keys():
            promap[ll] = np.array([])
        da = prodi[date][ll]
        
        app = 0
        for q in da:
            if (len(np.where(da==q)[0])/len(da) > 2./3.):
                app = q
        
        promap[ll] = np.append(promap[ll],app)
219/14:
pmap = np.zeros((LAT.size,LON.size))-100
for ll in promap.keys():
    da = promap[ll]
    lat = int(ll[3:])
    lon = int(ll[-3:])
    app = 0
    for q in da:
        if (len(np.where(da==q)[0])/len(da) > 2./3.):
            app = q
            
    pmap[lat,lon] = app
219/15:
pmap = np.zeros((LAT.size,LON.size))-100
for ll in promap.keys():
    da = promap[ll]
    print(ll)
    lat = int(ll[3:])
    lon = int(ll[-3:])
    app = 0
    for q in da:
        if (len(np.where(da==q)[0])/len(da) > 2./3.):
            app = q
            
    pmap[lat,lon] = app
219/16:
pmap = np.zeros((LAT.size,LON.size))-100
for ll in promap.keys():
    da = promap[ll]
    print(ll[0])
    print(ll[-3])
    lat = int(ll[3:])
    lon = int(ll[-3:])
    app = 0
    for q in da:
        if (len(np.where(da==q)[0])/len(da) > 2./3.):
            app = q
            
    pmap[lat,lon] = app
219/17:
pmap = np.zeros((LAT.size,LON.size))-100
for ll in promap.keys():
    da = promap[ll]
    
    
    lat = int(ll[:3])
    lon = int(ll[-3:])
    app = 0
    for q in da:
        if (len(np.where(da==q)[0])/len(da) > 2./3.):
            app = q
            
    pmap[lat,lon] = app
219/18:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

import xarray as xr
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle
219/19:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
219/20: cmap = ListedColormap(['orange','green','saddlebrown',,'dodgerblue','blue','magenta','salmon','red'])
219/21: cmap = ListedColormap(['orange','green','saddlebrown','dodgerblue','blue','magenta','salmon','red'])
219/22: norm = BoundaryNorm([1 ,2, 3, 4, 5, 6,7,8,9], cmap.N)
219/23: levels = np.arange(0.5,9,1)
219/24: labs = helper.traced_vars_IFS()labs = helper.traced_vars_IFS()
219/25: labs = helper.traced_vars_IFS()
219/26: domlabs = labs[8:]
219/27:
for q in domlabs:
    ticklabels = np.append(ticklabels,q[3:])
219/28:
ticklabels  = np.array([])

for q in domlabs:
    ticklabels = np.append(ticklabels,q[3:])
219/29:
lc=ax.contourf(LON,LAT,pmap,levels=levels,cmap=cmap,extend='both',norm=norm)
lc.cmap.set_under('white')
219/30:
maxv = 3000
minv = 800
elv_levels = np.arange(minv,maxv,400)
219/31:
pload = '/atmosdyn2/ascherrmann/010-IFS/data/DEC17/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'
maxv = 3000
minv = 800
elv_levels = np.arange(minv,maxv,400)

data = xr.open_dataset(pload + 'IFSORO')
219/32:
lon = data['lon']
lat = data['lat']
ZB = data['ZB'].values[0,0]
219/33: ax.contour(lon,lat,ZB,levels=elv_levels,linewidths=0.5,colors='black')
219/34:
minpltlatc = 15
minpltlonc = -20

maxpltlatc = 60
maxpltlonc = 50
219/35: lc.cmap.set_under('grey')
219/36:
lonticks=np.arange(minpltlonc, maxpltlonc,5)
latticks=np.arange(minpltlatc, maxpltlatc,5)

ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=8)
ax.set_yticklabels(labels=latticks,fontsize=8)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())

ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
219/37:
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=levels,cax=cbax)

func=resize_colorbar_vert(cbax, ax, pad=0.01, size=0.02)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=8)
cbar.ax.set_xlabel(' ',fontsize=8)
cbar.ax.set_yticklabels(ticklabels)

figname = psave + 'process-gridmap-test' + '-PVedge-' + str(PVedge) + '.png'
fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
219/38: PVedge = 0.75
219/39:
cbax = fig.add_axes([0, 0, 0.1, 0.1])
cbar=plt.colorbar(lc, ticks=levels,cax=cbax)

func=resize_colorbar_vert(cbax, ax, pad=0.01, size=0.02)
fig.canvas.mpl_connect('draw_event', func)

cbar.ax.tick_params(labelsize=8)
cbar.ax.set_xlabel(' ',fontsize=8)
cbar.ax.set_yticklabels(ticklabels)

figname = psave + 'process-gridmap-test' + '-PVedge-' + str(PVedge) + '.png'
fig.savefig(figname,dpi=300,bbox_inches="tight")
plt.close()
219/40: %save -r processgridmap.py 1-999
220/1: import numpy as np
220/2: import os
220/3: import pickle
220/4: ls *.txt
220/5: traj = np.array([])
220/6:
for d in os.listdir('./'):
    if d.startswith(trajectories-mature-'):
        traj = np.append(traj,d)
220/7:
for d in os.listdir('./'):
    if d.startswith('trajectories-mature-'):
        traj = np.append(traj,d)
220/8: traj = np.sort(traj)
220/9: f = open('PV-data-MEDdPSP-100-ZB-800.txt','rb')
220/10: data = pickle.load(f)
220/11: f.close()
220/12: datadi = data['rawdata']
220/13:
radii = dict()
rads = np.append(np.arange(0,801,50),1000000000)
for date in datadi.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    clon = np.mean(datadi[date]['lon'][idp,0])
    clat = np.mean(datadi[date]['lat'][idp,0])
    radii[date] = dict()
    labs = helper.traced_vars_IFS()
    PVRS = labs[8:]
    for q in PVRS:
        radii[date][q] = np.zeros((len(idp),len(rads)))
    for q,i in enumerate(idp):
        for x in range(0,49):
            dlon = clon - datadi[date]['lon'][i,x]
            dlat = clat - datadi[date]['lat'][i,x]
            rl = np.sqrt(dlon**2 + dlat**2)
            r  = helper.convert_lon_lat_dis_to_radial_dis(rl)
            loc = np.where((rads-r)>0)[0][0]-1
            for pv in PVRS:
                radii[date][pv][q,loc] += datadi[date][pv][i,x]
    break
220/14: import sys
220/15: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
220/16: import helper
220/17:
radii = dict()
rads = np.append(np.arange(0,801,50),1000000000)
for date in datadi.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    clon = np.mean(datadi[date]['lon'][idp,0])
    clat = np.mean(datadi[date]['lat'][idp,0])
    radii[date] = dict()
    labs = helper.traced_vars_IFS()
    PVRS = labs[8:]
    for q in PVRS:
        radii[date][q] = np.zeros((len(idp),len(rads)))
    for q,i in enumerate(idp):
        for x in range(0,49):
            dlon = clon - datadi[date]['lon'][i,x]
            dlat = clat - datadi[date]['lat'][i,x]
            rl = np.sqrt(dlon**2 + dlat**2)
            r  = helper.convert_lon_lat_dis_to_radial_dis(rl)
            loc = np.where((rads-r)>0)[0][0]-1
            for pv in PVRS:
                radii[date][pv][q,loc] += datadi[date][pv][i,x]
    break
220/18: date
220/19: radii[date]['PVRLS']
220/20: np.mean(radii[date]['PVRLS'],axis=0)
220/21:
radii = dict()
rads = np.append(np.arange(0,801,50),1000000000)
for date in datadi.keys():
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    clon = np.mean(datadi[date]['lon'][idp,0])
    clat = np.mean(datadi[date]['lat'][idp,0])
    radii[date] = dict()
    labs = helper.traced_vars_IFS()
    PVRS = labs[8:]
    for q in PVRS:
        radii[date][q] = np.zeros((len(idp),len(rads)))
    for q,i in enumerate(idp):
        for x in range(0,49):
            dlon = clon - datadi[date]['lon'][i,x]
            dlat = clat - datadi[date]['lat'][i,x]
            rl = np.sqrt(dlon**2 + dlat**2)
            r  = helper.convert_lon_lat_dis_to_radial_dis(rl)
            loc = np.where((rads-r)>0)[0][0]-1
            for pv in PVRS:
                radii[date][pv][q,loc] += datadi[date][pv][i,x]
220/22:
rp = dict()
for q, date in enumerate(datadi.keys()):
    for pv in PVRS:
        if q==0:
           rp[pv] = radii[date][pv]
        else:
            rp[pv] = np.concatenate((rp[pv],radii[date][pv]),axis=0)
220/23: rp[pv].shape
220/24: rads
220/25: pv
220/26: np.mean(rp[pv],axis=0)
220/27: np.mean(rp['PVRCONVT'],axis=0)
220/28: %save -r process-distance.py 1-999
221/1: import numpy as np
221/2: import pickle
221/3: ls traj/use/*data*
221/4: f = open('traj/use/PV-data-dPSP-100-ZB-800.txt','rb')
221/5: PVdata = pickle.load(f)
221/6: dipv = PVdata['dipv']
221/7:
adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

for d in dipv.keys():
    PV = PVdata['datadi'][d]['PV']
    i = np.where(PV[:,0]>=0.75)[0]
    pvend = PV[i,0]
    pvstart = PV[i,-1]
    cypv = dipv[d][c][i,0]
    enpv = dipc[d][e][i,0]
    adv = np.append(adv,pvstart/pvend)
    cyc = np.append(cyc,cypv/pvend)
    env = np.append(env,enpv/pvend)
221/8:
adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

for d in dipv.keys():
    PV = PVdata['rawdata'][d]['PV']
    i = np.where(PV[:,0]>=0.75)[0]
    pvend = PV[i,0]
    pvstart = PV[i,-1]
    cypv = dipv[d][c][i,0]
    enpv = dipc[d][e][i,0]
    adv = np.append(adv,pvstart/pvend)
    cyc = np.append(cyc,cypv/pvend)
    env = np.append(env,enpv/pvend)
221/9:
adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

for d in dipv.keys():
    PV = PVdata['rawdata'][d]['PV']
    i = np.where(PV[:,0]>=0.75)[0]
    pvend = PV[i,0]
    pvstart = PV[i,-1]
    cypv = dipv[d][c][i,0]
    enpv = dipv[d][e][i,0]
    adv = np.append(adv,pvstart/pvend)
    cyc = np.append(cyc,cypv/pvend)
    env = np.append(env,enpv/pvend)
221/10: adv
221/11: cyc[np.where(adv<0.5)]
221/12: env[np.where(adv<0.5)]
221/13: len(env[np.where(adv<0.5)])
221/14: np.mean(adv)
221/15: np.mean(cyc)
221/16: np.mean(env)
221/17: np.mean(cyc[np.where(adv<0.5)])
221/18: np.mean(cyc[np.where(adv<0.3)])
221/19: np.mean(cyc[np.where(adv<0.2)])
221/20: np.mean(env[np.where(adv<0.2)])
221/21: %save -r traj-cyc-env-adv.py 1-999
222/1:
import numpy as np
import pickle
import os
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'
222/2: dipv['20171203_00-011']
222/3: dipv['20171203_00-014']
222/4: dipv['20171203_00-014'][c].keys()
223/1:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


import itertools
from matplotlib.cbook import _reshape_2D
import matplotlib.pyplot as plt
import numpy as np

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
223/2: cyc = np.array([])
223/3: env = np.array([])
223/4:
c = 'cyc'
e = 'env'
for q,k in enumerate(dipv.keys()):
    i = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    if q==0:
        cyc = dipv[k][c][i]
        env = dipv[k][e][i]
    else:
        cyc = np.concatenate((cyc,dipv[k][c][i]),axis=0)
        env = np.concatenate((env,dipv[k][e][i]),axis=0)
223/5: len(cyc[:,0])
223/6: cym = np.mean(cyc,axis=0)
223/7: enm = np.mean(env,axis=0)
223/8: cym
223/9: t = np.flip(np.arange(-48,1))
223/10: fig,ax = plt.subplots()
223/11: ax.plot(t,cym,color='k')
223/12: ax.plot(t,enm,color='k',linestyle=':')
223/13: fig.show()
223/14: ax.set_xlim(-48,0)
223/15: ax.set_xlabel('time to mature stage [h]')
223/16: ax.set_ylabel('PV [PVU]')
223/17: ax.set_xlim(-0.1,1.0)
223/18: ax.set_xlim(-48,0)
223/19: ax.set_ylim(-0.1,1.0)
223/20: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/av-env-cyc-contribution.png',dpi=300,bbox_inches="tight")
223/21: plt.close('all')
223/22: fig,ax = plt.subplots()
223/23: ax.set_xlim(-48,0)
223/24: ax.set_xlabel('time to mature stage [h]')
223/25: ax.set_ylabel('PV [PVU]')
223/26: ax.set_ylim(-0.1,1.0)
223/27: ax.set_xticks(ticks=np.arange(-48,1,6))
223/28: ax.plot(t,cym,color='k')
223/29: ax.plot(t,enm,color='k',linestyle=':')
223/30: ax.tick_params(labelright=False,right=True)
223/31: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/av-env-cyc-contribution.png',dpi=300,bbox_inches="tight")
223/32: cym[0] + enm[0]
223/33: plt.close()
223/34:
c = 'cyc'
e = 'env'
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
aa = 0
for qq,k in enumerate(dipv.keys()):
    q = np.where(avaID==int(k))[0][0]
    if hourstoSLPmin[q][0]>-6:
        continue
    
    i = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    if aa==0:
        cyc6h = dipv[k][c][i]
        env6h = dipv[k][e][i]
        cyc6hm = np.mean(dipv[k][c][i],axis=0)
        env6hm = np.mean(dipv[k][e][i],axis=0)
        aa+=1
    else:
        cyc6h = np.concatenate((cyc6h,dipv[k][c][i]),axis=0)
        env6h = np.concatenate((env6h,dipv[k][e][i]),axis=0)
        cyc6hm = np.concatenate((cyc6hm,np.mean(dipv[k][c][i],axis=0)),axis=0)
        env6hm = np.concatenate((env6hm,np.mean(dipv[k][e][i],axis=0)),axis=0)
223/35: len(cyc6h)
223/36: len(cyc6hm)
223/37: np.mean(dipv[k][c][i],axis=0)
223/38: np.mean(dipv[k][e][i],axis=0)
223/39: len(cyc6hm[:,0])
223/40: len(cyc6hm[0])
223/41: cyc6hm[0]
223/42: cyc6hm.shape
223/43: np.concatenate((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)),axis=0)
223/44: np.concatenate((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)),axis=1)
223/45: np.concatenate((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0),axis=0))
223/46: np.concatenate((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)),axis=0)
223/47: len(np.concatenate((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)),axis=0))
223/48: np.vstack((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)),axis=0)
223/49: np.vstack((np.mean(dipv[k][c][i],axis=0),np.mean(dipv[k][c][i],axis=0)))
223/50:
aa = 0
for qq,k in enumerate(dipv.keys()):
    q = np.where(avaID==int(k))[0][0]
    if hourstoSLPmin[q][0]>-6:
        continue
    
    i = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    if aa==0:
        cyc6h = dipv[k][c][i]
        env6h = dipv[k][e][i]
        cyc6hm = np.mean(dipv[k][c][i],axis=0)
        env6hm = np.mean(dipv[k][e][i],axis=0)
        aa+=1
    else:
        cyc6h = np.vstack((cyc6h,dipv[k][c][i]))
        env6h = np.vstack((env6h,dipv[k][e][i]))
        cyc6hm = np.vstack((cyc6hm,np.mean(dipv[k][c][i],axis=0)))
        env6hm = np.vstack((env6hm,np.mean(dipv[k][e][i],axis=0)))
223/51: plt.close('all')
223/52: fig,ax = plt.subplots()
223/53: t
223/54: cyc6hmm = np.mean(cyc6hm,axis=0)
223/55: env6hmm = np.mean(env6hm,axis=0)
223/56: cy6h = np.mean(cyc6h,axis=0)
223/57: en6h = np.mean(env6h,axis=0)
223/58: ax.plot(t,cyc6hmm,color='grey')
223/59: ax.plot(t,env6hmm,color='grey',ls=':')
223/60: ax.plot(t,cy6h,color='k')
223/61: ax.plot(t,en6h,color='k',ls=':')
223/62: ax.set_xlabel('time to mature stage [h]')
223/63: ax.set_ylabel('PV [PVU]')
223/64: ax.set_xlim(-48,0)
223/65: ax.set_ylim(-0.1,1.0)
223/66: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/av-env-cyc-contribution-6h.png',dpi=300,bbox_inches="tight")
223/67: plt.close('all')
223/68: fig,ax = plt.subplots()
223/69: ax.plot(t,cy6h,color='k')
223/70: ax.plot(t,en6h,color='k',ls=':')
223/71: ax.set_xlabel('time to mature stage [h]')
223/72: ax.set_ylabel('PV [PVU]')
223/73: ax.set_xlim(-48,0)
223/74: ax.set_ylim(-0.1,1.0)
223/75: ax.tick_params(labelright=False,right=True)
223/76: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/av-env-cyc-contribution-6h.png',dpi=300,bbox_inches="tight")
223/77: ax.set_xticks(ticks=np.arange(-48,1,6))
223/78: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/av-env-cyc-contribution-6h.png',dpi=300,bbox_inches="tight")
224/1:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


import itertools
from matplotlib.cbook import _reshape_2D
import matplotlib.pyplot as plt
import numpy as np

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
224/2:
aa = 0
c = 'cyc'
e = 'env'
pvloc = dict()
pvloe = dict()
pvl6c = dict()
pvl6e = dict()
for h in range(0,49):
    pvloc[h] =np.array([])
    pvloe[h] =np.array([])
    pvl6e[h] =np.array([])
    pvl6c[h] =np.array([])
    
for qq,k in enumerate(dipv.keys()):
    q = np.where(avaID==int(k))[0][0]
    i = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    if hourstoSLPmin[q][0]>-6:
        for h in range(0,49):
         pvloc[h] = np.append(pvloc[h],dipv[k][c][i,h])
         pvloe[h] = np.append(pvloe[h],dipv[k][e][i,h])        
        continue
    for h in range(0,49):
        pvl6c[h] = np.append(pvloc[h],dipv[k][c][i,h])
        pvl6e[h] = np.append(pvloc[h],dipv[k][e][i,h])
224/3:
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
224/4:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
224/5:
aa = 0
c = 'cyc'
e = 'env'
pvloc = dict()
pvloe = dict()
pvl6c = dict()
pvl6e = dict()
for h in range(0,49):
    pvloc[h] =np.array([])
    pvloe[h] =np.array([])
    pvl6e[h] =np.array([])
    pvl6c[h] =np.array([])
    
for qq,k in enumerate(dipv.keys()):
    q = np.where(avaID==int(k))[0][0]
    i = np.where(PVdata['rawdata'][k]['PV'][:,0]>=0.75)[0]
    if hourstoSLPmin[q][0]>-6:
        for h in range(0,49):
         pvloc[h] = np.append(pvloc[h],dipv[k][c][i,h])
         pvloe[h] = np.append(pvloe[h],dipv[k][e][i,h])        
        continue
    for h in range(0,49):
        pvl6c[h] = np.append(pvloc[h],dipv[k][c][i,h])
        pvl6e[h] = np.append(pvloc[h],dipv[k][e][i,h])
224/6: t = np.flip(np.arange(-48,1))
224/7: fig,ax = plt.subplots()
224/8:
boxpvc = []
boxpve = []
boxpv6c = []
boxpv6e = []
for h in np.flip(np.arange(0,49)):
    boxpvc.append(np.sort(pvloc[h]))
    boxpve.append(np.sort(pvloe[h]))
    boxpv6c.append(np.sort(pvl6c[h]))
    boxpv6e.append(np.sort(pvl6e[h]))
224/9:
flier = dict(marker='+',markerfacecolor='grey',markersize=1,linestyle=' ',markeredgecolor='grey')
meanline = dict(linestyle='-',linewidth=1,color='red')

meanline2 = dict(linestyle=':',linewidth=1,color='navy')
capprops = dict(linestyle=':',linewidth=1,color='dodgerblue')
medianprops = dict(linestyle=':',linewidth=1,color='purple')
boxprops = dict(linestyle=':',linewidth=1.,color='slategrey')
whiskerprops= dict(linestyle=':',linewidth=1,color='dodgerblue')


fig,ax = plt.subplots()
ax.set_ylabel(r'PV [PVU]')
ax.set_xlabel(r'time to mature stage [h]')
ax.set_ylim(-.25,2.0)
ax.set_xlim(0,50)
t = np.arange(-48,1)
bp = ax.boxplot(boxpvc,whis=(10,90),labels=t,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True,showfliers=False)
ax.set_xticks(ticks=range(1,len(t)+1,6))
ax.tick_params(labelright=False,right=True)
ax.set_xticklabels(labels=t[0::6])
224/10: bp2 = ax.boxplot(boxpve,whis=(10,90),labels=xx,flierprops=flier,meanprops=meanline2,meanline=True,showmeans=True,showbox=True,showcaps=True,showfliers=False,medianprops=medianprops,capprops=capprops,whiskerprops=whiskerprops,boxprops=boxprops)
224/11: xx = t
224/12: bp2 = ax.boxplot(boxpve,whis=(10,90),labels=xx,flierprops=flier,meanprops=meanline2,meanline=True,showmeans=True,showbox=True,showcaps=True,showfliers=False,medianprops=medianprops,capprops=capprops,whiskerprops=whiskerprops,boxprops=boxprops)
224/13:
ax.set_xticks(ticks=range(1,len(xx)+1))
ax.set_xticklabels(labels=xx)
224/14:
ax.set_xticks(ticks=range(1,len(t)+1,6))
ax.tick_params(labelright=False,right=True)
ax.set_xticklabels(labels=t[0::6])
224/15: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/boxwis-env-cyc-contribution-all.png',dpi=300,bbox_inches="tight")
224/16: plt.close('all')
224/17: fig,ax = plt.subplots()
224/18:
ax.set_ylabel(r'PV [PVU]')
ax.set_xlabel(r'time to mature stage [h]')
ax.set_ylim(-.25,2.0)
ax.set_xlim(0,50)
t = np.arange(-48,1)
bp = ax.boxplot(boxpv6c,whis=(10,90),labels=t,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True,showfliers=False)
ax.set_xticks(ticks=range(1,len(t)+1,6))
ax.tick_params(labelright=False,right=True)
ax.set_xticklabels(labels=t[0::6])
224/19: bp2 = ax.boxplot(boxpv6e,whis=(10,90),labels=xx,flierprops=flier,meanprops=meanline2,meanline=True,showmeans=True,showbox=True,showcaps=True,showfliers=False,medianprops=medianprops,capprops=capprops,whiskerprops=whiskerprops,boxprops=boxprops)
224/20: fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/boxwis-env-cyc-contribution-6h.png',dpi=300,bbox_inches="tight")
224/21: plt.close('all')
224/22: %save -r boxwis-cyc-env.py 1-999
225/1:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
225/2:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
225/3: pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
225/4:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
225/5:
for u,x in enumerate(savings):
    f = open(pload[:-9] + x + 'furthersel-no-kicking.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID2 = np.array([])
for k in range(len(ID)):
    avaID2=np.append(avaID2,ID[k][0].astype(int))
225/6: len(avaID)
225/7: len(avaID2)
225/8: avaID2[:100]
225/9: avaID[:100]
225/10: avaID[300:400]
225/11: avaID2[300:400]
225/12:
var = []
for u,x in enumerate(savings):
    f = open(pload[:-9] + x + 'furthersel-no-kicking.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID2 = np.array([])
for k in range(len(ID)):
    avaID2=np.append(avaID2,ID[k][0].astype(int))
225/13: len(avaID2)
225/14: len(avaID2)-len(avaID)
225/15: sameID = np.array([])
225/16:
for k in avaID:
    if np.any(avaID2==k):
        sameID = np.append(sameID,k)
225/17: len(sameID)
225/18: pwd
225/19: cd traj/use/
225/20: np.savetxt('trustyIDs.txt',sameID.astype(int),fmt='%i',delimiter=' ',newline='\n')
225/21: sameID = np.array([])
225/22:
diID = np.array([])
for k in avaID2:
    if np.any(avaID==k):
        sameID = np.append(sameID,k)
    else:
        diID = np.append(diID,k)
225/23: len(diID)
225/24: len(sameID)
225/25:
for a,k in enumerate(diID):
    q = np.where(avaID2==k)[0][0]
    if a%50=0:
        fig,ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
225/26:
for a,k in enumerate(diID):
    q = np.where(avaID2==k)[0][0]
    if a%50=0:
        fig,ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
225/27:
for a,k in enumerate(diID):
    q = np.where(avaID2==k)[0][0]
    if a%50==0:
        fig,ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
    ax.plot(lon[q],lat[q],linewidth=1)
    if a%50==49:
        lonticks=np.arange(-10, 51,10)
        latticks=np.arange(25,51,5)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)
        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([-10,51,25,51], ccrs.PlateCarree())
        fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/kicked-tracks-%i.png'%k,dpi=300,bbox_inches="tight")
        plt.close('all')
225/28:
import matplotlib
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
225/29:
for a,k in enumerate(diID):
    q = np.where(avaID2==k)[0][0]
    if a%50==0:
        fig,ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
        ax.coastlines()
    ax.plot(lon[q],lat[q],linewidth=1)
    if a%50==49:
        lonticks=np.arange(-10, 51,10)
        latticks=np.arange(25,51,5)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks,fontsize=6)
        ax.set_yticklabels(labels=latticks,fontsize=6)
        ax.xaxis.set_major_formatter(LongitudeFormatter())
        ax.yaxis.set_major_formatter(LatitudeFormatter())
        ax.set_extent([-10,51,25,51], ccrs.PlateCarree())
        fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/kicked-tracks-%i.png'%k,dpi=300,bbox_inches="tight")
        plt.close('all')
225/30:
var = []
for u,x in enumerate(savings):
    f = open(pload[:-9] + x + 'furthersel-no-kicking.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID3 = np.array([])
for k in range(len(ID)):
    avaID3=np.append(avaID3,ID[k][0].astype(int))
225/31: len(avaID3)
225/32: len(avaID2)
225/33:
var = []
for u,x in enumerate(savings):
    f = open(pload[:-9] + x + 'furthersel-no-kicking.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID3 = np.array([])
for k in range(len(ID)):
    avaID3=np.append(avaID3,ID[k][0].astype(int))
225/34: len(avaID3)
225/35:
diID = np.array([])
sameID = np.array([])
for k in avaID3:
    if np.any(avaID==k):
        sameID = np.append(sameID,k)
    else:
        diID = np.append(diID,k)
225/36: len(diID)
225/37: np.savetxt('trustyIDs.txt',sameID.astype(int),fmt='%i',delimiter=' ',newline='\n')
225/38: np.savetxt('diffIDs.txt',sameID.astype(int),fmt='%i',delimiter=' ',newline='\n')
225/39: diID
225/40: np.savetxt('diffIDs.txt',diID.astype(int),fmt='%i',delimiter=' ',newline='\n')
226/1: -46%6
226/2: -42%6
227/1:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


import itertools
from matplotlib.cbook import _reshape_2D
import matplotlib.pyplot as plt
import numpy as np

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
dit = PVdata['dit']
227/2:
c = 'cyc'
e = 'env'
227/3:
f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW.txt','rb')
locdata =  pickle.load(f)
f.close()

MON = np.array([])
for d in os.listdir(pload[:-4]):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)
MON = np.sort(MON)
PVstart = np.array([])
PVend = np.array([])
227/4:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>3:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
227/5:
pvloc = dict()
ac = dict()
pressuredi = dict()
for h in np.arange(0,49):
    pvloc[h] = np.array([])


CYM = np.array([])
227/6:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>3:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
227/7:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>3:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
    for h in i:
        cyid = np.where(dit[d][c][h]==0)[0][0]
    print(cyid)
227/8: dit[d][c][h]
227/9: cyid
227/10: np.where(dit[d][c][h]==0)
227/11: np.where(dit[d][c][h]==0)[0][0]
227/12: dit[d][c].shape
227/13: i
227/14: len(i)
227/15: h
227/16:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>1:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
    for h in i[:10]:
        print(h,dit[d][c][h]]
        cyid = np.where(dit[d][c][h]==0)[0][0]
        print(cyid)
227/17:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>1:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
    for h in i[:10]:
        print(h,dit[d][c][h])
        cyid = np.where(dit[d][c][h]==0)[0][0]
        print(cyid)
227/18:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>1:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
    for we in i[:10]:
        print(we,dit[d][c][we])
        cyid = np.where(dit[d][c][we]==0)[0][0]
        print(cyid)
227/19: i[:10]
227/20:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>0:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    print(len(i))
    for we in i[:10]:
        print(we,dit[d][c][we])
        cyid = np.where(dit[d][c][we]==0)[0][0]-1
        print(cyid)
227/21: i[:10]
227/22:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>0:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    
    for we in i[:10]:
        cyid = np.where(dit[d][c][we]==0)[0][0]-1
        tn = np.flip(np.arange(-48,1))-np.flip(np.arange(-48,1))[cyid]
        print(cyid,tn)
227/23:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>0:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    
    for we in i[:10]:
        cyid = np.where(dit[d][c][we]==0)[0][0]-1
        tn = np.flip(np.arange(-48,1))-np.flip(np.arange(-48,1))[cyid]
        for a,b in enumerate(tn):
            ac[d][b] = np.append(ac[d][b],PV[i,a])
        print(len(ac[d][b]))
227/24:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>0:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    
    for we in i[:10]:
        cyid = np.where(dit[d][c][we]==0)[0][0]-1
        tn = np.flip(np.arange(-48,1))-np.flip(np.arange(-48,1))[cyid]
        for a,b in enumerate(tn):
            ac[d][b] = np.append(ac[d][b],PV[we,a])
        print(len(ac[d][b]))
227/25:
for q,d in enumerate(dipv.keys()):
    ac[d] = dict()
    pressuredi[d] = dict()
    for h in np.arange(-48,49):
        ac[d][h] = np.array([])
        pressuredi[d][h] = np.array([])
    if q>0:
        break

    mon = MON[q][-9:-4:]
    ids = int(d[-3:])
    if (locdata[mon][ids]['hzeta'][0]>-6):
        continue

    OL = PVdata['rawdata'][d]['OL']
    PV = PVdata['rawdata'][d]['PV']
    pre = PVdata['rawdata'][d]['P']
    i = np.where(PV[:,0]>=0.75)[0]
    
    for we in i[:10]:
        cyid = np.where(dit[d][c][we]==0)[0][0]-1
        tn = np.flip(np.arange(-48,1))-np.flip(np.arange(-48,1))[cyid]
        for a,b in enumerate(tn):
            ac[d][b] = np.append(ac[d][b],PV[we,a])
            pressuredi[d][b] = np.append(pressuredi[d][b],pre[we,a])
        print(len(ac[d][b]))
228/1:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


import itertools
from matplotlib.cbook import _reshape_2D
import matplotlib.pyplot as plt
import numpy as np

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
dit = PVdata['dit']

adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW.txt','rb')
locdata =  pickle.load(f)
f.close()
228/2: datadi = PVdata['rawdata']
228/3:
for d in datadi.keys():
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
228/4:
for d in datadi.keys():
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d][x]==0)[0][0]
        if k>=12:
            print(d,x)
228/5: d
228/6: x
228/7:
for d in datadi.keys():
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==0)[0][0]
        if k>=12:
            print(d,x)
228/8:
for d in datadi.keys():
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==0)[0][0]
        if k>=30:
            print(d,x)
228/9:
for q,d in enumerate(datadi.keys()):
    if q>4:
        break
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==0)[0][0]
        if k>=30:
            print(d,x)
228/10: cyctrajid = 1004
228/11:
for q,d in enumerate(datadi.keys()):
    if q>4:
        break
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==1)[0][-1]
        if k<=6:
            print(d,x)
228/12: envtrajid = 195
228/13:
for q,d in enumerate(datadi.keys()):
    if q>3:
        break
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==1)[0][-1]
        if k<=2:
            print(d,x)
228/14:
for q,d in enumerate(datadi.keys()):
    if q>3:
        break
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==1)[0][-1]
        if k<=3:
            print(d,x)
228/15: envtrajid = 194
228/16:
for q,d in enumerate(datadi.keys()):
    if q>3:
        break
    i = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    for x in i:
        k = np.where(dit[d]['cyc'][x]==1)[0][-1]
        if k<=12:
            print(d,x)
228/17: bothtrajid = 1308
228/18: cyctrajid
228/19: envtrajid
228/20: bothtrajid
228/21: trajids = np.array([cyctrajid,envtrajid,bothtrajid])
228/22: trajids
228/23:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
228/24: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
228/25: colors = ['red','blue','grey']
228/26:
ax.coastlines()
for q,k in enumerate(trajids):
    ax.plot(datadi['20171214_02-073']['lon'][k],datadi['20171214_02-073']['lat'][k],color=colors[q])
228/27: locdata.keys()
228/28: locdata['DEC17'][73].keys()
228/29: locdata['DEC17'][73]['clat']
228/30: LON = np.linspace(-180,180,901)
228/31: LAT = np.linspace(0,90,226)
228/32: lon = np.mean(locdata['DEC17'][73]['clon'],axis=1)
228/33: lat = np.mean(locdata['DEC17'][73]['clat'],axis=1)
228/34: ax.plot(LON[lon],LAT[lat],color='orange')
228/35: ax.plot(LON[lon.astype(int)],LAT[lat.astype(int)],color='orange')
228/36: plt.show()
229/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
229/2:
import numpy as np
import pickle
import os
import matplotlib
from matplotlib import pyplot as plt
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper


import itertools
from matplotlib.cbook import _reshape_2D
import matplotlib.pyplot as plt
import numpy as np

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
dit = PVdata['dit']

adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW.txt','rb')
locdata =  pickle.load(f)
f.close()
229/3: cyctrajid = 1004
229/4:
envtrajid = 194

bothtrajid = 1308
229/5: trajids = np.array([cyctrajid,envtrajid,bothtrajid])
229/6: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
229/7: colors = ['red','blue','grey']
229/8: ax.coastlines()
229/9: LON = np.linspace(-180,180,901)
229/10: LAT = np.linspace(0,90,226)
229/11: lon = np.mean(locdata['DEC17'][73]['clon'],axis=1)
229/12: lat = np.mean(locdata['DEC17'][73]['clat'],axis=1)
229/13: ax.plot(LON[lon.astype(int)],LAT[lat.astype(int)],color='orange')
229/14: lonticks = np.arange(5,50.1,5)
229/15: latticks = np.arange(20,50.1,5)
229/16:
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)
229/17:
ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
229/18: ax.set_extent([5,50,20,50], ccrs.PlateCarree())
229/19: ax.legend(['cyclonic traj','environmental traj','cyc & env traj','cyclone track'],boxon=False)
229/20: ax.legend(['cyclonic traj','environmental traj','cyc & env traj','cyclone track'],box=False)
229/21: ax.legend(['cyclonic traj','environmental traj','cyc & env traj','cyclone track'],frameon=False)
229/22: plt.show()
229/23: plt.close()
229/24: fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
229/25:
for q,k in enumerate(trajids):
    ax.plot(datadi['20171214_02-073']['lon'][k],datadi['20171214_02-073']['lat'][k],color=colors[q])
229/26: datadi = PVdata['rawdata']
229/27:
for q,k in enumerate(trajids):
    ax.plot(datadi['20171214_02-073']['lon'][k],datadi['20171214_02-073']['lat'][k],color=colors[q])
229/28: ax.plot(LON[lon.astype(int)],LAT[lat.astype(int)],color='orange')
229/29: ax.coastlines()
229/30:
ax.set_xticks(lonticks, crs=ccrs.PlateCarree());
ax.set_yticks(latticks, crs=ccrs.PlateCarree());
ax.set_xticklabels(labels=lonticks,fontsize=10)
ax.set_yticklabels(labels=latticks,fontsize=10)

ax.xaxis.set_major_formatter(LongitudeFormatter())
ax.yaxis.set_major_formatter(LatitudeFormatter())
229/31: ax.set_extent([5,50,20,50], ccrs.PlateCarree())
229/32: ax.legend(['cyclonic traj','environmental traj','cyc & env traj','cyclone track'],frameon=False)
229/33: plt.show()
230/1: %history -g
230/2: %history -g > history.txt
230/3: ls
230/4: cd ../
230/5: ls -lrt
230/6: %history -g > history.txt
230/7: ls -lrt
230/8: %history -g -f history.txt
231/1: %history -g -f /atmosdyn2/ascherrmann/history.txt
232/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from matplotlib import cm
from scipy.stats.stats import pearsonr
import pickle

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

datadi = PVdata['rawdata']


both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
minSLP = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    minSLP = np.append(minSLP,SLP[k][abs(hourstoSLPmin[k][0]).astype(int)])


pvival = np.array([-100,0.2,0.5,0.75,100])

anomaly = dict()
mature = dict()
layercounter = dict()
cycc =0

pinvals = np.arange(700,925.1,12.5)
plvlcounter = dict()

SPV = np.array([])
sLPV = np.array([])
PVmax = np.array([])
PVav = np.array([])
PVLav = np.array([])
PVmin = np.array([])
nT = np.array([])
nP  = np.array([])
SLPs = np.array([])
232/2:
for ll,k in enumerate(datadi.keys()):
    q = np.where(avaID==int(k))[0][0]
    d = k

    if (hourstoSLPmin[q][0]>-6):
        continue

    PV = datadi[d]['PV'][:,0]
    i = np.where(PV>=0.75)[0]

    SPV = np.append(SPV,np.sum(PV))
    sLPV = np.append(sLPV,np.sum(PV[i]))
    nP = np.append(nP,len(PV))
    nT = np.append(nT,len(i))
    PVmax = np.append(PVmax,np.max(PV))
    PVmin = np.append(PVmin,np.min(PV))
    PVav = np.append(PVav,np.mean(PV))
    PVLav = np.append(PVLav,np.mean(PV[i]))
    SLPs = np.append(SLPs,minSLP[q])


order = np.argsort(SLPs)
SLPs2 = SLPs[order]
SPV = SPV[order]
sLPV = sLPV[order]
PVmax = PVmax[order]
PVav = PVav[order]
PVLav =PVLav[order]
PVmin =PVmin[order]
nT = nT[order]
nP  = nP[order]
232/3: k
232/4: len(SPV)
232/5: fig, ax = plt.subplots()
232/6: ax.plot(SLPs2,SPV)
232/7: fig.show()
232/8: print(pearsonr(SLPs2,SPV))
232/9: print(pearsonr(SLPs2,sLPV))
232/10: print(pearsonr(SLPs2,nP))
232/11: print(pearsonr(SLPs2,nT))
232/12: print(pearsonr(SLPs2,PVmin))
232/13: print(pearsonr(SLPs2,PVmax))
232/14: print(pearsonr(SLPs2,PVav))
232/15: print(pearsonr(SLPs2,PVLav))
232/16: PVLav
232/17: np.where(PVLav>100)
232/18: np.where(PVLav=np.nan)
232/19: np.where(PVLav==np.nan)
232/20: PVLav
232/21: print(pearsonr(SLPs2,PVLav))
232/22: plt.close()
232/23: fig.show()
232/24: fig, ax = plt.subplots()
232/25: ax.plot(SLPs2,PVLav)
232/26: fig.show()
232/27: np.sum(PVLav)
232/28: PVLav.isnan
232/29: np.isnan(PVLav)
232/30: PVLav[np.isnan(PVLav)]
232/31: PVLav[np.isnan(PVLav)] =0
232/32: print(pearsonr(SLPs2,PVLav))
232/33:
SPV = np.array([])
sLPV = np.array([])
PVmax = np.array([])
PVav = np.array([])
PVLav = np.array([])
PVmin = np.array([])
nT = np.array([])
nP  = np.array([])
SLPs = np.array([])

for ll,k in enumerate(datadi.keys()):
    q = np.where(avaID==int(k))[0][0]
    d = k

    if (hourstoSLPmin[q][0]>-6):
        continue

    PV = datadi[d]['PV'][:,0]
    P = datadi[d]['P'][:,0]
    i = np.where((PV>=0.75) & (P<925))[0]
    i2 = np.where(P<925)[0]

    SPV = np.append(SPV,np.sum(PV))
    sLPV = np.append(sLPV,np.sum(PV[i]))
    nP = np.append(nP,len(i2))
    nT = np.append(nT,len(i))
    PVmax = np.append(PVmax,np.max(PV))
    PVmin = np.append(PVmin,np.min(PV))
    PVav = np.append(PVav,np.mean(PV))
    PVLav = np.append(PVLav,np.mean(PV[i]))
    SLPs = np.append(SLPs,minSLP[q])


order = np.argsort(SLPs)
SLPs2 = SLPs[order]
SPV = SPV[order]
sLPV = sLPV[order]
PVmax = PVmax[order]
PVav = PVav[order]
PVLav =PVLav[order]
PVmin =PVmin[order]
nT = nT[order]
nP  = nP[order]
232/34: print(pearsonr(SLPs2,PVLav))
232/35: PVLav[np.isnan(PVLav)] =0
232/36: print(pearsonr(SLPs2,PVLav))
232/37: plt.close('all')
232/38: fig, ax = plt.subplots()
232/39: ax.plot(SLPs2,SPV,color='k')
232/40: ax.plot(SLPs2,sLPV,color='r')
232/41: fig.show()
232/42: plt.close('all')
232/43:
SPV = np.array([])
sLPV = np.array([])
PVmax = np.array([])
PVav = np.array([])
PVLav = np.array([])
PVmin = np.array([])
nT = np.array([])
nP  = np.array([])
SLPs = np.array([])

for ll,k in enumerate(datadi.keys()):
    q = np.where(avaID==int(k))[0][0]
    d = k

    if (hourstoSLPmin[q][0]>-6):
        continue

    PV = datadi[d]['PV'][:,0]
    P = datadi[d]['P'][:,0]
    PV[np.where(PV<-4)]=0
    i = np.where((PV>=0.75) & (P<925))[0]
    i2 = np.where(P<925)[0]

    SPV = np.append(SPV,np.sum(PV))
    sLPV = np.append(sLPV,np.sum(PV[i]))
    nP = np.append(nP,len(i2))
    nT = np.append(nT,len(i))
    PVmax = np.append(PVmax,np.max(PV))
    PVmin = np.append(PVmin,np.min(PV))
    PVav = np.append(PVav,np.mean(PV))
    PVLav = np.append(PVLav,np.mean(PV[i]))
    SLPs = np.append(SLPs,minSLP[q])


order = np.argsort(SLPs)
SLPs2 = SLPs[order]
SPV = SPV[order]
sLPV = sLPV[order]
PVmax = PVmax[order]
PVav = PVav[order]
PVLav =PVLav[order]
PVmin =PVmin[order]
nT = nT[order]
nP  = nP[order]
232/44: fig, ax = plt.subplots()
232/45: ax.plot(SLPs2,SPV,color='k')
232/46: ax.plot(SLPs2,sLPV,color='r')
232/47: fig.show()
232/48: np.max(nT)
232/49: np.min(nT)
232/50: np.where(nT==0)
232/51: np.mean(nT/nP)
232/52: np.max(nT/nP)
232/53: np.min(nT/nP)
233/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
import pickle

pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

CT = 'MED'

f = open(pload + 'PV-data-' + CT + 'dPSP-100-ZB-800PVedge-0.3.txt','rb')
data = pickle.load(f)
f.close()
labs = helper.traced_vars_IFS()
dipv = data['dipv']
dit = data['dit']

resev = dict()
cycres = dict()
envres =dict()

for h in range(0,49):
    resev[h] = np.array([])
    cycres[h] = np.array([])
    envres[h]= np.array([])

boxres = []
cycboxres = []
envboxres = []
233/2:
for q,date in enumerate(data['rawdata'].keys()):
    if q>0:
        break
    PVf = data['rawdata'][date]['PV']
    datadi = data['rawdata']
    idp = np.where(PVf[:,0]>=0.75)[0]
#    APVTOT = np.zeros(data['rawdata'][date]['PV'].shape)
#    for pv in labs[8:]:
#        APVTOT[:,1:] +=np.cumsum(data['rawdata'][date][pv][:,1:],axis=1)

#    res = (APVTOT[idp,:]) - (PVf[idp,:]*(-1.) + PVf[idp,0][:,None])
    res = (dipv[date]['env']['APVTOT'][idp,:] + dipv[date]['cyc']['APVTOT'][idp,:])-(PVf[idp,:]-PVf[idp,-1][:,None])
    PV = np.mean(PVf[idp,:],axis=0)

    datadi[date]['DELTAPV'] = np.zeros(datadi[date]['PV'].shape)
    datadi[date]['DELTAPV'][:,1:] = datadi[date]['PV'][:,:-1]-datadi[date]['PV'][:,1:]
    datadi[date]['RES'] = np.zeros(datadi[date]['PV'].shape)

    datadi[date]['PVRTOT'] = np.zeros(datadi[date]['PV'].shape)
    for pv in labs[8:]:
        datadi[date]['PVRTOT']+=datadi[date][pv]

    datadi[date]['RES'][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date]['PVRTOT'][:,1:],axis=1),axis=1),axis=1)-np.flip(np.cumsum(np.flip(datadi[date]['DELTAPV'][:,1:],axis=1),axis=1),axis=1)
233/3: date
233/4: datedi[date]['RES']
233/5: datadi[date]['RES']
233/6:
for q,date in enumerate(data['rawdata'].keys()):
    if q>0:
        break
    PVf = data['rawdata'][date]['PV']
    datadi = data['rawdata']
    idp = np.where(PVf[:,0]>=0.75)[0]
#    APVTOT = np.zeros(data['rawdata'][date]['PV'].shape)
#    for pv in labs[8:]:
#        APVTOT[:,1:] +=np.cumsum(data['rawdata'][date][pv][:,1:],axis=1)

#    res = (APVTOT[idp,:]) - (PVf[idp,:]*(-1.) + PVf[idp,0][:,None])
    res = (dipv[date]['env']['APVTOT'][idp,:] + dipv[date]['cyc']['APVTOT'][idp,:])-(PVf[idp,:]-PVf[idp,-1][:,None])
    PV = np.mean(PVf[idp,:],axis=0)

    datadi[date]['DELTAPV'] = np.zeros(datadi[date]['PV'].shape)
    datadi[date]['DELTAPV'][:,1:] = datadi[date]['PV'][:,:-1]-datadi[date]['PV'][:,1:]
    datadi[date]['RES'] = np.zeros(datadi[date]['PV'].shape)

    datadi[date]['PVRTOT'] = np.zeros(datadi[date]['PV'].shape)
    for pv in labs[8:]:
        datadi[date]['PVRTOT']+=datadi[date][pv]

    datadi[date]['RES'][:,:-1] = np.flip(np.cumsum(np.flip(datadi[date]['PVRTOT'][:,1:],axis=1),axis=1),axis=1)-np.flip(np.cumsum(np.flip(datadi[date]['DELTAPV'][:,1:],axis=1),axis=1),axis=1)
    if q==0:
        break
233/7: date
233/8: dit[date]['cyc'][idp,0]
233/9: dit[date]['cyc'][idp,0][dit[date]['cyc'][idp,0]==1]
233/10: dit[date]['cyc'][idp,10][dit[date]['cyc'][idp,0]==1]
233/11: dit[date]['cyc'][idp,10][dit[date]['cyc'][idp,0]!=1]
233/12: dit[date]['cyc'][idp,10][dit[date]['cyc'][idp,10]!=1]
233/13: a = dit[date]['cyc'][idp,10]
233/14: a
233/15: a[a!=0]
233/16: res = datadi[date]['RES'][idp,10]
233/17: res
233/18: res[a[a!=0]]
233/19: res[a!=0]
234/1:
import numpy as np
import pickle

CT = 'MED'
pload ='/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()
datadi = data['rawdata']
dipv = data['dipv']
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    lv = np.linspace(minval,maxval,nlevels)
    norm = BoundaryNorm(lv,cmap.N)
    return newmap, norm

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

if CT=='MED':
    minpltlonc = -5
    maxpltlonc = 45
    minpltlatc = 30
    maxpltlatc = 50
    steps = 5
lonticks=np.arange(minpltlonc+5, maxpltlonc+1,steps*2)
latticks=np.arange(minpltlatc, maxpltlatc+1,steps)

apl = cm.seismic
minv = -1.5 #* 100
mav = 1.5 #* 100
steps = 0.25 #* 100
lvls = np.arange(minv,(mav+0.000001),steps)

cmap,norm = colbar(apl,minv,mav,len(lvls))
cmap.set_under('black')
cmap.set_over('darkorange')
#for  k in range(48,80):
for k in range(110,160):
    cmap.colors[k] = np.array([189/256, 195/256, 199/256, 1.0])
234/2: cmap
234/3: cmap.colors
234/4: cmap(1)
234/5: cmap(0)
234/6: cmap(100)
234/7: cmap(0)
234/8: cmap.colors[0]
234/9: len(cmap.colors)
234/10: np.linspace(-1.5,1.5,256)
235/1:
import numpy as np
import pickle

CT = 'MED'
pload ='/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800.txt','rb')
data = pickle.load(f)
f.close()
datadi = data['rawdata']
dipv = data['dipv']
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    lv = np.linspace(minval,maxval,nlevels)
    norm = BoundaryNorm(lv,cmap.N)
    return newmap, norm

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

if CT=='MED':
    minpltlonc = -5
    maxpltlonc = 45
    minpltlatc = 30
    maxpltlatc = 50
    steps = 5
lonticks=np.arange(minpltlonc+5, maxpltlonc+1,steps*2)
latticks=np.arange(minpltlatc, maxpltlatc+1,steps)

apl = cm.seismic
minv = -1.5 #* 100
mav = 1.5 #* 100
steps = 0.25 #* 100
lvls = np.arange(minv,(mav+0.000001),steps)
sp = np.linspace(-1.5,1.5,256)

cmap,norm = colbar(apl,minv,mav,len(lvls))
cmap.set_under('black')
cmap.set_over('darkorange')
#for  k in range(48,80):
for k in range(110,160):
    cmap.colors[k] = np.array([189/256, 195/256, 199/256, 1.0])
#print(cmap(1))
#print(cmap(100))

labels = ['a)','b)','c)','d)','e)','f)']

proc = ['PVR-T','PVR-T','PVRTURBM','PVRLS','PVRLWH','PVRLWC']
lab = ['CONVT','TURBT','TURBM','LS','LWH','LWC']
235/2: np.mean(dipv['20171214_02-073']['cyc']['APVTOT'][:,0])
235/3: np.mean(dipv['20171214_02-073']['cyc']['LS'][:,0])
235/4: np.mean(dipv['20171214_02-073']['cyc']['PVRLS'][:,0])
235/5: ids = np.where(datadi['20171214_02-073']['PV'][:,0]>=0.75)
235/6: ids = np.where(datadi['20171214_02-073']['PV'][:,0]>=0.75)[0]
235/7: np.mean(dipv['20171214_02-073']['cyc']['PVRLS'][idp,0])
235/8: np.mean(dipv['20171214_02-073']['cyc']['PVRLS'][ids,0])
235/9: len(ids)
236/1:
import numpy as np
import pickle

CT = 'MED'
pload ='/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3.txt','rb')
data = pickle.load(f)
f.close()
datadi = data['rawdata']
dipv = data['dipv']
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    lv = np.linspace(minval,maxval,nlevels)
    norm = BoundaryNorm(lv,cmap.N)
    return newmap, norm

LON=np.linspace(-180,180,901)
LAT=np.linspace(0,90,226)

if CT=='MED':
    minpltlonc = -5
    maxpltlonc = 45
    minpltlatc = 30
    maxpltlatc = 50
    steps = 5
lonticks=np.arange(minpltlonc+5, maxpltlonc+1,steps*2)
latticks=np.arange(minpltlatc, maxpltlatc+1,steps)

apl = cm.seismic
minv = -1.0 #* 100
mav = 1.0 #* 100
steps = 0.25 #* 100
lvls = np.arange(minv,(mav+0.000001),steps)
sp = np.linspace(-1.,1.,256)
labs = helper.traced_vars_IFS()
cmap,norm = colbar(apl,minv,mav,len(lvls))
cmap.set_under('black')
cmap.set_over('darkorange')
#for  k in range(48,80):
for k in range(96,160):
    cmap.colors[k] = np.array([189/256, 195/256, 199/256, 1.0])
236/2:
for qq, key in enumerate(['cyc','env']):
 fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
 axes = axes.flatten()

 for q, ax in enumerate(axes[:]):
    ax.coastlines()
    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval=>0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
    ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
    ax.set_yticks(latticks, crs=ccrs.PlateCarree())

    if q%2==0:
        ax.set_yticklabels(labels=latticks,fontsize=10)
        ax.yaxis.set_major_formatter(LatitudeFormatter())
    if q==4 or q==5:
        ax.set_xticklabels(labels=lonticks,fontsize=10)
        ax.xaxis.set_major_formatter(LongitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
    ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
    ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

 cax = fig.add_axes([0.925,0.11,0.0175,0.77])
 cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
 cbar.ax.set_xlabel('PVU')
 for t in cbar.ax.get_yticklabels():
     t.set_fontsize(8)
 plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
 fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + 'cyclones-processes-scatter-traj' + key + '.png',dpi=300,bbox_inches="tight")
 plt.close('all')
236/3:
for qq, key in enumerate(['cyc','env']):
 fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
 axes = axes.flatten()

 for q, ax in enumerate(axes[:]):
    ax.coastlines()
    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval>=0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
    ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
    ax.set_yticks(latticks, crs=ccrs.PlateCarree())

    if q%2==0:
        ax.set_yticklabels(labels=latticks,fontsize=10)
        ax.yaxis.set_major_formatter(LatitudeFormatter())
    if q==4 or q==5:
        ax.set_xticklabels(labels=lonticks,fontsize=10)
        ax.xaxis.set_major_formatter(LongitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
    ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
    ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

 cax = fig.add_axes([0.925,0.11,0.0175,0.77])
 cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
 cbar.ax.set_xlabel('PVU')
 for t in cbar.ax.get_yticklabels():
     t.set_fontsize(8)
 plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
 fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + 'cyclones-processes-scatter-traj' + key + '.png',dpi=300,bbox_inches="tight")
 plt.close('all')
236/4:
labels = ['a)','b)','c)','d)','e)','f)']

proc = ['PVR-T','PVR-T','PVRCONVM','PVRTURBM','PVRLS','APVRAD']#'PVRLWH','PVRLWC']
lab = ['CONVT','TURBT','CONVM','TURBM','LS','RAD']
236/5:
for qq, key in enumerate(['cyc','env']):
 fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
 axes = axes.flatten()

 for q, ax in enumerate(axes[:]):
    ax.coastlines()
    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval>=0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
    ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
    ax.set_yticks(latticks, crs=ccrs.PlateCarree())

    if q%2==0:
        ax.set_yticklabels(labels=latticks,fontsize=10)
        ax.yaxis.set_major_formatter(LatitudeFormatter())
    if q==4 or q==5:
        ax.set_xticklabels(labels=lonticks,fontsize=10)
        ax.xaxis.set_major_formatter(LongitudeFormatter())

    ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
    ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
    ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

 cax = fig.add_axes([0.925,0.11,0.0175,0.77])
 cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
 cbar.ax.set_xlabel('PVU')
 for t in cbar.ax.get_yticklabels():
     t.set_fontsize(8)
 plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
 fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + 'cyclones-processes-scatter-traj' + key + '.png',dpi=300,bbox_inches="tight")
 plt.close('all')
236/6:
for qq, key in enumerate(['cyc','env']):
# fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
# axes = axes.flatten()
 for ul, date in enumerate(datadi.keys()):
     fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
     axes = axes.flatten()
     for q, ax in enumerate(axes[:]):
        ax.coastlines()
#    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval>=0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())

        if q%2==0:
            ax.set_yticklabels(labels=latticks,fontsize=10)
            ax.yaxis.set_major_formatter(LatitudeFormatter())
        if q==4 or q==5:
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.xaxis.set_major_formatter(LongitudeFormatter())

        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
        ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
        ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

     cax = fig.add_axes([0.925,0.11,0.0175,0.77])
     cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
     cbar.ax.set_xlabel('PVU')
     for t in cbar.ax.get_yticklabels():
     t.set_fontsize(8)
     plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
     fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + key + '-scatter/cyclones-processes-scatter-traj' + key + '.png',dpi=300,bbox_inches="tight")
     plt.close('all')
236/7:
for qq, key in enumerate(['cyc','env']):
# fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
# axes = axes.flatten()
 for ul, date in enumerate(datadi.keys()):
     fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
     axes = axes.flatten()
     for q, ax in enumerate(axes[:]):
        ax.coastlines()
#    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval>=0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())

        if q%2==0:
            ax.set_yticklabels(labels=latticks,fontsize=10)
            ax.yaxis.set_major_formatter(LatitudeFormatter())
        if q==4 or q==5:
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.xaxis.set_major_formatter(LongitudeFormatter())

        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
        ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
        ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

     cax = fig.add_axes([0.925,0.11,0.0175,0.77])
     cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
     cbar.ax.set_xlabel('PVU')
     for t in cbar.ax.get_yticklabels():
         t.set_fontsize(8)
     plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
     fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + key + '-scatter/cyclones-processes-scatter-traj' + key + '.png',dpi=300,bbox_inches="tight")
     plt.close('all')
236/8:
for qq, key in enumerate(['cyc','env']):
# fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
# axes = axes.flatten()
 for ul, date in enumerate(datadi.keys()):
     fig, axes = plt.subplots(3, 2, subplot_kw=dict(projection=ccrs.PlateCarree()),sharex=True,sharey=True)
     axes = axes.flatten()
     for q, ax in enumerate(axes[:]):
        ax.coastlines()
#    for ul, date in enumerate(datadi.keys()):
        idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
        lon = np.mean(datadi[date]['lon'][:,0])
        lat = np.mean(datadi[date]['lat'][:,0])

        colval = np.mean(dipv[date][key][proc[q]][idp,0])#/np.mean(dipv[date][key]['APVTOT'][idp,0]) * 100
        if q==0:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))<abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        if q==1:
            if abs(np.sum(dipv[date][key]['PVRCONVT'][idp,0]))>abs(np.sum(dipv[date][key]['PVRTURBT'][idp,0])):
                colval = 0
        ids = np.where(abs(sp-colval)==np.min(abs(sp-colval)))[0][0]

        if ids==255:
            ids+=1
        if ids==0:
            ids-=1
        col = cmap(ids)
        ac = ax.scatter(lon,lat,color=col,marker='o',zorder=1,s=3)
        if colval>=0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]>colval-0.1)[0]
        if colval<0:
            envtraj = np.where(dipv[date][key][proc[q]][idp,0]<colval+0.1)[0]
            
        for envt in envtraj:
            ax.plot(datadi[date]['lon'][idp[envt]],datadi[date]['lat'][idp[envt]],color='gray',linewidth=0.1)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())

        if q%2==0:
            ax.set_yticklabels(labels=latticks,fontsize=10)
            ax.yaxis.set_major_formatter(LatitudeFormatter())
        if q==4 or q==5:
            ax.set_xticklabels(labels=lonticks,fontsize=10)
            ax.xaxis.set_major_formatter(LongitudeFormatter())

        ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc])#, ccrs.PlateCarree())
        ax.text(0.06, 0.85, labels[q], transform=ax.transAxes,fontsize=12, fontweight='bold',va='top')
        ax.text(0.45, 0.95, lab[q], transform=ax.transAxes,fontsize=8,va='top')

     cax = fig.add_axes([0.925,0.11,0.0175,0.77])
     cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax ,extend='both',orientation='vertical')
     cbar.ax.set_xlabel('PVU')
     for t in cbar.ax.get_yticklabels():
         t.set_fontsize(8)
     plt.subplots_adjust(left=0.1,bottom=None,top=None,right=0.925,hspace=0,wspace=0)
     fig.savefig('/atmosdyn2/ascherrmann/010-IFS/' + key + '-scatter/cyclones-processes-scatter-traj' + date + '-' + key + '.png',dpi=300,bbox_inches="tight")
     plt.close('all')
237/1:
import numpy as np
import pickle

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm
237/2:
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-']
tmp = dict()
fin = dict()

import matplotlib
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'

pltlat = np.linspace(0,90,226)[70:121]
pltlon = np.linspace(-180,180,901)[440:541]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]
237/3: counter = 0
237/4:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1010)):
        dlon = np.array(tmp['lon-'][l][1:])-np.array(tmp['lon-'][l][:-1])
        dlat = np.array(tmp['lat-'][l][1:])-np.array(tmp['lat-'][l][:-1])

        r = np.sqrt(dlon**2 + dlat**2)
        if np.any(r>4):
            if (len(np.where(r>4)[0])<3):
             for x in savings:
                fin[x].append(tmp[x][l])
             counter+=1   
            else:
                continue
237/5: counter
237/6: counter = 0
237/7:
print(len(fin['SLP']))
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1010)):
        dlon = np.array(tmp['lon-'][l][1:])-np.array(tmp['lon-'][l][:-1])
        dlat = np.array(tmp['lat-'][l][1:])-np.array(tmp['lat-'][l][:-1])

        r = np.sqrt(dlon**2 + dlat**2)
        #if np.any(r>4):
        #    if (len(np.where(r>4)[0])<3):
        #     for x in savings:
        #        fin[x].append(tmp[x][l])
        #    else:
        #        continue
        if (np.any(r>3.5)):
            uy = np.array(np.where(r>3.5)[0])
            slp = np.where(tmp['SLP-'][l]==np.min(tmp['SLP-'][l]))[0][0]

            if (np.all(uy>slp)):
              for x in savings:
                fin[x].append(tmp[x][l])

            elif(len(uy)<3):
                uy = np.insert(uy,0,0)
                for la, lo in enumerate(uy[:-1]):

                    jump = uy[la+1]
                    lth = uy[la+1]-lo
                    if lth>12:
                        idtm = np.ones(lth)*(tmp['ID-'][l][0]+la)
                        lontm = tmp['lon-'][l][lo:jump]
                        lattm = tmp['lat-'][l][lo:jump]
                        slptm = tmp['SLP-'][l][lo:jump]

                        datestm = tmp['dates-'][l][lo:jump]

                        httm = tmp['hourstoSLPmin-'][l][lo:jump]
                        httm = httm - httm[np.where(slptm==np.min(slptm))[0][0]]

                        if(np.max(slptm)-np.min(slptm)>5):
                            fin['lon-'].append(lontm)
                            fin['lat-'].append(lattm)
                            fin['SLP-'].append(slptm)
                            fin['dates-'].append(datestm)
                            fin['hourstoSLPmin-'].append(httm)
                            fin['ID-'].append(idtm)
                        else:
                            continue
                    else:
                        continue

                    if(uy[la+1]>slp):

                       idtm = np.ones(uy[-1]-lo)*(tmp['ID-'][l][0]+la+1)
                       lontm = tmp['lon-'][l][jump:]
                       lattm = tmp['lat-'][l][jump:]
                       slptm = tmp['SLP-'][l][jump:]
                       datestm = tmp['dates-'][l][jump:]
                       httm = tmp['hourstoSLPmin-'][l][jump:]
                       httm = httm - httm[np.where(slptm==np.min(slptm))[0][0]]
                       if(np.max(slptm)-np.min(slptm)>5):
                           fin['lon-'].append(lontm)
                           fin['lat-'].append(lattm)
                           fin['SLP-'].append(slptm)
                           fin['dates-'].append(datestm)
                           fin['hourstoSLPmin-'].append(httm)
                           fin['ID-'].append(idtm)

                           break
                       else:
                           break

                    else:
                       continue

        else:
#        if True:
            for x in savings:
                fin[x].append(tmp[x][l])
237/8: fin
237/9: fin.keys()
237/10: len(fin['SLP-'])
237/11:
print(len(fin['SLP-']))
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1010)):
        dlon = np.array(tmp['lon-'][l][1:])-np.array(tmp['lon-'][l][:-1])
        dlat = np.array(tmp['lat-'][l][1:])-np.array(tmp['lat-'][l][:-1])

        r = np.sqrt(dlon**2 + dlat**2)
        #if np.any(r>4):
        #    if (len(np.where(r>4)[0])<3):
        #     for x in savings:
        #        fin[x].append(tmp[x][l])
        #    else:
        #        continue
        if (np.any(r>3.5)):
            uy = np.array(np.where(r>3.5)[0])
            slp = np.where(tmp['SLP-'][l]==np.min(tmp['SLP-'][l]))[0][0]

            if (np.all(uy>slp)):
              for x in savings:
                fin[x].append(tmp[x][l])

            elif(len(uy)<3):
                uy = np.insert(uy,0,0)
                for la, lo in enumerate(uy[:-1]):

                    jump = uy[la+1]
                    lth = uy[la+1]-lo
                    if lth>12:
                        idtm = np.ones(lth)*(tmp['ID-'][l][0]+la)
                        lontm = tmp['lon-'][l][lo:jump]
                        lattm = tmp['lat-'][l][lo:jump]
                        slptm = tmp['SLP-'][l][lo:jump]

                        datestm = tmp['dates-'][l][lo:jump]

                        httm = tmp['hourstoSLPmin-'][l][lo:jump]
                        httm = httm - httm[np.where(slptm==np.min(slptm))[0][0]]

                        if(np.max(slptm)-np.min(slptm)>5):
                            fin['lon-'].append(lontm)
                            fin['lat-'].append(lattm)
                            fin['SLP-'].append(slptm)
                            fin['dates-'].append(datestm)
                            fin['hourstoSLPmin-'].append(httm)
                            fin['ID-'].append(idtm)
                        else:
                            continue
                    else:
                        continue

                    if(uy[la+1]>slp):

                       idtm = np.ones(uy[-1]-lo)*(tmp['ID-'][l][0]+la+1)
                       lontm = tmp['lon-'][l][jump:]
                       lattm = tmp['lat-'][l][jump:]
                       slptm = tmp['SLP-'][l][jump:]
                       datestm = tmp['dates-'][l][jump:]
                       httm = tmp['hourstoSLPmin-'][l][jump:]
                       httm = httm - httm[np.where(slptm==np.min(slptm))[0][0]]
                       if(np.max(slptm)-np.min(slptm)>5):
                           fin['lon-'].append(lontm)
                           fin['lat-'].append(lattm)
                           fin['SLP-'].append(slptm)
                           fin['dates-'].append(datestm)
                           fin['hourstoSLPmin-'].append(httm)
                           fin['ID-'].append(idtm)

                           break
                       else:
                           break

                    else:
                       continue

        else:
#        if True:
            for x in savings:
                fin[x].append(tmp[x][l])
237/12: len(fin['SLP-'])
237/13:
fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if ((len(tmp['ID-'][l])>12) & ((np.max(tmp['SLP-'][l])-np.min(tmp['SLP-'][l]))>5) & (np.min(tmp['SLP-'][l])<1010)):
          for x in savings:
                fin[x].append(tmp[x][l])
237/14: len(fin['SLP-'])
237/15:
for x in savings:
    f = open(p + x + 'furthersel-no-kicking.txt',"wb")
    pickle.dump(fin[x],f)
    f.close()
237/16: avaIDN = np.array([])
237/17:
for k in range(len(fin['ID-'])):
    avaIDN = np.append(fin['ID-'][k,0])
237/18:
for k in range(0,len(fin['ID-'])):
    avaIDN = np.append(fin['ID-'][k][0])
237/19: fin[ID-][0]
237/20: fin['ID-'][0]
237/21: fin['ID-'][0][0]
237/22: len(fin['ID-'])
237/23:
for k in range(0,len(fin['ID-'])):
    avaIDN = np.append(avaIDN,fin['ID-'][k][0])
237/24:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
237/25:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
237/26: len(avaID)
237/27: identical = np.array([])
237/28:
for k in avaID:
    if np.any(avaIDN==k):
        identical = np.append(identical,k)
237/29: len(identical)
238/1: p1 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/'
238/2: p2 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ntraj/'
238/3: import filecmp
238/4: d = trastart-mature-19790101_20-ID-957094.txt
238/5: d = 'trastart-mature-19790101_20-ID-957094.txt'
238/6: f1 = p1+d
238/7: f2 = p2+d
238/8: filecmp(f1,f2)
238/9: filecmp.cmp(f1,f2)
238/10: import os
238/11: samids = np.array([])
238/12: import numpy as np
238/13: samids = np.array([])
238/14: samefiles =np.array([])
238/15: diffiles =np.array([])
238/16: newfiles = np.array([])
238/17: cd p1
238/18: p1
238/19: cd /atmosdyn2/ascherrmann/009-ERA-5/MED/traj/
238/20: cd ../
238/21: cd traj/
238/22:
olddif = np.array([])
for q,f in enumerate(os.listdir('./')):
    if q==0:
        break
    if f.startswith('trastart-mature'):
        f1 = f
        f2 = p2 + f
        
        if os.path.isfile(f2):
            samids=np.append(f[-10:-4])
            if filecmp.cmp(f1,f2):
                samefiles = np.append(samefiles,f)
            else:
                diffiles = np.append(diffiles,f)
        else:
            olddif = np.append(olddif,f)
            
for q,f in enumerate(os.listdir('../ntraj/')):
    if q==0:
        break
    if f.startswith('trastart-mature'):
        if np.any(samefiles==f) or np.any(diffiles==f):
            continue
        else:
            newfiles = np.append(newfiles,f)
238/23: ls ../ntraj/ | tail -10
238/24: ls ../ntraj/ | tail -10
238/25: ls ../ntraj/ | tail -10
238/26:
olddif = np.array([])
for q,f in enumerate(os.listdir('./')):
#    if q==0:
#        break
    if f.startswith('trastart-mature'):
        f1 = f
        f2 = p2 + f
        
        if os.path.isfile(f2):
            samids=np.append(f[-10:-4])
            if filecmp.cmp(f1,f2):
                samefiles = np.append(samefiles,f)
            else:
                diffiles = np.append(diffiles,f)
        else:
            olddif = np.append(olddif,f)
            
for q,f in enumerate(os.listdir('../ntraj/')):
#    if q==0:
#        break
    if f.startswith('trastart-mature'):
        if np.any(samefiles==f) or np.any(diffiles==f):
            continue
        else:
            newfiles = np.append(newfiles,f)
238/27:
olddif = np.array([])
for q,f in enumerate(os.listdir('./')):
#    if q==0:
#        break
    if f.startswith('trastart-mature'):
        f1 = f
        f2 = p2 + f
        
        if os.path.isfile(f2):
            samids=np.append(samids,f[-10:-4])
            if filecmp.cmp(f1,f2):
                samefiles = np.append(samefiles,f)
            else:
                diffiles = np.append(diffiles,f)
        else:
            olddif = np.append(olddif,f)
            
for q,f in enumerate(os.listdir('../ntraj/')):
#    if q==0:
#        break
    if f.startswith('trastart-mature'):
        if np.any(samefiles==f) or np.any(diffiles==f):
            continue
        else:
            newfiles = np.append(newfiles,f)
238/28: len(samefiles)
238/29: len(diffiles)
238/30: len(olddif)
238/31: len(newfiles)
238/32: pwd
238/33: mkdir filesmoved
238/34:
for f in olddif:
    os.rename(f,'filesmoved/' + f)
238/35: pwd
238/36: mkdir use/movedfiles/
238/37: ls use/ |head -10
238/38: ls use/ |head -20
238/39:
for f in olddif:
    end = f[-25:]
    os.rename('use/trajectories-matures-' + end,'use/movedfiles/trajectories-matures-' + f)
238/40: ls use//trajectories-matures-19790315_04-ID-001576.txt
238/41: ls use/trajectories-matures-19790315_04-ID-001576.txt
238/42: end
238/43: olddif[0]
238/44:
for f in olddif[1:]:
    end = f[-25:]
    os.rename('use/trajectories-matures-' + end,'use/movedfiles/trajectories-matures-' + f)
238/45:
for f in olddif[:]:
    end = f[-25:]
    os.rename('use/trajectories-mature-' + end,'use/movedfiles/trajectories-mature-' + f)
238/46: qf = np.array(['mature-19960101_06-ID-214932.txt'])
238/47: qf = np.array(['19960101_06-ID-214932.txt'])
238/48:
for q,f in enumerate(olddif[:]):
    if f[-25:]=='19960101_06-ID-214932.txt':
        break
238/49: q
238/50: np.delete(olddif,74)
238/51: olddiff = np.delete(olddif,74)
238/52:
for f in olddiff[74:]:
    f
238/53:
for q,f in enumerate(olddiff[74:]):
    end = f[-25:]
    if os.path.isfile('use/trajectories-mature-' + end):
        os.rename('use/trajectories-mature-' + end,'use/movedfiles/trajectories-mature-' + f)
    else:
        qf = np.append(qf,end)
238/54: qf
238/55: ls use/trajectories*.txt | wc -l
238/56: len(samefiles)
238/57: len(newfiles)
238/58: pwd
238/59:
mkdir ../ntraj/samefiles/
for f in samefiles:
    os.rename('../ntraj/'+f,'../ntraj/samefiles/' + f)
238/60: mkdir ../ntraj/samefiles
238/61:
for f in samefiles:
    os.rename('../ntraj/'+f,'../ntraj/samefiles/' + f)
238/62: %save -r check-ERA5-cyclones.py 1-999
239/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import pickle
import argparse
239/2: rdis=800
239/3: CT='ETA'
239/4: deltaPSP=100
239/5: zbb=800
239/6:
f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW.txt','rb')
td = pickle.load(f)
f.close()
240/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import pickle
import argparse
240/2:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
plload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'

traj = np.array([])
for d in os.listdir(pload):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(plload):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)

MON = np.sort(MON)
traj = np.sort(traj)
240/3: CT='ETA'
240/4:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
plload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'

traj = np.array([])
for d in os.listdir(pload):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(plload):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)

MON = np.sort(MON)
traj = np.sort(traj)
240/5: MON[:150]
240/6:
for uyt, txt in enumerate(traj[:100]):
    montmp = MON[uyt][-9:-4]
    print(MON[uyt],txt)
241/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import pickle
import argparse
241/2: CT='ETA'
241/3:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
plload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'

traj = np.array([])
for d in os.listdir(pload):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(plload):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)

MON = np.sort(MON)
traj = np.sort(traj)
241/4: len(MON)
241/5: len(traj)
241/6:
for uyt, txt in enumerate(traj[600:]):
    montmp = MON[uyt+600][-9:-4]
    print(MON[uyt+600],txt)
241/7:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/use/'
plload = '/atmosdyn2/ascherrmann/010-IFS/traj/' + CT + '/'

traj = np.array([])
for d in os.listdir(pload):
    if(d.startswith('trajectories-mature-')):
            traj = np.append(traj,d)

MON = np.array([])
for d in os.listdir(plload):
    if(d.startswith('traend-')):
        MON = np.append(MON,d)

MON = np.sort(MON)
traj = np.sort(traj)
241/8:
for uyt, txt in enumerate(traj[600:]):
    montmp = MON[uyt+600][-9:-4]
    print(MON[uyt+600],txt)
242/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from matplotlib import cm
from scipy.stats.stats import pearsonr
import pickle
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER


pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
psave = '/atmosdyn2/ascherrmann/009-ERA-5/MED/orocyclones/'

f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

datadi = PVdata['rawdata']
dipv = PVdata['dipv']
ORO = PVdata['oro']

both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
242/2:
SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
minSLP = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    minSLP = np.append(minSLP,SLP[k][abs(hourstoSLPmin[k][0]).astype(int)])
242/3: lon[0]
243/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from matplotlib import cm
from scipy.stats.stats import pearsonr
import pickle
sys.path.append('/home/raphaelp/phd/scripts/basics/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER


pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
psave = '/atmosdyn2/ascherrmann/009-ERA-5/MED/orocyclones/'

f = open(pload + 'PV-data-dPSP-100-ZB-800.txt','rb')
PVdata = pickle.load(f)
f.close()

datadi = PVdata['rawdata']
dipv = PVdata['dipv']
ORO = PVdata['oro']

both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
243/2:
Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
HourstoSLPmin = var[4]
dates = var[5]
243/3: hourstoSLPmin[0]
244/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle

parser = argparse.ArgumentParser(description="plot accumulated average PV gain that is associated with the cyclone and the environment")
parser.add_argument('rdis',default='',type=int,help='distance from center in km that should be considered as cyclonic')
parser.add_argument('deltaPSP',default='',type=int,help='difference between surface pressure and pressure that should be evaluated as orographical influence')

parser.add_argument('ZBB',default='',type=int,help='evelation in m at which PV changes should be evaluated as orographic')

args = parser.parse_args()
rdis = int(args.rdis)
deltaPSP = int(args.deltaPSP)
zbb = int(args.ZBB)

deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
244/2: rdis=400
244/3:
deltaLONLAT = helper.convert_radial_distance_to_lon_lat_dis(rdis)

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
244/4:
HourstoSLPmin = var[4]
dates = var[5]


avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])

for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    maturedates = np.append(maturedates,dates[k][loc])
    SLPminid = np.append(SLPminid,loc)
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])


traj = np.array([])

for d in os.listdir(pload):
    if(d.startswith('trajectories-mature')):
            traj = np.append(traj,d)
244/5: len(ID)
244/6: len(traj)
245/1:
import numpy as np
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import os
import pickle
245/2:
regions = ['MED','NA','SA','NP','NP','SP','SP','I']
boundaries = ['lon','lat']

NAlatup = 83
LON = [np.array([-5,2,42]),np.array([-95,-75,-5,15]),np.array([-67,30]),np.array([-180,-97]),np.array([115,180]),np.array([-180,-70]),np.array([115,180]),np.array([30,110])]
LAT = [np.array([30,42,30,48]),np.array([15,NAlatup,0,NAlatup,50,NAlatup]),np.array([-55,0]),np.array([0,70]),np.array([0,70]),np.array([-55,0]),np.array([-55,0]),np.array([-55,25])]
245/3:
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
245/4:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
245/5:
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
245/6: 360/24
245/7: 720/24
245/8: days = 30
245/9: 725/25
245/10: 725/24
245/11: 720//24
245/12: 720%24
245/13:
tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)

tracks = np.sort(tracks)
245/14: track[:10]
245/15: tracks[:10]
245/16: tracks[:11]
245/17: tracks[:12]
245/18: tracks[:100]
245/19: tracks[360:361]
245/20: tracks[340:361]
245/21: tracks[346:]
245/22: tracks[346:376]
245/23: tracks[346:376]
246/1:
import numpy as np
import pickle
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
REG = []
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']
246/2:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/'

regions = ['MED','NA','SA','NP','SP','IO']

NAlatup = 83
LON = [np.array([-5,2,42]),np.array([-95,-75,-5,15]),np.array([-67,30]),np.array([-180,-97]),np.array([115,180]),np.array([-180,-70]),np.array([115,180]),np.array([30,110])]
LAT = [np.array([30,42,30,48]),np.array([15,NAlatup,0,NAlatup,50,NAlatup]),np.array([-55,0]),np.array([0,70]),np.array([0,70]),np.array([-55,0]),np.array([-55,0]),np.array([-55,25])]
246/3:
import numpy as np
import pickle
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

import matplotlib
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

regions = ['MED','NA','SA','NP','SP','IO']
246/4:
regtmp = dict()
slpdi = dict()
fulldi = dict()


for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])
246/5:
for k in range(1979,2021):
  tmp = dict()
  for x in savings:

    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'])):

      ID = tmp['ID-'][l]
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-']==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/6: regtmp['NA']
246/7:
for k in range(1979,1980):#2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:10])):
      ID = tmp['ID-'][l]
      print(ID)
      
#      fulldi[ID] = dict()
#      for x in savings:
#          fulldi[ID][x] = tmp[x][l]

#      for r in regions:
#          if tmp['REG-']==r:
#              regtmp[r] = np.append(regtmp[r],ID)
#              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/8:
for k in range(1979,1980):#2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:10])):
      ID = tmp['ID-'][l]
      print(ID)
      
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          print(tmp['REG-'])
#          if tmp['REG-']==r:
#              regtmp[r] = np.append(regtmp[r],ID)
#              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/9:
for k in range(1979,1980):#2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:10])):
      ID = tmp['ID-'][l]
      print(ID)
      
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          print(tmp['REG-'][l])
#          if tmp['REG-']==r:
#              regtmp[r] = np.append(regtmp[r],ID)
#              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/10:
for k in range(1979,1980):#2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:10])):
      ID = tmp['ID-'][l]
      print(ID)
      
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
#          print(tmp['REG-'][l])
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/11: regtmp
246/12:
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:])):
      ID = tmp['ID-'][l]
      print(ID)
      
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/13:
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'][:])):
      ID = tmp['ID-'][l]
      
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/14: regtmp['IO']
246/15: regtmp['NA']
246/16: len(regtmp['NA'])
246/17: len(regtmp['SA'])
246/18: len(regtmp['MED'])
246/19: len(regtmp['SP'])
246/20: len(regtmp['NP'])
246/21: :q
246/22:
reg = dict()
for r in regions:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(len(regtmp)):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/23:
reg = dict()
for r in regions[:-1]
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(len(regtmp)):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/24:
reg = dict()
for r in regions[:-1]:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(len(regtmp)):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/25: len(reg['MED'])
246/26: len(reg['NA'])
246/27: reg['MED'].keys()
246/28:
regtmp = dict()
slpdi = dict()
fulldi = dict()


for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])

for k in range(1979,2021):
  tmp = dict()
  for x in savings:

    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()

  for l in range(len(tmp['lon-'])):

      ID = tmp['ID-'][l]
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
246/29: len(regtmp['NA'])
246/30: len(regtmp['MED'])
246/31: len(regtmp['IO'])
246/32: len(regtmp['I'])
246/33:
reg = dict()
for r in regions:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(len(regtmp[r])):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/34: len(reg['NA'])
246/35:
reg = dict()
for r in regions:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(0,len(regtmp[r])+1):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/36:
reg = dict()
for r in regions[:-1]
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(0,len(regtmp[r])+1):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/37:
reg = dict()
for r in regions[:-1]:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(0,len(regtmp[r])+1):
        #take 1000 deepest cyclones
        if q>=1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/38: len(reg['NA'])
246/39: slpdi['NA']
246/40: slpdi['NA'][:1000]
246/41: slpdi['SA'][:1000]
246/42: slpdi['MED'][:1000]
246/43: slpdi['SP'][:1000]
246/44: slpdi['NP'][:1000]
246/45: len(reg['NA'])
246/46:
reg = dict()
for r in regions[:-1]:
    order = np.argsort(slpdi[r])
    regtmp[r] = regtmp[r][order]
    slpdi[r] = slpdi[r][order]
    reg[r] = dict()

    for q in range(0,len(regtmp[r])+1):
        #take 1000 deepest cyclones
        if q>1000:
            continue
        ID = regtmp[r][q]
        reg[r][ID] = dict()
        for x in savings:
            reg[r][ID][x] = fulldi[ID][x]
246/47: len(reg['NA'])
246/48: regions
247/1:
import numpy as np
import pickle
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

regions = ['MED','NA','SA','NP','SP','I']

regtmp = dict()
slpdi = dict()
fulldi = dict()

for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])
247/2:
for k in range(1979,1980):
    tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
247/4:
for k in range(1979,1980):
    tmp = dict()
    for x in savings:
     f = open(p + x + str(k) + '.txt',"rb")
     tmp[x] = pickle.load(f)
     f.close()
247/5: len(tmp['ID-'])
247/6: len(tmp['SLP-'])
247/7: len(tmp['REG-'])
247/8:
import numpy as np
import pickle
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

regions = ['MED','NA','SA','NP','SP','I']

regtmp = dict()
slpdi = dict()
fulldi = dict()

for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])

for k in range(1979,1980):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
247/9: len(tmp['ID-'])
247/10: len(tmp['lon-'])
247/11:
for l, ID in enumerate(tmp['ID-']):
    fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
247/12:
for l, ID in enumerate(tmp['ID-']):
      fulldi[ID] = dict()
      for x in savings:
          fulldi[ID][x] = tmp[x][l]

      for r in regions:
          if tmp['REG-'][l]==r:
              regtmp[r] = np.append(regtmp[r],ID)
              slpdi[r] = np.append(slpdi[r],np.min(tmp['SLP-'][l]))
248/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle

def colbar(cmap,minval,maxval,nlevels,levels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(levels,cmap.N)
    return newmap, norm

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'

f = open(pload + 'PV-data-dPSP-100-ZB-800-2-400.txt','rb')
data = pickle.load(f)
f.close()

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
maturedates = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
248/2: len(avaID)
248/3: datadi = data['rawdata']
248/4: datadi.keys().astype(int)
248/5:
for q,k in enumerate(datadi.keys()):
    q
248/6: q
248/7: avaID
248/8: np.where(avaID==460854)
248/9: lon[3551]
248/10: lat[3551]
248/11: hourstoSLPmin[3551]
249/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from matplotlib import pyplot as plt
from matplotlib import cm
from scipy.stats.stats import pearsonr
import pickle

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
psave = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'

f = open(pload + 'PV-data-dPSP-100-ZB-800-2-400.txt','rb')
PVdata = pickle.load(f)
f.close()

datadi = PVdata['rawdata']
dipv = PVdata['dipv']
ORO = PVdata['oro']

both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
minSLP = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    minSLP = np.append(minSLP,SLP[k][abs(hourstoSLPmin[k][0]).astype(int)])


pvival = np.array([-100,0.2,0.5,0.75,100])

anomaly = dict()
mature = dict()
layercounter = dict()
cycc =0

pinvals = np.arange(700,925.1,12.5)
plvlcounter = dict()

SPV = np.array([])
sLPV = np.array([])
PVmax = np.array([])
PVav = np.array([])
PVLav = np.array([])
PVmin = np.array([])
nT = np.array([])
nP  = np.array([])
SLPs = np.array([])
ids = np.array([])

split = ['cyc','env']
linestyle = ['-',':']
fsl=6
oroids = np.array([])

Pdata = np.loadtxt(pload + 'precip-trace-19881213_04-ID-119896.txt')
249/2: precip = (Pdata[:,-2]*1000 + Pdata[:,-1]*1000).reshape(-1,49)
249/3: precip
249/4: np.where(precip!=0)
249/5: np.sum(precip,axis=1)
249/6: len(precip)
250/1:
import numpy as np
import pickle
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm
250/2: rdis = 400
250/3:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()
250/4:
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()
250/5:
SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
maturedates = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    maturedates = np.append(maturedates,dates[k][abs(hourstoSLPmin[k][0]).astype(int)])
250/6: t = np.arange(-72,73)
250/7: t
250/8: SLPA = np.zeros(t.shape)
250/9: np.where(t==hourstoSLPmin[0][0])
250/10: prematurelifespan = np.array([])
250/11: postmaturelifespan = np.array([])
250/12: countert = np.zeros(t.shape)
250/13: t = np.arange(-96,97)
250/14: SLPA = np.zeros(t.shape)
250/15: countert = np.zeros(t.shape)
250/16: SLPA = dict()
250/17: hourstoSLPmin[0]
250/18: len(hourstoSLPmin[0])
250/19: len(avaID)
250/20:
SLPA = np.zeros(4232,t.shape)
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])
    i = len(hourstoSLPmin[q])
    countert[h:h+i]+=1
    SLPA[u,h:h+i]=SLP[q]
250/21:
SLPA = np.zeros((4232,t.shape))
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])
    i = len(hourstoSLPmin[q])
    countert[h:h+i]+=1
    SLPA[u,h:h+i]=SLP[q]
250/22:
SLPA = np.zeros((4232,len(t)))
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])
    i = len(hourstoSLPmin[q])
    countert[h:h+i]+=1
    SLPA[u,h:h+i]=SLP[q]
250/23:
SLPA = np.zeros((4232,len(t)))
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])[0][0]
    i = len(hourstoSLPmin[q])
    countert[h:h+i]+=1
    SLPA[u,h:h+i]=SLP[q]
250/24: len(SLP[q])
250/25: len(t)
250/26: SLPA.shape
250/27: h
250/28:
SLPA = np.zeros((4232,len(t)))
counter = np.zeros(len(t))
prematurelifespan = np.array([])
postmaturelifespan = np.array([])
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])[0][0]
    i = len(hourstoSLPmin[q])
    prematurelifespan = np.append(prematurelifespan,abs(hourstoSLPmin[q][0]))
    postmaturelifespan = np.append(postmaturelifespan,hourstoSLPmin[q][-1])
    
    if h+i>len(t):
        countert[h:]+=1
        SLPA[u,h:]=SLP[q][:h+i-len(t)]
    else:
        countert[h:h+i]+=1
        SLPA[u,h:h+i]=SLP[q]
250/29: h
250/30: i
250/31: h+i-len(t)
250/32: t[h]
250/33: len(t[h:])
250/34:
SLPA = np.zeros((4232,len(t)))
counter = np.zeros(len(t))
prematurelifespan = np.array([])
postmaturelifespan = np.array([])
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])[0][0]
    i = len(hourstoSLPmin[q])
    prematurelifespan = np.append(prematurelifespan,abs(hourstoSLPmin[q][0]))
    postmaturelifespan = np.append(postmaturelifespan,hourstoSLPmin[q][-1])
    
    if h+i>len(t):
        countert[h:]+=1
        SLPA[u,h:]=SLP[q][:len(t[h:])]
    else:
        countert[h:h+i]+=1
        SLPA[u,h:h+i]=SLP[q]
250/35: hourstoSLPmin
250/36: hourstoSLPmin[q]
250/37: t = np.arange(-120,121)
250/38:
SLPA = np.zeros((4232,len(t)))
counter = np.zeros(len(t))
prematurelifespan = np.array([])
postmaturelifespan = np.array([])
for u,k in enumerate(PVdata['rawdata'].keys()):
    q = np.where(avaID==int(k))[0][0]
    h = np.where(t==hourstoSLPmin[q][0])[0][0]
    i = len(hourstoSLPmin[q])
    prematurelifespan = np.append(prematurelifespan,abs(hourstoSLPmin[q][0]))
    postmaturelifespan = np.append(postmaturelifespan,hourstoSLPmin[q][-1])
    
    if h+i>len(t):
        countert[h:]+=1
        SLPA[u,h:]=SLP[q][:len(t[h:])]
    else:
        countert[h:h+i]+=1
        SLPA[u,h:h+i]=SLP[q]
250/39: np.mean(prematurelifespan)
250/40: np.mean(postmaturelifespan)
250/41: slpav = np.array([])
250/42: slp10 = np.array([])
250/43: slp90 = np.array([])
250/44:
for u,r in enumerate(t):
    i = np.where(SLPA[u,:]!=0)[0]
    slpav = np.append(slpav,np.mean(SLPA[u,i]))
    slp10 = np.append(slp10,np.percentile(SLPA[u,i],10))
    slp90 = np.append(slp90,np.percentile(SLPA[u,i],90))
250/45: fig,axes = plt.subplot(2,1)
250/46: fig,axes = plt.subplots(2,1)
250/47: axes = axes.flatten()
250/48: ax.plot(t,slpav,color='red')
250/49: axes[0].plot(t,slpav,color='red')
250/50: axes[0].plot(t,slp10,color='grey')
250/51: axes[0].plot(t,slp90,color='grey')
250/52: axes[0].plot(t,slpav,color='k')
250/53: axes[0].fill_between(t,slp10,slp90,alpha=0.5,color='grey')
250/54: axes[0].set_ylabel('SLP [hPa]')
250/55: axes[1].hist(countert,facecolor='blue',edgecolor='blue')
250/56: axes[1].hist(countert,bins=193,facecolor='blue',edgecolor='blue')
250/57: counter
250/58: countert
250/59: fig.show()
250/60: %save -r cyclone-statistics.py 1-999
251/1:
import numpy as np
import pickle
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-']
tmp = dict()
fin = dict()

import matplotlib
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'

pltlat = np.linspace(0,90,226)[70:121]
pltlon = np.linspace(-180,180,901)[440:541]

minpltlatc = pltlat[0]
maxpltlatc = pltlat[-1]

minpltlonc = pltlon[0]
maxpltlonc = pltlon[-1]


fin = dict()
for x in savings:
    fin[x] = []
for k in range(1979,2021):
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
  for l in range(len(tmp['ID-'])):
      if tmp['ID-']==524945:
          for x in savings:
                fin[x].append(tmp[x][l])
251/2: fin
251/3:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'

tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)

tracks = np.sort(tracks)
251/4: import os
251/5:
SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []

savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']
yeartmp = 1979

for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    if year==2018:
        d = np.loadtxt(trackpath + fdate,skiprows=4)
        if np.any(d[:,-1]==524945):
            ids = np.where(d[:,-1]==524945)[0]
            ID.append(d[ids[0],-1])
            SLP.append(np.array(d[ids,3]))
            lon.append(np.array(d[ids,1]))
            lat.append(np.array(d[ids,2]))
            hourstoSLPmin.append(np.array(d[ids,0]-d[np.where(d[ids,3]==np.min(d[ids,3]))[0]]))
            tmp = np.array([])
            for u,v in enumerate(d[ids,0]):
             # if on first days of next month
             if((np.floor(v/24).astype(int) + 1)>days):
                 #if next month is next year
                 if ((int(fdate[-2:]) + 1)>12):
                    #                           add 1 to the year    # so next month -12 in the next year
                    tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                            #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                            '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                 else:
                     #                  same year               # next month
                    tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                            #  same as above
                         '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


             else:
                 tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                         '_%02d'%(v%24).astype(int))
            dates.append(tmp)
251/6: ID
251/7: d = np.loadtxt(trackpath + 'fi_201809',skiprow=4)
251/8: d = np.loadtxt(trackpath + 'fi_201809',skiprows=4)
251/9: np.where(d[:,-1]==524945)
251/10: np.any(d[:,-1]==524945)
251/11:
if np.any(d[:,-1]==524945):
            ids = np.where(d[:,-1]==524945)[0]
            ID.append(d[ids[0],-1])
            SLP.append(np.array(d[ids,3]))
            lon.append(np.array(d[ids,1]))
            lat.append(np.array(d[ids,2]))
            hourstoSLPmin.append(np.array(d[ids,0]-d[np.where(d[ids,3]==np.min(d[ids,3]))[0]]))
            tmp = np.array([])
            for u,v in enumerate(d[ids,0]):
             # if on first days of next month
             if((np.floor(v/24).astype(int) + 1)>days):
                 #if next month is next year
                 if ((int(fdate[-2:]) + 1)>12):
                    #                           add 1 to the year    # so next month -12 in the next year
                    tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                            #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                            '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                 else:
                     #                  same year               # next month
                    tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                            #  same as above
                         '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


             else:
                 tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                         '_%02d'%(v%24).astype(int))
            dates.append(tmp)
251/12: hourstoSLPmin
251/13: hourstoSLPmin.append(np.array(d[ids,0]-d[np.where(d[ids,3]==np.min(d[ids,3]))[0],0]))
251/14:
for u,v in enumerate(d[ids,0]):
    if((np.floor(v/24).astype(int) + 1)>days):
                  #if next month is next year
                  if ((int(fdate[-2:]) + 1)>12):
                     #                           add 1 to the year    # so next month -12 in the next year
                     tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                             #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                             '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                  else:
                      #                  same year               # next month
                     tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                             #  same as above
                          '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


    else:
                  tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                          '_%02d'%(v%24).astype(int))
dates.append(tmp)
251/15: days=30
251/16:
for u,v in enumerate(d[ids,0]):
    if((np.floor(v/24).astype(int) + 1)>days):
                  #if next month is next year
                  if ((int(fdate[-2:]) + 1)>12):
                     #                           add 1 to the year    # so next month -12 in the next year
                     tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                             #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                             '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                  else:
                      #                  same year               # next month
                     tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                             #  same as above
                          '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


    else:
                  tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                          '_%02d'%(v%24).astype(int))
dates.append(tmp)
251/17: fdate='fi_201809'
251/18:
for u,v in enumerate(d[ids,0]):
    if((np.floor(v/24).astype(int) + 1)>days):
                  #if next month is next year
                  if ((int(fdate[-2:]) + 1)>12):
                     #                           add 1 to the year    # so next month -12 in the next year
                     tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                             #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                             '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                  else:
                      #                  same year               # next month
                     tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                             #  same as above
                          '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


    else:
                  tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                          '_%02d'%(v%24).astype(int))
dates.append(tmp)
251/19: dates
251/20: len(dates)
251/21: tmp
251/22: len(SLP)
251/23: SLP
251/24: len(lon)
251/25: lon
251/26: lat
251/27: hourstoSLPmin
251/28: hourstoSLPmin = []
251/29: hourstoSLPmin.append(np.arange(0,len(SLP[0]))-np.arange(0,len(SLP[0]))[np.where(SLP[0]==np.min(SLP[0]))[0]])
251/30: hourstoSLPmin
251/31: d[ids,0]
251/32: dates=[]
251/33:
for u,v in enumerate(d[ids,0]):
    if((np.floor(v/24).astype(int) + 1)>days):
                  #if next month is next year
                  if ((int(fdate[-2:]) + 1)>12):
                     #                           add 1 to the year    # so next month -12 in the next year
                     tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                             #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                             '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                  else:
                      #                  same year               # next month
                     tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                             #  same as above
                          '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


    else:
                  tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                          '_%02d'%(v%24).astype(int))
251/34: tmp=np.array([])
251/35:
for u,v in enumerate(d[ids,0]):
    if((np.floor(v/24).astype(int) + 1)>days):
                  #if next month is next year
                  if ((int(fdate[-2:]) + 1)>12):
                     #                           add 1 to the year    # so next month -12 in the next year
                     tmp = np.append(tmp,str(int(fdate[-6:-2]) + 1) + '%02d'%(int(fdate[-2:])+1-12) +
                             #days=30, v/24 = 30.5 -> 30-30 + 1          # add the hours of next day
                             '%02d'%(np.floor(v/24).astype(int)-days+1) + '_%02d'%(v%24).astype(int))
                  else:
                      #                  same year               # next month
                     tmp = np.append(tmp,fdate[-6:-2] + '%02d'%(int(fdate[-2:])+1) +
                             #  same as above
                          '%02d'%(np.floor(v/24).astype(int)-days + 1) + '_%02d'%(v%24).astype(int))


    else:
                  tmp = np.append(tmp,str(fdate[-6:]) + '%02d'%(np.floor(v/24).astype(int)+1) +
                          '_%02d'%(v%24).astype(int))
251/36: tmp
251/37: dates.append(tmp)
251/38: zorb = dict()
251/39: zorb['SLP'] = SLP[0]
251/40: zorb['lon'] = lon[0]
251/41: zorb['lat'] = lat[0]
251/42: zorb['ID'] = ID[0]
251/43: zorb['hourstoSLPmin'] = hourstoSLPmin[0]
251/44: zrob['dates'] = dates[0]
251/45: zorb['dates'] = dates[0]
251/46: f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/cases/zorbas-data.txt','wb')
251/47: pickle.dump(zorb,f)
251/48: f.close()
251/49: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/zorbas-get-data.py 1-999
252/1: 0.7%0.5
252/2: 0.7-0.7%0.5
253/1: import numpy as np
253/2:
r = 6370
if True:
    DisLon = np.linspace(0,2 * np.pi * r,901)
    DisLat = np.linspace(0,0.5 * np.pi * r,226)

    DisLon = DisLon - DisLon[450]
    DisLat = DisLat- DisLat[113]

    disx, disy = np.meshgrid(DisLon,DisLat)

    r = np.sqrt(disx**2 + disy**2)
    Latids, Lonids = np.where(r<dis)
253/3: dis=200
253/4:
r = 6370
if True:
    DisLon = np.linspace(0,2 * np.pi * r,901)
    DisLat = np.linspace(0,0.5 * np.pi * r,226)

    DisLon = DisLon - DisLon[450]
    DisLat = DisLat- DisLat[113]

    disx, disy = np.meshgrid(DisLon,DisLat)

    r = np.sqrt(disx**2 + disy**2)
    Latids, Lonids = np.where(r<dis)
253/5: DisLon2 = np.linspace(0,2 * np.pi * r * np.cos(np.pi/6),901)
253/6: disx2, disy2 = np.meshgrid(DisLon2,DisLat)
254/1: dis=200
254/2: import numpy as np
254/3: r = 6370
254/4:
r = 6370
if True:
    DisLon = np.linspace(0,2 * np.pi * r,901)[:100]
    DisLat = np.linspace(0,0.5 * np.pi * r,226)[:100]

    DisLon = DisLon - DisLon[50]
    DisLat = DisLat- DisLat[50]

    disx, disy = np.meshgrid(DisLon,DisLat)

    r = np.sqrt(disx**2 + disy**2)
254/5: DisLon2 = np.linspace(0,2 * np.pi * r * np.cos(np.pi/6),901)[:100]
254/6: del(DisLon2)
254/7: R =6370
254/8: DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),901)[:100]
254/9: DisLon2 = DisLon2- DisLon2[50]
254/10: disx2, disy2 = np.meshgrid(DisLon,DisLat)
254/11: r2 = np.sqrt(disx2**2 + disy2**2)
254/12: disx
254/13: disy
254/14: disx2
254/15: disy2
254/16: disx2, disy2 = np.meshgrid(DisLon2,DisLat)
254/17: disx2
254/18: disy2
254/19: lonids,latids = np.wher(r<200)
254/20: lonids,latids = np.where(r<200)
254/21: lonids2,latids2 =np.where(r2<200)
254/22: len(lonids)
254/23: len(latids)
254/24: len(latids2)
254/25: len(lonids2)
254/26: DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/4),901)[:100]
254/27: DisLon2 = DisLon2- DisLon2[50]
254/28: disx2, disy2 = np.meshgrid(DisLon2,DisLat)
254/29: r2 = np.sqrt(disx2**2 + disy2**2)
254/30: lonids2,latids2 =np.where(r2<200)
254/31: len(latids2)
254/32: len(lonids2)
254/33: DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/4),901)[:100]
254/34: DisLon2 = DisLon2- DisLon2[50]
254/35: DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),901)[:100]
254/36: DisLon2 = DisLon2- DisLon2[50]
254/37: disx2, disy2 = np.meshgrid(DisLon2,DisLat)
254/38: r2 = np.sqrt(disx2**2 + disy2**2)
254/39: lonids2,latids2 =np.where(r2<200)
254/40: len(lonids2)
254/41:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/4),721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
254/42:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
254/43:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R,721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
254/44: r
254/45: r[40:60,40:60]
254/46: r[44:57,44:57]
254/47: r[50,40:60]
254/48: r[50,40:61]
254/49:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
254/50: r[50,40:61]
254/51:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/4),721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
254/52: r[50,40:61]
255/1: import numpy as np
255/2: R = 6370
255/3:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),721)[:100]
    DisLon2 = DisLon2- DisLon2[50]
    DisLat = np.linspace(0, np.pi * R,361)[:100]
    DisLat = DisLat - DisLat[50]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
255/4: disy
255/5: DisLat
255/6: disy.shape
255/7: disx.shape
255/8: disx
255/9:
if True:
    DisLon2 = np.linspace(0,2 * np.pi * R * np.cos(np.pi/6),721)
    DisLon2 = DisLon2- DisLon2[360]
    DisLat = np.linspace(0, np.pi * R,361)
    DisLat = DisLat - DisLat[180]
    disx, disy = np.meshgrid(DisLon2,DisLat)
    r = np.sqrt(disx**2 + disy**2)
    lonids,latids =np.where(r<200)
    print(len(lonids))
255/10: disx.shape
255/11: disy.shape
255/12:
R=6370
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat0)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)
255/13:
R=6370
centerlat=35
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat0)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)
255/14:
R=6370
centerlat=35
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)
255/15:
for q,k in enumerate(lat):
    DisLON[q] = np.linspace(0,2 * np.pi * r * np.cos(k/180*np.pi),721)
    DisLAT[q] = DisLAT[q] * latdis[q]
255/16: DisLON.shape
255/17: k
255/18:
for q,k in enumerate(lat):
    DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
    DisLAT[q] = DisLAT[q] * latdis[q]
255/19: DisLON
255/20:
R=6370
centerlat=35
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)
255/21:
for q,k in enumerate(lat):
    DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
    DisLAT[q] = DisLAT[q] * latdis[q]
255/22: DisLON
255/23: DisLON[0]
255/24: DisLON[180]
255/25: DisLON[120]
255/26: DisLON[10]
255/27: DisLON[5]
255/28: DisLON[1]
255/29: DisLON
255/30: DisLON.shape
255/31: DisLON-DisLON[circid][360]
255/32: (DisLON-DisLON[circid][360])[360]
255/33: test = DisLON-DisLON[circid][360]
255/34: test
255/35: test[10:]
255/36: test[10]
255/37: test[360]
255/38: test[circid]
255/39: test[circid+1]
255/40: test[circid+1][360]
255/41:
R=6370
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat0)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
        DisLAT[q] = DisLAT[q]-DisLat[q][360]
    DisLON = DisLON-DisLON[circid][360]
    r = np.sqrt(DisLON**2 + DisLAT**2)
255/42:
R=6370
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
        DisLAT[q] = DisLAT[q]-DisLat[q][360]
    DisLON = DisLON-DisLON[circid][360]
    r = np.sqrt(DisLON**2 + DisLAT**2)
255/43:
R=6370
if True:
    lat = np.arange(-90,90.1,0.5)
    circid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
        
    DisLON = DisLON-DisLON[circid][360]
    r = np.sqrt(DisLON**2 + DisLAT**2)
255/44: DisLAT
255/45: DisLAT = DisLAT-DisLAT[180]
255/46: DisLAT
255/47: DisLON
255/48: r = np.sqrt(DisLON**2 + DisLAT**2)
255/49: r
255/50: rdis = 200
255/51: Latids, Lonids = np.where(r<dis)
255/52: Latids, Lonids = np.where(r<rdis)
255/53: Latids
255/54: len(Latids)
255/55: len(lonids)
255/56: r[170:190]
255/57: len(Lonids)
256/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle
import os

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'ctraj/'

Lat = np.arange(90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel-no-kicking.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    ##check correct date format
    if len(dates[l][ids])==11:
    ##

        lat[l][ids] = Lat[np.where(abs(Lat-lat[l][ids])==np.min(abs(Lat-lat[l][ids])))[0]]
        lon[l][ids] = Lon[np.where(abs(Lon-lon[l][ids])==np.min(abs(Lon-lon[l][ids])))[0]]

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
256/2:
p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.arange(90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    ##check correct date format
    if len(dates[l][ids])==11:
    ##

        lat[l][ids] = Lat[np.where(abs(Lat-lat[l][ids])==np.min(abs(Lat-lat[l][ids])))[0]]
        lon[l][ids] = Lon[np.where(abs(Lon-lon[l][ids])==np.min(abs(Lon-lon[l][ids])))[0]]

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
256/3: maturedates
256/4:
for q,k in enumerate(maturedates):
    if int(k[4:6])==13:
        print(q,k)
256/5: len(maturedates)
257/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle
import os

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.arange(90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel-no-kicking.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    ##check correct date format
    if len(dates[l][ids])==11:
    ##

        lat[l][ids] = Lat[np.where(abs(Lat-lat[l][ids])==np.min(abs(Lat-lat[l][ids])))[0]]
        lon[l][ids] = Lon[np.where(abs(Lon-lon[l][ids])==np.min(abs(Lon-lon[l][ids])))[0]]

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
257/2: len(ID)
257/3:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle
import os

p = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'
p += 'traj/'

Lat = np.arange(90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']

SLP = []
lon = []
lat = []
ID = []
hourstoSLPmin = []
dates = []

var = [SLP, lon, lat, ID, hourstoSLPmin, dates]

for u,x in enumerate(savings):
    f = open(p + x + 'furthersel.txt',"rb")
    var[u] = pickle.load(f)
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]

maturedates = np.array([])
clat = np.zeros(len(ID))
clon = np.zeros(len(ID))
for l in range(len(ID[:])):
    ids = np.where(hourstoSLPmin[l]==0)[0][-1]
    ##check correct date format
    if len(dates[l][ids])==11:
    ##

        lat[l][ids] = Lat[np.where(abs(Lat-lat[l][ids])==np.min(abs(Lat-lat[l][ids])))[0]]
        lon[l][ids] = Lon[np.where(abs(Lon-lon[l][ids])==np.min(abs(Lon-lon[l][ids])))[0]]

        maturedates = np.append(maturedates,dates[l][ids])
        clat[l] = np.where(Lat==np.round(lat[l][ids],1))[0][0]
        clon[l] = np.where(Lon==np.round(lon[l][ids],1))[0][0]
257/4: len(ID)
258/1: import numpy as np
258/2:
def radial_ids_around_center_calc_ERA5(dis):
    """
    Return longitude, latidue ids that are within radius r=dis around the center
    """
    r = 6370

    DisLon = np.linspace(0,2 * np.pi * r,721)
    DisLat = np.linspace(0,np.pi * r,361)

    DisLon = DisLon - DisLon[360]
    DisLat = DisLat- DisLat[180]

    disx, disy = np.meshgrid(DisLon,DisLat)

    r = np.sqrt(disx**2 + disy**2)
    Latids, Lonids = np.where(r<dis)
    Lonids = Lonids-360 #use 450 and 113 as the shift is alraedy accounted for in the txt files created
    Latids = Latids-180 #therefore this works with the true center and need no shift

    return Lonids, Latids
258/3:
def ERA5_radial_ids_correct(rdis,centerlat):
    R=6370
    lat = np.arange(-90,90.1,0.5)
    latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]

    DisLON = DisLON-DisLON[latid][360]
    DisLAT = DisLAT-DisLAT[180]

    r = np.sqrt(DisLON**2 + DisLAT**2)
    Latids, Lonids = np.where(r<rdis)

    Lonids=Lonids-360
    Latids=Latids-180

    return Lonids, Latids
258/4: dis =200
258/5: rdis = 200
258/6: centerlat=44.5
258/7: print(ERA5_radial_ids_correct(rdis,centerlat))
258/8:
R=6370
if True:
    lat = np.arange(-90,90.1,0.5)
    latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
    DisLON = np.zeros((361,721))
    DisLAT = np.ones((361,721))
    latdis = np.linspace(0,np.pi * R,361)

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
258/9: DisLON
258/10: DisLON[latid]
258/11: DisLON-DisLON[latid][360]
258/12: DisLON[latid]-DisLON[latid][360]
258/13: np.where((DisLON-DisLON[latid][360])<200)[0]
258/14: np.where((DisLON[latid]-DisLON[latid][360])**2<200)[0]
258/15: DisLON[latid]-DisLON[latid][360]
258/16: np.where(np.sqrt((DisLON[latid]-DisLON[latid][360])**2)<200)
258/17:
DisLON = DisLON-DisLON[latid][360]
DisLAT = DisLAT-DisLAT[180]
258/18: np.where((DisLON**2)<200)
258/19: np.where((DisLON[latid]**2)<200)
258/20: np.where(np.sqrt(DisLON[latid]**2)<200)
258/21: np.where(np.sqrt(DisLON[latid+1]**2)<200)
258/22: trash, LATIDS = helper.radial_ids_around_center_calc_ERA5(rdis)
258/23: trash, LATIDS = radial_ids_around_center_calc_ERA5(rdis)
258/24: LATIDS = np.unique(LATIDS).astype(int)
258/25: LATIDS
258/26: np.linspace(0,2 * np.pi * r,721)[:5]
258/27: np.linspace(0,2 * np.pi * R,721)[:5]
258/28:
lat = np.arange(-90,90.1,0.5)
    latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0] + LATIDS
258/29:
lat = np.arange(-90,90.1,0.5)
latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0] + LATIDS
258/30: latid
259/1: import numpy as np
259/2:
def radial_ids_around_center_calc_ERA5(dis):
    """
    Return longitude, latidue ids that are within radius r=dis around the center
    """
    r = 6370

    DisLon = np.linspace(0,2 * np.pi * r,721)
    DisLat = np.linspace(0,np.pi * r,361)

    DisLon = DisLon - DisLon[360]
    DisLat = DisLat- DisLat[180]

    disx, disy = np.meshgrid(DisLon,DisLat)

    r = np.sqrt(disx**2 + disy**2)
    Latids, Lonids = np.where(r<dis)
    Lonids = Lonids-360 #use 450 and 113 as the shift is alraedy accounted for in the txt files created
    Latids = Latids-180 #therefore this works with the true center and need no shift

    return Lonids, Latids
259/3:
R=6370
if True:
    trash, LATIDS = radial_ids_around_center_calc_ERA5(rdis)
    LATIDS = np.unique(LATIDS).astype(int) #unaffected by latitude strech of longitude

    lat = np.arange(-90,90.1,0.5)
    latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0] + LATIDS
259/4: rdis=200
259/5: centerlat=44.5
259/6:
R=6370
if True:
    trash, LATIDS = radial_ids_around_center_calc_ERA5(rdis)
    LATIDS = np.unique(LATIDS).astype(int) #unaffected by latitude strech of longitude

    lat = np.arange(-90,90.1,0.5)
    latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0] + LATIDS
259/7: latid
259/8:
DisLON = np.zeros((len(latid),721))
DisLAT = np.ones((len(latid),721))
259/9: latdis = np.linspace(0,np.pi * R,361)[latid]
259/10: latdis
259/11: latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
259/12: latids = latids+LATIDS
259/13: latids = latid + LATIDS
259/14: latdis = np.linspace(0,np.pi * R,361)
259/15: latdis = latdis-latdis[latid]
259/16: latdis[latids]
259/17:
for q,k in enumerate(lat[latids]):
    DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
    DisLAT[q] = DisLAT[q] * latdis[q]
259/18: DisLAT
259/19: latdis
259/20:
latdis = np.linspace(0,np.pi * R,361)
latdis = latdis - latdis[latid]
latdis = latdis[latids]
259/21: latdis
259/22:
DisLON = np.zeros((len(latids),721))
DisLAT = np.ones((len(latids),721))
259/23: DisLAT.shape
259/24:
for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
259/25:
for q,k in enumerate(lat[latids]):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] = DisLAT[q] * latdis[q]
259/26: DisLAT
259/27: DisLAT.shape
259/28: latdis
259/29: lat[latids]
259/30: k
259/31: q
259/32: DisLAT[q]
259/33: latdis[q]
259/34:
DisLON = np.zeros((len(latids),721))
DisLAT = np.ones((len(latids),721))
259/35: DisLAT
259/36: DisLAT[0]
259/37: DisLAT[0] *=latdis[0]
259/38: DisLAT[0]
259/39:
latid = np.where(abs(lat-centerlat)==np.min(abs(lat-centerlat)))[0][0]
if True:
    latids = latid + LATIDS

    DisLON = np.zeros((len(latids),721))
    DisLAT = np.ones((len(latids),721))
    latdis = np.linspace(0,np.pi * R,361)
    latdis = latdis - latdis[latid]
    latdis = latdis[latids]

    for q,k in enumerate(lat):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] *=  latdis[q]
259/40:
DisLON = np.zeros((len(latids),721))
if True:
    DisLAT = np.ones((len(latids),721))
    latdis = np.linspace(0,np.pi * R,361)
    latdis = latdis - latdis[latid]
    latdis = latdis[latids]

    for q,k in enumerate(lat[latids]):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] *=  latdis[q]
259/41: DisLAT[q]
259/42: DisLON[q]
259/43:
DisLON = np.zeros((len(latids),721))
if True:
    DisLAT = np.ones((len(latids),721))
    latdis = np.linspace(0,np.pi * R,361)
    latdis = latdis - latdis[latid]
    latdis = latdis[latids]

    for q,k in enumerate(lat[latids]):
        DisLON[q] = np.linspace(0,2 * np.pi * R * np.cos(k/180*np.pi),721)
        DisLAT[q] *=  latdis[q]
        DisLON[q] = DisLON[q]-DisLON[q][360]
259/44: DisLON[q]
259/45: r = np.sqrt(DisLON**2 + DisLAT**2)
259/46: Latids, Lonids = np.where(r<rdis)
259/47: Lonids=Lonids-360
259/48: Latids=Latids-180
259/49: Lonids
259/50: len(Lonids)
259/51: Latids
259/52: Latids, Lonids = np.where(r<rdis)
259/53: Latids
259/54: latids
259/55: Latids-=3
259/56: Latids
260/1:
import numpy as np
import pickle
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm
import argparse
import cartopy
import matplotlib.gridspec as gridspec
260/2: rdis=400
260/3:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
datadi = PVdata['rawdata']
dit = PVdata['dit']

both = np.array([])
adv = np.array([])
cyclonic = np.array([])
environmental = np.array([])

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
maturedates = np.array([])
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    maturedates = np.append(maturedates,dates[k][abs(hourstoSLPmin[k][0]).astype(int)])
260/4:
for ll,k in enumerate(dipv.keys()):
    q = np.where(avaID==int(k))[0][0]
    if int(k)==10599:
        print(len(datadi[k]['PV'][:,0]))
        print(len(np.where(datadi[k]['PV'][:,0]>=0.75)[0]))
261/1:
import numpy as np
airports = ['BGI','CDG','DEL','DOH','DSM','EWR','EYW','HND',
            'ICN','JFK','LGA','LHR','ORD','SAN','SFO','SIN','TLV','BUD']
            
rountes=[
['DSM','ORD'],
['ORD','BGI'],
['BGI','LGA'],
['SIN','CDG'],
['CDG','SIN'],
['CDG','BUD'],
['DEL','DOH'],
['DEL','CDG'],
['TLV','DEL'],
['EWR','HND'],
['HND','ICN'],
['HND','JFK'],
['ICN','JFK'],
['JFK','LGA'],
['EYW','LHR'],
['LHR','SFO'],
['SFO','SAN'],
['SFO','DSM'],
['SAN','EYW']
]
261/2:
import numpy as np
airports = ['BGI','CDG','DEL','DOH','DSM','EWR','EYW','HND','ICN','JFK','LGA','LHR','ORD','SAN','SFO','SIN','TLV','BUD']

routes=[
['DSM','ORD'],
['ORD','BGI'],
['BGI','LGA'],
['SIN','CDG'],
['CDG','SIN'],
['CDG','BUD'],
['DEL','DOH'],
['DEL','CDG'],
['TLV','DEL'],
['EWR','HND'],
['HND','ICN'],
['HND','JFK'],
['ICN','JFK'],
['JFK','LGA'],
['EYW','LHR'],
['LHR','SFO'],
['SFO','SAN'],
['SFO','DSM'],
['SAN','EYW']
]
261/3: start = 'LGA'
261/4:
for r in routes:
    print(r,r[0],r[1])
262/1: start = 'LGA'
262/2:
import numpy as np
airports = ['BGI','CDG','DEL','DOH','DSM','EWR','EYW','HND','ICN','JFK','LGA','LHR','ORD','SAN','SFO','SIN','TLV','BUD']

routes=[
['DSM','ORD'],
['ORD','BGI'],
['BGI','LGA'],
['SIN','CDG'],
['CDG','SIN'],
['CDG','BUD'],
['DEL','DOH'],
['DEL','CDG'],
['TLV','DEL'],
['EWR','HND'],
['HND','ICN'],
['HND','JFK'],
['ICN','JFK'],
['JFK','LGA'],
['EYW','LHR'],
['LHR','SFO'],
['SFO','SAN'],
['SFO','DSM'],
['SAN','EYW']
]
262/3:
connect = dict()
for air in airports[airports!='LGA']:
    connect[air] = np.array([])
    for r in routes:
        if r[0]==air:
           conntect[air] = np.append(connect[air],r[1])
262/4: connect[air]
262/5: connect
262/6:
connect = dict()
for air in airports:
    connect[air] = np.array([])
    for r in routes:
        if r[0]==air:
           conntect[air] = np.append(connect[air],r[1])
262/7:
connect = dict()
for air in airports:
    connect[air] = np.array([])
    for r in routes:
        if r[0]==air:
           connect[air] = np.append(connect[air],r[1])
262/8: connect
262/9:
connect = dict()
for air in airports:
    connect[air] = np.array([])
    for r in routes:
        if r[0]==air and r[1]!='LGA':
           connect[air] = np.append(connect[air],r[1])
262/10: connect
262/11: goto = dict()
262/12:
for c in connect.keys():
    goto[c] = 0
    
for c in connect.keys():
    for k in connect[c]:
        goto[k]+=1
262/13: goto
263/1: import numpy as np
263/2: import pandas as pd
264/1: import numpy as np import pandas as pd import pickle
264/2: import numpy as np
264/3: import pandas as pd
264/4: import pickle as pi
265/1: import pandas as pd
265/2: import numpy as np
265/3: import pickle
265/4: regions = ['MED','NA','SA','NP','SP','IO']
265/5: mature = dict()
265/6:
other = dict()
for r in regions:
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-96h-pre-track-deep-over-sea-12h.txt','rb')
    mature[r] = pickle.load(f)
    f.close()
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-mature-deep-over-sea-12h.txt','rb')
    other[r] = pickle.load(f)
    f.close()
265/7: other['MED'].shape
265/8: df = pd.DataFrame(other['MED'],colums=['ID','lon','lat','htSLPmin','minSLP'])
265/9: df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP'])
265/10: df
265/11: df.loc[df['htSLPmin']<12]
265/12: df.loc[df['htSLPmin']>=12]
265/13: dfn = df.loc[df['htSLPmin']>=12]
265/14: dfn
265/15: dfn.loc[dfn['minSLP']<1000]
265/16: dfn.describe()
265/17: dfn.loc[dfn['minSLP']<1000].describe()
265/18: dfn.loc[dfn['minSLP']<1000]['minSLP'].describe()
265/19: df
265/20: dfn
265/21: dfn['reg'] = ['MED']
265/22: dfn['reg'] = 'MED'
265/23: dfn
265/24: tmpdf = pd.DataFrame(other['NA'],columns=['ID','lon','lat','htSLPmin','minSLP'])
265/25: tmpdf
265/26: tmpdf = tmpdf.loc[tmpdf['htSLPmin']>=12]
265/27: tmpdf
265/28: tmpdf.describe
265/29: tmpdf = tmpdf.loc[tmpdf['minSLP']<1000]
265/30: tmpdf
265/31: tmpdf['reg'] = 'NA'
265/32: tmpdf
265/33: tmpdf = tmpdf[[cols[-1]] + cols[:-1]]
265/34: cols = list(df.columns)
265/35: cols
265/36: tmpdf = tmpdf[[cols[-1]] + cols[:-1]]
265/37: tmpdf
265/38: tmpdf = pd.DataFrame(other['NA'],columns=['ID','lon','lat','htSLPmin','minSLP'])
265/39: tmpdf = tmpdf.loc[tmpdf['htSLPmin']>=12]
265/40: tmpdf = tmpdf.loc[tmpdf['minSLP']<1000]
265/41: tmpdf
265/42: tmpdf['reg'] = 'NA'
265/43: cols = list(tmpdf.columns)
265/44: cols
265/45: tmpdf = tmpdf[[cols[-1]] + cols[:-1]]
265/46: tmpdf
265/47: dfn
265/48: dfn = dfn.loc[dfn['minSLP']<1000]
265/49: dfn
265/50: dfn = dfn[[cols[-1]] + cols[:-1]]
265/51: dfn
265/52: dfn.append(tmpdf,ignore_index=True)
265/53:
for r in regions[1:]:
    tmp = pd.DataFrame(other[r],columns=['ID','lon','lat','htSLPmin','minSLP'])
    tmp['reg'] = r
    tmp = tmp[[cols[-1]] + cols[:-1]]
    tmp = tmp.loc[(tmp['minSLP']<1000) & (tmp['htSLPmin']>=12)]
    dfn = dfn.append(tmp,ignore_index=True)
265/54: dfn
265/55: pd.unique(dfn['reg'])
265/56: pd.unique(dfn['minSLP'])
265/57: mature
265/58: mature['MED']
265/59: mature['MED'].shape
265/60: dfn
265/61: df
265/62: df = pd.DataFrame(mature['MED'])
265/63: df
265/64: df = pd.DataFrame(mature['MED'],colums=['ID',np.arange(-96,1,1)])
265/65: df = pd.DataFrame(mature['MED'],columns=['ID',np.arange(-96,1,1)])
265/66: df = pd.DataFrame(mature['MED'],columns=np.append('ID',np.arange(-96,1,1)))
265/67: df
265/68: df = df[:2]
265/69: df
265/70: nvalues = []
265/71: df.shape
265/72:
for k in df.shape[1]:
    tl = []
    for l in df.shape[0]:
        if k==0 & l==0:
            nvalues.append(df[k,l])
        elif k==0 & l==1:
            continue
        else:
            tl.append(df[k,l])
            
    nvalues.append(tl)
265/73:
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 & l==0:
            nvalues.append(df[k,l])
        elif k==0 & l==1:
            continue
        else:
            tl.append(df[k,l])
            
    nvalues.append(tl)
265/74: df.shape[0]
265/75: df[0,0]
265/76: df[1,0]
265/77: df[1,1]
265/78:
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 & l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 & l==1:
            continue
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/79: nvalues
265/80:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 & l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 & l==1:
            continue
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/81: nvalues
265/82: len(nvalues)
265/83: nvalues[:5]
265/84:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 & l==0:
            nvalues.append(df[ncol[k]][l])
        if k==0 and l==1:
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/85: nvalues
265/86: l
265/87: k
265/88:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        if k==0 and l==1:
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/89: nvalues
265/90:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/91: nvalues
265/92: nvalues = []
265/93:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/94: nvalues
265/95: nvalues = []
265/96: nvalues
265/97:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        print(k,l)
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/98:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            print('first')
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            print('second')
            break
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/99:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            print('first')
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            print('second')
            continue
        else:
            tl.append(df[ncol[k]][l])
            
    nvalues.append(tl)
265/100: nvalues
265/101:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = []
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            continue
        else:
            tl.append(df[ncol[k]][l])
    if k>0:        
        nvalues.append(tl)
265/102: nvalues
265/103: df
265/104: df.append(nvalues,ignore_index=True)
265/105: df
265/106:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = np.array([])
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            continue
        else:
            tl = np.append(tl,df[ncol[k]][l])
    if k>0:        
        nvalues.append(tl)
265/107: nvalues
265/108: df.append(nvalues,ignore_index=True)
265/109: tup =()
265/110: tup[0] = 1
265/111: tip
265/112: tup
265/113: tup+(1,)
265/114: tup+(1)
265/115: tup+(1,2)
265/116: tup+(1)
265/117: tup+(1,)
265/118: tup+(1,)+(2,)
265/119: tup +=(1,2)
265/120: tup[0]
265/121: tup[1]
265/122:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = ()
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            continue
        else:
            tl += (df[ncol[k]][l],)
    if k>0:        
        nvalues.append(tl)
265/123: nvalues
265/124: test
265/125: test = pd.DataFrame(nvalues,columns = [np.append('ID',np.arange(-96,1,1))])
265/126: nvalues
265/127: df
265/128: ncols
265/129: cols
265/130: ncol
265/131: df[ncol[1:]]
265/132: df[ncol[1:]][0]
265/133: df[ncol[1:]]
265/134: df[ncol[1:]][1]
265/135: df[ncol[1:][0]]
265/136: df[ncol[1:][0,0]]
265/137: df[ncol[1:][0]]
265/138: df[ncol[1:][0]].values
265/139: df[ncol[1:]].values
265/140: zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])
265/141: *zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])
265/142: pd.DataFrame(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1]))
265/143: pd.DataFrame(*zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1]))
265/144: pd.DataFrame(dict(col=*zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])))
265/145: pd.DataFrame(dict(col=zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])))
265/146: pd.DataFrame(dict(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])))
265/147: pd.DataFrame(dict(col = zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1][0])))
265/148: pd.DataFrame(dict(col = zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])))
265/149: zip
265/150: zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1]).values
265/151: zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])
265/152: list(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1]))
265/153: pd.DataFrame(list(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])))
265/154: pd.DataFrame(list(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1])),columns=np.arange(-96,1,1))
265/155: pd.DataFrame(zip(df[ncol[1:]].values[0],df[ncol[1:]].values[1]),columns=np.arange(-96,1,1))
265/156: df
265/157: daf = pd.DataFrame([(),(),(),()],columns=[-3,-2,-1,0])
265/158: daf = pd.DataFrame([[(),(),(),()],[(),(),(),()]],columns=[-3,-2,-1,0])
265/159: daf
265/160: daf[['-3]]
265/161: daf['-3]
265/162: daf['-3']
265/163: daf
265/164: daf.shape
265/165: daf[0]
265/166: daf[-3]
265/167: daf[-3].values
265/168: daf[-3].values[0] = daf[-3].values[0]+(500,500)
265/169: daf[-3].values[1] = daf[-3].values[1]+(500,500)
265/170: daf[-3]
265/171: daf
265/172: df
265/173: test
265/174: df.values
265/175: df.values[0][0]
265/176: df.values[0][1]=(500,500)
265/177: daf
265/178: daf.append(daf)
265/179: daf = pd.DataFrame([[5,(),(),(),()],[6,(),(),(),()]],columns=['ID',-3,-2,-1,0])
265/180: daf
265/181: daf[-3][0]
265/182: e0 = []
265/183:
for k in range(2):
    tmp = [1]
    for l in range(-96,1,1)
265/184:
for k in range(2):
    tmp = [1]
    for l in range(-96,1,1):
        tmp.append(())
    e0.append(tmp)
265/185: e0
265/186: linezero = pd.DataFrame(e0,columns=np.append('ID',np.arange(-96,1,1)))
265/187: linezero
265/188: nvalues
265/189: linezero
265/190: linezero.append(nvalues,ignore_index=True)
265/191: nvalues
265/192: nvalues2 = [nvalues,nvalues]
265/193: nvalues2
265/194: linezero
265/195: linezero.append(nvalues2)
265/196: linezero.append(nvalues2,ignore_index=True)
265/197: linezero.append([nvalues,[]],ignore_index=True)
265/198: test = pd.DataFrame([nvalues,[]])
265/199: test
265/200: linezero.append([nvalues],ignore_index=True)
265/201: test = pd.DataFrame([nvalues])
265/202: test
265/203:
nvalues = []
ncol = list(df.columns)
for k in range(df.shape[1]):
    tl = ()
    for l in range(df.shape[0]):
        if k==0 and l==0:
            nvalues.append(df[ncol[k]][l])
        elif k==0 and l==1:
            continue
        else:
            tl += (df[ncol[k]][l],)
    if k>0:        
        nvalues.append(tl)
265/204: nvalues
265/205: df
265/206: df.append(pd.DataFrame([nvalues],columns=np.append('ID',np.arange(-96,1,1))))
265/207: df = df.append(pd.DataFrame([nvalues],columns=np.append('ID',np.arange(-96,1,1))))
265/208: df[-96][3][0]
265/209: df
265/210: df.keys()
265/211: df['0']
265/212: df['0'][0]
265/213: df['0'][3]
265/214: df['0'][2]
265/215: df['0']
265/216: df.drop(0)
265/217: df.drop(0).drop(1)
265/218: df = df.drop(0).drop(1).append(pd.DataFrame([nvalues],columns=np.append('ID',np.arange(-96,1,1))),ignore_index=True)
265/219: df
265/220: df['0']
265/221: df['0'][0]
265/222: df['0'][0][1]
265/223: %save -r /atmosdyn2/ascherrmann/scripts/all-oceans/pandas-data.py 1-999
266/1: import pandas as pd
266/2: import numpy as np
266/3: adf = pd.DataFrame(colums=np.append('ID',np.arange(-96,1,1)))
266/4: adf = pd.DataFrame(columns=np.append('ID',np.arange(-96,1,1)))
266/5: adf
266/6:
regions = ['MED','NA','SA','NP','SP','IO']
mature = dict()
other = dict()

#### raw data
for r in regions:
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-96h-pre-track-deep-over-sea-12h.txt','rb')
    mature[r] = pickle.load(f)
    f.close()
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-mature-deep-over-sea-12h.txt','rb')
    other[r] = pickle.load(f)
    f.close()



#### dataframe for basic data
#### ID, mature lon and lat, hourstoSLPmin and minimal SLP
df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP'])
df['reg'] = 'MED'
cols = list(df.columns)
df = df [cols[-1]] + cols[:-1]

for r in regions[1:]:
    tmp = pd.DataFrame(other[r],columns=['ID','lon','lat','htSLPmin','minSLP'])
    tmp['reg'] = r
    tmp = tmp[[cols[-1]] + cols[:-1]]
    df = df.append(tmp,ignore_index=True)
266/7:
import pickle

regions = ['MED','NA','SA','NP','SP','IO']
mature = dict()
other = dict()

#### raw data
for r in regions:
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-96h-pre-track-deep-over-sea-12h.txt','rb')
    mature[r] = pickle.load(f)
    f.close()
    f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/' + r + '-mature-deep-over-sea-12h.txt','rb')
    other[r] = pickle.load(f)
    f.close()



#### dataframe for basic data
#### ID, mature lon and lat, hourstoSLPmin and minimal SLP
df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP'])
df['reg'] = 'MED'
cols = list(df.columns)
df = df [cols[-1]] + cols[:-1]

for r in regions[1:]:
    tmp = pd.DataFrame(other[r],columns=['ID','lon','lat','htSLPmin','minSLP'])
    tmp['reg'] = r
    tmp = tmp[[cols[-1]] + cols[:-1]]
    df = df.append(tmp,ignore_index=True)
266/8:
df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP'])
df['reg'] = 'MED'

cols = list(df.columns)
df = df [cols[-1]] + cols[:-1]
print(df)
266/9: df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP'])
266/10: df['reg'] = 'MED'
266/11: cols = list(df.columns)
266/12: cols
266/13: df = df[[cols[-1]] + cols[:-1]]
266/14:
for r in regions[1:]:
    tmp = pd.DataFrame(other[r],columns=['ID','lon','lat','htSLPmin','minSLP'])
    tmp['reg'] = r
    tmp = tmp[[cols[-1]] + cols[:-1]]
    df = df.append(tmp,ignore_index=True)
266/15: df
266/16: df['ID']
266/17: df['ID'].astype(int)
266/18: df['ID'] = df['ID'].astype(int)
266/19: df
266/20: df['htSLPmin'] = df['htSLPmin'].astype(int)
266/21: df
266/22: adf = pd.DataFrame(columns=np.append('ID',np.arange(-96,1,1)))
266/23:
nvalues = []
ncol = list(adf.columns)
266/24: ncol
266/25: adf = pd.DataFrame(columns=np.append('reg',np.append('ID',np.arange(-96,1,1))))
266/26: adf
266/27: adv[-3]
266/28: adf[-3]
266/29: adf['-3']
266/30:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
appendvalues = []
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
  for u in range(len(mature[r][:,0]),2)
    nvalues = [r,mature[r][u,0]]
    for k in range(le):
        tl = ()
        for l in range(2):
            tl += (mature[r][u][k,l],)
        if k>0:
            nvalues.append(tl)
  appendvalues.append(nvalues)

adf = adf.append(pd.DataFrame([appendvalues],columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1))),ignore_index=True)
266/31:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
appendvalues = []
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
  for u in range(len(mature[r][:,0]),2):
    nvalues = [r,mature[r][u,0]]
    for k in range(le):
        tl = ()
        for l in range(2):
            tl += (mature[r][u][k,l],)
        if k>0:
            nvalues.append(tl)
  appendvalues.append(nvalues)

adf = adf.append(pd.DataFrame([appendvalues],columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1))),ignore_index=True)
266/32: appendvalues[0]
266/33: appendvalues
266/34:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
appendvalues = []
ncol = list(adf.columns)
le = len(mature['MED'][0])
266/35: le
266/36: adf
266/37:
for r in regions:
    for u in range(len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u][k,l],)
            if k>0:
                nvalues.append(tl)
    appendvalues.append(nvalues)
266/38: appendvalues
266/39: regions
266/40:
for r in regions:
    for u in range(len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u][k,l],)
            if k>0:
                nvalues.append(tl)
        appendvalues.append(nvalues)
266/41: appendvalues
266/42:
for r in regions[:1]
    print(r)
    for u in range(len(mature[r][:,0]),2):
        print(u)
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u][k,l],)
            if k>0:
                nvalues.append(tl)
266/43:
for r in regions[:1]:
    print(r)
    for u in range(len(mature[r][:,0]),2):
        print(u)
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u][k,l],)
            if k>0:
                nvalues.append(tl)
266/44: mature[r].shape
266/45:
for r in regions[:1]:
    print(r)
    for u in range(0,len(mature[r][:,0]),2):
        print(u)
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u][k,l],)
            if k>0:
                nvalues.append(tl)
266/46:
for r in regions[:1]:
    print(r)
    for u in range(0,len(mature[r][:,0]),2):
        print(u)
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][k,u+l],)
            if k>0:
                nvalues.append(tl)
266/47:
for r in regions[:1]:
    print(r)
    for u in range(0,len(mature[r][:,0]),2):
        print(u)
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)
266/48:
appendvalues = []
for r in regions[:1]:
    for u in range(0,len(mature[r][:,0]),2):        
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)
        appendvalues.append(nvalues)
266/49: appendvalues
266/50: nvalues
266/51:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)

    adf = adf.append(pd.DataFrame([nvalues],columns=ncol,ignore_index=True))
266/52:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)

    adf = adf.append(pd.DataFrame([nvalues],columns=ncol),ignore_index=True)
266/53: adf
266/54:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)

        adf = adf.append(pd.DataFrame([nvalues],columns=ncol),ignore_index=True)
266/55:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    appendvalues = []
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)
        appendvalues.append(nvalues)

    adf = adf.append(pd.DataFrame([appendvalues],columns=ncol),ignore_index=True)
266/56:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    appendvalues = []
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)
        appendvalues.append([nvalues])

    adf = adf.append(pd.DataFrame([appendvalues],columns=ncol),ignore_index=True)
266/57:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    appendvalues = []
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)
        appendvalues.append([nvalues])

    adf = adf.append(pd.DataFrame(appendvalues,columns=ncol),ignore_index=True)
266/58: appendvalues.shape
266/59: appendvalues
266/60:
adf = pd.DataFrame(columns=np.append(np.array(['reg','ID']),np.arange(-96,1,1)))
ncol = list(adf.columns)
le = len(mature['MED'][0])
for r in regions[:1]:
    for u in range(0,len(mature[r][:,0]),2):
        nvalues = [r,mature[r][u,0]]
        for k in range(le):
            tl = ()
            for l in range(2):
                tl += (mature[r][u+l,k],)
            if k>0:
                nvalues.append(tl)

        adf = adf.append(pd.DataFrame([nvalues],columns=ncol),ignore_index=True)
266/61: adf
266/62: df[ncols[-5:]]
266/63: df[ncol[-5:]]
266/64: df[ncol[-5]]
266/65: df
266/66: adf[ncol[-5:]]
267/1:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)

def inter2level(varr3D, parr3D, plevel):
    """
    Interpolates 3-D (level, lat, lon) over level for variable array varr with
    associated pressure grid parr to the scalar pressure level plevel
    """
    v_i = interpolate(varr3D[::1,:, :], parr3D[:, :], plevel)
    return(v_i)


############# end functions ##################


## Import modules
from dypy.intergrid import Intergrid
import matplotlib.colors as col
import matplotlib.cm as cm
from mpl_toolkits.basemap import Basemap
import numpy as np
import netCDF4
from netCDF4 import Dataset as ncFile
from dypy.small_tools import interpolate
from dypy.lagranto import Tra
import matplotlib.pyplot as plt
import matplotlib as mpl
import cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from matplotlib.gridspec import GridSpec
from matplotlib.colors import from_levels_and_colors
import datetime as dt
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
267/2: date='20180928_04'
267/3: lon_start = 13
267/4: lon_end = 25
267/5: lat_start = 34
267/6: lat_end = 34
267/7:
var='PV'
unit='PVU'#g kg$^{-1}$'
cmap,pv_levels,norm,ticklabels=PV_cmap2()
levels=pv_levels
# Define lower and upper bound for vertical cross section (y-axis)
ymin = 200.
ymax = 1000.

dynfmt = '%Y%m%d_%H'
datobj=dt.datetime.strptime(dat,dynfmt)  # change to python time
outpath  = '/atmosdyn2/ascherrmann/009-ERA-5/MED/' #Wo Plot gespeichert wird

y=dat[0:4]
m=dat[4:6]
print(dat)
267/8: dat = date
267/9:
var='PV'
unit='PVU'#g kg$^{-1}$'
cmap,pv_levels,norm,ticklabels=PV_cmap2()
levels=pv_levels
# Define lower and upper bound for vertical cross section (y-axis)
ymin = 200.
ymax = 1000.

dynfmt = '%Y%m%d_%H'
datobj=dt.datetime.strptime(dat,dynfmt)  # change to python time
outpath  = '/atmosdyn2/ascherrmann/009-ERA-5/MED/' #Wo Plot gespeichert wird

y=dat[0:4]
m=dat[4:6]
print(dat)
267/10:
pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat  #für Lothar ändern clim_era5/lothar ohne +y+ und +m+
sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat
bfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/B'+dat
slp=readcdf(bfile,'MSL')
ps=readcdf(pfile,'PS')
#pv=readcdf(sfile,var) #change file if necessary
PV=readcdf(sfile,'PV')
pv=PV
q=readcdf(pfile,'Q')
rh=readcdf(sfile,'RH')
th=readcdf(sfile,'TH')
iwc=readcdf(pfile,'IWC')
swc=readcdf(pfile,'SWC')
lwc=readcdf(pfile,'LWC')
rwc=readcdf(pfile,'RWC')
lons=readcdf(pfile,'lon')
lats=readcdf(pfile,'lat')
hyam=readcdf(pfile,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pfile,'hybm')  #   ''
ak=hyam[hyam.shape[0]-pv.shape[1]:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-pv.shape[1]:]
267/11: ds = 5.
267/12:
mvcross    = Basemap()
line,      = mvcross.drawgreatcircle(lon_start, lat_start, lon_end, lat_end, del_s=ds)
path       = line.get_path()
lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
dimpath    = len(lonp)
267/13:
p3d=np.full((pv.shape[1],pv.shape[2],pv.shape[3]),-999.99)
ps3d=np.tile(ps[0,:,:],(pv.shape[1],1,1)) # write/repete ps to each level of dim 0
p3d=(ak/100.+bk*ps3d.T).T
unit_p3d = 'hPa'
267/14: vcross = np.zeros(shape=(pv.shape[1],dimpath))
267/15:
vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
bottomleft = np.array([lats[0], lons[0]])
topright   = np.array([lats[-1], lons[-1]])
267/16:
for k in range(pv.shape[1]):
    f_vcross     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    for i in range(dimpath):
        vcross[k,i]     = f_vcross.at([latp[i],lonp[i]])
        vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
        vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
267/17:
xcoord = np.zeros(shape=(pv.shape[1],dimpath))
for x in range(pv.shape[1]):
    xcoord[x,:] = np.array([ i*ds for i in range(dimpath) ])
267/18: xcoord.shape
267/19: xcoord
267/20: vcross_p.shape
267/21: levels
267/22: vcross_PV.shape
267/23: pv.shape
267/24: dimpath.shape
267/25: dimpath
267/26: mvcross
267/27: line
267/28: path
267/29: path.vertices
267/30: path.vertices.shape
267/31: lonc = 19
267/32: latc=34
267/33:
dis = 500 #km

dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)

# Define cross section line for each date (tini)
lon_start = lonc-dlon
lon_end   = lonc+dlon
lat_start = latc
lat_end   = latc
267/34:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
267/35:
dis = 500 #km

dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)

# Define cross section line for each date (tini)
lon_start = lonc-dlon
lon_end   = lonc+dlon
lat_start = latc
lat_end   = latc
267/36: import helper
267/37:
dis = 500 #km

dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)

# Define cross section line for each date (tini)
lon_start = lonc-dlon
lon_end   = lonc+dlon
lat_start = latc
lat_end   = latc
267/38:
def convert_radial_distance_to_lon_lat_dis_new(dis,latitude):
    return (dis /np.pi/6370/np.cos(latitude/180*np.pi) * 180)
267/39:
dis = 500 #km

dlon = convert_radial_distance_to_lon_lat_dis_new(dis,latc)

# Define cross section line for each date (tini)
lon_start = lonc-dlon
lon_end   = lonc+dlon
lat_start = latc
lat_end   = latc
267/40: lonstart
267/41: lon_start
267/42: latstart
267/43: lon_end
267/44:
pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat  #für Lothar ändern clim_era5/lothar ohne +y+ und +m+
sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat
bfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/B'+dat
slp=readcdf(bfile,'MSL')
ps=readcdf(pfile,'PS')
PV=readcdf(sfile,'PV')
pv=PV
#q=readcdf(pfile,'Q')
#rh=readcdf(sfile,'RH')
#th=readcdf(sfile,'TH')
#the=readcdf(sfile,'THE')
lons=readcdf(pfile,'lon')
lats=readcdf(pfile,'lat')
hyam=readcdf(pfile,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pfile,'hybm')  #   ''
ak=hyam[hyam.shape[0]-pv.shape[1]:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-pv.shape[1]:] # reduce to 98 levels

# Define distance delta for great circle line
ds = 5.

# Extract coordinates of great circle line between start and end point
mvcross    = Basemap()
line,      = mvcross.drawgreatcircle(lon_start, lat_start, lon_end, lat_end, del_s=ds)
path       = line.get_path()
lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
dimpath    = len(lonp)
267/45: lonp
267/46: latp
267/47: len(latp)
267/48: len(lonp)
267/49: latc2 = 10
267/50: latc3 = 60
267/51: dlon2 = convert_radial_distance_to_lon_lat_dis_new(dis,latc2)
267/52: dlon3 = convert_radial_distance_to_lon_lat_dis_new(dis,latc3)
267/53: dlon2
267/54: dlon3
267/55: lon_start2 = lonc-dlon2
267/56: lon_start3 = lonc-dlon3
267/57: lon_end3 = lonc+dlon3
267/58: lon_end2 = lonc+dlon2
267/59: line2,= mvcross.drawgreatcircle(lon_start2, lat_start, lon_end2, lat_end, del_s=ds)
267/60: line3,= mvcross.drawgreatcircle(lon_start3, lat_start, lon_end3, lat_end, del_s=ds)
267/61: path2       = line2.get_path()
267/62: path3       = line3.get_path()
267/63: lonp2, latp2 = mvcross(path2.vertices[:,0], path2.vertices[:,1], inverse=True)
267/64: lonp3, latp3 = mvcross(path3.vertices[:,0], path3.vertices[:,1], inverse=True)
267/65: dimpath2    = len(lonp2)
267/66: dimpath3    = len(lonp3)
267/67: dimpath2
267/68: dimpath3
267/69: dimpath
267/70: line2,= mvcross.drawgreatcircle(lon_start2, latc2, lon_end2, latc2, del_s=ds/)
267/71: line2,= mvcross.drawgreatcircle(lon_start2, latc2, lon_end2, latc2, del_s=ds)
267/72: path2       = line2.get_path()
267/73: lonp2, latp2 = mvcross(path2.vertices[:,0], path2.vertices[:,1], inverse=True)
267/74: dimpath2    = len(lonp2)
267/75: dimpath2
267/76: line3,= mvcross.drawgreatcircle(lon_start3, latc3, lon_end3, latc3, del_s=ds)
267/77: path3       = line3.get_path()
267/78: lonp3, latp3 = mvcross(path3.vertices[:,0], path3.vertices[:,1], inverse=True)
267/79: dimpath3
267/80: dimpath3    = len(lonp3)
267/81: dimpath3
267/82: p3d
267/83: ps3d
267/84: p3d
267/85: p3d.shape
267/86: vcross_p.shape
267/87: vcross_PV.shape
267/88: topright
267/89: bottomleft
267/90: ak
267/91: bk
267/92: ak
267/93: dat  = '19861123_07'
267/94:
y=dat[0:4]
m=dat[4:6]
print(dat)

pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat  #für Lothar ändern clim_era5/lothar ohne +y+ und +m+
sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat
bfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/B'+dat
slp=readcdf(bfile,'MSL')
ps=readcdf(pfile,'PS')
PV=readcdf(sfile,'PV')
pv=PV
#q=readcdf(pfile,'Q')
#rh=readcdf(sfile,'RH')
#th=readcdf(sfile,'TH')
#the=readcdf(sfile,'THE')
lons=readcdf(pfile,'lon')
lats=readcdf(pfile,'lat')
hyam=readcdf(pfile,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pfile,'hybm')
267/95:
ak2=hyam[hyam.shape[0]-pv.shape[1]:] # only 98 levs are used:
bk2=hybm[hybm.shape[0]-pv.shape[1]:]
267/96: ak2-ak
267/97: bk2-bk
267/98: ak
268/1:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)

def inter2level(varr3D, parr3D, plevel):
    """
    Interpolates 3-D (level, lat, lon) over level for variable array varr with
    associated pressure grid parr to the scalar pressure level plevel
    """
    v_i = interpolate(varr3D[::1,:, :], parr3D[:, :], plevel)
    return(v_i)


from dypy.intergrid import Intergrid
import matplotlib.colors as col
import matplotlib.cm as cm
from mpl_toolkits.basemap import Basemap
import numpy as np
import netCDF4
from netCDF4 import Dataset as ncFile
from dypy.small_tools import interpolate
from dypy.lagranto import Tra
import matplotlib.pyplot as plt
import matplotlib as mpl
import cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from matplotlib.gridspec import GridSpec
from matplotlib.colors import from_levels_and_colors
import datetime as dt

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pandas as pd
import pickle
268/2: dis = 500
268/3: elper.convert_radial_distance_to_lon_lat_dis_new(dis,0)
268/4: helper.convert_radial_distance_to_lon_lat_dis_new(dis,0)
268/5:
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0)
268/6: initl
268/7:
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True).
268/8:
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
268/9: initlop
268/10:
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,ds=ds)
268/11:
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
268/12: ds =5
268/13:
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
268/14:
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)
268/15: initdim
269/1:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)

def inter2level(varr3D, parr3D, plevel):
    """
    Interpolates 3-D (level, lat, lon) over level for variable array varr with
    associated pressure grid parr to the scalar pressure level plevel
    """
    v_i = interpolate(varr3D[::1,:, :], parr3D[:, :], plevel)
    return(v_i)


from dypy.intergrid import Intergrid
import matplotlib.colors as col
import matplotlib.cm as cm
from mpl_toolkits.basemap import Basemap
import numpy as np
import netCDF4
from netCDF4 import Dataset as ncFile
from dypy.small_tools import interpolate
from dypy.lagranto import Tra
import matplotlib.pyplot as plt
import matplotlib as mpl
import cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from matplotlib.gridspec import GridSpec
from matplotlib.colors import from_levels_and_colors
import datetime as dt

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pandas as pd
import pickle
### load cyclone data
###
pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

DF = pd.read_csv(pload + 'pandas-basic-data-all-deep-over-sea-12h.csv')
DFcol = DF.columns
269/2: DFcol
269/3: DFcol[0]
269/4: DF['reg']
269/5: DF['reg'].values
269/6: DF['ID'].values
269/7: np.array(['test','test2'])
269/8: DF.loc[(DF['reg']=='MED') & (DF['SLPmin']<1000)]
269/9: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]
269/10: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates']
269/11: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
269/12:
dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values
269/13: lons
269/14: lats
269/15:
DF = pd.read_csv(pload + 'pandas-basic-data-all-deep-over-sea-12h.csv')
DFcol = DF.columns

dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values


bo = 13
ad = 1
dates = dates[bo:bo+ad]
lons = lons[bo:bo+ad]
lats = lats[bo:bo+ad]

### vars needed in calculation
###
dis = 500 # longitudinal distance to cyclone center to west and east
ds = 5. ## distance for crosssection

### prepare array for  average
###
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)

###craete average arrays
###
compovcross_PV = np.zeros(shape=(98,initdim))
compovcross_p = np.zeros(shape=(98,initdim))

bottomleft = np.array([-90., -180.])
topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### start calculation
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon
    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/16: compovcross_p
269/17: compovcross_p.shape
269/18: compovcross_p[:10,:10]
269/19: compovcross_p[-10:,:10]
269/20: compovcross_p[-3:,:100]
269/21: compovcross_p[-1]
269/22: lonp
269/23: latp
269/24:
DF = pd.read_csv(pload + 'pandas-basic-data-all-deep-over-sea-12h.csv')
DFcol = DF.columns

dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values


bo = 100
ad = 1
dates = dates[bo:bo+ad]
lons = lons[bo:bo+ad]
lats = lats[bo:bo+ad]

### vars needed in calculation
###
dis = 500 # longitudinal distance to cyclone center to west and east
ds = 5. ## distance for crosssection

### prepare array for  average
###
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)

###craete average arrays
###
compovcross_PV = np.zeros(shape=(98,initdim))
compovcross_p = np.zeros(shape=(98,initdim))

bottomleft = np.array([-90., -180.])
topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### start calculation
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon
    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/25: lonp
269/26: compovcross_p[-1]
269/27: compovcross_p[-1]-compovcross_p[-2]
269/28: np.mean(compovcross_p[-1]-compovcross_p[-2])
269/29: np.mean(compovcross_p[-2]-compovcross_p[-3])
269/30: np.mean(compovcross_p[-3]-compovcross_p[-4])
269/31: p3d
269/32: f_p3d_vcross
269/33: f_p3d_vcross.keys()
269/34: f_p3d_vcross.dim
269/35: ps3d
269/36:
dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values


bo = 600
ad = 1
dates = dates[bo:bo+ad]
lons = lons[bo:bo+ad]
lats = lats[bo:bo+ad]

### vars needed in calculation
###
dis = 500 # longitudinal distance to cyclone center to west and east
ds = 5. ## distance for crosssection

### prepare array for  average
###
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)

###craete average arrays
###
compovcross_PV = np.zeros(shape=(98,initdim))
compovcross_p = np.zeros(shape=(98,initdim))

#bottomleft = np.array([-90., -180.])
#topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### start calculation
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T
    for k in range(PV.shape[1]):
#        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=[latc-5,lonc-2dlon], hi=[latc+5,lonc+2dlon], verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=[latc-5,lonc-2dlon], hi=[latc+5,lonc+2dlon], verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/37:
dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values


bo = 600
ad = 1
dates = dates[bo:bo+ad]
lons = lons[bo:bo+ad]
lats = lats[bo:bo+ad]

### vars needed in calculation
###
dis = 500 # longitudinal distance to cyclone center to west and east
ds = 5. ## distance for crosssection

### prepare array for  average
###
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)

###craete average arrays
###
compovcross_PV = np.zeros(shape=(98,initdim))
compovcross_p = np.zeros(shape=(98,initdim))

#bottomleft = np.array([-90., -180.])
#topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### start calculation
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T
    for k in range(PV.shape[1]):
#        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=[latc-5,lonc-2*dlon], hi=[latc+5,lonc+2*dlon], verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=[latc-5,lonc-2*dlon], hi=[latc+5,lonc+2*dlon], verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/38:
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

    hi = np.array([latc-5,lonc-2*dlon])
    low = np.array([latc+5,lonc+2*dlon])
#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
#        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=, hi=, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=, hi=, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/39:
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

    hi = np.array([latc-5,lonc-2*dlon])
    low = np.array([latc+5,lonc+2*dlon])
#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
#        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=low, hi=hi, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=low, hi=hi, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/40: compovcrpss_p
269/41: compovcross_p
269/42:
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/43:
compovcross_PV = np.zeros(shape=(98,initdim))
compovcross_p = np.zeros(shape=(98,initdim))

#bottomleft = np.array([-90., -180.])
#topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### start calculation
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')

    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((PV.shape[1],PV.shape[2],PV.shape[3]),-999.99)
    ps3d=np.tile(ps[0,:,:],(PV.shape[1],1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(PV.shape[1]):
        f_vcross_PV   = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/44: compovcross_p
269/45: ps3d
269/46: ps3d.T
269/47: ps3d
269/48: ps3d
269/49: ps3d.T
269/50: compovcross_p
269/51: compovcross_p.shape
269/52: compovcross_p[10]
269/53: compovcross_p[20]
269/54: compovcross_p[30]
269/55: compovcross_p[35]
269/56: compovcross_p[33]
269/57: compovcross_p[34]
269/58: ps3d
269/59: ps3d.shape
269/60: ps3d[0]
269/61: ps3d[0].shape
269/62: ps3d[1].shape
269/63: ps3d[1]
269/64: ps3d[1]-ps3d[0]
269/65: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates']
269/66: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].index
269/67: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].index[0]
269/68: DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].index.values
269/69: p3d
269/70: p3d[0]
269/71: ps3d[1]
269/72: p3d[0]
269/73: p3d[0].values
269/74: p3d[0]
269/75: p3d[-1]-p3d[-2]
269/76:
dates = ['20180928_04']
lons = [19]
lats =[34.5]
####



### start calculation
###
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/77: sav = 30
269/78:
dates = ['20180928_04']
lons = [19]
lats =[34.5]
####



### start calculation
###
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/79:
sav=30
hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98 + sav:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98 + sav:] #remove calculation above level of interest ~ 160 hPa

###craete average arrays
###
compovcross_PV = np.zeros(shape=(len(ak),initdim))
compovcross_p = np.zeros(shape=(len(ak),initdim))


### verification of calculation for zorbas
dates = ['20180928_04']
lons = [19]
lats =[34.5]
####



### start calculation
###
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
#            vcross_PV[k,i]   = f_vcross_PV.at([latp[i],lonp[i]])
#            vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
            compovcross_PV[k,i] +=f_vcross_PV.at([latp[i],lonp[i]])
            compovcross_p[k,i] += f_p3d_vcross.at([latp[i],lonp[i]])
269/80: compovcross_p
269/81: compovcross_p.shape
269/82: nwp = compovcross_p[:-1]-compovcross_p[1:]
269/83: nwp
269/84: nwp = compovcross_p[1:]-compovcross_p[:-1]
269/85: nwp
269/86: np.mean(nwp,axis=1)
269/87: nwp[0]
269/88: compovcross_p[0]
269/89: compovcross_p[1]
269/90: np.mean(nwp,axis=1)
269/91: nwp
269/92: np.std(nwp,axis=1)
269/93: np.max(nwp,axis=1)-np.min(nwp,axis=1)
269/94: pressures = np.arange(200,1001,10)
269/95: pressures
269/96: counter = np.zeros((len(pressures),len(dimpath)))
269/97: counter = np.zeros((len(pressures),dimpath))
269/98: counter.shape
269/99: lonp
269/100: latp
269/101: f_p3d_vcross.at([34.5,13.54293044])
269/102: f_p3d_vcross.at([[34.5,13.54293044],[34.5,13.54293044]])
269/103:
for u in f_p3d_vcross.at([[34.5,13.54293044],[34.5,13.54293044]]):
    if u>1000 or u<195:
        continue:
    else:
        l = np.where((pressures[:-1]>=u) & (pressures[1:]<=u))[0][0]+1
269/104:
for u in f_p3d_vcross.at([[34.5,13.54293044],[34.5,13.54293044]]):
    if u>1000 or u<195:
        continue
    else:
        l = np.where((pressures[:-1]>=u) & (pressures[1:]<=u))[0][0]+1
269/105:
hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98 + sav:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98 + sav:] #remove calculation above level of interest ~ 160 hPa
269/106:
compovcross_PV = np.zeros(shape=(len(pressures),initdim))
compovcross_p = np.zeros(shape=(len(pressures),initdim))
269/107: counter = np.zeros(compovcross_p.shape)
269/108: f_vcross_PV.at([latp,lonp])
269/109: lalo = np.zeros((len(latp),2))
269/110: lalo[0] = latp
269/111: lalo[:,0] = latp
269/112: lalo[:,1] = lonp
269/113: f_vcross_PV.at(lalo)
269/114: f_vcross_PV.at([lalo])
269/115:
PVn = np.zeros(counter.shape)
PRES = PVn
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
            u = f_p3d_vcross.at([latp[i],lonp[i]])
            if u>1000 or u<195:
                continue
            else:
                l = np.where((pressures[:-1]>=u) & (pressures[1:]<=u))[0][0]+1
                counter[l,i]+=1
                PVn[l,i]+=f_vcross_PV.at([latp[i],lonp[i]])
269/116:
PVn = np.zeros(counter.shape)
PRES = PVn
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
            u = f_p3d_vcross.at([latp[i],lonp[i]])
            if u>1000 or u<200:
                continue
            else:
                l = np.where((pressures[:-1]>=u) & (pressures[1:]<=u))[0][0]+1
                counter[l,i]+=1
                PVn[l,i]+=f_vcross_PV.at([latp[i],lonp[i]])
269/117:
PVn = np.zeros(counter.shape)
PRES = PVn
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
            u = f_p3d_vcross.at([latp[i],lonp[i]])
            if u>1000 or u<200:
                continue
            else:
                l = np.where(abs(pressures-u)==np.min(abs(pressures-u)))[0][0]+1
                counter[l,i]+=1
                PVn[l,i]+=f_vcross_PV.at([latp[i],lonp[i]])
269/118: counter.shape
269/119:
PVn = np.zeros(counter.shape)
PRES = PVn
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        for i in range(dimpath):
            u = f_p3d_vcross.at([latp[i],lonp[i]])
            if u>1000 or u<200:
                continue
            else:
                l = np.where(abs(pressures-u)==np.min(abs(pressures-u)))[0][0]
                counter[l,i]+=1
                PVn[l,i]+=f_vcross_PV.at([latp[i],lonp[i]])
269/120: PRES = np.ones(PVn.shape)*pres[:,None]
269/121: PRES = np.ones(PVn.shape)*pressures[:,None]
269/122: PRES
269/123: latp
269/124: lonp
269/125: list(zip(latp,lonp))
269/126: list([*zip(latp,lonp)])
269/127: list(*zip(latp,lonp))
269/128: list(zip(latp,lonp))
269/129: f_vcross_PV.at(list(zip(latp,lonp)))
269/130: f_p3d_vcross.at(list(zip(latp,lonp)))
270/1:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)

def inter2level(varr3D, parr3D, plevel):
    """
    Interpolates 3-D (level, lat, lon) over level for variable array varr with
    associated pressure grid parr to the scalar pressure level plevel
    """
    v_i = interpolate(varr3D[::1,:, :], parr3D[:, :], plevel)
    return(v_i)


from dypy.intergrid import Intergrid
import matplotlib.colors as col
import matplotlib.cm as cm
from mpl_toolkits.basemap import Basemap
import numpy as np
import netCDF4
from netCDF4 import Dataset as ncFile
from dypy.small_tools import interpolate
from dypy.lagranto import Tra
import matplotlib.pyplot as plt
import matplotlib as mpl
import cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
import matplotlib.gridspec as gridspec
from matplotlib.colors import from_levels_and_colors
import datetime as dt

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pandas as pd
import pickle
### load cyclone data
###
pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

DF = pd.read_csv(pload + 'pandas-basic-data-all-deep-over-sea-12h.csv')
DFcol = DF.columns

dates = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['dates'].values
lons = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lon'].values
lats = DF.loc[(DF['reg']=='MED') & (DF['minSLP']<1000)]['lat'].values
270/2:
dates = ['20180928_04']
lons = [19]
lats =[34.5]
270/3:
dis = 500 # longitudinal distance to cyclone center to west and east
ds = 5. ## distance for crosssection

### prepare array for  average
###
mvcross    = Basemap()
initl, = mvcross.drawgreatcircle(-1 * helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,helper.convert_radial_distance_to_lon_lat_dis_new(dis,0),0,del_s=ds)
initpa = initl.get_path()
initlop,initlap = mvcross(initpa.vertices[:,0],initpa.vertices[:,1], inverse=True)
initdim = len(initlop)

bottomleft = np.array([-90., -180.])
topright   = np.array([90., 179.5])


### load modellevel data
pf = '/atmosdyn/era5/cdf/2018/09/P20180928_04'

sav=30
hyam=readcdf(pf,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pf,'hybm')  #   ''
ak=hyam[hyam.shape[0]-98 + sav:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98 + sav:] #remove calculation above level of interest ~ 160 hPa

### define background pressure grid
###
pres = np.arange(200,1016,15)

###craete average arrays
###
counter = np.zeros((len(pres),initdim))
PVn = np.zeros(counter.shape)
PRES = np.ones(PVn.shape)*pres[:,None]

#compovcross_PV = np.zeros(shape=(len(ak),initdim))
#compovcross_p = np.zeros(shape=(len(ak),initdim))


### verification of calculation for zorbas
dates = ['20180928_04']
lons = [19]
lats =[34.5]
270/4:
for dat,lonc,latc in zip(dates,lons,lats):
    dlon = helper.convert_radial_distance_to_lon_lat_dis_new(dis,latc)
    los = lonc-dlon
    loe = lonc+dlon

    y=dat[0:4]
    m=dat[4:6]

    pfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/P'+dat
    sfile='/net/thermo/atmosdyn/era5/cdf/'+y+'/'+m+'/S'+dat

    ps=readcdf(pfile,'PS')
    PV=readcdf(sfile,'PV')
    PV = PV[0,sav:]
    line,= mvcross.drawgreatcircle(los, latc, loe, latc, del_s=ds)
    path       = line.get_path()
    lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
    dimpath    = len(lonp)

    p3d=np.full((len(ak),PV.shape[0],PV.shape[1]),-999.99)
    ps3d=np.tile(ps[0,:,:],(len(ak),1,1)) # write/repete ps to each level of dim 0
    p3d=(ak/100.+bk*ps3d.T).T

#    vcross_PV = np.zeros(shape=(PV.shape[1],dimpath))
#    vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
    PVtmp = np.zeros((len(ak),initdim))
    prestmp = np.zeros(PVtmp.shape)
    for k in range(len(ak)):
        f_vcross_PV   = Intergrid(PV[k,:,:], lo=bottomleft, hi=topright, verbose=0)
        f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)

        PVtmp[k] = f_vcross_PV.at(list(zip(latp,lonp)))
        prestmp[k] = f_p3d_vcross.at(list(zip(latp,lonp)))

    maxpres = np.max(prestmp,axis=0)
270/5: maxpres
271/1: import pandas as pd
271/2: df1 = pd.readcsv('pandas-ERA5-basic-data.csv')
271/3: df1 = pd.read_csv('pandas-ERA5-basic-data.csv')
271/4: df2 = pd.read_csv('pandas-gaindata.csv')
271/5: df1
271/6: df2
271/7: df.sort_values(['ID'])
271/8: df1.sort_values(['ID'])
271/9: df2.sort_values(['ID'])
271/10: df3 = df1.sort_values(['ID'])
271/11: df3
271/12: df3 = df1.sort_values(['ID'],ignore_index=True)
271/13: df3
271/14: df2 = df2.sort_values(['ID'],ignore_index=True)
271/15: df2
271/16: ndf = pd.DataFrame(columns['test'])
271/17: ndf = pd.DataFrame(columns=['test'])
271/18: col = df3.columns()
271/19: col = df3.columns
271/20: col2 = df2.columns
271/21: col
271/22: col2
271/23: ndf = pd.DataFrame(columns=[col[:],col2[2:]])
271/24: ndf = pd.DataFrame(columns=col.append(col2[2:]))
271/25: ndf
271/26:
for i in df3['ID'].values:
    if np.any(df2['ID].values==i)
271/27:
ncols = ndf.columns
for i in df3['ID'].values:
    if np.any(df2['ID].values==i):
        stack = df3.loc[df3['ID']==i]
271/28:
ncols = ndf.columns
for i in df3['ID'].values:
    if np.any(df2['ID'].values==i):
        stack = df3.loc[df3['ID']==i]
271/29: import numpy as np
271/30:
ncols = ndf.columns
for i in df3['ID'].values:
    if pd.any(df2['ID'].values==i):
        stack = df3.loc[df3['ID']==i]
271/31:
ncols = ndf.columns
for i in df3['ID'].values:
    if np.any(df2['ID'].values==i):
        stack = df3.loc[df3['ID']==i]
271/32: stack
271/33:
ncols = ndf.columns
for i in df3['ID'].values:
    if np.any(df2['ID'].values==i):
        stack = df3.loc[df3['ID']==i]
        stack2 =d2.loc[df2['ID']==i]
271/34:
ncols = ndf.columns
for i in df3['ID'].values:
    if np.any(df2['ID'].values==i):
        stack = df3.loc[df3['ID']==i]
        stack2 =df2.loc[df2['ID']==i]
271/35: stack
271/36: stack2
271/37: df3.join(stack2)
271/38: df3.join(stack2,ignore_index=True)
271/39: df3.assign(stack2)
271/40: pd.concat([df3,df2],axis=1)
271/41: pd.concat([df3,df2[2:]],axis=1)
271/42: col2
271/43: pd.concat([stack,stack2[col2[2:]]],axis=1)
271/44: pd.concat([stack,stack2[col2[2:]]])
271/45: pd.concat([stack,stack2[col2[2:]]]).columns
271/46:
ncols = ndf.columns
df = df3
for i in df3['ID'].values:
    if np.all(df2['ID'].values!=i):
       
        df = df.drop([np.where(df['ID'].values==i)[0][0]])
271/47: df
271/48:
ncols = ndf.columns
df = df3
for i in df3['ID'].values:
    if np.all(df2['ID'].values!=i):
       
        df = df.drop([np.where(df['ID'].values==i)[0][0]],ignore_index=True)
271/49:
ncols = ndf.columns
df = df3
for i in df3['ID'].values:
    if np.all(df2['ID'].values!=i):
       
        df = df.drop([np.where(df['ID'].values==i)[0][0]])
271/50: df
271/51: pd.concat([df,df2[cols2[2:]]],axis=1)
271/52: col2
271/53: pd.concat([df,df2[col2[2:]]],axis=1)
271/54: pd.concat([df,df2[col2[2:]]],axis=1,ignore_index=True)
271/55: df
271/56: df.reset_index()
271/57: df.reset_index(drop=True)
271/58: df =df.reset_index(drop=True)
271/59: pd.concat([df,df2[col2[2:]]],axis=1)
271/60: pd.concat([df,df2[col2[1:]]],axis=1)
271/61: df['ID'].values
271/62: df2['ID'].values
271/63: len(df2['ID'].values)
271/64: len(df['ID'].values)
271/65: df
271/66:
for k in df['ID'].values:
    if np.any(df2['ID'].values==k):
        continue
    else:
        print(k)
271/67: %save -r /atmosdyn2/ascherrmann/scripts/ERA5/pandas-combine-data.py 1-999
271/68: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/pandas-combine-data.py 1-999
272/1:
import pandas as pd
df1 = pd.read_csv('pandas-ERA5-basic-data.csv')
df2 = pd.read_csv('pandas-gaindata.csv')
272/2: df3 = df1.sort_values(['ID'],ignore_index=True)
272/3: df2 = df2.sort_values(['ID'],ignore_index=True)
272/4: df2
272/5: col2 = df2.columns
272/6: df2 = df2[col2[1:]]
272/7: df2
272/8: i,k,l =0
272/9: i=0,k=0,l=0
272/10: i=o
272/11: i=0
272/12: k=0
272/13: l=0
272/14: col2=df2.columns
272/15:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3.drop(np.arange(q,q+i),axis=0)
272/16: import numpy as pn
272/17: import numpy as np
272/18:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3.drop(np.arange(q,q+i),axis=0)
272/19: df3
272/20:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3 = df3.drop(np.arange(q,q+i),axis=0)
272/21: df3
272/22: df2
272/23:
for q,k in df3['ID'].values:
    if df2['ID'].values[q]!=k:
        print(q,k)
272/24:
for q,k in enumerate(df3['ID'].values):
    if df2['ID'].values[q]!=k:
        print(q,k)
272/25: df3 = df1.sort_values(['ID'],ignore_index=True)
272/26:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3 = df3.drop(np.arange(q,q+i),axis=0)
        df3 = df3.reset_index(drop=True,inplace=True)
272/27: df3
272/28: df3
272/29: df3 = df1.sort_values(['ID'],ignore_index=True)
272/30: df3
272/31:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3 = df3.drop(np.arange(q,q+i),axis=0)
        df3.reset_index(inplace=True)
272/32:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        df3 = df3.drop(np.arange(q,q+i),axis=0)
        df3=df3.reset_index(inplace=True)
272/33:
l = 0
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q-l]==t:
        continue
    else:
           
        l+=1
272/34: df3
272/35: df3 = df1.sort_values(['ID'],ignore_index=True)
272/36: df3
272/37: df3.drop(0)
272/38: df3.drop(np.arange(0,5))
272/39: df3.drop(np.arange(0,5)).reset_index()
272/40: df3.drop(np.arange(0,5)).reset_index(inplace=True)
272/41: df3.drop(np.arange(0,5)).reset_index()
272/42: df3.drop(np.arange(0,5)).reset_index().drop(0)
272/43: df3.drop(np.arange(0,5)).reset_index().drop(0).reset_index()
272/44: df3
272/45:
l = 0
ids = df3['ID'].values
for q,t in enumerate(df2['ID'].values):
    if ids[q-l]==t:
        continue
    else:
        df3 = df3.drop(q-l).reset_index()
        ids = df3['ID'].values
        l+=1
273/1:
import pandas as pd
df1 = pd.read_csv('pandas-ERA5-basic-data.csv')
df2 = pd.read_csv('pandas-gaindata.csv')
273/2: cd traj
273/3:
import pandas as pd
df1 = pd.read_csv('pandas-ERA5-basic-data.csv')
df2 = pd.read_csv('pandas-gaindata.csv')
273/4: import numpy as np
273/5: df1
273/6: df3 = df1.drop(np.arange(0,10))
273/7: df3
273/8: df3 = df1.drop(np.arange(0,10)).reset_index
273/9: df3
273/10: df3 = df1.drop(np.arange(0,10)).reset_index()
273/11: df3
273/12:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        print(i)
273/13: df3
273/14: df3 = df1
273/15: df3
273/16:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i=0
        while df3['ID'].values[q+i]!=t:
            i+=1
        print(i)
273/17:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        break
273/18: q
273/19: t
273/20: df2.sort(['ID'])
273/21: df1 = df1.sort_values(['ID'],ignore_index=True)
273/22: df2 = df2.sort_values(['ID'],ignore_index=True)
273/23: df3 = df1
273/24: df3
273/25:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        break
273/26: q
273/27: t
273/28:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i = 0
        while i<150:
            i+=1
            if df3['ID'].values[q+i]==t:
                break
273/29: i
273/30: df3['ID'].values[q+i]
273/31: t
273/32: q
273/33:
for q,t in enumerate(df2['ID'].values):
    if df3['ID'].values[q]==t:
        continue
    else:
        i = 0
        while i<150:
            i+=1
            if df3['ID'].values[q+i]==t:
                print(i)
                break
273/34: i= 0
274/1: import pandas as pd
274/2: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
274/3: df
274/4: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
274/5: df
274/6: df['date']
275/1: import pandas as pd
275/2: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
275/3: df
275/4: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
275/5: df
275/6: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
275/7: df
275/8: df.columns
275/9: df.drop(['Unnamed: 0'])
275/10: df.drop(['ID'])
275/11: df.drop(columns=['ID'])
275/12: df.drop(columns=['Unnamed: 0'])
275/13: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
275/14: df
276/1: import pandas aspd
276/2: import pandas as pd
276/3: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
276/4: df
276/5: df.loc[['minSLP']<=1000]
276/6: df.loc[df['minSLP']<=1000]
276/7: df.loc[df['minSLP']<=1000].describe()
276/8: df.describe()
276/9: df['minSLP'].describe
276/10: df['minSLP'].describe()
276/11: df['PVgain'].describe()
276/12: df['cycPV'].describe()
276/13: df['envPV'].describe()
276/14: df.columns
276/15: df['PVsum'].describe
276/16: df['PVsum'].describe()
276/17: df['PV075sum'].describe()
276/18: sumcol = ['PVsum','PV075sum','ntraj','ntraj075']
276/19: df[sumcol].describe()
276/20: df.sort_values(['minSLP'])[sumcol]
276/21: import pearsonr
276/22: from scipy.stats import pearsonr
276/23: pearsonr(df['minSLP'],df['PVsum'])
276/24: pearsonr(df['minSLP'],df['PV075sum'])
276/25: df2 = df.loc[df['minSLP']<=1000]
276/26: pearsonr(df2['minSLP'],df2['PV075sum'])
276/27: pearsonr(df2['minSLP'],df2['PVsum'])
276/28: pearsonr(df2['minSLP'],df2['ntraj075'])
276/29: pearsonr(df2['minSLP'],df2['ntraj075'])
277/1:
import numpy as np
import pandas as pd

pl = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/'
df = pd.read_csv(pl + 'pandas-all-data.csv')
col = df.columns
277/2: df[['dates']]
277/3: df[['date']]
277/4: df['date']
277/5: df['date'].values
277/6:
for d in df['date']:
    print(d)
278/1: import pandas as pd
278/2: import numpy as np
278/3: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
278/4: df.sort_values(['ntraj075'])
278/5: df.sort_values(['ntraj075'])['ntraj075']
278/6: df.sort_values(['ntraj075'],descending=True)['ntraj075']
278/7: df.sort_values(['ntraj075'],descending)['ntraj075']
278/8: df.sort_values(['ntraj075'],ascending=False)['ntraj075']
278/9: df.sort_values(['ntraj075'],ascending=False)['ntraj075'].values[:1000]
278/10: df.sort_values(['ntraj075'],ascending=False)['sumPV075'].values[:1000]
278/11: col = df.columns
278/12: col
278/13: df.sort_values(['ntraj075'],ascending=False)['PV075sum'].values[:1000]
278/14: df.sort_values(['ntraj075'],ascending=False)['PV075sum'].values[:1000].describe
278/15: df.sort_values(['ntraj075'],ascending=False)['PV075sum'].values[:1000].describe()
278/16: df2 = df.sort_values(['ntraj075'],ascending=False).head(1000)
278/17: df2
278/18: df2.describe()
278/19: df2.['minSLP']describe()
278/20: df2['minSLP'].describe()
278/21: df2['PVsum'].describe()
278/22: df2['PV075sum'].describe()
278/23: df2['cycper']*df2['ntraj075']
278/24: np.sum(df2['cycper']*df2['ntraj075'])/np.sum(df2['ntraj075'])
278/25: df2['htSLPmin'].describe()
278/26: col
278/27: df2['htminSLP'].describe()
278/28: df2 = df.loc[df['htminSLP']>5].sort_values(['ntraj075'],ascending=False).head(1000)
278/29: np.sum(df2['cycper']*df2['ntraj075'])/np.sum(df2['ntraj075'])
278/30: df3 = df.loc[df['htminSLP']>5].sort_values(['PV075sum'],ascending=False).head(1000)
278/31: np.sum(df2['cycper']*df2['ntraj075'])/np.sum(df2['ntraj075'])
278/32: np.sum(df3['cycper']*df3['ntraj075'])/np.sum(df3['ntraj075'])
278/33: df4 = df.loc[df['htminSLP']<5].sort_values(['PV075sum'],ascending=False)
278/34: df4
278/35: df4['minSLP'].describe()
278/36: df4['PVsum'].describe()
278/37: df4['PV075sum'].describe()
278/38: df5 = df.loc[df['ntraj075']>200].sort_values(['PV075sum'],ascending=False)
278/39: df5
278/40: df5 = df.loc[df['ntraj075']>300].sort_values(['PV075sum'],ascending=False)
278/41: df5
278/42: df5 = df.loc[df['ntraj075']>500].sort_values(['PV075sum'],ascending=False)
278/43: df5
278/44: df5 = df.loc[df['ntraj075']>550].sort_values(['PV075sum'],ascending=False)
278/45: df5
278/46: df5 = df.loc[df['ntraj075']>600].sort_values(['PV075sum'],ascending=False)
278/47: df5
278/48: df5.describe()
278/49: np.sum(df5['cycper']*df5['ntraj075'])/np.sum(df5['ntraj075'])
278/50: df6 = df5.loc[df5['htminSLP']>5]
278/51: df6
278/52: np.sum(df6['cycper']*df6['ntraj075'])/np.sum(df6['ntraj075'])
278/53: df6.describe
278/54: df6.describe()
278/55: df6['minSLP'].describe()
278/56: from scipy.statistics import pearsonr
278/57: from scipy.stats import pearsonr
278/58: pearsonr(df5['minSLP'],df5['PV075sum'])
278/59: pearsonr(df5['minSLP'],df5['PVsum'])
279/1: import pandas as pd
279/2: import numpy as np
279/3: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
279/4: df.loc[df['ID']==119896]
279/5: df.loc[df['ID']==119896].values
279/6: df.columns
279/7: from scipy.stats import pearsonr
279/8: df.sort_values(['envper'])
279/9: pearsonr(df['envper'],df['minSLP'])
279/10: pearsonr(df['advper'],df['minSLP'])
279/11: pearsonr(df['cycper'],df['minSLP'])
279/12: pearsonr(df['minSLP'],df['PVsum'])
279/13: pearsonr(df['minSLP'],df['PV075sum'])
279/14: pearsonr(df['minSLP'],df['cycPV'])
279/15: pearsonr(df['minSLP'],df['envPV'])
279/16: pearsonr(df['minSLP'],df['advPV'])
279/17: pearsonr(df.sort_values(['PV075sum'])['minSLP'].head(1000),df.sort_values(['PV075sum'])['PV075sum'].head(1000))
279/18: df.sort_values(['PV075sum'])['minSLP'].head(1000)
279/19: df.sort_values(['PV075sum'])['PV075sum'].head(1000)
279/20: pearsonr(df.sort_values(['PV075sum'])['minSLP'].tail(1000),df.sort_values(['PV075sum'])['PV075sum'].tail(1000))
279/21: df.sort_values(['PV075sum'])['PV075sum'].tail(1000)
279/22: pearsonr(df.sort_values(['PV075sum'])['minSLP'].tail(1000),df.sort_values(['PV075sum'])['PVsum'].tail(1000))
279/23: pearsonr(df.sort_values(['minSLP'])['minSLP'].head(1000),df.sort_values(['minSLP'])['PV075sum'].head(1000))
279/24: pearsonr(df.sort_values(['minSLP'])['minSLP'].head(500),df.sort_values(['minSLP'])['PV075sum'].head(500))
279/25: pearsonr(df.sort_values(['minSLP'])['minSLP'].head(200),df.sort_values(['minSLP'])['PV075sum'].head(200))
279/26: pearsonr(df.sort_values(['minSLP'])['minSLP'].head(1500),df.sort_values(['minSLP'])['PV075sum'].head(1500))
279/27: df
279/28: df.loc[df['minSLP']<1000]
279/29: df.loc[df['minSLP']<1000].describe()
279/30: deep = df.loc[df['minSLP']<1000]
279/31: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/32: np.sum(deep['envper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/33: np.sum(deep['advper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/34: deep = df.loc[(df['minSLP']<1000) & (df['htminSLP']>3)]
279/35: deep
279/36: np.sum(deep['advper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/37: np.sum(deep['envper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/38: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/39: deep = df.loc[(df['minSLP']<1000) & (df['htminSLP']>5)]
279/40: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/41: deep = df.loc[(df['minSLP']<1000) & (df['htminSLP']>12)]
279/42: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/43: deep = df.loc[ (df['htminSLP']>12)]
279/44: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/45: deep = df.loc[df['htminSLP']>12]
279/46: np.sum(deep['cycper'] * deep['ntraj075'])/np.sum(deep['ntraj075'])
279/47: import matplotlib
279/48:
import cartopy
import matplotlib.gridspec as gridspec
279/49: import matplotlib.pyplot as plt
279/50:
fig=plt.figure(figsize=(8,6))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
279/51: import cartopy.crs as ccrs
279/52:
fig=plt.figure(figsize=(8,6))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
279/53: ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
279/54: deep = df.loc[df['minSLP']<1000]
279/55: ax.scatter(deep['lon'],deep['lat'],color='k')
279/56: plt.show
279/57: plt.show()
279/58: plt.close('all')
279/59: fig
279/60: plt.close(fig)
279/61: fig
279/62: deep6 = deep.loc[deep['htminSLP']<6]
279/63: deep6
279/64: deep6c = deep.loc[deep['htminSLP']>=6]
279/65: np.sum(deep6c['cycper'] * deep6c['ntraj075'])/np.sum(deep6c['ntraj075'])
279/66: np.sum(deep6['cycper'] * deep6['ntraj075'])/np.sum(deep6['ntraj075'])
279/67: np.sum(deep6['envper'] * deep6['ntraj075'])/np.sum(deep6['ntraj075'])
279/68: np.sum(deep6['advper'] * deep6['ntraj075'])/np.sum(deep6['ntraj075'])
279/69: np.sum(deep6c['advper'] * deep6c['ntraj075'])/np.sum(deep6c['ntraj075'])
279/70: deep
279/71: deep6c
279/72: deep6
279/73: pearsonr(deep6['htminSLP'],deep6['envper'])
279/74: pearsonr(deep6c['htminSLP'],deep6c['cycper'])
279/75: pearsonr(deep6c['htminSLP'],deep6c['envper'])
279/76: pearsonr(deep6['htminSLP'],deep6['cycper'])
279/77: df6 = df.loc[df['htminSLP']<6]
279/78: df6c = df.loc[df['htminSLP']>=6]
279/79: pearsonr(df6c['htminSLP'],df6c['envper'])
279/80: pearsonr(df6c['htminSLP'],df6c['cycper'])
279/81: pearsonr(df6['htminSLP'],df6['envper'])
279/82: pearsonr(df6['htminSLP'],df6['cycper'])
279/83: df6 = df.loc[(df['htminSLP']<6) & (df['ntraj075']>200)]
279/84: df6
279/85: df6c = df.loc[(df['htminSLP']>=6) & (df['ntraj075']>200)]
279/86: df6c
279/87: pearsonr(df6c['htminSLP'],df6c['envper'])
279/88: pearsonr(df6c['htminSLP'],df6c['cycper'])
279/89: pearsonr(df6['htminSLP'],df6['envper'])
279/90: pearsonr(df6['htminSLP'],df6['cycper'])
279/91: test = df.loc[df['ntraj075']>200]
279/92: (test['ntraj075']/test['ntraj']).describe()
279/93: pearsonr(test['minSLP'],test['ntraj075']/test['ntraj'])
279/94: pearsonr(test['htminSLP'],test['ntraj075']/test['ntraj'])
279/95: np.sum(df6['cycper']*df6['ntraj075'])/np.sum(df6['ntraj075'])
279/96: np.sum(df6c['cycper']*df6c['ntraj075'])/np.sum(df6c['ntraj075'])
279/97: np.sum(df6['envper']*df6['ntraj075'])/np.sum(df6['ntraj075'])
279/98: np.sum(df6['advper']*df6['ntraj075'])/np.sum(df6['ntraj075'])
280/1: import pandas as pd
280/2: import numpy as np
280/3: df = pd.read_csv('pandas-all-data.csv')
280/4: df1 = df.loc[df['ntraj075']>=100,ignore_index=True]
280/5: df1 = df.loc[df['ntraj075']>=100]
280/6: df2 = df.loc[df['ntraj075']>=200]
280/7: col = df.columns
280/8: df1
280/9: df2
280/10:
def per(p,d):
    p = p + 'per'
    return np.sum(d[p] * d['ntraj075'])/np.sum(d['ntraj075'])
280/11: c = 'cyc'
280/12: e = 'env'
280/13: a = 'adv'
280/14: per(c,df1)
280/15: per(c,df2)
280/16: per(e,df2)
280/17: per(e,df1)
280/18: per(a,df1)
280/19: per(a,df2)
280/20: df16 = df1.loc[df1['htminSLP']>=6]
280/21: df26 = df2.loc[df2['htminSLP']>=6]
280/22: per(c,df16)
280/23: per(c,df26)
280/24: import pickle
280/25: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt')
280/26: PVdata = pickle.load(f)
280/27: qw = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt')
280/28: PVdata = pickle.load(f)
280/29: pwd
280/30: cd /atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/
280/31: f.close()
280/32: qw.close()
280/33: q = open('PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
280/34: PVdata = pickle.load(q)
280/35: q.close()
280/36: datadi = PVdata['rawdata']
280/37:
for d in datadi.keys():
    idp = np.where(datadi[d]['PV'][:,0]>=0.75)[0]
    if len(idp)<200:
        print('dam')
280/38: len(idP)
280/39: len(idp)
280/40:
def pv(p,d):
    p = p + 'PV'  
    return np.sum(d[p] * d['ntraj075'])/np.sum(d['ntraj075'])
280/41: pv(c,df2)
280/42: pv(e,df2)
280/43: pv(e,df26)
280/44: pv(c,df26)
280/45: pv(c,df1)
280/46: pv(c,df2) + pv(e,df2)
280/47: df2
281/1: import pandas as pd
281/2: df = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/pandas-basic-data-all-deep-over-sea-12h.csv')
281/3: df
281/4: dfs = dict()
281/5: regions = ['MED','NA','SA','NP','SP','IO']
281/6:
for r in regions:
    dfs[r] = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/pandas-' + r + '-track-data-all-deep-over-sea-12h.csv')
281/7: dfs['NA']
281/8: dft = dfs['MED']
281/9:
for r in regions[1:]:
    dft=dft.append(dfs[r],ignore_index=True)
281/10: dft
281/11: ID1 = df['ID'].values
281/12: ID2 = dft['ID'].values
281/13: np.where((ID1-ID2)!=0)[0]
281/14: import numpy as np
281/15: np.where((ID1-ID2)!=0)[0]
281/16: dfs['MED']
281/17: dfs['MED'][0]
281/18: dfs['MED']
281/19: dfs['MED'].values
281/20: dfs['MED'].values[0]
281/21: dfs['MED'].values[0][10]
281/22: dfs['MED'].values[0][10][1]
281/23: eval(dfs['MED'].values[0][10])
281/24: eval(dfs['MED'].values[0][10])[1]
281/25: dfs['MED']
281/26: dfs['MED'][-96]
281/27: dfs['MED']['-96']
281/28: dfs['MED']['-96'][0]
281/29: dfs['MED']['-96'][0][0]
281/30: dfs['MED']['-96']
281/31: eval(dfs['MED']['-96'].values)
281/32: dfs['MED']['-96'].values
282/1:
import numpy as np
import netCDF4
import os


def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
    .
282/2:
import numpy as np
import netCDF4
import os


def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
282/3:
LON=np.arange(-180,180.1,0.4)
LAT=np.arange(0,90.1,0.4)

xx,yy=np.meshgrid(LON,LAT)

latids1,lonids1 = np.where((xx>=-5) & (xx<2) & (yy>=30) & (yy<=42))
latids2,lonids2 = np.where((xx>=2) & (xx<=42) & (yy>=30) & (yy<48))

lonids = np.append(lonids1,lonids2)
latids = np.append(latids1,latids2)


c = dict()
PV = dict()
### initialize summed PV and counter for every month 1-12 and 0 for total
###
for m in range(0,13):
    c[m] = 0
    PV[m] = 0


fp = '/atmosdyn/era5/cdf/2018/09/P20180928_04'
### save only up to around 600 hPa to speed up the process
###
sav = 55
hyam=readcdf(fp,'hyam')
hybm=readcdf(fp,'hybm')
ak=hyam[hyam.shape[0]-98 + sav:]
bk=hybm[hybm.shape[0]-98 + sav:]
282/4: pv = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04')
282/5: pv = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PV')
282/6: ps = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PS')
282/7: pv = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PV')[0,sav:,lonids,latids]
282/8: pv = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PV')[0,sav:,latids,lonids]
282/9: pv
282/10: pv.values
282/11: pv.shape
282/12: ps = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PS')
282/13: pv = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PV')
282/14: pv[0]
282/15: pv[0,10,20]
282/16: pv.shape
282/17: pv = pv[0,sav:,latids,lonids]
282/18: pv.shape
282/19: len(pv[0])
282/20: m=9
282/21:
for q, ps in enumerate(PS):
                    p = ak/100.+bk*ps
                    idp = np.where((p<=975) & (p>=700))[0]
                    c[m]+=len(idp)
                    c[0]+=len(idp)
                    PV[m]+=pv[q,idp]
                    PV[0]+=pv[q,idp]
282/22: PS = readcdf('/atmosdyn/era5/cdf/2018/09/S20180928_04','PS')[0,latids,lonids]
282/23: PS
282/24:
for q, ps in enumerate(PS):
                    p = ak/100.+bk*ps
                    idp = np.where((p<=975) & (p>=700))[0]
                    c[m]+=len(idp)
                    c[0]+=len(idp)
                    PV[m]+=pv[q,idp]
                    PV[0]+=pv[q,idp]
282/25: idp
282/26: q
282/27: pv[85]
282/28: pv[85].shape
282/29:
c = dict()
PV = dict()
### initialize summed PV and counter for every month 1-12 and 0 for total
###
for m in range(0,13):
    c[m] = 0
    PV[m] = 0
282/30:
for q, ps in enumerate(PS):
                    p = ak/100.+bk*ps
                    idp = np.where((p<=975) & (p>=700))[0]
                    c[m]+=len(idp)
                    c[0]+=len(idp)
                    PV[m]+=np.sum(pv[q,idp])
                    PV[0]+=np.sum(pv[q,idp])
282/31: PV[9]
282/32: m
282/33: PV[12]
282/34: PV[0]
282/35: c[12]
282/36:
for q, ps in enumerate(PS):
                    p = ak/100.+bk*ps
                    idp = np.where((p<=975) & (p>=700))[0]
                    c[m]+=len(idp)
                    c[0]+=len(idp)
                    PV[m]+=np.sum(pv[q,idp])
                    PV[0]+=np.sum(pv[q,idp])
282/37:
c = dict()
PV = dict()
### initialize summed PV and counter for every month 1-12 and 0 for total
###
for m in range(0,13):
    c[m] = 0
    PV[m] = 0
282/38:
for q, ps in enumerate(PS[:10]):
                    p = ak/100.+bk*ps
                    idp = np.where((p<=975) & (p>=700))[0]
                    print(LON[lonids[q]],LAT[latids[q]])
                    print(p)
                    c[m]+=len(idp)
                    c[0]+=len(idp)
                    PV[m]+=np.sum(pv[q,idp])
                    PV[0]+=np.sum(pv[q,idp])
283/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle
import xarray as xr

from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
from dypy.small_tools import CrossSection
from dypy.netcdf import read_var_bbox
from dypy.small_tools import interpolate
from dypy.tools.py import print_args,ipython
import netCDF4
import math
import dypy.netcdf as nc

import cartopy
import matplotlib.gridspec as gridspec
import functools
import pandas as pd

CT = 'MED'

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/scripts/ERA5-utils/NORO')


savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
for u,x in enumerate(savings):
    f = open(pload[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
avaID = np.array([])
minSLP = np.array([])
283/2:
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    minSLP = np.append(minSLP,SLP[k][abs(hourstoSLPmin[k][0]).astype(int)])


df = pd.read_csv(pload[:-4] + 'pandas-all-data.csv')
df = df.loc[df['ntraj075']>=200]
ndf = pd.DataFrame(columns=df.columns)

ID = df['ID'].values

psave = '/atmosdyn2/ascherrmann/009-ERA-5/MED/'

oro = data['oro']
datadi = data['rawdata']

dipv = data['dipv']
rdis = 400
H = 48
a = 1

PVstart = np.array([])
PVend = np.array([])
adv = np.array([])
cyc = np.array([])
env = np.array([])
oroa = np.array([])

minpltlatc = 30
minpltlonc = -5

maxpltlatc = 50
maxpltlonc = 50

soroc = np.array([])
soroe = np.array([])
loroe = np.array([])
loroc = np.array([])

c = 'cyc'
e = 'env'

#fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
#ax.coastlines()

fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)

orocounter = 0
sorocounter =0

LON=np.arange(-180,180.1,0.5)
LAT=np.arange(-90,90.1,0.5)
counter = np.zeros((len(LAT),len(LON)))

hcyc = 0
tj = 0
con = 0
slpdis = np.array([])
soroslp = np.array([])
283/3:
for qq,date in enumerate(dipv.keys()):
    if np.all(ID!=int(date)):
        continue
 #if date=='108215' or date=='269867':
    q = np.where(avaID==int(date))[0][0]

#    if date!='540325' and date!='460854':
#        continue

    if (hourstoSLPmin[q][0]>-1 * hcyc):
        continue
    con +=1

    d = date
    idp = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    cLLon = lon[q][abs(hourstoSLPmin[q][0]).astype(int)]
    cLLat = lat[q][abs(hourstoSLPmin[q][0]).astype(int)]
    slpdis = np.append(slpdis,SLP[q][abs(hourstoSLPmin[q][0]).astype(int)])
#    tralon = datadi[date]['lon'][:,:]
#    tralat = datadi[date]['lat'][:,:]
    PV = datadi[date]['PV'][idp,:]

    pvstart = PV[:,-1]
    pvend = PV[:,0]
    PVstart = np.append(PVstart,pvstart)
    PVend = np.append(PVend,pvend)
    cypv = dipv[d][c][idp,0]

    enpv = dipv[d][e][idp,0]

    adv = np.append(adv,pvstart/pvend)
    cyc = np.append(cyc,cypv/pvend)
    env = np.append(env,enpv/pvend)



    PVoro = oro[date]['env'][idp,:]

    pvoro = oro[date]['env'][idp,0] + oro[date]['cyc'][idp,0]
    if np.where(pvoro!=0)[0].size==0:
        continue
    orot = len(np.where(pvoro!=0)[0])# & ((abs(oro[date]['cyc'][idp,0])<0.05)))[0])
    if len(idp)<tj:
        continue
    if (np.mean(pvoro/pvend)>0.5):
     orocounter+=1
     if NORO['ZB'][0,np.where(abs(NORO['lat']-cLLat)==np.min(abs(NORO['lat']-cLLat)))[0][0],np.where(abs(NORO['lon']-cLLon)==np.min(abs(NORO['lon']-cLLon)))[0][0]]<1:
        sorocounter+=1
        soroslp = np.append(soroslp,SLP[q][abs(hourstoSLPmin[q][0]).astype(int)])
        soroc = np.append(soroc,np.mean(oro[date]['cyc'][idp,0]/pvend))
        soroe = np.append(soroe,np.mean(oro[date]['env'][idp,0]/pvend))

#     if np.mean(cypv/pvend)<0.3 and np.mean(enpv/pvend)>0.5:
#     if orot/len(idp)>=0.4:
#      if np.mean(datadi[d]['OL'][idp,0]<0.5):
#      if np.mean(tralon)<36.5 and np.mean(tralon)>0 and np.mean(tralat)>35 and np.mean(datadi[d]['OL'][idp,0]<0.7):
        oroa = np.append(oroa,pvoro/pvend)
#        print(d,'cyc','env','adv','oro')

#        ax.scatter(cLLon,cLLat,color='k',s=2)#s=(len(idp)/100),color='k')
     else:
         loroc = np.append(loroc,np.mean(oro[date]['cyc'][idp,0]/pvend))
         loroe = np.append(loroe,np.mean(oro[date]['env'][idp,0]/pvend))

     if lat[q][abs(hourstoSLPmin[q][0]).astype(int)]<30 or lat[q][abs(hourstoSLPmin[q][0]).astype(int)]>48:
         continue
     if lon[q][abs(hourstoSLPmin[q][0]).astype(int)]<-5 or lon[q][abs(hourstoSLPmin[q][0]).astype(int)]>42:
         continue
     if lon[q][abs(hourstoSLPmin[q][0]).astype(int)]<2 and lat[q][abs(hourstoSLPmin[q][0]).astype(int)]>42:
         continue

     if (lon[q][abs(hourstoSLPmin[q][0]).astype(int)]%0.5!=0):
         lon[q][abs(hourstoSLPmin[q][0]).astype(int)]=np.round(lon[q][abs(hourstoSLPmin[q][0]).astype(int)],0)
     if (lat[q][abs(hourstoSLPmin[q][0]).astype(int)]%0.5!=0):
         lat[q][abs(hourstoSLPmin[q][0]).astype(int)]=np.round(lat[q][abs(hourstoSLPmin[q][0]).astype(int)],0)
     if lat[q][abs(hourstoSLPmin[q][0]).astype(int)]<30:
         continue
     lo = np.where(np.round(LON,1)==np.round(lon[q][abs(hourstoSLPmin[q][0]).astype(int)],1))[0][0]
     la = np.where(np.round(LAT,1)==np.round(lat[q][abs(hourstoSLPmin[q][0]).astype(int)],1))[0][0]
     counter[la,lo]+=1

     ndf = ndf.append(df.loc[df['ID']==int(date)])
283/4: ndf
283/5: ndf.loc[ndf['envper']>=0.4]
283/6: ndf.loc[ndf['envper']>=0.4].describe()
283/7: ndf.loc[ndf['envper']>=0.6].describe()
283/8: ndf.loc[ndf['envper']>=0.7].describe()
283/9: df
283/10: df['minSLP'].describe()
283/11: ndf.loc[ndf['envper']>=0.7]['minSLP'].describe()
283/12: ndf.loc[ndf['advper']>=0.7]['minSLP'].describe()
283/13: ndf.loc[ndf['advper']>=0.4]['minSLP'].describe()
283/14: ndf.loc[ndf['advper']>=0.6]['minSLP'].describe()
283/15: ndf.loc[ndf['cycper']>=0.6]['minSLP'].describe()
283/16: df.loc[ndf['cycper']>=0.6]['minSLP'].describe()
283/17: df.loc[df['cycper']>=0.6]['minSLP'].describe()
283/18: df.loc[df['envper']>=0.6]['minSLP'].describe()
283/19: df.loc[df['advper']>=0.6]['minSLP'].describe()
283/20: df6 = df.loc[df['htminSLP']>=6]
283/21: df6
283/22: df6.loc[df6['advper']>=0.6]['minSLP'].describe()
283/23: df6.loc[df6['envper']>=0.6]['minSLP'].describe()
283/24: df6.loc[df6['cycper']>=0.6]['minSLP'].describe()
283/25: from scipy.stats import pearsonr
283/26: pearsonr(df6['htminSLP'],df6['minSLP'])
283/27: df6.loc[(df6['envper']>=0.6) | (df6['advper']>=0.6)]['minSLP'].describe()
283/28: df.loc[(df['envper']>=0.6) | (df['advper']>=0.6)]['minSLP'].describe()
283/29: ndf
283/30: ndf.loc[ndf['envper']>=0.5]
283/31: ndf6 = ndf.loc[ndf['htminSLP']>=6]
283/32: ndf6.loc[ndf6['envper']>=0.4]['minSLP'].describe()
283/33: ndf6.loc[ndf6['envper']>=0.5]['minSLP'].describe()
285/1: import pickle
285/2: import numpy as np
285/3: f = open('climatologyPV.txt','rb')
285/4: data = pickle.load(f)
285/5: f.close()
285/6: data.keys()
285/7: data['PV'].keys()
285/8: data['PV']
285/9: data['count']
285/10: import pandas as pd
285/11: df = pd.DataFrame(columns=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],index=['PV','count','avPV','avcount'])
285/12: df = pd.DataFrame(columns=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],index=['PV','count','avPV','avcount'])
285/13: data['count'].values
285/14: data['count'].values()
285/15: list(data['count'].values())
285/16: df['count'] = list(data['count'].values())
285/17: df.columns
285/18: df.columns()
285/19: df.columns
285/20:
for k, mon in zip(range(0,13),df.columns):
    test
285/21: df['PV']
285/22: df.index['PV']
285/23: df.index
285/24: df.iloc[df.index=='PV']
285/25: df
285/26: df.PV
285/27: df['PV']
285/28: df[['PV']]
285/29: df.loc[['PV']]
285/30: df.loc[['PV']]=data['PV']
285/31: df.loc[['PV']]
285/32: df
285/33: df = pd.DataFrame(index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],columns=['PV','count','avPV','avcount'])
285/34: df
285/35: df['PV'] = list(data['PV'].values())
285/36: df
285/37: df['count'] = list(data['count'].values())
285/38: df['avcount'] = list(data['avcount'].values())
285/39: df['avPV'] = list(data['avPV'].values())
285/40: df
285/41: df['PV']/df['count']
285/42: df['avPV']/df['avcount']
285/43: pwd
285/44: ls traj/*.csv
285/45: cdata = pd.read_csv('traj/pandas-all-data.csv')
285/46: cdata
285/47: MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
285/48: MO = np.array([])
285/49:
for d in cdata['date'].values:
    MO = np.append(MO,MONTHS[int(d[4:6])-1])
285/50: MO
285/51: cdata['mon'] = MO
285/52: cdata
285/53: df
285/54: df = pd.DataFrame(index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],columns=['PV','count','avPV'])
285/55: df['PV'] = data['PV']
285/56: df['count'] = data['count']
285/57: df['avPV'] = df['PV']/df['count']
285/58: df
285/59: data
285/60: df['PV'] = list(data['PV'].values)
285/61: df['PV'] = list(data['PV'].values())
285/62: df['count'] = list(data['count'].values())
285/63: df['avPV'] = df['PV']/df['count']
285/64: df
285/65: cdata
285/66: cdata['sumPV']
285/67: cdata['PVsum']
285/68: cdata['PV075sum']
285/69: df2 = cdata.loc[cdata['ntraj075']>=200]
285/70: df2
285/71: df2['PV075sum']
285/72: df
285/73: df['avPV]
285/74: df['avPV']
285/75: df['avPV']['JAN']
285/76: cdata
285/77: pd.
285/78: cdata.to_csv('traj/pandas-all-data.csv',index=False)
285/79: ano = np.array([])
285/80:
bg = np.array([])
for n,k in zip(cdata['ntraj075'].values,cdata['mon'].values):
    bg = np.append(bg,df['avPV'][k]*n)
285/81: cdata['ano'] = cdata['PV075sum']-bg
285/82: cdata['ano']
285/83: df2 = cdata.loc[cdata['ntraj075']>=200]
285/84: df2
285/85: df2['ano']
285/86: from scipy.stats import pearsonr
285/87: pearsonr(df2['ano'],df2['minSLP'])
285/88: import matplotblie
285/89: import matplotblib
285/90: import matplotlib
285/91: import matplotlib.pyplot as plt
285/92: fig, ax = plt.subplots()
285/93: ax.scatter(df2['minSLP'],df2['ano'])
285/94: plt.show()
286/1: import pandas as pd
286/2: import numpy as np
286/3: import pickle
286/4: f = open('climatologyPV.txt','rb')
286/5: clim = pickle.load(f)
286/6: f.close()
286/7: clim['PV']
286/8: df = pd.DataFrame(index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],columns=['PV','count','avPV'])
286/9: df['PV'] = list(clim['PV'].values())
286/10: df['count'] = list(clim['count'].values())
286/11: df['avPV'] = df['PV']/df['count']
286/12: cdata = pd.read_csv('traj/pandas-all-data.csv')
286/13: cdata
286/14:
bg = np.array([])
for n,k in zip(cdata['ntraj075'].values,cdata['mon'].values):
    bg = np.append(bg,df['avPV'][k]*n)
286/15: cdata['ano'] = cdata['PV075sum']-bg
286/16: cdata['ano']
286/17: df2 = cdata.loc[cdata['ntraj075']>=200]
286/18: df2['ano']
286/19: df2.loc[df['ano']>=1000]
286/20: df2.loc[df2['ano']>=1000]
286/21: df2.loc[df2['ano']>=1500]
286/22:
import cartopy
import matplotlib.gridspec as gridspec
286/23:
import matplotlib
import matplotlib.pyplot as plt
286/24: import cartopy.crs as ccrs
286/25:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/26: ax.scatter(df2.loc[df2['ano']>=1500]['lon'],df2.loc[df2['ano']>=1500]['lat'],color='k',marker='.',s=10)
286/27: ax.set_extend([-10,45,25,50])
286/28: ax.set_extend([-10,45,25,50],crrs.PlateCarree())
286/29: ax.set_extent([-10,45,25,50],crrs.PlateCarree())
286/30: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/31: plt.show()
286/32: plt.close(fig)
286/33:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/34: ax.scatter(df2.loc[df2['ano']>=1000]['lon'],df2.loc[df2['ano']>=1000]['lat'],color='k',marker='.',s=10)
286/35: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/36: plt.show()
286/37: plt.close(fig)
286/38:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/39: df
286/40: df2
286/41: ax.scatter(df2.loc[df2['ano']<=1000]['lon'],df2.loc[df2['ano']<=1000]['lat'],color='k',marker='.',s=10)
286/42: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/43: plt.show()
286/44: plt.close(fig)
286/45: d3 = df2.loc[df2['ano']<=1000]
286/46: pearsonr(d3['ano'],d3['minSLP'])
286/47: from scipy.stats import pearsonr
286/48: pearsonr(d3['ano'],d3['minSLP'])
286/49: d3 = df2.loc[df2['ano']<=800]
286/50: pearsonr(d3['ano'],d3['minSLP'])
286/51: d3 = df2.loc[df2['ano']<=600]
286/52: pearsonr(d3['ano'],d3['minSLP'])
286/53: d3 = df2.loc[df2['ano']<=1500]
286/54: pearsonr(d3['ano'],d3['minSLP'])
286/55: df
286/56: cdata
286/57: pearsonr(cdata['ano'],cdata['minSLP'])
286/58: df2
286/59: d3
286/60: MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
286/61: bb = dict()
286/62:
for mo in MONTHS:
    bb[mo] = []
286/63: pearsonr(cdata['ano'],cdata['minSLP'])
286/64: pearsonr(df2['ano'],df2['minSLP'])
286/65: pearsonr(d3['ano'],d3['minSLP'])
286/66:
for an,mo in zip(d3['ano'],d3['mon']):
    bb[mo].append(an)
286/67: plt.close(fig)
286/68: plt.close('all')
286/69: fig,ax =plt.subplots()
286/70:
dd = []
for mo in MONTHS:
    dd.append(bb[mo])
286/71: bp = ax.boxplot(dd,whis=(10,90),laels=MONTHS)
286/72: meanline = dict(linestyle='-',linewidth=1,color='red')
286/73: medianprops = dict(linestyle='-',linewidth=1,color='grey')
286/74: medianprops = dict(linestyle='-',linewidth=1,color='k')
286/75: bp = ax.boxplot(dd,whis=(10,90),labels=MONTHS,meanprops=meanline,meanline=True,showmeans=True,showfliers=False)
286/76: plt.show()
286/77: plt.close()
286/78: fig,ax =plt.subplots()
286/79: bp = ax.boxplot(dd,whis=(10,90),labels=MONTHS,meanprops=meanline,meanline=True,showmeans=True,showfliers=True)
286/80: ax.set_ylabel('PV anomaly [PVU]')
286/81: plt.show()
286/82: plt.close('all')
286/83:
bg = np.array([])
for n,k in zip(cdata['ntraj'].values,cdata['mon'].values):
    bg = np.append(bg,df['avPV'][k]*n)
286/84: cdata
286/85: cdata['fullano'] = cdata['PVsum']-bg
286/86: df2 = cdata.loc[cdata['ntraj075']>=200]
286/87: df2
286/88: df2.loc[df2['fullano']<0]
286/89:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/90: ax.scatter(df2.loc[df2['fullano']<0]['lon'],df2.loc[df2['fullano']<0]['lat'])
286/91: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/92: plt.show()
286/93: df2['ntraj'].describe()
286/94: plt.close('all')
286/95:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/96: ax.scatter(df2.loc[df2['ntraj']<1800]['lon'],df2.loc[df2['ntraj']<1800]['lat'],color='k',s=5,marker='.')
286/97: plt.show()
286/98: plt.close('all')
286/99:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/100: ax.scatter(df2.loc[df2['ntraj']<1800]['lon'],df2.loc[df2['ntraj']<1800]['lat'],color='k',s=5,marker='.')
286/101: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/102: plt.show()
286/103: df2.loc[df2['ntraj']<1800]['minSLP'].describe()
286/104: plt.close(fig)
286/105:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/106: ax.scatter(df2.loc[df2['ntraj']<2000]['lon'],df2.loc[df2['ntraj']<2000]['lat'],color='k',s=5,marker='.')
286/107: plt.show()
286/108: plt.close(fig)
286/109:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/110: ax.scatter(df2.loc[df2['ntraj']<2500]['lon'],df2.loc[df2['ntraj']<2500]['lat'],color='k',s=5,marker='.')
286/111: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/112: plt.show()
286/113: plt.close(fig)
286/114:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/115: ax.scatter(df2.loc[df2['ntraj']>2500]['lon'],df2.loc[df2['ntraj']>2500]['lat'],color='k',s=5,marker='.')
286/116: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/117: plt.show()
286/118: plt.close(fig)
286/119: df2.loc[df2['ntraj']>2500]
286/120:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/121: ax.scatter(df2.loc[df2['ntraj']>2350]['lon'],df2.loc[df2['ntraj']>2350]['lat'],color='k',s=5,marker='.')
286/122: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/123: plt.show()
286/124: plt.close(fig)
286/125:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
286/126: ax.scatter(df2.loc[df2['ntraj']<2300]['lon'],df2.loc[df2['ntraj']<2300]['lat'],color='k',s=5,marker='.')
286/127: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
286/128: plt.show()
286/129: plt.close(fig)
286/130: df3 = df2.loc[df2['ntraj']<2300]
286/131: df3
286/132: pearsonr(df3['ano'],df3['minSLP'])
286/133: df3 = df2.loc[df2['ntraj']<2400]
286/134: pearsonr(df3['ano'],df3['minSLP'])
286/135: pearsonr(df3['ano'],df3['minSLP'])
286/136: cdata
286/137: cdata.to_csv('traj/pandas-all-data.csv',index=False)
287/1: import pickle
287/2: import numpy as np
287/3: f = open('climatologyPV.txt','rb')
287/4: clim = pickle.load(f)
287/5: f.close()
287/6: avPV = clim['PV']/clim['count']
287/7: avPV = clim['PV'].values()/clim['count'].values()
287/8: avPV = list(clim['PV'].values())/list(clim['count'].values())
287/9: PV,count = list(clim['PV'].values()),list(clim['count'].values())
287/10: PV
287/11: PV/count
287/12: np.array(PV)/np.array(count)
288/1: import netCDF4
288/2:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
288/3: mask = readcdf(C20180915_23,'LABEL')
288/4: mask = readcdf('C20180915_23','LABEL')
288/5: mask
288/6: mask.shape
289/1: import pickle
289/2: f = open('climatologyPV-wo-cyclones-1985-1989.txt','rb')
289/3: d = pickle.load(f)
289/4: f.close()
289/5: d.keys()
289/6: d['locPV']
289/7: d['locPV'].keys()
289/8: d['locPV'][1].keys()
290/1: import pickle
290/2: f = open('climatologyPV-wo-cyclones.txt','rb')
290/3: d = pickle.load(f)
290/4: f.close()
290/5: PV = d['PV']
290/6: PV
290/7: count = d['count']
290/8: PV.values()
290/9: np.array(list(PV.values()))
290/10: import numpy as np
290/11: np.array(list(PV.values()))
290/12: avPV = np.array(list(PV.values()))/np.array(list(count.values()))
290/13: avPV
290/14: f = open('climatologyPV.txt','rb')
290/15: d2 = pickle.load(f)
290/16: f.close()
290/17: d2.keys()
290/18: d2['avPV']
290/19: avPVwc = np.array(list(d2['PV'].values()))/np.array(list(d2['count']))
290/20: avPVwc = np.array(list(d2['PV'].values()))/np.array(list(d2['count'].values()))
290/21: avPVwc
290/22: np.array(list(d2['PV'].values()))
290/23: np.array(list(d2['PV'].values()))/np.array(list(d['PV'].values()))
290/24: import matplotlib
290/25: import matplotlib.pyplot as plt
290/26:
import cartopy
import matplotlib.gridspec as gridspec
import functools
290/27: import cartopy.crs as ccrs
290/28: fig = plt.figure(figsize=(8,6))
290/29:
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
290/30: ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
290/31: lon = np.arange(-5,42.1,0.5)
290/32: lat = np.arange(30,48.1,0.5)
290/33: con = np.zeros(len(lat),len(lon))
290/34: con = np.zeros((len(lat),len(lon)))
290/35: con = dict()
290/36:
for m in range(0,13):
    con[m] = np.zeros((len(lat),len(lon)))
290/37:
for m in range(0,13):
    for k in locPV[m].keys():
        lo = np.where(lon==int(k[:3]))[0][0]
        la = np.where(lat==int(k[-3:]))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/38:
locPV = d['locPV']
loccount = d['loccount']

for m in range(0,13):
    for k in locPV[m].keys():
        lo = np.where(lon==int(k[:3]))[0][0]
        la = np.where(lat==int(k[-3:]))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/39:
locPV = d['locPV']
loccount = d['loccount']

for m in range(0,13):
    for k in locPV[m].keys():
        lo = np.where(lon==int(k[:-5]))[0][0]
        la = np.where(lat==int(k[-4:]))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/40:
locPV = d['locPV']
loccount = d['loccount']

for m in range(0,13):
    for k in locPV[m].keys():
        lo = np.where(lon==int(str(k[:-5])))[0][0]
        la = np.where(lat==int(str(k[-4:])))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/41:
locPV = d['locPV']
loccount = d['loccount']

for m in range(0,13):
    for k in locPV[m].keys():
        lo = np.where(lon==float(k[:-5]))[0][0]
        la = np.where(lat==float(k[-4:]))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/42:
locPV = d['locPV']
loccount = d['loccount']

for m in range(0,13):
    for k in locPV[m].keys():
        if loccount[m][k]==0:
            continue
        lo = np.where(lon==float(k[:-5]))[0][0]
        la = np.where(lat==float(k[-4:]))[0][0]
        con[m][la,lo] = locPV[m][k]/loccount[m][k]
290/43: ax.contour(lon,lat,con[1],cmap=matplotlib.cm.jet)
290/44: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
290/45: plt.show()
290/46: plt.close(fig)
290/47:
fig=plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
290/48: ax.contourf(lon,lat,con[1],cmap=matplotlib.cm.jet,levels=np.arange(0,0.6,0.05))
290/49: ax.set_extent([-10,45,25,50],ccrs.PlateCarree())
290/50: plt.show()
290/51: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/avPVmap.py 1-999
292/1: %history -g -f history.py
293/1: import pandas as pd
293/2: import numpy as np
293/3: df = pd.read_csv('pandas-all-data.csv')
293/4: col = df.columns()
293/5: col = df.columns
293/6: col
293/7: df = df.loc[df['ntraj075']>=200]
293/8: df
293/9: import matplotlib.pyplot as plt
293/10: fig,ax = plt.subplots()
293/11: df['mon'].unique
293/12: df['mon'].values.unique
293/13: np.unique(df['mon'].values)
293/14: MONTHS = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
293/15: data = []
293/16:
data2 = []
slps = []
for m in MONTHS:
    ids = np.where(df['mon'].values()==m)[0]
    data.append(df['ano'].values()[ids])
    data2.append(df['fullano'].values()[ids])
    slps.append(df['minSLP'].values()[ids])
293/17:
data2 = []
slps = []
for m in MONTHS:
    ids = np.where(df['mon'].values==m)[0]
    data.append(df['ano'].values[ids])
    data2.append(df['fullano'].values[ids])
    slps.append(df['minSLP'].values[ids])
293/18: len(slps)
293/19: dat = [data, data2, slps]
293/20: plt.close(fig)
293/21:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,label=MONTHS,whis=(10,90))
    ax.set_xlim(1,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/ + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/22:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,label=MONTHS,whis=(10,90))
    ax.set_xlim(1,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/23:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90))
    ax.set_xlim(1,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/24:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showflier=False)
    ax.set_xlim(1,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/25:
flier = dict(marker='+',markerfacecolor='grey',markersize=1,linestyle=' ',markeredgecolor='grey')
meanline = dict(linestyle='-',linewidth=1,color='red')
293/26:
capprops = dict(linestyle='-',linewidth=1,color='grey')
medianprops = dict(linestyle='-',linewidth=1,color='grey')
293/27: medianprops1 = dict(linestyle='-',linewidth=1,color='black')
293/28:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(1,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/29:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(0,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
293/30: from scipy.stats import pearsonr
293/31: pearsonr(df['ano'].values,df['minSLP'])
293/32: df2 = df.loc[df['ntraj075']>=500]
293/33: df2
293/34: pearsonr(df2['ano'].values,df2['minSLP'])
293/35: anov = np.array([])
293/36: slpv = np.array([])
293/37:
for a,s in zip(data,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/38: pearsonr(anov,slpv)
293/39: anov = np.array([])
293/40: slpv = np.array([])
293/41:
for a,s in zip(data,slps):
    anov=np.append(anov,np.median(a))
    slpv=np.append(slpv,np.median(s))
293/42: pearsonr(anov,slpv)
293/43: slpv = np.array([])
293/44: anov = np.array([])
293/45:
for a,s in zip(data2,slps):
    anov=np.append(anov,np.median(a))
    slpv=np.append(slpv,np.median(s))
293/46: pearsonr(anov,slpv)
293/47: anov = np.array([])
293/48: slpv = np.array([])
293/49:
for a,s in zip(data2,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/50: pearsonr(anov,slpv)
293/51: df['cycanoper']
293/52: df['cycperano']
293/53:
data2 = []
slps = []
data = []
for m in MONTHS:
    ids = np.where(df2['mon'].values==m)[0]
    data.append(df2['ano'].values[ids])
    data2.append(df2['fullano'].values[ids])
    slps.append(df2['minSLP'].values[ids])
293/54:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(0,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution-500traj.png',dpi=300,bbox_inches='tight')
    plt.close('all')
293/55: dat = [data, data2, slps]
293/56:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(0,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution-500traj.png',dpi=300,bbox_inches='tight')
    plt.close('all')
293/57: anov = np.array([])
293/58: slpv = np.array([])
293/59:
for a,s in zip(data,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/60: pearsonr(anov,slpv)
293/61: slpv = np.array([])
293/62: anov = np.array([])
293/63:
for a,s in zip(data2,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/64: pearsonr(anov,slpv)
293/65: df2 = df.loc[df['ntraj075']>=1000]
293/66:
data2 = []
slps = []
data = []
for m in MONTHS:
    ids = np.where(df2['mon'].values==m)[0]
    data.append(df2['ano'].values[ids])
    data2.append(df2['fullano'].values[ids])
    slps.append(df2['minSLP'].values[ids])
293/67:
sav = ['ano','fullano','slps']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(0,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution-1000traj.png',dpi=300,bbox_inches='tight')
    plt.close('all')
293/68: anov = np.array([])
293/69: slpv = np.array([])
293/70:
for a,s in zip(data,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/71: pearsonr(anov,slpv)
293/72: anov = np.array([])
293/73: slpv = np.array([])
293/74:
for a,s in zip(data2,slps):
    anov=np.append(anov,np.mean(a))
    slpv=np.append(slpv,np.mean(s))
293/75: pearsonr
293/76: pearsonr(anov,slpv)
293/77: cyd = []
293/78:
data2 = []
slps = []
data = []
envd = []
cyd = []
for m in MONTHS:
    ids = np.where(df['mon'].values==m)[0]
    data.append(df['ano'].values[ids])
    data2.append(df['fullano'].values[ids])
    slps.append(df['minSLP'].values[ids])
    cyd.append(df['cycperano'].values[ids])
    envd.append(df['envperano'].values[ids])
293/79: dat = [data, data2, slps, cyd, envd]
293/80:
sav = ['ano','fullano','slps','cyclonic-ano-per','env-per-ano']
for q,d in enumerate(dat):
    fig,ax = plt.subplots()
    ax.boxplot(d,labels=MONTHS,whis=(10,90),showfliers=False,flierprops=flier,meanprops=meanline,meanline=True,showmeans=True)
    ax.set_xlim(0,13)
    ax.set_xticks(ticks=np.arange(1,13))
    ax.set_xticklabels(labels=MONTHS)
    fig.savefig('/atmosdyn2/ascherrmann/009-ERA-5/MED/' + sav[q] + '-year-distribution.png',dpi=300,bbox_inches='tight')
    plt.close('all')
293/81: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/corrleations-cycper.pz 1-999
293/82: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/corrleations-cycper.py 1-999
294/1: import numpy as np
294/2: import pandas as pd
294/3: import pickle
294/4: f= open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt',\'rb')
294/5: f= open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
294/6: PVdata = pickle.load(f)
294/7: f.close()
294/8: datadi = PVdata['rawdata']
294/9: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
294/10: df = df.loc[df['ntraj075']>=200]
294/11: ID = df['ID'].values()
294/12: ID = df['ID'].values
294/13:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
294/14: lon = df['lon'].values
294/15: lat = df['lat'].values
294/16:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
ID = df['ID'].values
lon = df['lon'].values
lat = df['lat'].values

avdis = np.zeros(len(ID))
avpres = np.zeros(len(ID))

for q,date in enumerate(datadi.keys()):
    if np.all(ID!=int(date)):
        continue
    I = np.where(ID==int(date))[0][0]
    ids = np.where(datadi[date]['PV'][:,0]>=0.75)[0]
    tmplo = datadi[date]['lon'][ids,0] * (-1)
    tmpla = datadi[date]['lat'][ids,0] * (-1)
    dlo = tmplo + lon[I]
    dla = tmpla + lat[I]
    avdis[I] = np.mean(helper.convert_dlon_dlat_to_radial_dis_new(dlo,dla,lat[I]))
    avpres[I] = np.mean(datadi[date]['P'][ids,0])
294/17: df['averagepressure'] = avpres
294/18: df['averagedistance'] = avdis
294/19: df.to_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv',index=False)
294/20: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/pandas-append-tmp.py 1-999
295/1:
import numpy as np
import pickle
import xarray as xr
295/2:
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
295/3: add = 'deep-over-sea'
295/4: regions = ['NA']
295/5:
hoursel = 12
add = add + '-%dh'%hoursel
295/6:
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    pickle.dump(reg[r],f)
    f.close()
295/7: reg = dict()
295/8:
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    pickle.dump(reg[r],f)
    f.close()
295/9: reg['NA'] = dict()
295/10:
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    pickle.dump(reg[r],f)
    f.close()
295/11:
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    reg = pickle.load(f)
    f.close()
295/12: reg.keys()
295/13: reg[2655]
296/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle
import xarray as xr
import pandas as pd
296/2: data = numpy.loadtxt('orocases-data.txt')
296/3: data = np.loadtxt('orocases-data.txt')
296/4:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
296/5: ax.scatter(data[:,1],data[:,2])
296/6:
for k in range(len(data[:,0])):
    plt.annotate('%d'%data[k,6],(data[k,1],data[k,2]),fontsize=6)
296/7: plt.show
296/8: plt.show()
296/9: plt.close()
296/10:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
296/11: ax.scatter(data[:,1],data[:,2])
296/12:
for k in range(len(data[:,0])):
    plt.annotate('%d'%data[k,6],(data[k,1],data[k,2]),fontsize=10)
296/13: plt.show()
296/14:
for k in range(len(data[:,0])):
    plt.annotate('%d'%data[k,4],(data[k,1],data[k,2]-2),fontsize=10)
296/15: plt.show()
296/16: plt.close('all')
296/17:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
296/18: ax.scatter(data[:,1],data[:,2])
296/19:
for k in range(len(data[:,0])):
    plt.annotate('%d'%data[k,4],(data[k,1],data[k,2]-2),fontsize=10)
296/20:
for k in range(len(data[:,0])):
    plt.annotate('%d'%data[k,6],(data[k,1],data[k,2]),fontsize=10)
296/21: plt.show()
296/22: plt.show()
296/23: plt.close('all')
296/24: data[:,4]
296/25: data[:,3]
296/26: data[:,6]
296/27: pd.read_csv('traj/pandas-all-data.csv')
296/28: df = pd.read_csv('traj/pandas-all-data.csv')
296/29: df = df.loc[df['ntraj075']>=200]
296/30: envdf = df.loc[df['envperano']>=0.8]
296/31: envdf
296/32: envdf = df.loc[df['envperano']>0.8]
296/33: envdf
296/34: envdf = df.loc[(df['envperano']>0.8) & (df['htminSLP']>5)]
296/35: envdf
296/36: plt.close('all')
296/37:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
296/38: ax.scatter(df['lon'].values,df['lat'].values)
296/39: plt.show()
296/40: plt.close('all')
296/41:
fig, ax = plt.subplots(1, 1, subplot_kw=dict(projection=ccrs.PlateCarree()))
ax.coastlines()
296/42: ax.scatter(envdf['lon'].values,envdf['lat'].values)
296/43: plt.show()
296/44: import pickle
296/45: f = open('check-IDS.txt','rb')
296/46: idc = pickle.load(f)
296/47: f.close()
296/48: init = idc['initialID']
296/49: new = idc['newID']
296/50: init
296/51: new
296/52:
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
296/53: envdf = df.loc[(df['envperano']>0.4) & (df['htminSLP']>5)]
296/54:
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
296/55: envdf = df.loc[(df['envperano']>0.4)]
296/56:
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
296/57: envdf = df.loc[(df['envperano']>0.4) & (df['htminSLP']>5)]
296/58:
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
296/59:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
        c+=1
296/60:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
        c+=1
print(c)
296/61: envdf = df.loc[((df['envperano']>0.4) |(df['advperano']>0.4)) & (df['htminSLP']>5)]
296/62: envdf
296/63:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
        c+=1
print(c)
296/64: envdf = df.loc[((df['envperano']>0.5) |(df['advperano']>0.5)) & (df['htminSLP']>5)]
296/65:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
        c+=1
print(c)
296/66: envdf = df.loc[((df['envperano']>0.5) |(df['advperano']>0.5))]
296/67:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        print(k)
        c+=1
print(c)
296/68: kickID = np.array([])
296/69:
c = 0
for k in envdf['ID'].values:
    if np.any(new==k):
        kickID = np.append(kickID,k)
        c+=1
print(c)
296/70: kickID
296/71: np.savetxt('kick-IDS.txt',kickID,fmt='%d',delimiter=' ', newline='\n')
296/72: %save -r /atmosdyn2/ascherrmann/scripts/ipython-sessions/determine-IDS-to-potentially-kick-due-to-track-split.py 1-999
297/1: import numpy as np
297/2: a = np.array([5,6,7])
297/3: a[:1000]
297/4: import pandas as pd
297/5: pd.data_frame
297/6: pd.DataFrame
297/7: df = pd.read_csv('data/pandas-basic-data-all-deep-over-sea-12h.csv')
297/8: df.columns()
297/9: df.columns
297/10: dt = pd.DataFrame(columns=df.columns)
297/11: dt
298/1: import pandas as pd
298/2: df = pd.read_csv('data/pandas-basic-data-all-deep-over-sea-12h.csv')
298/3: df[:][:1000]
298/4: MEDtrack = pd.read_csv('data/pandas-MED-track-data-all-deep-over-sea-12h.csv')
298/5: MEDtrack
298/6: df.loc[df['reg']=='MED']
298/7: mkdir data/usecyc
298/8: df[list(df.columns)[1:]]
299/1: import pandas as pd
299/2: df = pd.read_csv('data/pandas-basic-data-all-deep-over-sea-12h.csv')
299/3: df = pd.read_csv('../pandas-basic-data-all-deep-over-sea-12h.csv')
299/4: col = df.columns
299/5: rdf = pd.DataFrame(columns=col)
299/6: tmp = df.loc[df['reg']=='MED']
299/7: tmp
299/8: tmp[:][:1000]
299/9: rdf.append(tmp[:][:1000])
299/10: rdf
299/11: rdf = rdf.append(tmp[:][:1000])
299/12: rdf
299/13:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

reg = ['MED','NA','SA','NP','SP','IO']

bd = np.array([-90,-60,-45,-30,-15,0,15,30,45,60,90])
columns = df.columns
for r in reg:
    tmp = df.loc[df['reg']==r]
    SLP = tmp['minSLP'].values
    lat = tmp['lat'].values
    lon = tmp['lon'].values

    tracks = pd.read_csv(p + 'data/pandas-'+ r +'-track-data-all-deep-over-sea-12h.csv')
    if r!='MED':
     for q,b in enumerate(bd[:-1]):

        ### save them distinct for ever region
        ### basic data
        rdf = pd.DataFrame(columns=columns)
        ### track data
        trtmp = pd.DataFrame(columns=list(tracks.columns)[1:])
        # get latitude between boundaries bd to have different regions
        ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
        if len(ids)==0:
            continue
        ### the cyclones should be sorted by minimum SLP and thus select the 1000 deepest
        ### or if less, as many as there are
        ###
        ids = ids[:1000]
        rdf = tmp[:][ids]
        trtmp = tracks[list(tracks.columns)[1:]][ids-ids[0]]

        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
    else:
        rdf = tmp[:][:1000]
        trtmp = tracks[list(tracks.columns)[1:]][:1000]
        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest.csv',index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest.csv',index=False)
299/14: ls
299/15: q
299/16: b
299/17: ids
299/18: len(ids)
299/19: tmp
299/20: r
299/21: tmp[:][ids]
299/22: tmp[:]
299/23: tmp[:][:10]
299/24: tmp[:][5,10]
299/25: tmp[:][5:10]
299/26:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

reg = ['MED','NA','SA','NP','SP','IO']

bd = np.array([-90,-60,-45,-30,-15,0,15,30,45,60,90])
columns = df.columns
for r in reg:
    tmp = df.loc[df['reg']==r]
    SLP = tmp['minSLP'].values
    lat = tmp['lat'].values
    lon = tmp['lon'].values

    tracks = pd.read_csv(p + 'data/pandas-'+ r +'-track-data-all-deep-over-sea-12h.csv')
    if r!='MED':
     for q,b in enumerate(bd[:-1]):

        ### save them distinct for ever region
        ### basic data
        rdf = pd.DataFrame(columns=columns)
        ### track data
        trtmp = pd.DataFrame(columns=list(tracks.columns)[1:])
        # get latitude between boundaries bd to have different regions
        ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
        if len(ids)==0:
            continue
        ### the cyclones should be sorted by minimum SLP and thus select the 1000 deepest
        ### or if less, as many as there are
        ###
        ids = ids[:1000]
        for i in ids:
        rdf = rdf.append(tmp[:][i])
        trtmp = trtmp.append(tracks[list(tracks.columns)[1:]][i-ids[0]])

        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
    else:
        rdf = tmp[:][:1000]
        trtmp = tracks[list(tracks.columns)[1:]][:1000]
        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest.csv',index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest.csv',index=False)
299/27:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

reg = ['MED','NA','SA','NP','SP','IO']

bd = np.array([-90,-60,-45,-30,-15,0,15,30,45,60,90])
columns = df.columns
for r in reg:
    tmp = df.loc[df['reg']==r]
    SLP = tmp['minSLP'].values
    lat = tmp['lat'].values
    lon = tmp['lon'].values

    tracks = pd.read_csv(p + 'data/pandas-'+ r +'-track-data-all-deep-over-sea-12h.csv')
    if r!='MED':
     for q,b in enumerate(bd[:-1]):

        ### save them distinct for ever region
        ### basic data
        rdf = pd.DataFrame(columns=columns)
        ### track data
        trtmp = pd.DataFrame(columns=list(tracks.columns)[1:])
        # get latitude between boundaries bd to have different regions
        ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
        if len(ids)==0:
            continue
        ### the cyclones should be sorted by minimum SLP and thus select the 1000 deepest
        ### or if less, as many as there are
        ###
        ids = ids[:1000]
        for i in ids:
            rdf = rdf.append(tmp[:][i])
            trtmp = trtmp.append(tracks[list(tracks.columns)[1:]][i-ids[0]])

        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
    else:
        rdf = tmp[:][:1000]
        trtmp = tracks[list(tracks.columns)[1:]][:1000]
        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest.csv',index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest.csv',index=False)
299/28: tmp
299/29: tmp[:][0]
299/30: tmp[:][1]
299/31: tmp
299/32: tmp[:][26818]
299/33: tmp
299/34: tmp[:].keys
299/35: tmp[:][:]
299/36: tmp[:][10]
299/37: tmp[:][:10]
299/38: tmp[:]['26818']
299/39:
for r in reg:
    tmp = df.loc[df['reg']==r]
    lat = tmp['lat'].values
    ID = tmp['ID'].values

    tracks = pd.read_csv(p + 'data/pandas-'+ r +'-track-data-all-deep-over-sea-12h.csv')
    if r!='MED':
     for q,b in enumerate(bd[:-1]):

        ### save them distinct for ever region
        ### basic data
        rdf = pd.DataFrame(columns=columns)
        ### track data
        trtmp = pd.DataFrame(columns=list(tracks.columns)[1:])
        # get latitude between boundaries bd to have different regions
        ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
        if len(ids)==0:
            continue
        ### the cyclones should be sorted by minimum SLP and thus select the 1000 deepest
        ### or if less, as many as there are
        ###
        ids = ids[:1000]
        for i in ids:
            rdf = rdf.append(tmp.loc[tmp['ID']==ID[i]])
            trtmp = trtmp.append(tracks.loc[tracks['ID']==ID[i]][list(tracks.columns)[1:]])

        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
    else:
        rdf = tmp[:][:1000]
        trtmp = tracks[list(tracks.columns)[1:]][:1000]
        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest.csv',index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest.csv',index=False)
299/40: ls
299/41: df.loc[df['reg']=='NA']
299/42: df.loc[df['reg']==np.nan]
299/43: df
299/44: df[:1000]
299/45: df[4000:5000:]
299/46: df.loc[df['reg']==NaN]
299/47: df.loc[df['reg']==np.NaN]
299/48:
MEDend = np.where(df['reg']=='MED')[0][-1] + 1
SAstart = np.where(df['reg']=='SA')[0][0]

df['reg'].values[MEDend:SAstart]='NA'
299/49: df[4000:5000]
299/50:
for r in ['NA']:
    tmp = df.loc[df['reg']==r]
    lat = tmp['lat'].values
    ID = tmp['ID'].values

    tracks = pd.read_csv(p + 'data/pandas-'+ r +'-track-data-all-deep-over-sea-12h.csv')
    if r!='MED':
     for q,b in enumerate(bd[:-1]):

        ### save them distinct for ever region
        ### basic data
        rdf = pd.DataFrame(columns=columns)
        ### track data
        trtmp = pd.DataFrame(columns=list(tracks.columns)[1:])
        # get latitude between boundaries bd to have different regions
        ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
        if len(ids)==0:
            continue
        ### the cyclones should be sorted by minimum SLP and thus select the 1000 deepest
        ### or if less, as many as there are
        ###
        ids = ids[:1000]
        for i in ids:
            rdf = rdf.append(tmp.loc[tmp['ID']==ID[i]])
            trtmp = trtmp.append(tracks.loc[tracks['ID']==ID[i]][list(tracks.columns)[1:]])

        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest-ge-%d-l-%d.csv'%(b,bd[q+1]),index=False)
    else:
        rdf = tmp[:][:1000]
        trtmp = tracks[list(tracks.columns)[1:]][:1000]
        rdf.to_csv(p + 'data/usecyc/' + r + '-data-deepest.csv',index=False)
        trtmp.to_csv(p + 'data/usecyc/' + r + '-tracks-deepest.csv',index=False)
300/1: import pickle
300/2: import numpy as np
300/3: f = open('All-CYC-entire-year-NEW-correct.txt','rb')
300/4: d = pickle.load(f)
300/5: f.close()
300/6: d.keys()
300/7: d['FEB18'][17]
300/8: d['FEB18'][15]
300/9: d['MAR18'][20]
300/10: d['APR18'][25]
301/1:
import numpy as np
import pickle

pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import xarray as xr
import cartopy
import matplotlib.gridspec as gridspec
import pandas as pd
301/2: trf = np.loadtxt('FEB18-TRACKED_CYCLONES')
301/3: trf = np.loadtxt('FEB18-TRACKED_CYCLONES',skiprows=1)
301/4: trm = np.loadtxt('MAR18-TRACKED_CYCLONES',skiprows=1)
301/5: tra = np.loadtxt('APR18-TRACKED_CYCLONES',skiprows=1)
301/6:
fig = plt.figure(figsize=(8,6))
gs = gridspec.GridSpec(nrows=1, ncols=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.5)
301/7: trf[0]
301/8: idf1 = np.where(trf[:,1]==15)[0]
301/9: idf2 = np.where(trf[:,1]==17)[0]
301/10: idm = np.where(trm[:,1]==20)[0]
301/11: ida = np.where(trm[:,1]==25)[0]
301/12: ax.plot(trf[idf1,2],trf[idf1,3],color='red')
301/13: ax.plot(trf[idf2,2],trf[idf2,3],color='k')
301/14: ax.plot(tra[ida,2],tra[ida,3],color='b')
301/15: ax.plot(trm[ida,2],trm[idm,3],color='g')
301/16: ax.plot(trm[idm,2],trm[idm,3],color='g')
301/17: plt.show()
302/1: import pickle
302/2: import numpy as np
302/3: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/ETA/use/PV-data-ETAdPSP-100-ZB-800PVedge-0.3-800-correct-distance.txt,'rb')
302/4: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/ETA/use/PV-data-ETAdPSP-100-ZB-800PVedge-0.3-800-correct-distance.txt','rb')
302/5: data = pickle.load(f)
302/6: f.close()
302/7: raw = data['rawdata']
302/8: list(raw.keys)
302/9: list(raw.keys())
303/1:
import numpy as np
import pickle

pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import xarray as xr
import cartopy
import matplotlib.gridspec as gridspec
import pandas as pd
303/2: trf = np.loadtxt('FEB18-TRACKED_CYCLONES',skiprows=1)
303/3: trm = np.loadtxt('MAR18-TRACKED_CYCLONES',skiprows=1)
303/4: tra = np.loadtxt('APR18-TRACKED_CYCLONES',skiprows=1)
303/5: idf1 = np.where(trf[:,1]==15)[0]
303/6: idf2 = np.where(trf[:,1]==17)[0]
303/7: idm = np.where(trm[:,1]==20)[0]
303/8: ida = np.where(trm[:,1]==25)[0]
303/9: trf[0]
303/10: trf[200]
303/11: f15 = trf[idf1]
303/12: f17 = trf[idf2]
303/13: m20 = trm[idm]
303/14: a25 = tra[ida]
303/15: np.where(f15[:,6]==np.min(f15[:,6]))[0]
303/16: from datetime import datetime, date, timedelta
303/17: ft = date.toordinal(date(1950,1,1))
303/18: k = str(helper.datenum_to_datetime(ft+f15[36,0]/24))
303/19: Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
303/20: Date
303/21: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/ETA/use/PV-data-ETAdPSP-100-ZB-800PVedge-0.3-800-correct-distance.txt','rb')
303/22: data = pickle.load(f)
303/23: f.close()
303/24: data['FEB18'][15]['dates']
303/25: f = open('All-CYC-entire-year-NEW-correct.txt','rb')
303/26: f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW-correct.txt','rb')
303/27: data = pickle.load(f)
303/28: f.close()
303/29: data['FEB18'][15]['dates']
303/30: data['FEB18'][15]['SLp']
303/31: data['FEB18'][15]['SLP']
303/32: np.where(data['FEB18'][15]['SLP']==np.min(data['FEB18'][15]['SLP']))[0]
303/33: data['FEB18'][15]['htzeta']
303/34: data['FEB18'][15].keys()
303/35: data['FEB18'][15]['hzeta']
303/36: data['FEB18'][15]['zeta']
303/37: data['FEB18'][15]['zeta'][36]
303/38: np.where(f17[:,6]==np.min(f17[:,6]))[0]
303/39: k = str(helper.datenum_to_datetime(ft+f15[3,0]/24))
303/40: Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
303/41: Date
303/42: np.where(m20[:,6]==np.min(m20[:,6]))[0]
303/43: k = str(helper.datenum_to_datetime(ft+f17[3,0]/24))
303/44: Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
303/45: Date
303/46: k = str(helper.datenum_to_datetime(ft+m20[10,0]/24))
303/47: Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
303/48: Date
303/49: np.where(a25[:,6]==np.min(a25[:,6]))[0]
303/50: k = str(helper.datenum_to_datetime(ft+a25[13,0]/24))
303/51: Date = k[0:4]+k[5:7]+k[8:10]+'_'+k[11:13]
303/52: Date
303/53: f17[3,2], f17[3,3]
303/54: f15[36,2], f15[36,3]
303/55: m20[10,2],m20[10,3]
303/56: a25[13,2],a25[13,3]
303/57: %save -r /atmosdyn2/ascherrmann/scripts/WRF/check-romans-BL-cyclones.py 1-999
304/1:
import numpy as np
import xarray as xr

pl = '/net/helium/atmosdyn/erainterim/clim/jet/cdf/'
tmp = xr.open_dataset(pl + '2005/12/J20051207_00')
rm = tmp.dljet.values
304/2: rm
304/3: rm.shape
304/4: rm = tmp.dljet.values[0,0,91:]
304/5: rm
304/6: rm.shape
304/7: rm = tmp.dljet.values[0,0,121:]
304/8: rm = tmp.dljet.values[0,0,120:,30:151]
304/9: rm
304/10: rm.shape
304/11: np.where(rm==1)
304/12: lorm,larm=np.where(rm==1)
304/13: rm[lorm,larm]
304/14: c = np.sum(rm[lorm,larm])
304/15: c
304/16: c = len(lorm)
304/17: c
304/18:
import numpy as np
import xarray as xr
import os
import pickle

pl = '/net/helium/atmosdyn/erainterim/clim/jet/cdf/'
tmp = xr.open_dataset(pl + '2005/12/J20051207_00')
rm = tmp.dljet.values[0,0,120:,30:151]
lorm, larm = np.where(rm==1)

crm = len(lorm)

dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.lisdir(pl + '%d/%02d/'%(y,m)):
            tmp = xr.open_dataset(pl + d)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
pickle.dump(save,f)
f.close()
304/19:
dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.listdir(pl + '%d/%02d/'%(y,m)):
            tmp = xr.open_dataset(pl + d)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
pickle.dump(save,f)
f.close()
304/20:
dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.listdir(pl + '%d/%02d/'%(y,m)):
            tmp = xr.open_dataset(pl + f)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
pickle.dump(save,f)
f.close()
304/21:
dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.listdir(pl + '%d/%02d/'%(y,m)):
            tmp = xr.open_dataset(pl + '%d/%02d/'%(y,m) + f)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
pickle.dump(save,f)
f.close()
304/22:
dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.listdir(pl + '%d/%02d/'%(y,m)):
          if f.startswith('J'):
            tmp = xr.open_dataset(pl + '%d/%02d/'%(y,m) + f)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
pickle.dump(save,f)
f.close()
304/23:
dates = np.array([])
perc = np.array([])
for y in range(1979,1980):#2018):
    for m in np.array([1,2,11,12]):
        for f in os.listdir(pl + '%d/%02d/'%(y,m)):
          if f.startswith('J'):
            tmp = xr.open_dataset(pl + '%d/%02d/'%(y,m) + f)
            rm = tmp.dljet.values[0,0,120:,30:151]

            co = np.sum(rm[lorm,larm])
            if co/c>0.5:

                dates = np.append(dates,f[-11:])
                perc = np.append(perc,co/c)

save = dict()
save['date'] = dates
save['perc'] = perc

f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','wb')
pickle.dump(save,f)
f.close()
304/24: f = open('/atmosdyn2/ascherrmann/scripts/WRF/jet-overlap.txt','rb')
304/25: da = pickle.load(f)
304/26: f.close()
304/27: da['date']
304/28: da['perc']
305/1: import pickle
305/2: f = open('jet-overlap.txt','rb')
305/3: d = pickle.load(f)
305/4: f.close()
305/5: d['dates']
305/6: d['date']
305/7: len(d['date'])
305/8: p = d['perc']
305/9: da = d['date']
305/10: p
305/11: len(np.where(p>0.6)[0])
305/12: import numpy as np
305/13: len(np.where(p>0.6)[0])
305/14: len(np.where(p>0.55)[0])
305/15: da
305/16: nd  = np.array([])
305/17:
for di in da:
    if da[-2:]=='00':
        np.append(nd,di)
305/18:
for di in da:
    if di[-2:]=='00':
        np.append(nd,di)
305/19: len(nd)
305/20: di
305/21:
for di in da:
    if di[-2:]=='00':
        nd = np.append(nd,di)
305/22: len(nd)
305/23: f = open('jet-overlap.txt','rb')
305/24: d = pickle.load(f)
305/25: f.close()
305/26: da = d['date']
305/27: p = d['perc']
305/28: len(da)
305/29: nd = np.array([])
305/30:
for di in da:
    if di[-2:]=='00':
        nd = np.append(nd,di)
305/31: len(nd)
305/32: nd
306/1: import pickle
306/2: f = open('jet-overlap.txt','rb')
306/3: d = pickle.load(f)
306/4: f.close()
306/5: d['date']
306/6:
nd = np.array([])
for k in d['date']:
  if k[-2:]=='00':
    nd = np.apend(nd,k)
306/7: import numpy as np
306/8:
nd = np.array([])
for k in d['date']:
  if k[-2:]=='00':
    nd = np.apend(nd,k)
306/9:
nd = np.array([])
for k in d['date']:
  if k[-2:]=='00':
    nd = np.append(nd,k)
306/10: nd
306/11:
for k in nd:
    print(k)
307/1:
import sys,argparse
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from useful_functions import create_lonlat_from_file,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
from conversions import coord2grid
from conversions import level_to_index_T
import netCDF4 as nc
import load_netcdf
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import os.path
import xarray as xr
307/2: import pickle
307/3: f = open('Pmean-pressure-lvl.txt','rb')
307/4: d = pickle.load(f)
307/5: f.close()
307/6: d.keys()
307/7: T = d['T']
307/8: Q = d['Q']
307/9: Q.shape
307/10: fig,axes=plt.subplots(3,1)
307/11: ax = axes.flatten()
307/12: RH = Q[-1]/helper.qs(T[-1],1000*100) * 100
307/13: ax[0].contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),Q[-1],cmin=0.0005,cmax=0.02)
307/14: ax[1].contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),T[-1],cmin=270,cmax=310)
307/15: ax[2].contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmin=0,cmax=100)
307/16: plt.show()
307/17: fig.close()
307/18: plt.close(fig)
307/19: fig,axes=plt.subplots(3,1)
307/20: ax = axes.flatten()
307/21: plt.close(fig)
307/22: fig,axes=plt.subplots()
307/23: ax =axes
307/24: ax.contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmin=0,cmax=100,cmap=matplotlib.cm.jet)
307/25: cf=ax.contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmin=0,cmax=100,cmap=matplotlib.cm.jet)
307/26: plt.close(fig)
307/27: cmap=matplotlib.cm.jet
307/28: norm=plt.Normalize(0,100)
307/29: fig,ax = plt.subplots()
307/30: ax.contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmap=cmap,norm=norm)
307/31:
cbax=fig.add_axes([0,0,0.1,0.1])
cbar=plt.colorbar(cf,cax=cbax)
307/32: func=resize_colorbar_vert(cbax,ax)
307/33: fig.canvas.mpl_connect('draw_event',func)
307/34: plt.show()
307/35: plt.close(fig)
307/36: RH = Q[-1] * 1000 /helper.qs(T[-1],1000*100) * 100
307/37: fig,ax = plt.subplots()
307/38: ax.contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmap=cmap,norm=norm)
307/39: plt.show()
307/40:
def calc_RH(Q,T,p):
        return 0.263 * p * Q/ (np.exp(17.67 * (T-273.16)/(T-29.65)))
307/41: RH = calc_RH(Q[-1],T[-1],1000*100)
307/42: fig,ax = plt.subplots()
307/43: ax.contourf(np.linspace(-180,197.5,720),np.linspace(-90,90,361),RH,cmap=cmap,norm=norm)
307/44: plt.show()
308/1:
import numpy as np
import netCDF4
308/2:
ncread = netCDF4.Dataset('Zmeaninv',mode='r') ## data to be written into new file
nco = netCDF4.Dataset('inp/Z20060116_18','a')
308/3: var = list(nco.variables.keys())
308/4: var
308/5: ncread['Z'].shape
308/6: nco['Z'] = np.zeros(ncread['Z'].shape)
308/7: nco[v][:] = np.zeros((ncread[v].shape))nco[v][:] = np.zeros((ncread[v].shape))
308/8: nco[v][:] = np.zeros((ncread[v].shape))
308/9: v = 'Z'
308/10: nco[v][:] = np.zeros((ncread[v].shape))
308/11: nco.close()
308/12: nco = netCDF4.Dataset('inp/Ztest',mode='w')
308/13: nco
308/14: nco[v][:] = np.zeros((ncread[v].shape))
308/15: nco[v] = np.zeros((ncread[v].shape))
308/16: ncw = netCDF4.Dataset('inp/Z20060116_18',mode='r')
308/17: ncw.variables
308/18: ncw.variables.keys()
308/19: ncw.dimension
308/20: ncw.dimensions
308/21: ncw.dimensions.keys()
308/22: ncw.groups.keys()
308/23: ncw.file_format.keys()
308/24: ncw.file_format
308/25: ncw.keys()
308/26: ncw.attributes
308/27: ncw.attributes()
308/28: ncw.variables
308/29: ncw.variables[0]
308/30: list(ncw.variables)
308/31: ncw.variables
308/32: ncw.dimensions
308/33: nco
308/34: nco.dimensions
308/35: nco.dimensions = {'dimx_Z',<class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z', size = 720,'dimy_Z',<class 'netCDF4_netCDF4.Dimension'>: name = 'dimy_Z', size = 361,'dimz_Z', <class 'netCDF4._netCDF4.Dimension'>: name = 'dimz_Z', size = 11, 'time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 1}
308/36: nco.dimensions = {'dimx_Z'<class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z', size = 720,'dimy_Z',<class 'netCDF4_netCDF4.Dimension'>: name = 'dimy_Z', size = 361,'dimz_Z', <class 'netCDF4._netCDF4.Dimension'>: name = 'dimz_Z', size = 11, 'time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 1}
308/37: nco.dimensions = {'dimx_Z'<class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z',size = 720}
308/38: nco.dimensions = {'dimx_Z', <class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z',size = 720}
308/39: nco.dimensions = {'dimx_Z':<class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z',size = 720}
308/40: nco.dimensions = {'dimx_Z': <class 'netCDF4_netCDF4.Dimension'>: name = 'dimx_Z',size = 720}
308/41: ncw
308/42: ncw.variables
308/43: nco
308/44: nco.createDimension("time",1)
308/45: nco.createDimension("dimz_Z",11)
308/46: nco.createDimension("dimy_Z",361)
308/47: nco.createDimension("dimx_Z",720)
308/48: nco
308/49: nco.createVariable('Z',"f4",("time","dimz_Z","dimy_Z","dimx_Z"))
308/50: nco['Z']
308/51: nco['Z'][:]
308/52: ncrad
308/53: ncread
308/54: ncread['Z']
308/55: ncread['Z'][:]
308/56: ncread['Z'][:].shape
308/57: nco['Z'][:] = ncread['Z'][:]
308/58: nco['Z'][:] = ncread['Z'][:]/9.81
308/59: nco.close()
308/60: pwd
308/61: %save -r /atmosdyn2/ascherrmann/scripts/WRF/create-nc-files.py 1-999
309/1: import netCDF4
309/2: t = netCDF4.Dataset('TEST',mode='r')
309/3: t
309/4: t.group
309/5: t.groups
309/6: t.rootgroup
309/7: t
309/8: t.time
309/9: t['time']
309/10: t.variables
309/11: t.variables.QGPV
309/12: t.variables['QGPV']
309/13: t['QGPV']
309/14: t['QGPV'].keys()
309/15: t
309/16:
p = '/atmosdyn2/ascherrmann/scripts/WRF/pvinv-cart/'
nco = netCDF4.Dataset(p + 'Ztest',mode='w')

dimname = 'QGPV'

nco.createDimension("time",1)
nco.createDimension("dimz_" + dimname,21)
nco.createDimension("dimy_" + dimname,101)
nco.createDimension("dimx_" + dimname,101)
309/17: nco
309/18: t
309/19: nco.close()
309/20: nco = netCDF4.Dataset('inp/Ztest',mode='w',format='NETCDF3')
309/21: nco = netCDF4.Dataset('inp/Ztest',mode='w',format='NETCDF3_CLASSIC')
309/22: nco = netCDF4.Dataset(p + 'Ztest',mode='w',format='NETCDF3_CLASSIC')
309/23:
dimname = 'QGPV'

nco.createDimension("time",1)
nco.createDimension("dimz_" + dimname,21)
nco.createDimension("dimy_" + dimname,101)
nco.createDimension("dimx_" + dimname,101)
309/24: nco
309/25: t
309/26: t['x']
309/27: t.domain
309/28: t.domains
309/29: t.domain()
309/30: t
309/31: list(t.variables.keys())
309/32: t.ncattrs
309/33: print(t.ncattrs)
309/34: print(t.ncattrs())
309/35: nco
309/36: t.domxmin
309/37: t.shape
309/38: t['dimZ'].shape
309/39: t.dimension()
309/40: t.dimensions()
309/41: t.domamin
309/42: t.domamax
309/43: t
309/44: nco
309/45:
nz = 21
ny = 101
nx = 101

resx = 55588.74
resy = 55588.74    #m
resz = 200.         #m
309/46:
nco.domxmin = -1 *np.floor(nx/2)
nco.domxmax = -1 * nco.domxmin
nco.domymin = -1 *np.floor(ny/2)
nco.domymax = -1 * nco.domymin
nco.domzmin = -1 *np.floor(nz/2)
nco.domzmax = -1 * nco.domzmin
nco.domamin = 0
nco.domamax = 0
nco.constants_file_name = 'no_constants_file'
309/47: import numpy as np
309/48:
nco.domxmin = -1 *np.floor(nx/2)
nco.domxmax = -1 * nco.domxmin
nco.domymin = -1 *np.floor(ny/2)
nco.domymax = -1 * nco.domymin
nco.domzmin = -1 *np.floor(nz/2)
nco.domzmax = -1 * nco.domzmin
nco.domamin = 0
nco.domamax = 0
nco.constants_file_name = 'no_constants_file'
309/49: xc,yc,zc = np.floor(nx/2),np.floor(ny/2),np.floor(nz/2)
309/50:
x = np.linspace(0, nx * resx,nx)
x -= x[xc]
y = np.linspace(0, ny * resy,ny)
y -= y[yc]
z = np.linspace(0, nz * resz,nz)
z -= z[zc]
309/51: xc,yc,zc = np.floor(nx/2).astype(int),np.floor(ny/2).astype(int),np.floor(nz/2).astype(int)
309/52:
x = np.linspace(0, nx * resx,nx)
x -= x[xc]
y = np.linspace(0, ny * resy,ny)
y -= y[yc]
z = np.linspace(0, nz * resz,nz)
z -= z[zc]
309/53: x
309/54: xc
309/55: x = np.linspace(0, nx * resx,nx)
309/56: x
309/57: x = np.linspace(0, (nx+1) * resx,nx)
309/58: x
309/59: resx
309/60: nx*resx
309/61: (nx-1)*resx
309/62: np.linspace(0,(nx-1)*resx,nx)
309/63:
x = np.linspace(0, (nx-1) * resx,nx)
x -= x[xc]
y = np.linspace(0, (ny-1) * resy,ny)
y -= y[yc]
z = np.linspace(0, (nz-1) * resz,nz)
z -= z[zc]
309/64: x
309/65: xx,yy,zz = np.meshgrid(x,y,z)
309/66: xx
309/67: xx.shape
309/68: rr = np.srqt(xx**2  + yy**2 + zz**2)
309/69: rr = np.sqrt(xx**2  + yy**2 + zz**2)
309/70: rr
309/71: xi,yi,zi = np.where(rr<=r)
309/72: r=200000
309/73: xi,yi,zi = np.where(rr<=r)
309/74: xi
309/75: PVfield = np.zeros((nz,ny,nx))
309/76: PVfield[xi,yi,zi]
309/77: PVfield[zi,yi,xi]
309/78: list(t.variables.keys())
309/79: t['time']
309/80: t['time'][0]
309/81:
ano = 2e-6
for q,w,e in zip(xi,yi,zi):
        PVfield[e,w,q] += ano
309/82: PVfield
310/1:
import numpy as np
import netCDF4



## path and filename
p = '/atmosdyn2/ascherrmann/scripts/WRF/pvinv-cart/'
nco = netCDF4.Dataset(p + 'Mean-perturb-150hPa',mode='a')
310/2:
nco.createVariable('GHT',"f4",("time","dimz_" + dimname,"dimy_"+ dimname,"dimx_" + dimname))
pres = nco['PRE_REF'][0,:,0,0]
310/3: dimname='QGPV'
310/4:
nco.createVariable('GHT',"f4",("time","dimz_" + dimname,"dimy_"+ dimname,"dimx_" + dimname))
pres = nco['PRE_REF'][0,:,0,0]
310/5: pres
310/6: len(pres)
310/7: pres
310/8: pres[0]
310/9: pres.values
310/10: pres*100
310/11:
z = nco['Z_REF'][0,:,0,0]
T = nco['T'][0]
310/12: T
310/13: T.shape
310/14: z
310/15: pT = pres[::2]
310/16: pT
310/17: pres
310/18: pT.shape
310/19: zT = z[::2]
310/20: T[0]
310/21: T[50]
310/22: T[100]
310/23: T[50]
310/24: np.min(T[50])
310/25: np.min(T[56])
310/26: np.min(T[57])
310/27: np.min(T[58])
310/28: np.min(T[60])
310/29:
pres = nco['PRE_REF'][0,::2,0,0]
z = nco['Z_REF'][0,::2,0,0]
310/30: pres
310/31: z
310/32: P = np.ones(T.shape)
310/33: P.shape
310/34: P * pres
310/35: P[0]
310/36: P[1]
310/37: P[-1]
310/38: PP = P * pres
310/39: PP[0]
310/40: PP[0].shape
310/41: PP = P[:] * pres
310/42: PP[0]
310/43: pres[0]
310/44: PP[0] = PP[0] * pres[0]
310/45: PP[0]
310/46: pres
310/47: pres[0]
310/48: PP[0]
310/49: P
310/50: PP[0] = P[0] * pres[0]
310/51: PP[0]
310/52: PP[0] = pres[0]
310/53: PP[1] = pres[1]
310/54: PP[1]
310/55:
for q,w in enumerate(pres):
    P[q] = w
310/56: P[-1]
310/57: pp = nco['P'][0]
310/58: P+=pp
310/59: P
310/60: nco['GHT']
310/61:
pres = nco['PRE_REF'][0,::2,0,0]
z = nco['Z_REF'][0,::2,0,0]
T = nco['T'][0]
pp = nco['P'][0]
P = np.ones(T.shape)
310/62:
for q,w  in enumerate(pres):
    P[q] = w
P +=pp
310/63:
R = 287
g = 9.80665
310/64:
GHT[1:] =  R/g * (T[1:]+T[:-1])/2. * np.log(P[:-1]/P[1:])
nco['GHT'][0] = GHT
310/65:
GHT = np.zeros(T.shape)
GHT[1:] =  R/g * (T[1:]+T[:-1])/2. * np.log(P[:-1]/P[1:])
nco['GHT'][0] = GHT
310/66: nco['GHT'][0]
310/67: np.max(nco['GHT'][0])
310/68: np.min(nco['GHT'][0])
313/1: import numpy as np
313/2:
pres = np.array(['1', '2', '3',
            '5', '7', '10',
            '20', '30', '50',
            '70', '100', '125',
            '150', '175', '200',
            '225', '250', '300',
            '350', '400', '450',
            '500', '550', '600',
            '650', '700', '750',
            '775', '800', '825',
            '850', '875', '900',
            '925', '950', '975',
            '1000'])
pres = pres.astype(int)
313/3: from netCDF4 import Dataset as Ds
313/4: pert = Ds('Perturbation-fields-150hPa',mode='r')
313/5: pertp = pert['PRE_REF'][0,:,0,0]
313/6: pertp
313/7: mp = pres
313/8:
pmap = np.zeros((len(pertp),len(mp)))
for k in range(len(mp)):
        pmap[:,k] = abs(pertp-np.flip(mp)[k])
313/9: pmap
313/10: pmap[:,-1]
313/11: pertp
313/12: np
313/13: mp
313/14: pertp
313/15:
pmap = np.zeros((len(pertp),len(mp)))
for k in range(len(mp)):
        pmap[:,k] = abs(np.flip(mp)[k]-pertp)
313/16: pmap
313/17:
for k in range(len(mp)):
        pmap[:,k] = np.flip(mp)[k]-pertp
313/18: pmap
313/19:
pmap = np.zeros((len(pertp),len(mp)))
for k in range(len(mp)):
        pmap[:,k] = abs(np.flip(mp)[k]-pertp)
313/20: np.min(pmap,axis=0)
313/21: mp
313/22: overlap = np.array([])
313/23:
pmap = np.zeros((len(pertp),len(mp)))
for k in range(len(mp)):
        pmap[:,k] = abs(np.flip(mp)[k]-pertp)
        overlap = np.append(overlap,np.where(pmap[:,k]==np.min(pmap[:,k]))[0][0])
313/24:
pmap = np.zeros((len(pertp),len(mp)))
overlap = np.array([])
for k in range(len(mp)):
        pmap[:,k] = abs(np.flip(mp)[k]-pertp)
        if np.min(pmap[:,k])<5:
            overlap = np.append(overlap,np.where(pmap[:,k]==np.min(pmap[:,k]))[0][0])
313/25: overlap
313/26: overlap = overlap.astype(int)
313/27: overlap
313/28: pertp[overlap]
313/29: pres
313/30: nc
314/1:
import numpy as np
import pickle
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import xarray as xr
import cartopy
import matplotlib.gridspec as gridspec
import pandas as pd
314/2: LON = np.round(np.linspace(-180,179.5,720),1)
314/3: LAT = np.round(np.linspace(-90,90,361),1)
314/4: fs = ['Pmean','P-jet-overlap']
314/5:
pres = np.array(['1', '2', '3',
            '5', '7', '10',
                        '20', '30', '50',
                                    '70', '100', '125',
                                                '150', '175', '200',
                                                            '225', '250', '300',
                                                                        '350', '400', '450',
                                                                                    '500', '550', '600',
                                                                                                '650', '700', '750',
                                                                                                            '775', '800', '825',
                                                                                                                        '850', '875', '900',
                                                                                                                                    '925', '950', '975',
                                                                                                                                                '1000'])
314/6: pres = pres.astype(int)
314/7: ## save variables
314/8: U = np.zeros((len(pres),len(LAT),len(LON)))
314/9: V = np.zeros((len(pres),len(LAT),len(LON)))
314/10: Q = np.zeros((len(pres),len(LAT),len(LON)))
314/11: pres
314/12: p = xr.open_dataset('Pmean')
314/13: p.U.values.shape
314/14: PS=1000
314/15: P = helper,modellevel_to_pressure(PS)
314/16: P = helper.modellevel_to_pressure(PS)
314/17: P
314/18: u =p.U.values[0]
314/19: u
314/20:
for k in range(u.shape[0]):
    print(np.max(u))
314/21:
for k in range(u.shape[0]):
    print(np.max(u[k]))
314/22: P
314/23: np.max(u[0])
315/1:
import numpy as np
import xarray as xr
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import pickle
import os
315/2: s = xr.open_Dataset('/atmosdyn2/era5/cdf/2000/01/S20000115_00')
315/3: s = xr.open_dataset('/atmosdyn2/era5/cdf/2000/01/S20000115_00')
315/4: s
315/5: s.hyam.values
315/6: s.hybm.values
315/7: P = 0.01*s.hyam.values[137-98:] + s.hybm.values[137-98:] * 1000
315/8: P
315/9: P=hyam/100 +PS*hybm
315/10: helper.modellevel_ERA5
315/11: import wrf
315/12: s.PS.values
315/13: s.PS.values.shape
315/14: U =s.U.values[0]
315/15: PV =s.PV.values[0]
315/16: PV.shape
315/17: np.tile(PS,(PV.shape[0],1,1))
315/18: np.tile(s.PS.values,(PV.shape[0],1,1))
315/19: np.tile(s.PS.values,(PV.shape[0],1,1)).shape
315/20: np.tile(s.PS.values,(PV.shape[0],1,1))[0]
315/21: s.PS.values[0]
315/22: s.lon
315/23: s.lat
315/24: s.lat[0]
315/25: P3d = np.tile(s.PS.values,(PV.shape[0],1,1))
315/26: P3d.shape
315/27: P3d = ak/100 + bk * P3d
315/28: P3d = s.hyam.values/100 + s.hybm.values * P3d
315/29: P3d = s.hyam.values[137-98:]/100 + s.hybm.values[137-98] * P3d
315/30: P3d = s.hyam.values[137-98:]/100 + s.hybm.values[137-98] * P3d.T
315/31: P3d
315/32: P3d.shape
315/33: P3d.T
315/34: P3d = np.tile(s.PS.values,(PV.shape[0],1,1))
315/35: P3d = (s.hyam.values[137-98:]/100 + s.hybm.values[137-98] * P3d.T).T
315/36: P3d
315/37: P3d.shape
315/38: P3d.shape[0]
315/39: P3d[0]
315/40: P3d[-1]
315/41: P3d = np.tile(s.PS.values,(PV.shape[0],1,1))
315/42: P3d = s.hyam.values[137-98:]/100 + s.hybm.values[137-98:] * P3d
315/43: P3d = (s.hyam.values[137-98:]/100 + s.hybm.values[137-98:] * P3d.T).T
315/44: P3d[-1]
315/45: test = wrf.interplevel(s.PV.values[0],P3d,np.array([1,2,3,5,200,300,350,400,450,500,550,600,650,700,750,775,800,825,850,875,900,925,950,975,1000]),meta=False)
315/46: test.shape
315/47: test[0]
315/48: test[-1]
315/49: test[-1].shape
315/50: test[-1].values
315/51: test[-1,0,0]
315/52: test1 = wrf.interplevel(s.PV.values[0],P3d,1000,missing=-999.99)
315/53: test1
315/54: test1.shape
315/55: test1 = wrf.interplevel(s.PV.values[0],P3d,150,missing=-999.99)
315/56: test1
315/57: test1[1:360]
315/58: P3d
315/59: P3d.shape
315/60: P3d[-1]
315/61: P3d[-1,20:340]
315/62:
pres = np.array(['1', '2', '3',
            '5', '7', '10',
            '20', '30', '50',
            '70', '100', '125',
            '150', '175', '200',
            '225', '250', '300',
            '350', '400', '450',
            '500', '550', '600',
            '650', '700', '750',
            '775', '800', '825',
            '850', '875', '900',
            '925', '950', '975',
            '1000'])
pres = pres.astype(int)
315/63: pres
315/64: PVinter = wrf.interplevel(s.PV.values[0],P3d,pres,missing=-999.99)
315/65: PVinter.shape
315/66: intertest = wrf.interplevel(s.PV.values[0],P3d,np.array([100,975]))
315/67: intertest[0]
315/68: intertest[1]
315/69: intertest[0,20:340]
315/70: intertest[1,20:340]
315/71: intertest
315/72: ls
315/73: intertest = wrf.interplevel(s.PV.values[0],P3d,np.array([100,975]),meta=True)
315/74: intertest
315/75: intertest = wrf.interplevel(s.PV.values[0],P3d,np.array([100,975]),meta=False)
315/76: intertest
315/77: intertest[0]
315/78: intertest[1]
315/79: intertest.shape
315/80: np.savetxt('interpolationtest.txt',interterst,fmt='%.4f',delimiter=' ',newline='\n')
315/81: np.savetxt('interpolationtest.txt',intertertest,fmt='%.4f',delimiter=' ',newline='\n')
315/82: np.savetxt('interpolationtest.txt',intertest,fmt='%.4f',delimiter=' ',newline='\n')
315/83: intertest[:,:,:]
315/84: intertest.data
315/85: intertest.data.shape
315/86: np.savetxt('interpolationtest.txt',intertest.data,fmt='%.4f',delimiter=' ',newline='\n')
316/1: import numpy as np
316/2: f0=1e-4
316/3: z = np.arange(0,30001,200)
316/4: z
316/5: x = y = np.arange(-5000000,5000001,50000)
316/6: x
316/7: y
316/8: xx,yy,zz=np.meshgrid(x,y,z)
316/9: xx.shape
316/10: a = 1e6
316/11: r3 = np.sqrt(xx**2 +yy**2 + (zz-10000)**2)
316/12: np.where(r3<=a)
316/13: loc = np.where(r3<=a)
316/14: loc.shape
316/15: locx,locy,locz=np.where(r3<=a)
316/16: len(locz)
316/17: 201*201*151
316/18: from netCDF4 import Dataset as Ds
316/19: data = Ds('analytic-test')
316/20: data['NSQ_REF']
316/21: data['NSQ_REF'].shape
316/22: N = data['NSQ_REF']
316/23: data['NSQ_REF'].values
316/24: data['NSQ_REF'][0]
316/25: data['NSQ_REF'][0].flatten()
316/26: data['NSQ_REF'][0].flatten()[0]
316/27: N = data['NSQ_REF'][0].flatten()
316/28: f0/N
316/29: z
316/30: z-15000
316/31: N = data['NSQ_REF'][0].flatten()[::2]
316/32: N.shape
316/33: z.shape
316/34: np.sqrt((f0/N)**2 * (z-15000)**2)
316/35: np.sqrt((N/fo)**2 * (z-15000)**2)
316/36: np.sqrt((N/f0)**2 * (z-15000)**2)
316/37: 1/86400 * sin(np.pi/4)
316/38: 1/86400 * np.sin(np.pi/4)
316/39: 1/86400 * np.sin(45/180 * np/pi)
316/40: 1/86400 * np.sin(45/180 * np.pi)
316/41: 2 * pi/86400 * np.sin(45/180 * np.pi)
316/42: 2 * np.pi/86400 * np.sin(45/180 * np.pi)
316/43: N/(2 * np.pi/86400 * np.sin(45/180 * np.pi))
316/44: N
316/45: N
316/46: N/1e-5
316/47: (N/1e-5)**2
316/48: (N/1e-4)**2
316/49: N=1e-2
316/50: N/f0
316/51: (N/f0)**2
316/52: rc = np.sqrt(xx**2 + yy**2 + (N/f0)**2 * (zz-15000)**2)
317/1: import numpy as np
317/2: import netCDF4
317/3:
d1 = netCDF4.Dataset('plmean.nc',mode='r')
d2 = netCDF4.Dataset('plmean-2.nc',mode='r')


nco = netCDF4.Dataset('test.nc',mode='w')
317/4: nco.close
317/5: d1.variables.keys()
317/6: d1['time']
317/7: d1['time'][0]
317/8: d2['time']
317/9: d2['time'][0]
317/10: d2['time'].shape
317/11: d2['lon'].shape
317/12: d2['lon']
317/13: d2['lon'][:]
317/14: d2['plev'][:]
317/15: d1['plev'][:]
317/16: d2.variables
317/17: d2.variables.keys()
317/18: d2['var129']
317/19: d2['lon'].shape[0]
317/20: d2.attributes
317/21: d2.atr
317/22: d2.atrs
317/23: d2.ncattrs
317/24: d2.ncattrs()
317/25: d2['lon']
317/26: d2['plev']
317/27: np.arange(80,-20,0.5)
317/28: l = len(d1['lon'][:])
317/29: l
317/30: d1['var129'][:,:,:,:410]
317/31: d1['var129'][:,:,:,:410].shape
318/1:
import netCDF4
import numpy as np
318/2:
d1 = netCDF4.Dataset('plmean.nc',mode='r')
d2 = netCDF4.Dataset('plmean-2.nc',mode='r')
318/3: l = len(d1['lon'][:])
318/4:
nco = netCDF4.Dataset('test.nc',mode='w')

dim = 'time'
nco.createDimension(dim,d1[dim].shape[0])

dim = 'lon'
nco.createDimension(dim,d1[dim].shape[0]+d2[dim].shape[0])

dim = 'lat'

nco.createDimension(dim,d1[dim].shape[0])

dim = 'plev'
nco.createDimension(dim,d1[dim].shape[0])

nco.createVariable('time',"f4",("time"))
nco.createVariable('lon',"f4",("lon"))
nco.createVariable('lat',"f4",("lat"))
nco.createVariable('plev',"f4",("plev"))

nco['lon'][:] = np.arange(-150,80.5,0.5)
nco['lat'][:] = np.flip(np.arange(-20,80.1,0.5))
nco['plev'][:] = d2['plev'][:]
318/5: nco['var129'][:].shape
318/6:
for var in list(d1.variables.keys())[4:]:
    nco.createVariable(var,'f4',('time','plev','lon','lat'))
318/7: nco['var129'][:].shape
318/8: nco.close
318/9: nco.close()
318/10:
nco = netCDF4.Dataset('test.nc',mode='w')

dim = 'time'
nco.createDimension(dim,d1[dim].shape[0])

dim = 'lon'
nco.createDimension(dim,d1[dim].shape[0]+d2[dim].shape[0])

dim = 'lat'

nco.createDimension(dim,d1[dim].shape[0])

dim = 'plev'
nco.createDimension(dim,d1[dim].shape[0])

nco.createVariable('time',"f4",("time"))
nco.createVariable('lon',"f4",("lon"))
nco.createVariable('lat',"f4",("lat"))
nco.createVariable('plev',"f4",("plev"))

nco['lon'][:] = np.arange(-150,80.5,0.5)
nco['lat'][:] = np.flip(np.arange(-20,80.1,0.5))
nco['plev'][:] = d2['plev'][:]

for var in list(d1.variables.keys())[4:]:
    nco.createVariable(var,'f4',('time','plev','lat','lon'))
    nco[var][:,:,:,:l-1] = d1[var][:]
    nco[var][:,:,:,l-1:] = d2[var][:]
318/11: nco['var129'][:].shape
318/12: nco[var][:,:,:,:l-1].shape
318/13: d1[var][:].shape
319/1: import picle
319/2: import pickle
319/3:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400.txt','rb')
PVdata = pickle.load(f)
f.close()
319/4: PVdata.keys()
319/5: PVdata['oro'].keys()
319/6: PVdata['oro']['20171214_02-073'].keys()
319/7: PVdata['oro']['20171214_02-073']['env']
319/8: PVdata['oro']['20171214_02-073']['env'].keys()
320/1: import numpy as np
320/2: import pickle
320/3:
pload = '/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400.txt','rb')
PVdata = pickle.load(f)
f.close()
320/4:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400.txt','rb')
PVdata = pickle.load(f)
f.close()
320/5: raw=PVdata['rawdi']
320/6: raw=PVdata['rawdata']
320/7: lon=raw['20171214_02-073']['lon'][1452]
320/8: lat=raw['20171214_02-073']['lat'][1452]
320/9: f = open('ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
320/10: new = pickle.load(f)
320/11: f.close()
320/12: lonn = new['rawdata']['20171214_02-073']['lon']
320/13: latn = new['rawdata']['20171214_02-073']['lat']
320/14:
for k in range(len(lonn)):
    if np.all(lon==lonn[k]) and np.all(lat==latn[k]):
        print(k)
321/1: import wrf
321/2:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.cm import get_cmap
from netCDF4 import Dataset

from wrf import (getvar, to_np, vertcross, smooth2d, CoordPair,
                 get_basemap, latlon_coords)
321/3: ncfile = Dataset('wrfwind')
321/4: wspd = getvar(nc,"U")
321/5: wspd = getvar(ncfile,"U")
321/6: wspd.shape
321/7: z = getvar(ncfile,"P") + getvar(ncfile,"PB")
321/8: z
321/9: U
321/10: wdsp
321/11: wspd
321/12: z = z/100.
321/13: fig = plt.figure(figsize=(6,4))
321/14: ax = plt.axes()
321/15: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=)
321/16: from matplotlib.colors import ListedColormap, BoundaryNorm
321/17:
levels = np.arange(0,60,5)
norm = BoundaryNorm(levels,256)
321/18: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/19:
start_point = CoordPair(lat=10, lon=-65.0)
end_point = CoordPair(lat=80, lon=-65.0)
321/20:
start_point = CoordPair(lat=26.76, lon=-80.0)
end_point = CoordPair(lat=26.76, lon=-77.8)
321/21: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/22:
wspd_cross = vertcross(wspd, z, wrfin=ncfile, start_point=start_point,
                       end_point=end_point, latlon=True, meta=True)
321/23: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/24: import matplolib
321/25: import matplotlib
321/26: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/27: plt.colorbar(wspd_contours, ax=ax)
321/28: vert_vals = to_np(wspd_cross.coords["vertical"])
321/29: vert_vals
321/30:
v_ticks = np.arange(vert_vals.shape[0])
ax.set_yticks(v_ticks[::20])
ax.set_yticklabels(vert_vals[::20], fontsize=8)
321/31: plt.show()
321/32:
start_point = CoordPair(lat=26.76, lon=-65.0)
end_point = CoordPair(lat=26.76, lon=-65.0)
321/33: plt.close(fig)
321/34:
start_point = CoordPair(lat=20, lon=-65.0)
end_point = CoordPair(lat=80, lon=-65.0)
321/35:
start_point = CoordPair(lat=10, lon=-65.0)
end_point = CoordPair(lat=80, lon=-65.0)
321/36: fig = plt.figure(figsize=(6,4))
321/37: ax = plt.axes()
321/38:
wspd_cross = vertcross(wspd, z, wrfin=ncfile, start_point=start_point,
                       end_point=end_point, latlon=True, meta=True)
321/39: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/40: plt.colorbar(wspd_contours, ax=ax)
321/41: ax.set_yticks(ticks=np.arange(100,1001,100))
321/42: ax.invert_yaxis()
321/43: plt.show()
321/44: plt.close(fig)
321/45: fig = plt.figure(figsize=(6,4))
321/46: ax.invert_yaxis()
321/47: ax = plt.axes()
321/48: wspd_contours = ax.contourf(to_np(wspd_cross), cmap=matplotlib.cm.nipy_spectral,norm=norm,levels=levels,extend='both')
321/49: plt.colorbar(wspd_contours, ax=ax)
321/50:
vert_vals = to_np(wspd_cross.coords["vertical"])
v_ticks = np.arange(vert_vals.shape[0])
ax.set_yticks(v_ticks[::20])
ax.set_yticklabels(vert_vals[::20], fontsize=8)
321/51: plt.show()
321/52: %save -r /atmosdyn2/ascherrmann/scripts/WRF/vertical-cross-section-WRF.py 1-999
322/1: import numpy as np
322/2: import pandas as pd
322/3: df = pd.read_csv('pandas-all-data.csv')
322/4: df.colums()
322/5: df.coloms()
322/6: df.columns()
322/7: df.columns
322/8: df['cycperano']
322/9: df['cycperano'].values
322/10: df = df.loc[df['ntraj075']>=200]
322/11: df
322/12: df['cycperano'].values
322/13: cya = df['cycperano'].values
322/14: len(np.where(cya>=0.6)[0])
322/15: len(np.where(cya>=0.4)[0])
322/16: len(np.where(cya>=0.2)[0])
322/17: enva = df['envperano'].values
322/18: adva = df['advperano'].values
322/19: len(np.where(enva>=0.2)[0])
322/20: len(np.where(enva>=0.6)[0])
322/21: len(np.where(enva>=0.8)[0])
322/22: len(np.where(cya>=0.5)[0])
322/23: len(np.where(cye>=0.5)[0])
322/24: len(np.where(enva>=0.5)[0])
322/25: len(np.where(enva>=0.8)[0])
322/26: len(np.where(cya>=0.8)[0])
322/27: len(np.where(adva>=0.8)[0])
322/28: len(np.where(adva>=0.5)[0])
322/29: len(np.where(adva>=0.2)[0])
322/30: ntraj = df['ntraj075'].values
322/31: PVsum = df['sumPV075'].values
322/32: df.columns
322/33: sumPV = df['PVsum']
322/34: sumPV075 = df['PV075sum']
322/35: ano075 = df['ano']
322/36: ano = df['fullano']
322/37: adv80 = np.where(adva>=0.8)[0]
322/38: cy80 = np.where(cya>=0.8)[0]
322/39: SLP = df['minSLP']
322/40: ntraj075
322/41: ntraj075 = df['ntraj075']
322/42: htminSLP = df['htminSLP']
322/43: env80 = np.where(enva>=0.8)[0]
322/44: var = [sumPV,sumPV075,ano075,ano,SLP,htminSLP]
322/45: par = ['summedPV all','summed PV 0.75PVU','anomaly of 0.75', 'anomaly full','SLP','htminSLP']
322/46:
for v,p in zip(var,par):
    print(p,np.mean(v[cy80]),np.mean(v[env80]),np.mean(v[adv80]))
322/47: p
322/48: cy80
322/49: env80
322/50:
sumPV = df['PVsum'].values
sumPV075 = df['PV075sum'].values
ano075 = df['ano'].valus
ano = df['fullano'].values
adv80 = np.where(adva>=0.8)[0]
cy80 = np.where(cya>=0.8)[0]
SLP = df['minSLP'].values
322/51:
sumPV = df['PVsum'].values
sumPV075 = df['PV075sum'].values
ano075 = df['ano'].values
ano = df['fullano'].values
adv80 = np.where(adva>=0.8)[0]
cy80 = np.where(cya>=0.8)[0]
SLP = df['minSLP'].values
322/52:
ntraj075 = df['ntraj075'].values
htminSLP = df['htminSLP'].values
322/53: var = [sumPV,sumPV075,ano075,ano,SLP,htminSLP]
322/54:
for v,p in zip(var,par):
    print(p,np.mean(v[cy80]),np.mean(v[env80]),np.mean(v[adv80]))
322/55:
for v,p in zip(var,par):
    print(p + '\t\t %.3f\t%.3f\t%.3f'%(np.mean(v[cy80]),np.mean(v[env80]),np.mean(v[adv80])))
322/56: cy80 = np.where((cya>=0.8) & (htminSLP>=6))[0]
322/57: cy802 = np.where((cya>=0.8) & (htminSLP>=6))[0]
322/58: cy80 = np.where(cya>=0.8)[0]
322/59: env80 = np.where((enva>=0.8) & (htminSLP>=6))[0]
322/60: env802 = np.where((enva>=0.8) & (htminSLP>=6))[0]
322/61: env80 = np.where(enva>=0.8)[0]
322/62: adv802 = np.where((adva>=0.8) & (htminSLP>=6))[0]
322/63:
for v,p in zip(var,par):
    print(p + '\t\t %.3f\t%.3f\t%.3f'%(np.mean(v[cy802]),np.mean(v[env802]),np.mean(v[adv802])))
323/1: import pandas as pd
323/2: import numpy as np
323/3: from scipy.stats import pearsonr
323/4: df = pd.read_csf('pandas-all-data.csv')
323/5: df = pd.read_csv('pandas-all-data.csv')
323/6: df = df.loc[df['ntraj075']>=200]
323/7: minslp = df['minSLP'].values
323/8: sumPV = df['PVsum'].values
323/9: pearsonr(minslp,sumPV)
324/1: import numpy as np
324/2: import pickle
324/3: import matplotlib.pyplot as plt
324/4: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/use/PV-data-MEDdPSP-100-ZB-800-PVedge-0.3-400-correct-distance.txt','rb')
324/5: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800-PVedge-0.3-400-correct-distance.txt','rb')
324/6: ls /atmosdyn2/ascherrmann/010-IFS/ctraj/MED/
324/7: ls /atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/
324/8: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
324/9: data =pickle.load(data)
324/10: data =pickle.load(f)
324/11: rawdi = data['rawdata']
324/12: datadi = data['rawdata']
324/13: dipv = data['dipv']
324/14: CID = '20171214_02-073''
324/15: CID = '20171214_02-073'
324/16: lon0 = rawdi[CID]['lon'][:,-1]
324/17: lat0 = rawdi[CID]['lat'][:,-1]
324/18: len(lon0)
324/19: reg = [[5,46,15,90],[5,25,13,37],[5,38,21,46.5],[14,29,28,41]]
324/20: fig, ax = plt.subplots(2,2,wspace=0,hspace=0,sharex=True,sharey=True)
324/21: fig, ax = plt.subplots((2,2),wspace=0,hspace=0,sharex=True,sharey=True)
324/22: fig, ax = plt.subplots(2,2,hspace=0,sharex=True,sharey=True)
324/23: fig, axes = plt.subplots(2,2,hspace=0,sharex=True,sharey=True)
324/24: fig, axes = plt.subplots(2,2,sharex=True,sharey=True)
324/25: plt.subplots_adjust(left=0.1,wspace=0,hspace=0)
324/26: axes = axes.flatten()
324/27:
for r,ax in zip (reg,axes):
    traid = np.where((lon0>=reg[0]) & (lon0<=reg[2]) & (lat0>=reg[1]) & (lat0<=reg[-1]))[0]
    for pro,col in zip(['PVR-T','APVTOT','PVRLS','APVRAD','PVRCONVM','PVRTURBM'],['orange','k','r','b','g','dodgerblue']):
        for ls,key in zip(['-',':'],['cyc','env']):
            ax.plot(rawdi[CID]['time'][0],np.mean(dipv[CID][key][pro][traid]),color=col,linestyle=ls)
    ax.set_xlim(-48,0)
    ax.set_ylim(-0.3,1.8)
    ax.set_xticks(ticks=np.arange(-48,1,6))
324/28:
for r,ax in zip (reg,axes):
    traid = np.where((lon0>=r[0]) & (lon0<=r[2]) & (lat0>=r[1]) & (lat0<=r[-1]))[0]
    for pro,col in zip(['PVR-T','APVTOT','PVRLS','APVRAD','PVRCONVM','PVRTURBM'],['orange','k','r','b','g','dodgerblue']):
        for ls,key in zip(['-',':'],['cyc','env']):
            ax.plot(rawdi[CID]['time'][0],np.mean(dipv[CID][key][pro][traid]),color=col,linestyle=ls)
    ax.set_xlim(-48,0)
    ax.set_ylim(-0.3,1.8)
    ax.set_xticks(ticks=np.arange(-48,1,6))
324/29:
for r,ax in zip (reg,axes):
    traid = np.where((lon0>=r[0]) & (lon0<=r[2]) & (lat0>=r[1]) & (lat0<=r[-1]))[0]
    for pro,col in zip(['PVR-T','APVTOT','PVRLS','APVRAD','PVRCONVM','PVRTURBM'],['orange','k','r','b','g','dodgerblue']):
        for ls,key in zip(['-',':'],['cyc','env']):
            ax.plot(rawdi[CID]['time'][0],np.mean(dipv[CID][key][pro][traid],axis=0),color=col,linestyle=ls)
    ax.set_xlim(-48,0)
    ax.set_ylim(-0.3,1.8)
    ax.set_xticks(ticks=np.arange(-48,1,6))
324/30: plt.show()
324/31: %save -r /atmosdyn2/ascherrmann/scripts/IFS-Antlantic-MED/different-trajectory-APV.py 1-999
325/1: import numpy as np
325/2: import pickle
325/3: f = open('/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
325/4: data =pickle.load(f)
325/5: f.close()
325/6: f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
325/7: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/*.txt
325/8: ls /atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/*data*.txt
325/9: f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
325/10: data = pickle.load(f)
325/11: f.close()
325/12: datadi = data['rawdata']
325/13: dipv = data['dipv']
325/14: import pandas as pd
325/15: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
325/16: df = df.loc[df['ntraj075']>=200]
325/17: ID = df['ID'].values
325/18:
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    if np.mean(dipv[k]['env'][:,0])>0 and np.mean(oro[k]['env'][:,0])>0:
        poroid = np.append(poroid,k)
325/19: poroid
325/20: len(poroid)
325/21:
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    if np.mean(dipv[k]['env'][:,0]/(dipv[k]['cyc'][:,0] + dipv[k]['env'][:,0]))>0.5 and np.mean(oro[k]['env'][:,0])>0.2 :
        poroid = np.append(poroid,k)
325/22: poroid
325/23: len(poroid)
325/24: df['mon']
325/25:
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    if np.mean(dipv[k]['env'][:,0]/(dipv[k]['cyc'][:,0] + dipv[k]['env'][:,0]))>0.5 and np.mean(oro[k]['env'][:,0])>= np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/26: poroid
325/27: len(poroid)
325/28: df['lon']
325/29:
import xarray as xr
sid = np.array([])
NORO = xr.oped_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL']
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/30:
NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL']
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/31: NORO
325/32: NORO.shape
325/33: NORO['OL'].shape
325/34:
OL = NORO['OL'][0]
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/35: sid
325/36: len(sid)
325/37: col = df.column()
325/38: col = df.columns
325/39: col
325/40: dfo = df.Dataset(columns=col)
325/41: dfo = pd.DataFrame(columns=col)
325/42:
for ids in sid:
    pl = np.where(int(ids)==ID)[0][0]
    dfo = dfo.append(df[])
325/43:
for ids in sid:
    
    dfo = dfo.append(df.loc[df['ID']==int(ids)])
325/44: dfo
325/45: df['htminSLP'].mean
325/46: np.mean(df['htminSLP'])
325/47:
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    if np.mean(dipv[k]['env'][:,0]/datadi[k]['PV'][:,0])>0.5 and np.mean(oro[k]['env'][:,0])>= np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/48: poroid
325/49: len(poroid)
325/50:
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    if np.mean(dipv[k]['env'][:,0]/datadi[k]['PV'][:,0])>0.5 and np.mean(oro[k]['env'][:,0])>= 0.8 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/51: poroid
325/52: len(poroid)
325/53:
sid = np.array([])
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/54: sid
325/55: len(sid)
325/56:
clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.8 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/57: poroid
325/58: len(poroid)
325/59:
sid = np.array([])
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/60: sid
325/61: len(sid)
325/62:
clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 1 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/63: poroid
325/64: len(poroid)
325/65:
clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.6 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/66: len(poroid)
325/67:
clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)
325/68: len(poroid)
325/69:
sid = np.array([])
for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)
325/70: len(sid)
325/71: dfo = pd.DataFrame(columns=col)
325/72:
for ids in sid:
    
    dfo = dfo.append(df.loc[df['ID']==int(ids)])
325/73: dfo
325/74: np.mean(dfo['htminSLP'])
325/75: dfo['htminSLP'].stat
325/76: dfo['htminSLP'].stats
325/77: dfo['htminSLP'].stats()
325/78: dfo['htminSLP'].stat()
325/79: dfo['htminSLP'].describe
325/80: dfo['htminSLP'].describe()
325/81: dfo.describe()
325/82: np.where(dfo['minSLP']=980.9)
325/83: np.where(dfo['minSLP'].values==980.9)
325/84: dfo[:][54]
325/85: dfo = dfo.reset_index()
325/86: dfo
325/87: dfo[:][54]
325/88: dfo.iloc[[54]]
325/89: dfo.iloc[[54]]['htminSLP']
325/90: np.where(dfo['minSLP'].values<=995)
325/91: dfo.iloc[[33,54,88,108,113,122]]
325/92: dfo.iloc[[108]]['htminSLP']
325/93: dfo.iloc[[108]]['minSLP']
325/94: %save -r /atmosdyn2/ascherrmann/scripts/IFS-Antlantic-MED/real-orocases.py 1-999
326/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
326/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
pload2 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)

savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload2[:-4] + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

Slp = var[0]
SLP = var[0]
Clon = var[1]
Clat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
326/3: Clon[0]
326/4:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])
lons = []
lats = []
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    lons.append(np.array(Clon[k][:loc+1]))
    lats.append(np.array(Clat[k][:loc+1]))
    maturedates = np.append(maturedates,dates[k][loc])
    SLPminid = np.append(SLPminid,loc)
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
326/5:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])
lons = []
lats = []
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    lons.append(np.array(Clon[k][:loc+1]))
    lats.append(np.array(Clat[k][:loc+1]))
    
    SLPminid = np.append(SLPminid,loc)
    end = np.append(end,maturedates[k] + '-ID-%06d.txt'%avaID[k])
326/6:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])
lons = []
lats = []
for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    lons.append(np.array(Clon[k][:loc+1]))
    lats.append(np.array(Clat[k][:loc+1]))
    
    SLPminid = np.append(SLPminid,loc)
326/7: lons
326/8: import pandas as pd
326/9: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
326/10: df = df.loc[df['ntraj075']>=200]
326/11: ids = df['ID'].values
326/12:
avaID = np.array([])
maturedates = np.array([])
SLPminid = np.array([])
end = np.array([])
lons = []
lats = []
for k in range(len(ID)):
    if np.all(ids!=ID[k][0]):
        continue
    avaID=np.append(avaID,ID[k][0].astype(int))
    loc = np.where(hourstoSLPmin[k]==0)[0][0]
    lons.append(np.array(Clon[k][:loc+1]))
    lats.append(np.array(Clat[k][:loc+1]))
    
    SLPminid = np.append(SLPminid,loc)
326/13: f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
326/14: data = pickle.load(f)
326/15: f.close()
326/16: dipv = data['dipv']
326/17:
dfv = pd.DataFrame(colums=['cycper','envper','advper','v'])
cy = np.array([])
env = np.array([])
adv = np.array([])
v = np.array([])
for k in dipv.keys():
    if np.all(avaID!=int(k)):
        continue
    i = np.where(avaID==int(k))[0][0]
    if len(lons[i])<3:
        continue
    v = np.append(v,np.sqrt((lons[1:]-lons[:-1])**2 + (lats[1:]-lats[:-1])**2))
    cy = np.append(cy,np.mean(dipv[k]['cyc'][:,0]/data['rawdata'][k]['PV'][:,0]))
    env = np.append(env,np.mean(dipv[k]['env'][:,0]/data['rawdata'][k]['PV'][:,0]))
    adv = np.append(adv, np.mean(data['rawdata'][k]['PV'][:,-1]/data['rawdata'][k]['PV'][:,0]))
326/18:
dfv = pd.DataFrame(columns=['cycper','envper','advper','v'])
cy = np.array([])
env = np.array([])
adv = np.array([])
v = np.array([])
for k in dipv.keys():
    if np.all(avaID!=int(k)):
        continue
    i = np.where(avaID==int(k))[0][0]
    if len(lons[i])<3:
        continue
    v = np.append(v,np.sqrt((lons[1:]-lons[:-1])**2 + (lats[1:]-lats[:-1])**2))
    cy = np.append(cy,np.mean(dipv[k]['cyc'][:,0]/data['rawdata'][k]['PV'][:,0]))
    env = np.append(env,np.mean(dipv[k]['env'][:,0]/data['rawdata'][k]['PV'][:,0]))
    adv = np.append(adv, np.mean(data['rawdata'][k]['PV'][:,-1]/data['rawdata'][k]['PV'][:,0]))
326/19:
dfv = pd.DataFrame(columns=['cycper','envper','advper','v'])
cy = np.array([])
env = np.array([])
adv = np.array([])
v = np.array([])
for k in dipv.keys():
    if np.all(avaID!=int(k)):
        continue
    i = np.where(avaID==int(k))[0][0]
    if len(lons[i])<3:
        continue
    v = np.append(v,np.sqrt((np.array(lons[1:])-np.array(lons[:-1]))**2 + (np.array(lats[1:])-np.array(lats[:-1]))**2))
    cy = np.append(cy,np.mean(dipv[k]['cyc'][:,0]/data['rawdata'][k]['PV'][:,0]))
    env = np.append(env,np.mean(dipv[k]['env'][:,0]/data['rawdata'][k]['PV'][:,0]))
    adv = np.append(adv, np.mean(data['rawdata'][k]['PV'][:,-1]/data['rawdata'][k]['PV'][:,0]))
326/20:
dfv = pd.DataFrame(columns=['cycper','envper','advper','v'])
cy = np.array([])
env = np.array([])
adv = np.array([])
v = np.array([])
for k in dipv.keys():
    if np.all(avaID!=int(k)):
        continue
    i = np.where(avaID==int(k))[0][0]
    if len(lons[i])<3:
        continue
    v = np.append(v,np.sqrt((np.array(lons[i][1:])-np.array(lons[i][:-1]))**2 + (np.array(lats[i][1:])-np.array(lats[i][:-1]))**2))
    cy = np.append(cy,np.mean(dipv[k]['cyc'][:,0]/data['rawdata'][k]['PV'][:,0]))
    env = np.append(env,np.mean(dipv[k]['env'][:,0]/data['rawdata'][k]['PV'][:,0]))
    adv = np.append(adv, np.mean(data['rawdata'][k]['PV'][:,-1]/data['rawdata'][k]['PV'][:,0]))
326/21: dfv['cycper'] = cy
326/22: dfv['envper'] = env
326/23: dfv['advper'] = adv
326/24: dfv['v'] = v
326/25: v
326/26: len(v)
326/27:
dfv = pd.DataFrame(columns=['cycper','envper','advper','v'])
cy = np.array([])
env = np.array([])
adv = np.array([])
v = np.array([])
for k in dipv.keys():
    if np.all(avaID!=int(k)):
        continue
    i = np.where(avaID==int(k))[0][0]
    if len(lons[i])<3:
        continue
    v = np.append(v,np.mean(np.sqrt((np.array(lons[i][1:])-np.array(lons[i][:-1]))**2 + (np.array(lats[i][1:])-np.array(lats[i][:-1]))**2)))
    cy = np.append(cy,np.mean(dipv[k]['cyc'][:,0]/data['rawdata'][k]['PV'][:,0]))
    env = np.append(env,np.mean(dipv[k]['env'][:,0]/data['rawdata'][k]['PV'][:,0]))
    adv = np.append(adv, np.mean(data['rawdata'][k]['PV'][:,-1]/data['rawdata'][k]['PV'][:,0]))
326/28: dfv['v'] = v
326/29: dfv['advper'] = adv
326/30: dfv['envper'] = env
326/31: dfv['cycper'] = cy
326/32: dfv
326/33: from scipy.stats import pearsonr
326/34: pearsonr(cycper,v)
326/35: pearsonr(dfv['cycper'],v)
326/36: pearsonr(dfv['env'],v)
326/37: pearsonr(dfv['envper'],v)
326/38: pearsonr(dfv['advper'],v)
326/39: %save -r /atmosdyn2/ascherrmann/scripts/ERA5-utils/test-for-velocity-correlation.py 1-999
327/1:
import numpy as np
import pickle
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import matplotlib.gridspec as gridspec
import cartopy.crs as ccrs


f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
dipv = data['dipv']

df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
df = df.loc[df['ntraj075']>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)


sid = np.array([])
counter = np.zeros((361,721))
counter2 = np.zeros((361,721))

for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    counter[La,Lo]+=1
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)

steps = [[0,0],[0,1],[1,0],[1,1]]
for l in range(0,361):
    for a in range(0,721):
        tmp=[]
        for z,s in steps:
            tmp.append(np.sum(counter[l-1+z:l+z+2,a+s-1:a+s+2]))
        counter2[l,a] = np.mean(tmp)
327/2:
col = df.columns
dfo = pd.DataFrame(columns=col)
for ids in sid:
    dfo = dfo.append(df.loc[df['ID']==int(ids)])
327/3: dfo
327/4: dfo['minSLP'].describe()
327/5: dfo['htminSLP'].describe()
327/6: dfo['htminSLP'].values
327/7: dfo['htminSLP'].values[54]
327/8: from scipy.stats import pearsonr
327/9: pearsonr(dfo['minSLP'].values,dfo['htminSLP'].values)
327/10: len(np.where(dfo['htminSLP'].values==0)[0])
327/11: dfo['htminSLP'].values.describe()
328/1:
import numpy as np
import pickle
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import matplotlib.gridspec as gridspec
import cartopy.crs as ccrs


f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
dipv = data['dipv']

df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
df = df.loc[df['ntraj075']>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)


sid = np.array([])
counter = np.zeros((361,721))
counter2 = np.zeros((361,721))

for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    counter[La,Lo]+=1
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)

steps = [[0,0],[0,1],[1,0],[1,1]]
for l in range(0,361):
    for a in range(0,721):
        tmp=[]
        for z,s in steps:
            tmp.append(np.sum(counter[l-1+z:l+z+2,a+s-1:a+s+2]))
        counter2[l,a] = np.mean(tmp)
328/2:
col = df.columns
dfo = pd.DataFrame(columns=col)
for ids in sid:
    dfo = dfo.append(df.loc[df['ID']==int(ids)])
328/3: dfo['sumPV']
328/4: dfo['PVsum']
328/5: dfo['PVsum'].describe()
328/6: dfo['PV075sum'].describe()
328/7: df['PVsum'].describe()
328/8: df['PV075sum'].describe()
329/1:
import numpy as np
import pickle
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt
import cartopy
import matplotlib.gridspec as gridspec
import cartopy.crs as ccrs


f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
dipv = data['dipv']

df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
df = df.loc[df['ntraj075']>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]
    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
        poroid = np.append(poroid,k)


sid = np.array([])
counter = np.zeros((361,721))
counter2 = np.zeros((361,721))

for pi in poroid:
    pl = np.where(int(pi)==ID)[0][0]
    lo = df['lon'].values[pl]
    la = df['lat'].values[pl]
    Lo = np.where(LON==lo)[0][0]
    La = np.where(LAT==la)[0][0]
    counter[La,Lo]+=1
    if OL[La,Lo]==0:
        sid = np.append(sid,pi)

steps = [[0,0],[0,1],[1,0],[1,1]]
for l in range(0,361):
    for a in range(0,721):
        tmp=[]
        for z,s in steps:
            tmp.append(np.sum(counter[l-1+z:l+z+2,a+s-1:a+s+2]))
        counter2[l,a] = np.mean(tmp)
329/2:
col = df.columns
dfo = pd.DataFrame(columns=col)
for ids in sid:
    dfo = dfo.append(df.loc[df['ID']==int(ids)])
329/3: dfo
329/4: dfo['date'].values[54]
329/5: dfo['htminSLP'].values[54]
329/6: np.where(dfo['ID'].values=='119896')
329/7: poroid
329/8: np.where(poroid=='119896')
329/9: dfo['ID'].values
329/10: np.where(dfo['ID'].values==119896)
329/11: dfo['PVsum'].values[63]
329/12: dfo['PV075sum'].values[63]
329/13: dfo['PV075sum'].values[54]
329/14: dfo['PVsum'].values[54]
330/1: import numpy as np
330/2: import xarray as xr
330/3: from scipy.misc import derivative
330/4: data = xr.open_dataset('small-dom-mean-jet-left-enter-200hPa-2PVU-1000km')
330/5: rho= data['RHO_REF']
330/6: TH = data['THETA_REF']
330/7: z = data['Z_REF']
330/8: dz = z[1]-z[0]
330/9: z = data['Z_REF'].values
330/10: dz = z[1]-z[0]
330/11: z
330/12: np.flatten(z)
330/13: z = flatten(z)
330/14: z = z.flatten()
330/15: z
330/16: TH = TH.flatten()
330/17: TH
330/18: TH = TH.values.flatten()
330/19: TH
330/20: rho = rho.values.flatten()
330/21: dz
330/22: dz = z[1]-z[0]
330/23: dz
330/24: z
330/25: z = z[::2]
330/26: TH= TH[::2]
330/27: rho = rho[::2]
330/28: dz = z[1]-z[0]
330/29: dz
330/30: np.gradient(TH)
330/31: data.keys()
330/32:
PV = np.zeros(data['QGPV'].values.shape)
for k in range(data['QGPV'].values.shape[1]):
    for j in range(data['QGPV'].values.shape[2]):
        PV[:,k,j] = 1/rho * np.gradient(data['TH'][:,k,j]) * data['QGPV'][:,k,j]
330/33: np.gradient(TH)
330/34: np.gradient(TH).shape
330/35: rho.shape
330/36: k
330/37: j
330/38: data['QGPV'].values.shape
330/39:
PV = np.zeros(data['QGPV'].values.shape)
for k in range(data['QGPV'].values.shape[2]):
    for j in range(data['QGPV'].values.shape[3]):
        PV[0,:,k,j] = 1/rho * np.gradient(data['TH'].values[0,:,k,j]) * data['QGPV'].values[0,:,k,j]
330/40: PV
330/41: np.where(data['QGPV'].values==np.max(data['QGPV'].values))
330/42: data['QGPV'].values[0,58,61,47]
330/43: data['QGPV'].values[0,58,61,47] /rho[58] * np.gradient(data['TH'].values[0,:,61,47])[58]
330/44: rho[58]
330/45: data['QGPV'].values[0,58,61,47] /rho[58] * np.gradient(data['TH'].values[0,:,61,47])[58] *1e-3
330/46: data['QGPV'].values[0,58,61,47] /rho[58] * np.gradient(TH + data['TH'].values[0,:,61,47])[58]
330/47: data['QGPV'].values[0,58,61,47] /rho[58] * np.gradient(TH + data['TH'].values[0,:,61,47],z)[58]
330/48: p0 = data['P_REF'].values[::2]
330/49: p0 = data['PRE_REF'].values[::2]
330/50: T0 = data['T_REF'].values[::2]
330/51: P = data['P'].values
330/52: T = data['T'].values
330/53: data['QGPV'].values[0,58,61,47] /(rho[58]*(1 + P[0,58,61,47]/p0[58]-T[0,58,61,47]/T0[58])) * np.gradient(TH + data['TH'].values[0,:,61,47],z)[58]
330/54: P.shape
330/55: T.shape
330/56: T0
330/57: T0 = data['T_REF'].flatten()[::2]
330/58: T0 = data['T_REF'].values.flatten()[::2]
330/59: p0 = data['PRE_REF'].values.flatten()[::2]
330/60: data['QGPV'].values[0,58,61,47] /(rho[58]*(1 + P[0,58,61,47]/p0[58]-T[0,58,61,47]/T0[58])) * np.gradient(TH + data['TH'].values[0,:,61,47],z)[58]
330/61: data['QGPV'].values[0,58,61,47] /(rho[58]*(1 + P[0,58,61,47]/p0[58]-T[0,58,61,47]/T0[58])) * np.gradient(TH + data['TH'].values[0,:,61,47])[58]
330/62: data['QGPV'].values[0,58,61,47] /(rho[58]*(1 + P[0,58,61,47]/p0[58]-T[0,58,61,47]/T0[58])) * np.gradient(TH + data['TH'].values[0,:,61,47],z)[58]
330/63:
PV = np.zeros(data['QGPV'].values.shape)
for k in range(data['QGPV'].values.shape[2]):
    for j in range(data['QGPV'].values.shape[3]):
        PV[0,:,k,j] = 1/(rho*(1+ * np.gradient(data['TH'].values[0,:,k,j]) * data['QGPV'].values[0,:,k,j]))
330/64: %save -r /atmosdyn2/ascherrmann/scripts/WRF/pvinv-cart/convert-QGPV-to-PVU.py 1-999
331/1: PV = 2e-6
331/2: f=1e-4
331/3: rho=1.2
331/4: N=0.01
331/5: TH=300
331/6: PV * N/rho/10*TH -f
331/7: PV * rho * 10 /N /TH -f
331/8: PV * 10 * rho / TH /N**2 -f
332/1:
import numpy as np
import xarray as xr
332/2: p = '/atmosdyn2/ascherrmann/scripts/WRF/pvinv-cart/perturbations/'
332/3: ls
332/4: data = xr.open_dataset('checkPVU')
332/5:
rho0= data['RHO_REF'].values.flatten()[::2]
TH0 = data['THETA_REF'].values.flatten()[::2]
332/6:
zref = data['Z_REF'].values.flatten()[::2]
P0 = data['PRE_REF'].values.flatten()[::2]
T0 = data['T_REF'].values.flatten()[::2]
N0 = data['NSQ_REF'].values.flatten()[::2]
332/7:
P = data['P'].values
T = data['T'].values
QGPV = data['QGPV'].values
TH = data['TH'].values
332/8:
dxy = 55.58874 #km
Re = 6370 #km
f0 = 1e-4
phi0 = 10/180*np.pi
g = 9.8066
theta_hat = np.gradient(TH0,P0)
332/9:
dxy = 55.58874 #km
Re = 6370 #km
f0 = 1e-4
phi0 = 10/180*np.pi
g = 9.8066
theta_hat0 = np.gradient(TH0,P0)
332/10:
d = np.ones(QGPV.shape[2])
d[0]=0
d = np.cumsum(d*dxy)
OMEGA = 2 * np.pi/86400
f = 2 * OMEGA * np.sin(phi0 + d/Re)
332/11: f
332/12: f-f0
332/13: np.where(f-f0>0)[0][0]
332/14: z = np.where(zref==8000)[0][0]
332/15: rho[z]
332/16: rho0[z]
332/17: N0[z]
332/18: TH0[z]
332/19: np.sqrt(N0[z])
332/20: g
332/21: (rh0/TH0 * g/N0)[z]
332/22: (rho0/TH0 * g/N0)[z]
332/23: _ * 2
332/24: _ * 2 * 1e-6
332/25: _-f[56]
332/26: z
332/27: N0
332/28: np.sqrt(N0)
332/29: np.sqrt(N0)[z]
332/30: TH0
332/31: TH0[z-5:z+6]
332/32: (rho0[z-5]/TH0[z-5] * g/N0[z])
332/33: _*2e-6-f[56]
332/34: data = xr.open_dataset('checkPVU')
332/35:
rho0= data['RHO_REF'].values.flatten()[::2]
TH0 = data['THETA_REF'].values.flatten()[::2]
332/36:
zref = data['Z_REF'].values.flatten()[::2]
P0 = data['PRE_REF'].values.flatten()[::2]
T0 = data['T_REF'].values.flatten()[::2]
N0 = data['NSQ_REF'].values.flatten()[::2]
332/37: zref
332/38: z
332/39: zref[z]
332/40: rho0[z]
332/41: TH0[z]
332/42: N0[z]
332/43: rho0/TH0*g/N0 [z]
332/44: (rho0/TH0*g/N0)[z]
332/45: rho0[z-5]
332/46: rho0[z-10]
332/47: (rho0/TH0*g/N0)[z] * 2e-6 -f[40]
332/48: (rho0/TH0*g/N0)[z] * 2e-6
332/49: (rho0/TH0*g/N0)[z] * 2e-6 -f0
332/50: (rho0/TH0*g/N0)[z] * 2e-6 -f[30]
332/51: (rho0/TH0*g/N0)[z] * 2e-6 -f[56]
332/52: f[56]
333/1: import numpy as np
333/2: import xarray as xr
333/3: data = xr.open_dataset('ref-mean-small-unpert.nc')
333/4: U = data['UU']
333/5: T = data['TT']
333/6: P = data['PRES']
333/7: PS = data['PSFC']
333/8: data['XLAT']
333/9: LAT = data['XLAT_C']
333/10: LON = data['XLON_C']
333/11: LON = data['XLONG_C']
333/12: lon = lon[50:141]
333/13: lon = LON[50:141]
333/14: lat = LAT[25:81]
333/15:
for z in range(20,27):
    umloc = np.where(U)
    print()
333/16: U.shape
333/17:
kappa = 0.286
print('layer, pressure, Umax, theta, rho')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0],x[0]
    print(z, P[0,z,y,x], U[0,z,y,x], T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa, P[0,z,y,x]/287/T[0,z,y,x])
333/18: LAT
333/19: LON = data['XLONG_C'].values
333/20: LON
333/21: LON = data['XLONG_C'].values[0]
333/22: LAT = data['XLAT_C'].values[:,0]
333/23: P = data['PRES'].values
333/24: PS = data['PSFC'].values
333/25: U = data['UU'].values
333/26: T = data['TT'].values
333/27:
kappa = 0.286
print('layer, pressure, Umax, theta, rho')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0],x[0]
    print(z, P[0,z,y,x], U[0,z,y,x], T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa, P[0,z,y,x]/287/T[0,z,y,x])
333/28:
kappa = 0.286
print('layer, pressure, Umax, theta, rho')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    print(z, P[0,z,y,x], U[0,z,y,x], T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa, P[0,z,y,x]/287/T[0,z,y,x])
333/29: g
333/30: g = 9.0866
333/31: import metpy.calc
333/32: GHT = data['GHT'].values
333/33:
kappa = 0.286
print('layer, pressure, Umax, theta, rho, GHT, Nsquare')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    print(z, P[0,z,y,x], U[0,z,y,x], T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa, P[0,z,y,x]/287/T[0,z,y,x], GHT[0,z,y,x], g/(T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa) * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z])
333/34:
kappa = 0.286
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    print(z, P[0,z,y,x], U[0,z,y,x], T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa, P[0,z,y,x]/287/T[0,z,y,x], GHT[0,z,y,x], g/(T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa) * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z], np.sqrt(g/(T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa) * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z]))
333/35:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z]
    
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/36:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z]
    
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/37: y
333/38: f
333/39: LAT
333/40: LAT = data['XLAT_C'].values[:,0]
333/41: LAT
333/42: LAT = data['XLAT_C'].values[0]
333/43: LAT
333/44: LAT = data['XLAT_C'].values[0,:,0]
333/45: LAT
333/46:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,GHT[0,:,y,x])[z]
    
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/47: f
333/48: f[56]
333/49: z
333/50: GP = GHT * 9.78
333/51: zh = GP * 6370000/(9.78*6370000-GP)
333/52:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/53:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    N2 = 0.015**2
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/54:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    rho = 0.526
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    N2 = 0.015**2
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/55:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    #rho = 0.526
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    #N2 = 0.015**2
    print(z, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
332/53: np.where(abs(TH0-325)==np.min(abs(TH0-325)))
332/54: TH0[25]
332/55: rho0[25]
332/56: z
332/57: rho0[z]
333/56:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, latlevel, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    #rho = 0.526
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    #N2 = 0.015**2
    print(z,y, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
332/58: (rho0[z]/TH0[25]*g/N0[z]) * 2e-6 -f[57]
332/59: (rho0[25]/TH0[25]*g/N0[z]) * 2e-6 -f[57]
332/60: (rho0[25]/TH0[25]*g/0.02**2) * 2e-6 -f[57]
332/61: N0[z]
332/62: N0[z]/0.02**
332/63: N0[z]/0.02**2
332/64: np.sqrt(N0[z])
332/65: 1/(0.02/0.015)**2
332/66: (0.02/0.015)**2
333/57:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, latlevel, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    rho = 0.526
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    #N2 = 0.015**2
    print(z,y, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/58:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, latlevel, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    rho = 0.526
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    N2 = 0.015**2
    print(z,y, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
333/59:
kappa = 0.286
f = 2 * 2 * np.pi/86400 * np.sin(LAT/180*np.pi)
print('layer, latlevel, pressure, Umax, theta, rho, GHT, Nsquare, N, QGPV')
for z in range(20,27):
    y,x = np.where(U[0,z,25:81,50:141] == np.max(U[0,z,25:81,50:141]))
    y,x=y[0]+25,x[0]+50
    TH = T[0,z,y,x] * (PS[0,y,x]/P[0,z,y,x])**kappa
    rho = P[0,z,y,x]/287/T[0,z,y,x]
    rho = 0.6
    N2 = g/TH * np.gradient(T[0,z,y,x] * (PS[0,y,x]/P[0,:,y,x])**kappa,zh[0,:,y,x])[z]
    N2 = 0.015**2
    print(z,y, P[0,z,y,x], U[0,z,y,x], TH, rho, GHT[0,z,y,x], N2, np.sqrt(N2), (rho/TH * g/N2 * 2e-6 - f[y]))
332/67: rho0
332/68: QGPV = np.zeros((len(rho0),len(np.unique(N0)),len(TH0)))
332/69:
for ri,ni,ti,rho, N, THETA in zip(range(QGPV.shape[0]),range(QGPV.shape[1]),range(QGPV.shape[2]),rho0,np.unique(N0),TH0):
    QGPV[ri,ni,ti] = rho * g/THETA/N * 2e-6 - f[56]
332/70: QGPV = np.zeros((len(rho0),len(np.unique(N0)),len(TH0)))
332/71:
for ri, rho in zip(range(QGPV.shape[0]),rho0):
    for ni,N in zip(range(QGPV.shape[1]),np.unique(N0)):
        for ti,THETA in zip(range(QGPV.shape[2]),TH0):
            QGPV[ri,ni,ti] = rho * g/THETA/N * 2e-6 - f[56]
332/72: import matplotlib.pyplot as plt
332/73: fig,ax = plt.subplots()
332/74: QGPV
332/75: QGPV>shape
332/76: QGPV.shape
332/77: plt.close(fig)
332/78: fig,ax = plt.subplots(1,3,hspace=0,wspace=0,sharey=True)
332/79: fig,ax = plt.subplots(1,3,wspace=0,sharey=True)
332/80: fig,ax = plt.subplots(1,3,sharey=True)
332/81: axes = ax.flatten()
332/82: plt.subplots_adjust(wspace=0,hspace=0)
332/83: TH0
332/84: TH0[::10]
332/85: TH0[::7]
332/86: thref = TH0[::7]
332/87: rho0
332/88: rho0[::7]
332/89: rhoref=rho0[::7]
332/90: N
332/91: np.unique(N0)
332/92: nref = np.unique(N0)
332/93: f[56]
332/94: len(nref)
332/95: len(rhoref)
332/96:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink',palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0),7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
332/97:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink',palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0),7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
332/98:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink',palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0),7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
332/99:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b],color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:],color='cl[a])
332/100:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b],color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:],color='cl[a])
332/101:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid']
for q,ax in enumearte(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b],color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:],color=cl[a])
332/102:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid']
for q,ax in enumerate(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b],color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:],color=cl[a])
332/103: a
332/104: len(cl)
332/105:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid','darkseagreen','mediumpurple']
for q,ax in enumerate(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b],color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b],color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:],color=cl[a])
332/106: plt.show()
332/107: plt.close(fig)
332/108: fig,ax = plt.subplots(1,3,sharey=True)
332/109: axes = ax.flatten()
332/110:
cl = ['k','r','b','g','yellow','orange','grey','dodgerblue','purple','cyan','saddlebrown','gold','powderblue','slategray','lightgreen','olive','lightcoral','pink','palevioletred','orchid','darkorchid','darkseagreen','mediumpurple']
for q,ax in enumerate(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b]/1e-4,color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b]/1e-4,color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:]/1e-4,color=cl[a])
332/111: rho0
332/112: plt.show()
332/113: q
332/114: len(axes)
332/115: plt.close(fig)
332/116: fig,ax = plt.subplots(1,3,sharey=True)
332/117: plt.subplots_adjust(wspace=0,hspace=0)
332/118: rho0
332/119:
for q,ax in enumerate(axes[:1]):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b]/1e-4,color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b]/1e-4,color=cl[a])
    else:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:]/1e-4,color=cl[a])
332/120: plt.show()
332/121: plt.close(fig)
332/122: plt.close('all')
332/123: fig,ax = plt.subplots(1,3,sharey=True)
332/124: plt.subplots_adjust(wspace=0,hspace=0)
332/125:
for q,ax in enumerate(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b]/1e-4,color=cl[a])
            
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b]/1e-4,color=cl[a])
    if q==3:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:]/1e-4,color=cl[a])
332/126: plt.show()
332/127: plt.close('all')
332/128: fig,ax = plt.subplots(1,3,sharey=True)
332/129: plt.close(fig)
332/130: fig,axes = plt.subplots(1,3,sharey=True)
332/131: axes = axes.flatten()
332/132:
for q,ax in enumerate(axes):
    if q==1:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b]/1e-4,color=cl[a])
    if q==2:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b]/1e-4,color=cl[a])
    if q==3:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:]/1e-4,color=cl[a])
332/133: plt.show()
332/134: plt.close()
332/135: plt.close(fig)
332/136: fig,axes = plt.subplots(1,3,sharey=True)
332/137: axes = axes.flatten()
332/138: plt.subplots_adjust(wspace=0,hspace=0)
332/139:
for q,ax in enumerate(axes):
    if q==0:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(rho0,QGPV[:,a,b]/1e-4,color=cl[a])
    if q==1:
        for a,b in zip(range(len(np.arange(0,len(TH0),7))),np.arange(0,len(TH0),7)):
            ax.plot(nref,QGPV[b,:,b]/1e-4,color=cl[a])
    if q==2:
        for a,b in zip(range(len(nref)),np.arange(0,len(TH0)-21,7)):
            ax.plot(TH0,QGPV[b,a,:]/1e-4,color=cl[a])
332/140: axes[0].invert_xaxis()
332/141: plt.show()
333/60: %save -r /atmosdyn2/ascherrmann/scripts/WRF/pvinv-cart/what-ever-i-did-here.py 1-999
336/1:
import numpy as np
import netCDF4
import argparse
import cartopy
import matplotlib.gridspec as gridspec
import cartopy.crs as ccrs

import matplotlib.pyplot as plt
import matplotlib
import wrf

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
336/2: d = '20051207_00'
336/3:
pl = '/atmosdyn/era5/cdf/'+ d[:4] + '/' + d[4:6] + '/'
ps = '/atmosdyn2/ascherrmann/012-WRF-cyclones/'

PVlvl = np.arange(-2,2.1,0.25)
THlvl = np.arange(-20,20.1,2)
GHTlvl = np.arange(-300,300.1,50)

cmap = matplotlib.cm.BrBG
norm = plt.Normalize(np.min(PVlvl),np.max(PVlvl))
ticklabels=PVlvl

### wrf reference data
data = netCDF4.Dataset('/atmosdyn2/ascherrmann/scripts/WRF/wrf-mean-reference')
PVwrf = wrf.getvar(data,'pvo') #in PVU already
lonwrf = wrf.getvar(data,'XLONG')[0]-0.25
latwrf = wrf.getvar(data,'XLAT')[:,0]-0.25
336/4: lonwrf
336/5: lonwrf.values
337/1:
import numpy as np
import netCDF4
import argparse
import cartopy
import matplotlib.gridspec as gridspec
import cartopy.crs as ccrs

import matplotlib.pyplot as plt
import matplotlib
import wrf

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
337/2: d = '20051207_00'
337/3:
pl = '/atmosdyn/era5/cdf/'+ d[:4] + '/' + d[4:6] + '/'
ps = '/atmosdyn2/ascherrmann/012-WRF-cyclones/'

PVlvl = np.arange(-2,2.1,0.25)
THlvl = np.arange(-20,20.1,2)
GHTlvl = np.arange(-300,300.1,50)

cmap = matplotlib.cm.BrBG
norm = plt.Normalize(np.min(PVlvl),np.max(PVlvl))
ticklabels=PVlvl

### wrf reference data
data = netCDF4.Dataset('/atmosdyn2/ascherrmann/scripts/WRF/wrf-mean-reference')
PVwrf = wrf.getvar(data,'pvo',meta=False) #in PVU already
lonwrf = wrf.getvar(data,'lon',meta=False)[0]-0.25
latwrf = wrf.getvar(data,'lat',meta=False)[:,0]-0.25


THwrf = wrf.getvar(data,'T',meta=False) + 300
GHTwrf = wrf.getvar(data,'geopotential',meta=False)/9.81
Pwrf = wrf.getvar(data,'pressure',meta=False)
337/4: Pwrf
337/5:
f = pl + 'S' + d

lon = readcdf(f,'lon')
lat = readcdf(f,'lat')

loi = np.where((lon>=np.min(lonwrf)) & (lon<=np.max(lonwrf)))[0]
lai = np.where((lat>=np.min(latwrf)) & (lat<=np.max(latwrf)))[0]
337/6: loi
337/7: PV = readcdf(f,'PV')[0,:,lai,loi]
337/8: PV = readcdf(f,'PV')
337/9: PV
337/10: PV.shape
337/11: PV[0].shape
337/12: PV[0,:,lai]
337/13: PV[0,:,lai].shape
337/14: PV[0,:,lai,loi].shape
337/15: PV[0,:,lai].shape
337/16: PV[0,:,lai][:,:,loi]
337/17: PV[0,:,lai][:,:,loi].shape
338/1:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.cm import get_cmap
from netCDF4 import Dataset
import matplotlib
from matplotlib.colors import ListedColormap, BoundaryNorm
from wrf import (getvar, to_np, vertcross, smooth2d, CoordPair,
                 get_basemap, latlon_coords)

import argparse
338/2:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
338/3:
from dypy.intergrid import Intergrid
import matplotlib.colors as col
import matplotlib.cm as cm
from mpl_toolkits.basemap import Basemap
import numpy as np
import netCDF4
from netCDF4 import Dataset as ncFile
from dypy.small_tools import interpolate
from dypy.lagranto import Tra
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib
import cartopy
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from matplotlib.gridspec import GridSpec
from matplotlib.colors import from_levels_and_colors

import datetime as dt
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
338/4:
lon_start = -65
lon_end   = -65
lat_start = 10
lat_end   = 80

dis = (lat_end-lat_start)/360 * 2 * np.pi * 6370
338/5:
ps=readcdf(pfile,'PS')
T=readcdf(pfile,'T')
U=readcdf(pfile,'U')
V=readcdf(pfile,'V')
#PV=readcdf('S' + pfile[1:],'PV')
Z=readcdf('H' + pfile[1:],'Z')
Z/=9.81
338/6:
Z=readcdf('H' + pfile[1:],'Z')
Z/=9.81
338/7: pfile = 'P20010115_00'
338/8:
ps=readcdf(pfile,'PS')
T=readcdf(pfile,'T')
U=readcdf(pfile,'U')
V=readcdf(pfile,'V')
#PV=readcdf('S' + pfile[1:],'PV')
Z=readcdf('H' + pfile[1:],'Z')
Z/=9.81
pv=T
338/9:
lons=readcdf(pfile,'lon')
lats=readcdf(pfile,'lat')
hyam=readcdf(pfile,'hyam')  # 137 levels  #für G-file ohne levels bis
hybm=readcdf(pfile,'hybm')  #   ''
ak=hyam[hyam.shape[0]-pv.shape[1]:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-pv.shape[1]:]
338/10: ds = 5.
338/11:
mvcross    = Basemap()
line,      = mvcross.drawgreatcircle(lon_start, lat_start, lon_end, lat_end, del_s=ds)
path       = line.get_path()
lonp, latp = mvcross(path.vertices[:,0], path.vertices[:,1], inverse=True)
dimpath    = len(lonp)

# calculate pressure on model levels
p3d=np.full((pv.shape[1],pv.shape[2],pv.shape[3]),-999.99)
ps3d=np.tile(ps[0,:,:],(pv.shape[1],1,1)) # write/repete ps to each level of dim 0
p3d=(ak/100.+bk*ps3d.T).T
unit_p3d = 'hPa'
338/12:
vcross = np.zeros(shape=(pv.shape[1],dimpath)) #PV
vcross_T = np.zeros(shape=(T.shape[1],dimpath))
vcross_U= np.zeros(shape=(T.shape[1],dimpath))
vcross_V= np.zeros(shape=(T.shape[1],dimpath))
vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
#vcross_PV = np.zeros(shape=(T.shape[1],dimpath))
#vcross_TH = np.zeros(shape=(T.shape[1],dimpath))

bottomleft = np.array([lats[0], lons[0]])
topright   = np.array([lats[-1], lons[-1]])

vcross_Z = np.zeros(shape=(Z.shape[1],dimpath))
vcross_pZ = np.zeros(shape=(Z.shape[1],dimpath))
pH = readcdf('H' + pfile[1:],'plev')
338/13:
for k in range(pv.shape[1]):
    f_vcross     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_T   = Intergrid(T[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_U = Intergrid(U[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_V = Intergrid(V[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    for i in range(dimpath):
        vcross[k,i]     = f_vcross.at([latp[i],lonp[i]])
        vcross_T[k,i]   = f_vcross_T.at([latp[i],lonp[i]])
        vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
        vcross_U[k,i]   = f_vcross_U.at([latp[i],lonp[i]])
        vcross_V[k,i]   = f_vcross_V.at([latp[i],lonp[i]])
338/14:
for k in range(Z.shape[1]):
    f_vcross_Z = Intergrid(Z[0,k,:,:],lo=bottomleft, hi=topright, verbose=0)

    for i in range(dimpath):
        vcross_Z[k,i] =f_vcross_Z.at([latp[i],lonp[i]])
        vcross_pZ[k,i] = pH[k]
338/15:
xcoord = np.zeros(shape=(pv.shape[1],dimpath))
for x in range(pv.shape[1]):
    xcoord[x,:] = np.array([ i*ds-dis for i in range(dimpath) ])

xcoordZ = np.zeros(shape=(Z.shape[1],dimpath))
for x in range(Z.shape[1]):
    xcoordZ[x,:] = np.array([ i*ds-dis for i in range(dimpath) ])
338/16: xcoord.shape
338/17: vcross_p.shape
338/18: vcross_U.shape
338/19: vcross_p[-1,:]
338/20: vcross_p[0,:]
338/21: vcross_p[40,:]
338/22: vcross_p[35,:]
338/23: vcross_p[32,:]
338/24: vcross_p[33,:]
338/25: vcross_p[34,:]
338/26: np.max(vcross_p[34,:])
338/27: vcross_u.shape
338/28: vcross_U.shape
338/29: np.std(vcross_p[34])
338/30: data = netCDF4.Dataset('/atmosdyn2/ascherrmann/scripts/WRF/wrf-mean-reference')
338/31:
PVwrf = wrf.getvar(data,'pvo',meta=False) #in PVU already
lonwrf = wrf.getvar(data,'lon',meta=False)[0]-0.25
latwrf = wrf.getvar(data,'lat',meta=False)[:,0]-0.25


THwrf = wrf.getvar(data,'T',meta=False) + 300
GHTwrf = wrf.getvar(data,'geopotential',meta=False)/9.81
Pwrf = wrf.getvar(data,'pressure',meta=False)
338/32: import wrf
338/33:
PVwrf = wrf.getvar(data,'pvo',meta=False) #in PVU already
lonwrf = wrf.getvar(data,'lon',meta=False)[0]-0.25
latwrf = wrf.getvar(data,'lat',meta=False)[:,0]-0.25


THwrf = wrf.getvar(data,'T',meta=False) + 300
GHTwrf = wrf.getvar(data,'geopotential',meta=False)/9.81
Pwrf = wrf.getvar(data,'pressure',meta=False)
338/34: Pwrf.shape
338/35: np.std(Pwrf[0])
338/36: np.std(Pwrf[32])
338/37: Pwrf[32]
338/38: np.std(Pwrf[1])
338/39: np.std(Pwrf[2])
338/40: np.std(Pwrf[10])
338/41:
linew,      = mvcross.drawgreatcircle(lon_start, lat_start, lon_end, lat_end, del_s=ds)
pathw       = line.get_path()
lonpw, latpw = mvcross(pathw.vertices[:,0], pathw.vertices[:,1], inverse=True)
dimpathw    = len(lonpw)
338/42: p3dw = Pwrf
338/43: pv.shape[0]
338/44: pv.shape[1]
338/45: vcrossw = np.zeros(shape=(Pwrf.shape[0],dimpathw))
338/46:
bottomleft = np.array([latw[0], lonw[0]])
topright   = np.array([latw[-1], lonw[-1]])
338/47:
bottomleft = np.array([latwrf[0], lonwrf[0]])
topright   = np.array([latwrf[-1], lonwrf[-1]])
338/48: for k in range(Pwrf.shape[0]):f_vcross     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
338/49: for k in range(Pwrf.shape[0]):f_vcross     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
338/50:
vcross_p = np.zeros(shape=(Pwrf.shape[0],dimpathw))
for k in range(Pwrf.shape[0]):
    f_vcrossw     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_p3d_vcrossw = Intergrid(p3dw[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    for i in range(dimpath):
        vcross[k,i]     = f_vcross.at([latpw[i],lonpw[i]])
        vcross_p[k,i]   =f_p3d_vcrossw.at([latpw[i],lonpw[i]])
338/51:
vcross_p = np.zeros(shape=(Pwrf.shape[0],dimpathw))
for k in range(Pwrf.shape[0]):
    f_vcrossw     = Intergrid(PVwrf[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_p3d_vcrossw = Intergrid(p3dw[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    for i in range(dimpath):
        vcross[k,i]     = f_vcross.at([latpw[i],lonpw[i]])
        vcross_p[k,i]   =f_p3d_vcrossw.at([latpw[i],lonpw[i]])
338/52:
xcoordw = np.zeros(shape=(Pwrf.shape[0],dimpath))
for x in range(pv.shape[1]):
    xcoordw[x,:] = np.array([ i*ds-dis for i in range(dimpath) ])
338/53:
xcoordw = np.zeros(shape=(Pwrf.shape[0],dimpath))
for x in range(Pwrf.shape[0]):
    xcoordw[x,:] = np.array([ i*ds-dis for i in range(dimpath) ])
338/54: xcoordw.shape
338/55: fig,ax = plt.subplots(1,2,sharey=True)
338/56:
cmap,pv_levels,norm,ticklabels=PV_cmap2()
levels=pv_levels
338/57: ax[1].contourf(xcoordw,vcross_pm,vcross,levels=levels,cmap,cmap,norm=norm,extend='both')
338/58: levels
338/59: vcross.shape
338/60:
vcross = np.zeros(shape=(pv.shape[1],dimpath)) #PV
vcross_T = np.zeros(shape=(T.shape[1],dimpath))
vcross_U= np.zeros(shape=(T.shape[1],dimpath))
vcross_V= np.zeros(shape=(T.shape[1],dimpath))
vcross_p  = np.zeros(shape=(p3d.shape[0],dimpath)) #pressure
#vcross_PV = np.zeros(shape=(T.shape[1],dimpath))
#vcross_TH = np.zeros(shape=(T.shape[1],dimpath))

bottomleft = np.array([lats[0], lons[0]])
topright   = np.array([lats[-1], lons[-1]])

vcross_Z = np.zeros(shape=(Z.shape[1],dimpath))
vcross_pZ = np.zeros(shape=(Z.shape[1],dimpath))
pH = readcdf('H' + pfile[1:],'plev')

for k in range(pv.shape[1]):
    f_vcross     = Intergrid(pv[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_T   = Intergrid(T[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_U = Intergrid(U[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_vcross_V = Intergrid(V[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#    f_vcross_PV = Intergrid(PV[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
#    f_vcross_TH = Intergrid(TH[0,k,:,:], lo=bottomleft, hi=topright, verbose=0)
    f_p3d_vcross   = Intergrid(p3d[k,:,:], lo=bottomleft, hi=topright, verbose=0)
    for i in range(dimpath):
        vcross[k,i]     = f_vcross.at([latp[i],lonp[i]])
        vcross_T[k,i]   = f_vcross_T.at([latp[i],lonp[i]])
        vcross_p[k,i]   = f_p3d_vcross.at([latp[i],lonp[i]])
        vcross_U[k,i]   = f_vcross_U.at([latp[i],lonp[i]])
        vcross_V[k,i]   = f_vcross_V.at([latp[i],lonp[i]])
#        vcross_PV[k,i] = f_vcross_PV.at([latp[i],lonp[i]])
#        vcross_TH[k,i] = f_vcross_TH.at([latp[i],lonp[i]])

for k in range(Z.shape[1]):
    f_vcross_Z = Intergrid(Z[0,k,:,:],lo=bottomleft, hi=topright, verbose=0)

    for i in range(dimpath):
        vcross_Z[k,i] =f_vcross_Z.at([latp[i],lonp[i]])
        vcross_pZ[k,i] = pH[k]
338/61:
xcoord = np.zeros(shape=(pv.shape[1],dimpath))
for x in range(pv.shape[1]):
    xcoord[x,:] = np.array([ i*ds-dis for i in range(dimpath) ])
338/62: %save -r /atmosdyn2/ascherrmann/scripts/WRF/vcross-wrf-compare.py 1-999
339/1: import netCDF4
339/2: import numpy as np
339/3:
def readcdf(ncfile,varnam):
    infile = netCDF4.Dataset(ncfile, mode='r')
    var = infile.variables[varnam][:]
    return(var)
339/4:
LON = np.linspace(-180,179.5,720)
LAT = np.linspace(-90,90,361)
339/5:
roi = [-150,80,10,80]
xi, yi = np.where((LON>=roi[0]) & (LON<=roi[1]))[0], np.where((LAT>=roi[2]) & (LAT<=roi[3]))[0]
339/6: xi
339/7: x0,x1,y0,y1 = xi[0],xi[-1],yi[0],yi[-1]
339/8: p = '/atmosdyn2/era5/cdf/2020/10/'
339/9: p = '/atmosdyn2/era5/cdf/2020/10/P20201010_10'
339/10: P = netCDF4.Dataset(p)
339/11: U=P.variables['U'][:]
339/12: U.shape
339/13: U=P.variables['U'][0,:]
339/14: U.shape
339/15: U[:,y0:y1+1,x0:x1+1]
339/16: U[:,y0:y1+1,x0:x1+1].shape
339/17: U=P.variables['U'][0,:,y0:y1+1,x0:x1+1]
339/18: U.shape
339/19: U = readcdf(p,'U')[0,:,y0:y1+1,x0:x1+1]
339/20: U.shape
340/1: T,U,V,GHT,RH,TH,P,PS,MSL,SSTK,U10M,V10M,D2M,T2M =0
340/2: T,U,V,GHT,RH,TH,P,PS,MSL,SSTK,U10M,V10M,D2M,T2M = 0,0,0,0,0,0,0,0,0,0,0
340/3: T,U,V,GHT,RH,TH,P,PS,MSL,SSTK,U10M,V10M,D2M,T2M = 0,0,0,0,0,0,0,0,0,0,0,0,0,0
340/4: t = 'T'
340/5: atr(t)
341/1: import pickle
341/2: d = open('19790101_00.txt','rb')
341/3: f = pickle.load(d)
341/4: d.close()
341/5: d.keys()
341/6: f.keys()
341/7: d['2D'].keys()
341/8: d['2D']['PS']
341/9: f['2D'].keys()
341/10: f['2D']['PS']
341/11: f['2D']['PS'].shape
341/12: f['2D']['SSTK'].shape
341/13: f['2D']['SSTK']
341/14: f['isentropes']
341/15: f['isentropes'].keys()
341/16: f['isentropes']['TH']
341/17: f['isentropes']['Z']
341/18: f['isentropes']['Z'].shape
342/1: import numpy as np
342/2: import pickle
342/3: f = open('19861225_00.txt','rb')
342/4: d = pickle.load(f)
342/5: f.close()
342/6: d['isentropes']['TH']
342/7: I = 'isentropes'
342/8: d[I]['P'].shape
342/9: np.mean(d[I]['P'][48])
342/10: np.mean(d[I]['P'][38])
342/11: d[I]['TH'][38]
342/12: d[I]['TH'][32]
342/13: d[I]['TH'][32]
342/14: np.mean(d[I]['P'][32])
342/15: d[I]['P'][32]
342/16: d[I]['P'][23]
342/17: d[I]['P'][10]
342/18: np.max(d[I]['P'][10])
342/19: np.max(d[I]['P'][32])
342/20: d[I].keys()
342/21: list(d[I].keys())
342/22: x,y,z = np.where(d[I]['P']>1075)
342/23: x
342/24: y
342/25: z
342/26: d[I]['P'][x,y,z]
342/27: d[I]['P'][x,y,z].shape
342/28: d[I]['P'][d[I]['P']>1075]=np.nan
342/29: d[I]['P'].shape
342/30: np.max(d[I]['P'][23])
342/31: np.max(d[I]['P'][10])
342/32: np.max(d[I]['P'][9])
342/33: np.max(d[I]['P'][20])
342/34: np.max(d[I]['P'][19])
342/35: np.max(d[I]['P'][15])
342/36: np.max(d[I]['P'][12])
342/37: np.max(d[I]['P'][13])
342/38: np.max(d[I]['P'][14])
342/39: np.nan>1000
342/40: np.max(np.nan,1000)
342/41: np.max((np.nan,1000))
342/42: np.min((np.nan,1000))
342/43: TH = d[I]['TH']
342/44: TH[10]
342/45: TH[15]
342/46: import netCDF4
342/47: S = netCDF4.Dataset('/atmosdyn/era5/cdf/1986/12/S19861225_00')
342/48: Pf = netCDF4.Dataset('/atmosdyn/era5/cdf/1986/12/P19861225_00')
342/49: ths = S.variables['TH'][:]
342/50: ths.shape
342/51: ths = S.variables['TH'][0]
342/52: LAT = np.linspace(-90,90,361)
342/53: LAT[201]
342/54: LAT[200]
342/55: LAT[340]-LAT[200]
342/56: ths = ths[:,200:341,60:521]
342/57: ths.shape
342/58: LON = np.linspace(-180,179.5,720)
342/59: LON[60:521]
342/60: Pf
342/61: us = Pf.variables['U'][0,:,200:341,60:521]
342/62: us.shape
342/63: import wrf
342/64: u330 = wrf.interplevel(us,ths,330,meta=False)
342/65: u330
342/66: u330.shape
342/67: TH[15]
342/68: TH[14]
342/69: U330 = d[I]['U'][14]
342/70: U330.shape
342/71: U330-u330
342/72: np.max(U330-u330)
343/1: import pickle, numpy as np
343/2: import wrf
343/3: import os
343/4:
avdata=dict()

f = open('19790101_00','rb')
d = pickle.load(f)
f.close()

for k in d['2D'].keys():
    avdata[k] = np.zeros(d['2D'][k].shape)
    
for k in list(d['isentropes'].keys())[1:]:
    avdata[k] = np.zeros(d['isentropes'][k].shape)
    
TH = d['isentropes']['TH']
343/5: ls
343/6: cd txtfiles/
343/7:
avdata=dict()

f = open('19790101_00','rb')
d = pickle.load(f)
f.close()

for k in d['2D'].keys():
    avdata[k] = np.zeros(d['2D'][k].shape)
    
for k in list(d['isentropes'].keys())[1:]:
    avdata[k] = np.zeros(d['isentropes'][k].shape)
    
TH = d['isentropes']['TH']
343/8: ls
343/9:
avdata=dict()

f = open('19790101_00.txt','rb')
d = pickle.load(f)
f.close()

for k in d['2D'].keys():
    avdata[k] = np.zeros(d['2D'][k].shape)
    
for k in list(d['isentropes'].keys())[1:]:
    avdata[k] = np.zeros(d['isentropes'][k].shape)
    
TH = d['isentropes']['TH']
343/10: TH
343/11: i = 'isentropes'
343/12: d[i]['P'][20]
343/13: TH[20]
343/14: np.max(d[i]['P'][20])
343/15: d[i]['P'][d[i]['P']>1000].shape
343/16: d[i]['P'][d[i]['P'][20]>1000].shape
343/17: d[i]['P'][20][d[i]['P'][20]>1000].shape
343/18: d[i]['P'][20][d[i]['P'][20]>1000]
343/19: np.where(d[i]['P'][20]>1000)
343/20: d[i]['P'].shape
343/21: d[i]['U'][20,41,110]
343/22: counter = np.zeros(d[i]['U'].shape)
343/23: np.isnan(d[i]['P'])
343/24: P2 = d[i]['P']
343/25: P2[P2>1100] = np.NaN
343/26: np.isnan(d[i]['P'])
343/27: np.isnan(P2)
343/28: np.isnan(P2).astype(int)
343/29: np.isnan(d[i]['P']).astype(int)
343/30: np.isnan(d[i]['P'])
343/31: not np.isnan(d[i]['P'])
343/32: not all np.isnan(d[i]['P'])
343/33: not.all(np.isnan(d[i]['P']))
343/34: ~ np.isnan(d[i]['P'])
343/35: ~np.isnan(d[i]['P'])
343/36: (~np.isnan(d[i]['P'])).astype(int)
343/37:
for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
343/38:
for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
343/39:
c2d = 0 
for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata['2D'][k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys()][1:]:
        avdata[k][ma] += d[i][ma]
343/40:
c2d = 0 
for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata['2D'][k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys())[1:]:
        avdata[k][ma] += d[i][ma]
343/41: avdata
343/42: avdata.keys()
343/43:
c2d = 0 
for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata[k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys())[1:]:
        avdata[k][ma] += d[i][ma]
343/44: l
343/45: ma
343/46: c
343/47: counter
343/48:
c2d = 0 
counter = np.zeros(d[i]['P'].shape)

for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata[k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys())[1:]:
        avdata[k][ma] += d[i][ma]
343/49: k
343/50: ma.shape
343/51: ma
343/52:
c2d = 0 
counter = np.zeros(d[i]['P'].shape)

for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata[k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys())[1:]:
        avdata[k][ma] += d[i][k][ma]
343/53:
avdata=dict()

f = open('19790101_00.txt','rb')
d = pickle.load(f)
f.close()

for k in d['2D'].keys():
    avdata[k] = np.zeros(d['2D'][k].shape)
    
for k in list(d['isentropes'].keys())[1:]:
    avdata[k] = np.zeros(d['isentropes'][k].shape)
    
TH = d['isentropes']['TH']
343/54:
c2d = 0 
counter = np.zeros(d[i]['P'].shape)

for l in os.listdir('./'):
    f = open(l,'rb')
    d = pickle.load(f)
    f.close()
    
    for k in d['2D'].keys():
        avdata[k] += d['2D'][k]
        
    c2d +=1
     
    ma = ~np.isnan(d[i]['P'])
    c = ma.astype(int)
    counter+=c
    
    for k in list(d[i].keys())[1:]:
        avdata[k][ma] += d[i][k][ma]
343/55: l
343/56: f = open('isentropic-average-up-to-20080113','wb')
343/57: pickle.dump(avdata,f)
343/58: f.close()
343/59: f = open('../isentropic-average-up-to-20080113.txt','wb')
343/60: pickle.dump(avdata,f)
343/61: f.close()
343/62: avdata['counter']=counter
343/63: f = open('../isentropic-average-up-to-20080113.txt','wb')
343/64: pickle.dump(avdata,f)
343/65: f.close()
343/66: Uav = avdata['U']/avdata['counter']
343/67: Pav = avdata['P']/avdata['counter']
343/68: import wrf
343/69: Uav300 = wrf.interplevel(Uav,Pav,300,meta=False)
343/70: import netCDF4
343/71: Uwrf = netCDF4.Dataset('/atmosdyn2/ascherrmann/013-WRF-sim/015-mean-reference/wrfout_d01_2000-12-01_00:00:00').variables['U']
343/72: Uwrf.shape
343/73: wrfd = netCDF4.Dataset('/atmosdyn2/ascherrmann/013-WRF-sim/015-mean-reference/wrfout_d01_2000-12-01_00:00:00')
343/74: Uwrf = wrf.getvar(wrfd,'U')
343/75: Uwrf
343/76: Uwrf.shape
343/77: Uwrf.values
343/78: Uwrf = wrf.getvar(wrfd,'U').values
343/79: Pwrf = wrf.getvar(wrfd,'pressure').values
343/80: Pwrf
343/81: Uwrf300 = wrf.interplevel(Uwrf,Pwrf,300,meta=False)
343/82: Uwrf.shape
343/83: Pwrf.shape
343/84: Uwrf = (Uwrf[:,:,1:]+Uwrf[:,:,:-1])/2
343/85: Uwrf.shape
343/86: Uwrf300 = wrf.interplevel(Uwrf,Pwrf,300,meta=False)
343/87: lonwrf = wrf.getvar(dwrf,'lon')
343/88: lonwrf = wrf.getvar(wrfd,'lon')
343/89: lonwrf
343/90: lonwrf = wrf.getvar(wrfd,'lon').values
343/91: lonwrf
343/92: lonwrf = lonwrf[0]
343/93: lonwrf
343/94: lonwrf = lonwrf[1:]/2+lonwrf[:-1]/2
343/95: lonwrf
343/96: Uav
343/97: Uav.shape
343/98: Uav300
343/99: Uav300.shape
343/100: Uav300[1:,60:].shape
343/101: Uav300[1:,61:].shape
343/102: Uwrf300
343/103: Uwrf300.shape
343/104: Uwrf300-Uav300
343/105: Uwrf300-Uav300[1:,61:]
343/106: np.mean(Uwrf300-Uav300[1:,61:])
344/1: %history -g -f history.py
345/1: import numpy as np
345/2: d = np.loadtxt('trajectories.ll',skiprows=5)
345/3: d.shape
345/4: d.reshape(-1,144)
345/5: d.reshape(-1,144).shape
345/6: less startf.ll
345/7: t = d[:,0].reshape(-1,144)
345/8: lon = d[:,1].reshape(-1,144)
345/9: lat = d[:,2].reshpae(-1,144)
345/10: lat = d[:,2].reshape(-1,144)
345/11: lat.shape
345/12: lon.shape
345/13: lon[0]
345/14: t
345/15: z = d[:,3].reshape(-1,144)
345/16: z
345/17: np.min(z[:,0])
345/18: np.min(z[:,-1])
345/19: %save -r /atmosdyn2/ascherrmann/scripts/WRF/forward-trajectories.py 1-999
346/1: import pickle
346/2: f = open('isentropic-average.txt','rb')
346/3: d = pickle.load(f)
346/4: f.close()
346/5: d.keys()
346/6: d['2Dcounter']
346/7: c = d['counter']
346/8: c.shape
346/9: np.where(c==0)
346/10: import numpy as np
346/11: np.where(c==0)
346/12: np.min(c)
346/13: np.max(c)
346/14: P=d['P']
346/15: P
346/16: P/c
346/17: np.isnan(P)
346/18: P
346/19: 50 * 3971
346/20: 1050*3971
346/21: _/1e7
346/22: P[P>4.17e6]=np.NaN
346/23: P
346/24: P/c
346/25: np.where(np.isnan(P))
346/26: np.mean(P[0])
346/27: np.mean(P[10])
346/28: np.mean(P[15])
346/29: np.mean(P[19])
347/1: import numpy as np
347/2: import pickle
347/3: f = open('isentropic-average.txt','rb')
347/4: d= pickle.load(f)
347/5: f.close()
347/6: c = d['counter']
347/7: U = d['U']
347/8: P = d['P']
347/9: U
347/10: P[P>4e7]=np.NaN
347/11: np.isnan(P)
347/12: np.ma.mean(P,axis=(1,2),mask=~np.isnan(P))
347/13: ma = np.ma.array(P,mask=~np.isnan(P))
347/14: ma.mean()
347/15: ma = np.ma.array(P,mask=(~np.isnan(P)).astype(int))
347/16: ma.mean
347/17: ma = np.ma.array(P,mask=(np.isnan(P)).astype(int))
347/18: ma.mean
347/19: P2 = P
347/20: P2[np.isnan(P)]=0
347/21: P2
347/22: P2[np.isnan(P)] += (P2[np.isnan(P)]+10)
347/23: P2
347/24: ma
347/25: ma = np.ma.array(P,mask=(np.isnan(P)).astype(int))
347/26: ma.mean(axis=(1,2))
347/27: ma.mean(axis=(1,2))/3971
347/28: ma
347/29: ma2 = ma+1e3
347/30: ma2
347/31: P
347/32: P[P==0]=np.NaN
347/33: P
347/34: ma = np.ma.array(P,mask=(np.isnan(P)).astype(int))
347/35: ma
347/36: ma2 = ma+1e8
347/37: ma2
347/38: ma3 = np.zeros(ma.shape)
347/39: ma3
347/40: ma3[~np.isnan(P)] += ma2[~np.isnan(P)]
347/41: ma3
347/42: np.where(ma3==0)
347/43: ~np.isnan(P).astype(int)
347/44: (~np.isnan(P)).astype(int)
347/45: ma = ~np.isnan(P)
347/46: ma
347/47: ma.astype(int)
348/1: import pickle
348/2: import numpy as np
348/3: f = open('isentropic-average.txt','rb')
348/4: d = pickle.load(f)
348/5: f.close()
348/6: c = d['counter']
348/7: np.min(c)
348/8: np.max(c)
348/9: np.mean(c)
348/10: P = d['P']
348/11: P
348/12: mask = P[P==0].astype(int)
348/13: mask
348/14: P
348/15: P[P==0]
348/16: P[P==0]=np.NaN
348/17: mask = np.isnan(P).astype(int)
348/18: mask
348/19: c[c==0] = np.Nan
348/20: c[c==0] = np.NaN
348/21: mask
348/22: P[mask]
348/23: mask.shape
348/24: P[mask.astype(bool)]
348/25: P[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
348/26: P
348/27: ma
348/28: ma = np.ma.array(P,mask=np.isnan(P))
348/29: ma.mean(axis=(1,2))
348/30: U
348/31: U = d['U']
348/32: U
348/33: U[U==0]=np.NaN
348/34: U
348/35: %save -r /atmosdyn2/ascherrmann/scripts/WRF/isen-average.py 1-999
349/1:
import pickle
import numpy as np
import wrf


f = open('isentropic-average.txt','rb')
d = pickle.load(f)
f.close()

c = d['counter']
P = d['P']
P[P==0]=np.NaN
mask = np.isnan(P).astype(int)
c[c==0] = np.NaN

P[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
ma = np.ma.array(P,mask=np.isnan(P))

U = d['U']
U[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
V = d['V']
V[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
T = d['T']
T[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
GHT = d['Z']
GHT[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
RH = d['RH']
RH[~(mask.astype(bool))]/=c[~(mask.astype(bool))]



U[mask.astype(bool)]=np.NaN
V[mask.astype(bool)]=np.NaN
T[mask.astype(bool)]=np.NaN
GHT[mask.astype(bool)]=np.NaN
RH[mask.astype(bool)]=np.NaN

LON = np.linspace(-150,80,461)
LAT = np.linspace(10,80,141)

Lon,Lat = np.meshgrid(LON,LAT)
349/2: cd isentropic-data/
349/3:
import pickle
import numpy as np
import wrf


f = open('isentropic-average.txt','rb')
d = pickle.load(f)
f.close()

c = d['counter']
P = d['P']
P[P==0]=np.NaN
mask = np.isnan(P).astype(int)
c[c==0] = np.NaN

P[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
ma = np.ma.array(P,mask=np.isnan(P))

U = d['U']
U[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
V = d['V']
V[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
T = d['T']
T[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
GHT = d['Z']
GHT[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
RH = d['RH']
RH[~(mask.astype(bool))]/=c[~(mask.astype(bool))]



U[mask.astype(bool)]=np.NaN
V[mask.astype(bool)]=np.NaN
T[mask.astype(bool)]=np.NaN
GHT[mask.astype(bool)]=np.NaN
RH[mask.astype(bool)]=np.NaN

LON = np.linspace(-150,80,461)
LAT = np.linspace(10,80,141)

Lon,Lat = np.meshgrid(LON,LAT)
349/4: Lon
349/5: Lon.shape
349/6:
for k in Lon:
    print(k)
349/7: megadi = dict()
349/8:
for va in['P','T','U','V','RH','Z']:
    megadi[va] = dict()
    
for k in LON:
    for l in LAT:
        megadi[f'{k}{l}'] = np.zeros(len(d['TH']))
349/9:
for va in['P','T','U','V','RH','Z']:
    megadi[va] = dict()
    
TH = np.arange(260,500.1,5)

for k in LON:
    for l in LAT:
        megadi[f'{k}{l}'] = np.zeros(len(TH))
349/10:
for va in['P','T','U','V','RH','Z']:
    megadi[va] = dict()
    
TH = np.arange(260,500.1,5)

for k in LON:
    for l in LAT:
        for va in ['P','T','U','V','RH','Z']:
            megadi[va][f'{k}{l}'] = np.zeros(len(TH))
349/11: megadi.keys()
349/12:
megadi = dict()
for va in['P','T','U','V','RH','Z']:
    megadi[va] = dict()
    
TH = np.arange(260,500.1,5)

for k in LON:
    for l in LAT:
        for va in ['P','T','U','V','RH','Z']:
            megadi[va][f'{k}{l}'] = np.zeros(len(TH))
349/13: megadi.keys()
349/14: P
349/15:
P2 =  np.array(['50',
            '70', '100', '125',
            '150', '175', '200',
            '225', '250', '300',
            '350', '400', '450',
            '500', '550', '600'])

P = P[7:]
U = U[7:]
V = V[7:]
T = T[7:]
RH = RH[7:]
GHT = GHT[7:]

P2 = P2.astype(int)
p = np.zeros((len(P2),len(LAT),len(LON)))
u = np.zeros((len(P2),len(LAT),len(LON)))
v = np.zeros((len(P2),len(LAT),len(LON)))
rh = np.zeros((len(P2),len(LAT),len(LON)))
t = np.zeros((len(P2),len(LAT),len(LON)))
ght = np.zeros((len(P2),len(LAT),len(LON)))

for k in range(P[0].shape[0]):
    for l in range(P[0].shape[1]):
        if LON[l]>44 and np.any(np.isnan(P[:,k,l])):
            continue
        for q,pp in enumerate(P2):
            if np.min(P[:,k,l])<pp or np.any(np.isnan(P[:,k,l])):
                continue
            u[q,k,l] = wrf.interplevel(U[:,k,l],P[:,k,l],pp,meta=False)
            v[q,k,l] = wrf.interplevel(V[:,k,l],P[:,k,l],pp,meta=False)
            ght[q,k,l] = wrf.interplevel(GHT[:,k,l],P[:,k,l],pp,meta=False)
            rh[q,k,l] = wrf.interplevel(RH[:,k,l],P[:,k,l],pp,meta=False)
            t[q,k,l] = wrf.interplevel(T[:,k,l],P[:,k,l],pp,meta=False)
349/16: k
349/17: l
349/18: P[0].shape
349/19: len(LAT)
349/20: pp
349/21: u[:,53,0]
349/22: U[:,k,l]
349/23: P[:,k,l]
349/24: wrf.interplevel(U[:,k,l],P[:,k,l],50,meta=False)
349/25: wrf.interplevel(U[:,k,l],P[:,k,l],600,meta=False)
349/26: U[:,k,l]
349/27: U[:,k,l].reshape(len(U[:,k,l]),-1)
349/28: wrf.interplevel(U[:,k,l].reshape(len(U[:,k,l]),-1),P[:,k,l].reshape(len(U[:,k,l]),-1),600,meta=False)
349/29: np.where(np.isnan(P))
349/30: np.where(np.isnan(P))[2]
349/31: np.unique(np.where(np.isnan(P))[2])
349/32: np.unique(np.where(np.isnan(P))[1])
349/33: np.min(P[0])
349/34: np.min(P[1])
349/35: np.min(P[2])
349/36: np.min(P[3])
349/37: np.max(P[3])
349/38: np.where(np.isnan(P[2]))
349/39: P[2,1,375]
349/40: P[2,1,377]
349/41: P[2,0,376]
349/42: P[2,2,376]
349/43: P[2,1,376] = (P[2,1,375] + P[2,1,377] + P[2,0,376] + P[2,2,376] )/4
349/44: U[2,1,376] = (U[2,1,375] + U[2,1,377] + U[2,0,376] + U[2,2,376] )/4
349/45: V[2,1,376] = (V[2,1,375] + V[2,1,377] + V[2,0,376] + V[2,2,376] )/4
349/46: T[2,1,376] = (T[2,1,375] + T[2,1,377] + T[2,0,376] + T[2,2,376] )/4
349/47: GHT[2,1,376] = (GHT[2,1,375] + GHT[2,1,377] + GHT[2,0,376] + GHT[2,2,376] )/4
349/48: RH[2,1,376] = (RH[2,1,375] + RH[2,1,377] + RH[2,0,376] + RH[2,2,376] )/4
349/49: np.min(P[2])
349/50: np.where(P[2]==np.min(P[2]))
349/51: LON[373]
349/52: P[2,0,374]
349/53: P[2,0,373]
349/54: P[2,0,372]
349/55: P[2,1,373]
349/56: P[2,0,373] = (P[2,0,372] + P[2,1,373] + P[2,0,374])/3
349/57: U[2,0,373] = (U[2,0,372] + U[2,1,373] + U[2,0,374])/3
349/58: V[2,0,373] = (V[2,0,372] + V[2,1,373] + V[2,0,374])/3
349/59: RH[2,0,373] = (RH[2,0,372] + RH[2,1,373] + RH[2,0,374])/3
349/60: T[2,0,373] = (T[2,0,372] + T[2,1,373] + T[2,0,374])/3
349/61: GHT[2,0,373] = (GHT[2,0,372] + GHT[2,1,373] + GHT[2,0,374])/3
349/62: np.min(P,axis(1,2))
349/63: np.min(P,axis=(1,2))
349/64: np.max(P,axis=(1,2))
349/65: U500 = wrf.interplevel(U,P,500,meta=False)
349/66: U500
349/67: U500 = wrf.interplevel(U,P,300,meta=False)
349/68: U500
349/69: %save -r /atmosdyn2/ascherrmann/scripts/WRF/isen-average2.py 1-999
350/1:
import pickle
import numpy as np
import wrf


f = open('isentropic-average.txt','rb')
d = pickle.load(f)
f.close()

c = d['counter']
P = d['P']
P[P==0]=np.NaN
mask = np.isnan(P).astype(int)
c[c==0] = np.NaN

P[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
ma = np.ma.array(P,mask=np.isnan(P))

U = d['U']
U[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
V = d['V']
V[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
T = d['T']
T[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
GHT = d['Z']
GHT[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
RH = d['RH']
RH[~(mask.astype(bool))]/=c[~(mask.astype(bool))]



U[mask.astype(bool)]=np.NaN
V[mask.astype(bool)]=np.NaN
T[mask.astype(bool)]=np.NaN
GHT[mask.astype(bool)]=np.NaN
RH[mask.astype(bool)]=np.NaN
350/2: ls
350/3: pwd
350/4: cd isentropic-data/
350/5:
import pickle
import numpy as np
import wrf


f = open('isentropic-average.txt','rb')
d = pickle.load(f)
f.close()

c = d['counter']
P = d['P']
P[P==0]=np.NaN
mask = np.isnan(P).astype(int)
c[c==0] = np.NaN

P[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
ma = np.ma.array(P,mask=np.isnan(P))

U = d['U']
U[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
V = d['V']
V[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
T = d['T']
T[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
GHT = d['Z']
GHT[~(mask.astype(bool))]/=c[~(mask.astype(bool))]
RH = d['RH']
RH[~(mask.astype(bool))]/=c[~(mask.astype(bool))]



U[mask.astype(bool)]=np.NaN
V[mask.astype(bool)]=np.NaN
T[mask.astype(bool)]=np.NaN
GHT[mask.astype(bool)]=np.NaN
RH[mask.astype(bool)]=np.NaN
350/6: np.unique(np.where(np.isnan(P))[1])
350/7: np.unique(np.where(np.isnan(P[2:]))[1])
350/8: np.unique(np.where(np.isnan(P[5:]))[1])
350/9: np.unique(np.where(np.isnan(P[6:]))[1])
350/10: np.unique(np.where(np.isnan(P[6:]))[2])
350/11: np.unique(np.where(np.isnan(P[1:]))[1])
350/12: np.unique(np.where(np.isnan(P[0:]))[1])
350/13:
P[9,1,376] = (P[9,1,375] + P[9,1,377] + P[9,0,376] + P[9,2,376] )/4
U[9,1,376] = (U[9,1,375] + U[9,1,377] + U[9,0,376] + U[9,2,376] )/4
V[9,1,376] = (V[9,1,375] + V[9,1,377] + V[9,0,376] + V[9,2,376] )/4
T[9,1,376] = (T[9,1,375] + T[9,1,377] + T[9,0,376] + T[9,2,376] )/4
GHT[9,1,376] = (GHT[9,1,375] + GHT[9,1,377] + GHT[9,0,376] + GHT[9,2,376] )/4
RH[9,1,376] = (RH[9,1,375] + RH[9,1,377] + RH[9,0,376] + RH[9,2,376] )/4

P[9,0,373] = (P[9,0,372] + P[9,1,373] + P[9,0,374])/3
U[9,0,373] = (U[9,0,372] + U[9,1,373] + U[9,0,374])/3
V[9,0,373] = (V[9,0,372] + V[9,1,373] + V[9,0,374])/3
RH[9,0,373] = (RH[9,0,372] + RH[9,1,373] + RH[9,0,374])/3
T[9,0,373] = (T[9,0,372] + T[9,1,373] + T[9,0,374])/3
GHT[9,0,373] = (GHT[9,0,372] + GHT[9,1,373] + GHT[9,0,374])/3
350/14: wrf.interplevel(U[:,125:,:],P[:,125:,:],500,meta=False)
350/15: wrf.interplevel(U[:,125:,:],P[:,125:,:],600,meta=False)
350/16: np.unique(np.where(np.isnan(P[1:]))[1])
350/17: for k in range(10)
350/18:
border=len(lat)
for k in range(10):
    print(np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/19:
border=len(LAT)
for k in range(10):
    print(np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/20: LAT = np.linspace(10,80,141)
350/21:
border=len(LAT)
for k in range(10):
    print(np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/22:
border=len(LAT)
for k in range(10):
    print(k,np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/23:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1]==0):
        continue
    print(k,np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/24:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        continue
    print(k,np.max(np.unique(np.where(np.isnan(P[k:]))[1])))
    print(range(np.max(np.unique(np.where(np.isnan(P[k:]))[1])),border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/25:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/26:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowboard=0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/27:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowboard==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/28:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/29:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/30: lowbord=1000
350/31:
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/32:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/33:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
        break
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(k,range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/34:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
        continue
    if lowbord==0:
        print(range(lowbord,border))
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(k,range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/35:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
    if lowbord==0:
        print(range(lowbord,border))
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(k,range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/36:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
    if lowbord==0:
        print(range(lowbord,border))
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(k,range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
    if lowbord==0:
        break
350/37:
lowbord=1000
border=len(LAT)
for k in range(10):
    if len(np.where(np.isnan(P[k:]))[1])==0:
        lowbord=0
    if lowbord==0:
        print(range(lowbord,border))
        continue
    lowbord=np.max(np.unique(np.where(np.isnan(P[k:]))[1])) + 1
    print(k,range(lowbord,border))
    border = np.max(np.unique(np.where(np.isnan(P[k:]))[1]))
350/38: %save -r /atmosdyn2/ascherrmann/scripts/WRF/isen-average2.py 1-999
351/1:
import wrf.interplevel as intp
import wrf.getvar as get
import netCDF4
import numpy as np
351/2:
from wrf import interplevel as intp
from wrf import getvar as get
import netCDF4
import numpy as np
351/3: from netCDF4 import Dataset as ds
351/4: d = ds('wrfout_d01_2000-12-01_00:00:00','a')
351/5: d.dimension
351/6: d.dimensions
351/7: d.dimensions()
351/8: d.attributes
351/9: d.attributes()
351/10: d.variables()
351/11: d.variables
351/12: d.variables['U']
351/13: d.createVariable('PV',"f4",("Time,))
351/14: d.variables['P']
351/15: d.createVariable('PV',"f4",("Time","bottom_top","south_north","west_east"))
351/16: d.createVariable('PV',"f4",("Time","bottom_top","south_north","west_east"),coordinates="XLONG XLAT XTIME")
351/17: d.createVariable('PV',"f4",("Time","bottom_top","south_north","west_east"))
351/18: d["PV"]
351/19: get(d,'pvo')
351/20: get(d,'pvo').shape
351/21: d["PV"] = np.zeros((d['P'].values.shape))
351/22: d['P']
351/23: d['P'].values
351/24: d['P'][:]
351/25: d['P'][:].shape
351/26: d["PV"] = np.zeros((d['P'][:].shape))
351/27: d["PV"][:] = np.zeros((d['P'][:].shape))
351/28: d["PV"][0] = get(d,'pvo')
351/29: pwd
352/1:
from wrf import getvar as get
import numpy as np
from netCDF4 import Dataset as ds
import os
352/2: d = ds('wrfout_d01_2000-12-01_00:00:00','a')
352/3: d['PV']
352/4: d['PV'][:]
352/5:
if d['PV']:
    print('true')
352/6:
if d['test']:
    print('false')
352/7:
try d['test']:
    print('exists')
352/8:
try:
    if d['test']:
        print('exists')
except:
    print('does not exist yet')
353/1:
from wrf import getvar as get
import numpy as np
from netCDF4 import Dataset as ds
353/2: d = ds('wrfout_d01_2000-12-02_12\:00\:00','a')
353/3: d = ds('wrfout_d01_2000-12-02_12:00:00','a')
353/4: d['PV'][:]
353/5: d['PV'][0]=get(d,'pvo')
353/6: d['PV']
353/7: d['PV'][:]
353/8: d.close()
354/1:
from wrf import getvar as get
import numpy as np
from netCDF4 import Dataset as ds
354/2: d = ds('wrfout_d01_2000-12-02_12:00:00','a')
354/3: d.variables.keys()
355/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
355/2:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'

df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

MEDend = np.where(df['reg']=='MED')[0][-1] + 1
r = 'MED'

columns = df.columns

tmp = df.loc[df['reg']==r]
lat = tmp['lat'].values
ID = tmp['ID'].values
355/3: fig,ax = plt.subplots()
355/4: df.keys()
355/5: df['minSLP']
355/6: tmp
355/7: tmp['minSLP']
355/8: ax.hist(tmp['minSLP'],bins=32,range=[966,1030],facecolor='k',alpha=0.5)
355/9: plt.show()
355/10: counts,val = ax.hist(tmp['minSLP'],bins=32,range=[966,1030],facecolor='k',alpha=0.5)
355/11: stat = ax.hist(tmp['minSLP'],bins=32,range=[966,1030],facecolor='k',alpha=0.5)
355/12: stat
355/13: stat[0]
355/14: np.where(np.cumsum(np.flip(stat[0]))>100)
355/15: np.where(np.cumsum(np.flip(stat[0]))>100)[0]
355/16: np.where(np.cumsum(np.flip(stat[0]))>100)[0][0]
355/17: np.cumsum(np.flip(stat[0]))[7]
355/18: np.cumsum(np.flip(stat[0]))[6]
355/19: np.where(np.cumsum(stat[0])>=100)
355/20: np.cumsum(stat[0])[11]
355/21: stat[1][11]
355/22: stat[1][-6]
356/1:
import numpy as np
import pandas as pd
356/2:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'

df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

MEDend = np.where(df['reg']=='MED')[0][-1] + 1
r = 'MED'

columns = df.columns

tmp = df.loc[df['reg']==r]
356/3: tmp
356/4: np.flip(tmp)
356/5: tmp[rmp.columns[::-1]]
356/6: tmp[tmp.columns[::-1]]
356/7: tmp.iloc[::-1]
357/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'

df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

MEDend = np.where(df['reg']=='MED')[0][-1] + 1
r = 'MED'

columns = df.columns

tmp = df.loc[df['reg']==r]
tmp = tmp.iloc[::-1]
357/2: tmp.iloc[-100:]
357/3: tmp.iloc[:100]
357/4:
tmp = df.loc[df['reg']==r]
SLP = tmp['minSLP']

# average cyclone ids
sort = np.argsort(abs(SLP-mSLP))[:100]
sel = tmp.iloc[sort]
print(sel)
# weak cyclones
sel = tmp.iloc[::-1][:100]
print(sel)
# intense cyclones
sel = tmp.iloc[:100]
print(sel)
357/5:
tmp = df.loc[df['reg']==r]
SLP = tmp['minSLP'].values
mSLP = np.mean(SLP)
# average cyclone ids
sort = np.argsort(abs(SLP-mSLP))[:100]
sel = tmp.iloc[sort]
print(sel)
# weak cyclones
sel = tmp.iloc[::-1][:100]
print(sel)
# intense cyclones
sel = tmp.iloc[:100]
print(sel)
357/6:
def get_5days_before_mature_stage(d):
    if (int(d[6:8])-5)>=1:
        return d[:6] + '%02d'%(int(d[6:8])-5) + d[-3:]

    monthsn = int(d[4:6])-1
    if monthsn<1:
        return '%d'%(int(d[:4])-1) + '12' + '%02d'%(int(d[6:8]) + 31 - 5) + d[-3:]

    if monthsn<8 and monthsn%2==1:
        days = 31
    elif monthsn==2:
        days =28
        if int(d[:4])%4==0:
            days=29
    elif monthsn>=8 and monthsn%2==0:
        days=31
    else:
        days=30
    return d[:4] + '%02d'%(monthsn) + '%02d'%(int(d[6:8]) + days - 5)
357/7: sel
357/8: sel['5dayprior'] = get_5days_before_mature_stage(sel['dates'].values)
357/9: get_5days_before_mature_stage('19860130_19')
357/10: get_5days_before_mature_stage('19871203_19')
357/11:
def get_5days_before_mature_stage(d):
    if (int(d[6:8])-5)>=1:
        return d[:6] + '%02d'%(int(d[6:8])-5) + d[-3:]

    monthsn = int(d[4:6])-1
    if monthsn<1:
        return '%d'%(int(d[:4])-1) + '12' + '%02d'%(int(d[6:8]) + 31 - 5) + d[-3:]

    if monthsn<8 and monthsn%2==1:
        days = 31
    elif monthsn==2:
        days =28
        if int(d[:4])%4==0:
            days=29
    elif monthsn>=8 and monthsn%2==0:
        days=31
    else:
        days=30
    return d[:4] + '%02d'%(monthsn) + '%02d'%(int(d[6:8]) + days - 5) + d[-3:]
357/12: get_5days_before_mature_stage('19871203_19')
357/13: get_5days_before_mature_stage('19860303_19')
357/14: 1986/4
357/15: get_5days_before_mature_stage('19880303_19')
357/16: 2000%4
357/17: sel['dates'].values
357/18: fivedayspriormature = np.array([])
357/19:
for d in sel['dates'].values:
    fivedayspriormature = np.append(fivedayspriormature,get_5days_before_mature_stage(d))
357/20: fivedayspriormature
357/21:
def get_Xdays_before_mature_stage(d,X):

    if (int(d[6:8])-X)>=1:
        return d[:6] + '%02d'%(int(d[6:8])-X) + d[-3:]

    monthsn = int(d[4:6])-1
    if monthsn<1:
        return '%d'%(int(d[:4])-1) + '12' + '%02d'%(int(d[6:8]) + 31 - X) + d[-3:]

    if monthsn<8 and monthsn%2==1:
        days = 31
    elif monthsn==2:
        days =28
        if int(d[:4])%4==0:
            days=29
    elif monthsn>=8 and monthsn%2==0:
        days=31
    else:
        days=30
    return d[:4] + '%02d'%(monthsn) + '%02d'%(int(d[6:8]) + days - X) + d[-3:]
357/22: sixdaypriormature = np.array([])
357/23:
for d in sel['dates'].values:
    sixdayspriormature = np.append(sixdayspriormature,get_Xdays_before_mature_stage(d,6))
357/24:
for d in sel['dates'].values:
    sixdaypriormature = np.append(sixdaypriormature,get_Xdays_before_mature_stage(d,6))
357/25: sixdaypriormature
357/26: fivedayspriormature
357/27: sel.tocsv
357/28: sel.to_csv
357/29:
df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

MEDend = np.where(df['reg']=='MED')[0][-1] + 1
r = 'MED'

def get_Xdays_before_mature_stage(d,X):

    if (int(d[6:8])-X)>=1:
        return d[:6] + '%02d'%(int(d[6:8])-X) + d[-3:]

    monthsn = int(d[4:6])-1
    if monthsn<1:
        return '%d'%(int(d[:4])-1) + '12' + '%02d'%(int(d[6:8]) + 31 - X) + d[-3:]

    if monthsn<8 and monthsn%2==1:
        days = 31
    elif monthsn==2:
        days =28
        if int(d[:4])%4==0:
            days=29
    elif monthsn>=8 and monthsn%2==0:
        days=31
    else:
        days=30
    return d[:4] + '%02d'%(monthsn) + '%02d'%(int(d[6:8]) + days - X) + d[-3:]


columns = df.columns

tmp = df.loc[df['reg']==r]
SLP = tmp['minSLP'].values
mSLP = np.mean(SLP)
357/30:
sort = np.argsort(abs(SLP-mSLP))[:100]

selm = tmp.iloc[sort]
fdpm= np.array([])
sdpm= np.array([])
svdpm = np.array([])
357/31:
for d in selm['dates'].values:
    fdpm = np.append(fdpm,get_Xdays_before_mature_stage(d,5))
    sdpm = np.append(sdpm,get_Xdays_before_mature_stage(d,6))
    svdpm = np.append(svdpm,get_Xdays_before_mature_stage(d,7))
357/32:
selm['fivedaypriormature']=fdpm
selm['sixdaypriormature']=sdpm
selm['sevendaypriormature']=svdpm
357/33: selm
357/34:
selm.to_csv(ps + 'moderate-cyclones.csv',index=False)

# weak cyclones
selw = tmp.iloc[::-1][:100]
fdpm= np.array([])
sdpm= np.array([])
svdpm = np.array([])

for d in selw['dates'].values:
    fdpm = np.append(fdpm,get_Xdays_before_mature_stage(d,5))
    sdpm = np.append(sdpm,get_Xdays_before_mature_stage(d,6))
    svdpm = np.append(svdpm,get_Xdays_before_mature_stage(d,7))

selw['fivedaypriormature']=fdpm
selw['sixdaypriormature']=sdpm
selw['sevendaypriormature']=svdpm

selw.to_csv(ps + 'weak-cyclones.csv',index=False)
357/35: selw
357/36:
# intense cyclones
seli = tmp.iloc[:100]
fdpm= np.array([])
sdpm= np.array([])
svdpm = np.array([])

for d in seli['dates'].values:
    fdpm = np.append(fdpm,get_Xdays_before_mature_stage(d,5))
    sdpm = np.append(sdpm,get_Xdays_before_mature_stage(d,6))
    svdpm = np.append(svdpm,get_Xdays_before_mature_stage(d,7))

seli['fivedaypriormature']=fdpm
seli['sixdaypriormature']=sdpm
seli['sevendaypriormature']=svdpm

seli.to_csv(ps + 'intense-cyclones.csv',index=False)
357/37: seli
358/1:
import os
import shutil

reg = ['IO','MED','NA','NP','SA','SP']




trajp = '/atmosdyn2/ascherrmann/'
stb = '/atmosdyn2/ascherrmann/011-all-ERA5/traj/'
358/2:
for r in reg:
    for d in os.listdir(stb + r + '/'):
        print(stb + r + '/' + d)
358/3:
for r in reg:
    for d in os.listdir(stb + r + '/'):
        print(stb + r + '/' + d + '/')
358/4: ls /atmosdyn2/ascherrmann/011-all-ERA5/traj/MED/all/
358/5: ls /atmosdyn2/ascherrmann/011-all-ERA5/traj/MED/all/trastart-mature-20190517_17-ID-533315.txt
358/6:
if (ls /atmosdyn2/ascherrmann/011-all-ERA5/traj/MED/all/trastart-mature-20190517_17-ID-533315.txt):
    print('True')
358/7:
if (ls '/atmosdyn2/ascherrmann/011-all-ERA5/traj/MED/all/trastart-mature-20190517_17-ID-533315.txt'):
    print('True')
358/8: ls ../../
358/9: ls ../../MED/
358/10:
for r in reg:
    for d in os.listdir(stb + r + '/'):
        print(stb + r + '/' + d + '/')
        p = stb + r + '/' + d + '/'
        pn = stb + r + '/new' +  d + '/'
        for f in os.listdir(p):
            print(f[-10:-4])
358/11:
for r in reg:
    for d in os.listdir(stb + r + '/'):
        p = stb + r + '/' + d + '/'
        pn = stb + r + '/new' +  d + '/'
        for f in os.listdir(p):
          if f.startswith('trastart-'):
            ID = f[-10:-4]
            print(ID)
358/12: r
358/13:
for fc in os.listdir(trajp + r + '/'):
    IDc = fc[-10:-4]
    if IDc==ID:
        print('moved')
        continue
359/1: import os
359/2: ls
359/3: os.mkdir('test')
359/4: ls
359/5: rm -r test/
360/1:
from wrf import getvar as get
import numpy as np
from netCDF4 import Dataset as ds
import os
360/2: pwd
360/3: sim = 'forward-trajectories-0.7QGPV'
360/4: d = ds('wrfout_d01_2000-12-01_00:00:00',mode='a')
360/5: d.variables['T']
360/6: d.variables['T'].attributes
360/7: d.variables['T']
360/8: d.variables['T'].keys()
360/9: d.variables['T'].minvalue
360/10: d.variables['T'].coordinates
360/11: d.variables['T'].stagger
360/12: d.variables['T'].units
360/13: d.variables['T'].unlimiteddimension
360/14: d.variables['T'].unlimited_dimension
360/15: d.variables['T']
360/16: d.variables['U']
360/17: d.drop('PV')
360/18: d
360/19: d['T']
360/20: d['PV']
360/21: d['PV'].attrs
360/22: d['PV'].units = 'PVU'
360/23: d['PV']
360/24: d['PV'].FieldType = 104
360/25: d['PV'].MemoryOrder = 'XYZ'
360/26: d['PV'].description = 'potential vorticity in PVU'
360/27: d['PV'].stagger = ''
360/28: d['PV'].coordinates = 'XLONG XLAT XTIME'
360/29: d['PV']
360/30: d.to_netcdf('TEST','w')
360/31: d.close()
360/32: d['XLAT']
360/33: d.variables['XLAT']
360/34: d
360/35: d
360/36: d = ds('wrfout_d01_2000-12-01_00:00:00',mode='a')
360/37: d['XLAT']
360/38: sim
360/39: d.close()
360/40: exi
361/1: import numpy as np
361/2: d = np.loadtxt('WR-ERAI.txt',skiprows=29)
361/3: d.shape
361/4: d
361/5: hours = np.loadtxt('WR-ERAI.txt',skiprows=29)[:,0]
361/6: regime = np.loadtxt('WR-ERAI.txt',skiprows=29)[:,2]
361/7: days = np.genfromtxt('WR-ERAI.txt',skiprows=29)
361/8: days = np.genfromtxt('WR-ERAI.txt',dtype='str')[:,1]
361/9: days = np.genfromtxt('WR-ERAI.txt',dtype='str')
361/10: days
361/11: hours,days,regimes=
361/12: hours,days,regimes=np.genfromtxt('WR-ERAI.txt',dtype='str')
361/13: days = np.loadtxt('WR-ERAI.txt',usecols=1,dtype='str')
361/14: days = np.loadtxt('WR-ERAI.txt',usecols=1,dtype='str',skiprows=29)
361/15: days
361/16: import datetime
361/17: datetime.timedelta(days='19790116_06')
361/18: refd = datetime.datetime('19790101_00')
361/19: refd = datetime.datetime(1979,1,1,00,00)
361/20: refd
361/21: refd = datetime.datetime.strptime('19790116_06')
361/22: refd = datetime.datetime.strftime('19790116_06')
361/23: from datetime import date
361/24: date.toordinal(date(1979,1,1))
361/25: date.toordinal(date(1979,01,16,06))
361/26: date.toordinal(date(1979,1,16,06))
361/27: date.toordinal(date(1979,1,16,6))
361/28: ref
361/29: refd
361/30: date.toordinal(refd)
361/31: nd = datetime.datetime(1979,1,16,06)
361/32: nd = datetime.datetime(1979,1,16,6)
361/33: date.toordinal(nd)
361/34: date.toordinal(nd) - date.toordinal(refd)
361/35: refd = datetime.datetime(1979,1,1,0)
361/36: date.toordinal(refd)
361/37: date.toordinal(date(1979,1,1))
361/38: date.toordinal(date(1979,1,16))
361/39: date(1979,1,1)
361/40: date.toordinal(date(0,1,1))
361/41: date.toordinal(date(10,1,1))
361/42: date.toordinal(date(1,1,1))
361/43: (date.toordinal(nd) - date.toordinal(refd)) * 24
361/44: (date.toordinal(nd) - date.toordinal(refd)) * 24 + 6
362/1: import numpy as np
362/2: import pandas as pd
362/3: sel = pd.read_csv('../../013-WRF-sim/data/intense-cyclones.csv')
362/4: when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature']
362/5:
freq = dict()
for we in when:
    tmp = np.array([])
    R = sel[we + '-WR']
    for k in range(0,8):
        tmp = np.append(tmp,len(np.where(R==k)[0]))
    freq[we] = tmp
362/6: freq[we]
362/7: for we in when"
362/8:
for we in when:
    print(freq[we])
362/9: which = ['moderate-cyclones.csv','weak-cyclones.csv','intense-cyclones.csv']
362/10:
freq = dict()
for wi in which:
    freq[wi] = dict()
    for we in when:
        tmp = np.array([])
        R = sel[we + '-WR']
        for k in range(0,8):
            tmp = np.append(tmp,len(np.where(R==k)[0]))
        freq[wi][we] = tmp
362/11: for wi in which"
362/12:
for wi in which:
    print(wi)
    for we in when:
        print(freq[wi][we])
362/13:
freq = dict()
for wi in which:
    freq[wi] = dict()
    sel = pd.read_csv(wi)
    for we in when:
        tmp = np.array([])
        R = sel[we + '-WR']
        for k in range(0,8):
            tmp = np.append(tmp,len(np.where(R==k)[0]))
        freq[wi][we] = tmp
362/14: pw
362/15: pwd
362/16: dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
362/17:
freq = dict()
for wi in which:
    freq[wi] = dict()
    sel = pd.read_csv(p + wi)
    for we in when:
        tmp = np.array([])
        R = sel[we + '-WR']
        for k in range(0,8):
            tmp = np.append(tmp,len(np.where(R==k)[0]))
        freq[wi][we] = tmp
362/18:
freq = dict()
for wi in which:
    freq[wi] = dict()
    sel = pd.read_csv(dp + wi)
    for we in when:
        tmp = np.array([])
        R = sel[we + '-WR']
        for k in range(0,8):
            tmp = np.append(tmp,len(np.where(R==k)[0]))
        freq[wi][we] = tmp
362/19:
for wi in which:
    print(wi)
    for we in when:
        print(freq[wi][we])
362/20: regimes = ['no','AT','GL','AR','ZOEA','ZOWE','BL','ZO']
362/21:
for wi in which:
    print(wi)
    print(regimes)
    for we in when:
        print(freq[wi][we])
362/22:
for wi in which:
    print(wi)
    print(regimes)
    for we in when:
        print(we,freq[wi][we])
362/23: when = ['onedaypriormature','twodaypriormature','threedaypriormature','fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature']
362/24:
for wi in which:
    print(wi)
    print(regimes)
    for we in when:
        print(we,freq[wi][we])
362/25: %save -r /atmosdyn2/ascherrmann/scripts/WRF/WR-weak-moderate-intense-cyclone.py 1-999
363/1: import pickle
363/2: f = open('WR-days-24h-separated-for-average.txt','rb')
363/3: d = pickle.load(f)
363/4: f.close()
363/5: d['no']
363/6: d['AR']
363/7: d.keys()
363/8: d['GL']
363/9: d['ZOEA']
363/10:
for k in d.keys():
    print(len(d[k]))
364/1: import numpy as np
364/2: import pandas as pd
364/3: import matplotlib.pyplot as plt
364/4:
X=''
which = ['weak-' + X + 'cyclones.csv','moderate-' + X + 'cyclones.csv','intense-' + X + 'cyclones.csv']
364/5:
dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
364/6:
fig,ax = plt.subplots()
for ls,wi in zip(['-','--',':'], which):
    sel = pd.read_csv(dp + wi)
    mo = sel['month']
    freq = np.array([])
    for k in range(1,13):
        freq = np.append(freq,len(np.where(mo==k)[0])/len(mo))
    ax.plot(np.arange(1,13),freq*100,color='k',linestyle=ls)
364/7: ax.set_xticks(ticks=np.arange(1,13))
364/8: ax.set_xticklabels(labels=['J','F','M','A','M','J','J','A','S','O','N','D'])
364/9: plt.show()
364/10: plt.close('all')
364/11:
fig,ax = plt.subplots()
for col,wi in zip(['b','k','r'], which):
    sel = pd.read_csv(dp + wi)
    mo = sel['month']
    freq = np.array([])
    for k in range(1,13):
        freq = np.append(freq,len(np.where(mo==k)[0])/len(mo))
    ax.plot(np.arange(1,13),freq*100,color=col)
364/12: ax.set_xticks(ticks=np.arange(1,13))
364/13: ax.set_xticklabels(labels=['J','F','M','A','M','J','J','A','S','O','N','D'])
364/14: plt.show()
364/15: plt.close('all')
364/16:
fig,ax = plt.subplots()
for col,wi in zip(['b','k','r'], which):
    sel = pd.read_csv(dp + wi)
    mo = sel['month']
    freq = np.array([])
    for k in range(1,13):
        freq = np.append(freq,len(np.where(mo==k)[0])/len(mo))
    ax.plot(np.arange(1,13),freq*100,color=col)
364/17: ax.set_xticks(ticks=np.arange(1,13))
364/18: ax.set_xticklabels(labels=['J','F','M','A','M','J','J','A','S','O','N','D'])
364/19: ax.legend(['weak','moderate','intense'])
364/20: fig.savefig(di + 'seasonality-of-weak-moderate-intense-cyclones.png',dpi=300,bbox_inches='tight')
364/21: fig.savefig(pi + 'seasonality-of-weak-moderate-intense-cyclones.png',dpi=300,bbox_inches='tight')
364/22: %save -r /atmosdyn2/ascherrmann/scripts/WRF/seasonality-weak-moderate-intense-cyclones.py 1-999
365/1:
import numpy as np
import pandas as pd
365/2: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
365/3: p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
365/4: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
365/5: df['reg']
365/6: np.unique(df['reg'].values)
365/7: np.unique(df['reg'])
365/8: np.where(df['reg'].values=='MED')
365/9: df['reg'].values[3056]
365/10: np.where(np.isnan(df['reg'].values))
365/11: df['dates']
365/12: df.columns
365/13: months = np.array([])
365/14:
for d in df['dates']:
    months = np.append(months,int(d[4:6]))
365/15: df['months'] = months
365/16: df.to_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv',index=False)
366/1:
import numpy as np
import pandas as pd
366/2: import matplotlib.pyplot as plt
366/3: fig,ax =plt.subplots()
366/4: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
366/5: p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
366/6: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
366/7:
freq = np.array([])
for m in range(1,13):
    freq = np.append(freq,len(np.where(df['months'].values==m)[0])/len(df['months'].values)*100)
366/8: xlab = ['J','F','M','A','M','J','J','A','S','O','N','D']
366/9: ax.plot(np.arange(1,13),freq,color='k')
366/10: ax.set_xticks(ticks=np.arange(1,13))
366/11: ax.set_xticklabels(labels=xlab)
366/12: plt.show()
366/13: plt.close()
366/14: plt.close('all')
366/15: df2 = df.loc[df['reg']=='MED']
366/16: fig,ax =plt.subplots()
366/17:
freq = np.array([])
for m in range(1,13):
    freq = np.append(freq,len(np.where(df2['months'].values==m)[0])/len(df2['months'].values)*100)
366/18: ax.plot(np.arange(1,13),freq,color='k')
366/19: ax.set_xticks(ticks=np.arange(1,13))
366/20: ax.set_xticklabels(labels=xlab)
366/21: plt.show()
366/22: ax.twinx()
366/23: ax2 = ax.twinx()
366/24: avSLP = np.array([])
366/25:
for m in range(1,13):
    avSLP = np.append(avSLP,np.mean(df2['minSLP'].values[np.where(df2['months'].values==m)[0]]))
366/26: ax2.scatter(np.arange(1,13),avSLP,color='r',marker='o')
366/27: fig.savefig(p + 'seasonality-all-MED-cyclones',dpi=300,bbox_inches='tight')
366/28: plt.close('all')
367/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

p = '/atmosdyn2/ascherrmann/011-all-ERA5/'
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'

df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')

MEDend = np.where(df['reg']=='MED')[0][-1] + 1
r = 'MED'
367/2:
tmp = df.loc[df['reg']==r]
SLP = tmp['minSLP'].values

seasons = ['DJF','MAM','JJA','SON']
months = [np.array([12,1,2]),np.array([3,4,5]),np.array([6,7,8]),np.array([9,10,11])]
367/3:
for sea,mo in zip(seasons,months):
    dftmp = tmp.loc[(tmp['months']==mo[0]) | (tmp['months']==mo[1]) | (tmp['months']==mo[2])]
367/4: dftmp
367/5: dftmp.iloc[:100]
367/6:
for sea,mo in zip(seasons,months):
    dftmp = tmp.loc[(tmp['months']==mo[0]) | (tmp['months']==mo[1]) | (tmp['months']==mo[2])]
    print(dftmp.iloc[:100])
368/1:
for m in range(1,13):
    if (int(m)<8 and int(m)%2==1) or (int(m)>=8 and int(m)%2==0):
    d=31
elif (int(m)==2):
    d=28
    if y%4==0:
        d+=1
else:
    d=30
368/2:
for m in range(1,13):
    if (int(m)<8 and int(m)%2==1) or (int(m)>=8 and int(m)%2==0):
        d=31
    elif (int(m)==2):
        d=28
        if y%4==0:
            d+=1
    else:
        d=30
    print(d)
368/3: y = 2020
368/4:
for m in range(1,13):
    if (int(m)<8 and int(m)%2==1) or (int(m)>=8 and int(m)%2==0):
        d=31
    elif (int(m)==2):
        d=28
        if y%4==0:
            d+=1
    else:
        d=30
    print(d)
368/5: y = 2017
368/6:
for m in range(1,13):
    if (int(m)<8 and int(m)%2==1) or (int(m)>=8 and int(m)%2==0):
        d=31
    elif (int(m)==2):
        d=28
        if y%4==0:
            d+=1
    else:
        d=30
    print(d)
368/7: :q
369/1: import pickle
369/2: f = open('streamer-in-boxes.txt','rb')
369/3: d = pickle.load(f)
369/4: f.close()
369/5: d.keys()
369/6: d['2.537.5']
370/1: import pickle
370/2: f = open('streamer-in-boxes.txt','rb')
370/3: d = pickle.load(f)
370/4: f.close()
370/5: d.keys()
370/6: d['25.37.5']
370/7: d['2.537.5']
370/8: len(d['2.537.5'])
370/9:
for k in d.keys():
    print(len(d[k]))
370/10: import netCDF4.Dataset as ds
370/11: from netCDF4 import Dataset as ds
370/12:
import numpy as np
from wrf import interplevel as intp
370/13: era5 = '/atmosdyn/era5/cdf/'
370/14:
LON = np.linspace(-180,179.5,720)
LAT = np.linspace(-90,90,361)
370/15: avpv = dict()
370/16: roi = [-120,80,10,80]
370/17: lonmin,lonmax,latmin,latmax = -120,80,10,80
370/18: loi,lai = np.where((LON>=lonmin) & (LON<=lonmax))[0], np.where((LAT>=latmin) & (LAT<=latmax))[0]
370/19: lo0,lo1,la0,la1 = loi[0],loi[-1]+1,lai[0],lai[-1]+1
370/20: yy = 1979
370/21: yy = '1979'
370/22: mm = '02'
370/23: dh = '15_12'
370/24: cdfp =era5 +yy + '/' + mm + '/'
370/25: da = ds(cdfp + 'S' + yy + mm + dh,mode='r')
370/26: PV = da.varaibles['PV']
370/27: PV = da.variables['PV']
370/28: PV.shape
370/29: PV = da.variables['PV'][:]
370/30: PV = da.variables['PV'][:].shape
370/31: PV = da.variables['PV'][:]
370/32: PV.shape
370/33: PV = da.variables['PV']
370/34: PV
370/35: PV.values
370/36: PV[0]
370/37: PV[0].shape
370/38: PV[0,:,la0:la1,lo0:lo1].shape
370/39:
for k in d.keys():
    avpv[k] = np.zeros((len(lai),len(loi)))
    for da in d[k]:
        f = era5 + da[:4] + '/' + da[4:6] + '/S' + da
        dt = ds(f,mode='r')
        PV = dt.variables['PV'][0,:,la0:la1,lo0:lo1]
        TH = dt.variables['TH'][0,:,la0:la1,lo0:lo1]
        PV315 = intp(PV,TH,315,meta=False)
        avpv[k] +=PV315
    avpv[k]/=len(d[k])
370/40: import pickle
370/41: f = open('all-dates-streamer-boxes-avpv.txt','wb')
370/42: pickle.dump(avpc,f)
370/43: pickle.dump(avpv,f)
370/44: f.close()
370/45: %save -r /atmosdyn2/ascherrmann/scripts/WRF/streamer-inbox-average-pv.py 1-999
371/1: from netCDF4 import Dataset as ds
371/2: import numpy as np
371/3: d = ds('C20101010_10')
371/4:
LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lon = np.linspace(-120,80,401)
lat = np.linspace(10,80,141)

minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
371/5: LABELO = d.variables['LABEL'][0,la0:la1,lo0:lo1]
371/6: labeln = d.variables['LABEL'][0,la0:la1,lo0:lo1]
371/7: labeln.shape
371/8: d.variables['LABEL'].shape
371/9: LABELO = d.variables['LABEL'][0,0,la0:la1,lo0:lo1]
371/10: LABELO.shape
371/11: labeln = d.variables['LABEL'][0,0,la0:la1,lo0:lo1]
371/12: labeln.shape
371/13: new = labeln.flatten()
371/14: new.shape
371/15: new.reshape(-1,401)
371/16: new.reshape(-1,401).shape
371/17: np.any((LABELO-new.reshape(-1,401).shape)!=0)
371/18: np.any((LABELO-new.reshape(-1,401))!=0)
371/19: LABELO.shape
371/20: np.where(LABELO!=0).shape
371/21: y,x = np.where(LABELO!=0)
371/22: y.shape
371/23: pwd
372/1: import pickle
372/2: f = open('most-intense-weak-average-fields.txt','rb')
372/3: d = pickle.load(f)
372/4: f.close()
372/5: d.keys()
372/6: d['DJF'].keys()
372/7: d['DJF']['intense-cyclones.csv'].keys()
372/8: d['DJF']['intense-cyclones.csv'][50].keys()
372/9: d['DJF']['intense-cyclones.csv'][50]['dates'].keys()
372/10: d['DJF']['intense-cyclones.csv'][50]['dates']['TH850'].keys()
372/11: d['DJF']['intense-cyclones.csv'][50]['dates']['TH850'].shape
372/12: d['DJF']['intense-cyclones.csv'][50]['dates']['wcbcounter']
373/1: from datetime import date
373/2: tmp = date.toordinal(date(2000,02,1))*24 + 10
373/3: tmp = date.toordinal(date(2000,2,1))*24 + 10
373/4: tmp
373/5: tnp2 = tmp-23
373/6: tmp/24/365
373/7: from datetime import datetime, date, timedelta
373/8: ft = date.toordinal(date(0,1,1))
373/9: ft = date.toordinal(date(1,1,1))
373/10: ft
373/11:
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
373/12: tmp = date.toordinal(date(2000,2,1))
373/13: tmp
373/14: tmp/365
373/15: tmp = date.toordinal(date(2000,2,1)) + 10/24
373/16: w = str(helper.datenum_to_datetime(tmp))
373/17: w
373/18: d = w[0:4]+w[5:7]+w[8:10]+'_'+w[11:13]
373/19: d
373/20: tmp2 = tmp-25/24
373/21: w2 = str(helper.datenum_to_datetime(tmp2))
373/22: d2= w2[0:4]+w2[5:7]+w2[8:10]+'_'+w2[11:13]
373/23: d2
374/1: import os
374/2: cmd = "cdo -expr,'precip=LSP+CP;' -timsum -select,name=LSP,CP /atmosdyn2/ascherrmann/009-ERA-5/MED/data/P20200908_* testh"
374/3: os.system(cmd)
374/4: os.system(cmd)
375/1: 'a'+  'b'
375/2: 'a' + 'b' + ' c'
375/3:
from datetime import datetime, date, timedelta
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
375/4: ncview /atmosdyn2/ascherrmann/009-ERA-5/MED/data/P19790101_00
376/1: import pickle
376/2: import numpy as np
376/3: d = np.loadtxt('/atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt')
376/4: d = np.loadtxt('/atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt',skiprows=19)
376/5: less /atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt
376/6: f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt','rb')
376/7: d = pickle.load(f)
376/8: f.close()
376/9: d.keys()
376/10: d.keys()
376/11: d
376/12: len(d)
376/13: ls /atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/
376/14: less /atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/MED-tracks-deepest.csv
376/15: import pandas as pd
376/16: tf = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/MED-tracks-deepest.csv')
376/17: tf
376/18: tf[-48]
376/19: tf['-48']
376/20: tf['-48'][0]
376/21: tf['-48'][0][0]
376/22: eval(tf['-48'][0])
376/23: eval(tf['-48'][0])[0]
376/24: eval(tf['-48'].values[0])
376/25: eval(tf['-48'].values)
376/26: tf['-48'].values
376/27: tf.iloc[0]
376/28: tf.iloc[0].values
376/29: tf.iloc[tf['ID']==81312]
376/30: tf.iloc[tf['ID'].values==81312]
376/31: tf.iloc[tf['ID'].values==81312]
376/32: tf.iloc[tf['ID'].values==81312]['-56']
376/33: tf.iloc[tf['ID'].values==81312]['-56'].values
376/34: eval(tf.iloc[tf['ID'].values==81312]['-56'].values)
376/35: eval(tf.iloc[tf['ID'].values==81312]['-56'])
376/36: tf.iloc[tf['ID'].values==81312]
376/37: tf.iloc[tf['ID'].values==81312].values
376/38: tf.iloc[tf['ID'].values==81312]['-56']
376/39: tf.iloc[tf['ID'].values==81312]['-56'][0]
376/40: tf.iloc[tf['ID'].values==81312].values
376/41: tf.iloc[tf['ID'].values==81312].values[-12]
376/42: tf.iloc[tf['ID'].values==81312].values[0][-12]
376/43: tf.iloc[tf['ID'].values==81312].values[0][-13]
376/44: tf.iloc[tf['ID'].values==81312]['-56'][0]
376/45: eval(tf.iloc[tf['ID'].values==81312]['-56'][0])[0]
377/1: import pickle
377/2: f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt','rb')
377/3: d=  pickle.load(f)
377/4: f.close()
377/5: d
377/6: d.shape
377/7: less /atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt
378/1: import pickle
378/2: f = open('/atmosdyn2/ascherrmann/011-all-ERA5/data/MED-96h-pre-track-deep-over-sea-12h.txt','rb')
378/3: d=  pickle.load(f)
378/4: f.close()
378/5: d
378/6: d[:,0]
378/7: trID = d[:,0]
378/8: trID
378/9: np.where(trID==268860)
378/10: import numpy as np
378/11: np.where(trID==268860)
378/12: np.where(trID==268860)[0]
378/13: np.where(trID==268860)[0][1]
379/1: import pandas as pd
379/2: df = pd.read_csv('pandas-basic-data-all-deep-over-sea-12h.csv')
379/3: df['reg']
379/4: df['reg'].values[3056]
379/5: df['reg'].values[3055]
379/6:
import numpy as np
np.where(df['reg'].values=='SA')[0][0]
379/7: df['reg'].values[3056:26818]
379/8: df['reg'].values[3056:26819]
379/9: df['reg'].values[3056:26818] = 'NA'
379/10: df['reg'].values[3056:26819]
379/11: df['reg'].values[3055:26819]
379/12: df.to_csv('pandas-basic-data-all-deep-over-sea-12h.csv',index=False)
379/13: df = pd.read_csv('pandas-basic-data-all-deep-over-sea-12h.csv')
379/14: df['reg'].values[3056]
380/1: import pandas as pd
380/2: df = pd.read_csv('pandas-basic-data-all-deep-over-sea-12h.csv')
380/3: df['reg'].values[3056]
381/1:
import os
import shutil

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/traj/'
ps = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
381/2:
for o in os.listdir(sp):
    if os.path.isdir(o):
        print(o)
381/3:
for o in os.listdir(sp):
    if os.path.isdir(o):
        print(sp + o)
381/4:
for o in os.listdir(sp):
    if os.path.isdir(o):
        for r in in os.listdir(sp + o):
            if os.path.isdir(sp + o):
                print(o)
381/5:
for o in os.listdir(sp):
    if os.path.isdir(o):
        for r in os.listdir(sp + o):
            if os.path.isdir(sp + o):
                print(o)
                print(r)
                print(sp + o)
                print(sp + o + r)
381/6:
for o in os.listdir(sp):
    if os.path.isdir(o):
        for r in os.listdir(sp + o):
            if os.path.isdir(sp + o + r):
                print()
                print(o)
                print(r)
                print(sp + o)
                print(sp + o + r)
381/7:
for o in os.listdir(sp):
    if os.path.isdir(o):
        for r in os.listdir(sp + o):
            if os.path.isdir(sp + o + '/' + r):
                print()
                print(o)
                print(r)
                print(sp + o)
                print(sp + o + r)
382/1: import pickle
382/2: ls -lrt
382/3: import pickle
382/4: f = open('MED-mature-deep-over-sea-12h.txt','rb')
382/5: d = pickle.load(f)
382/6: f.close()
382/7: d.keys()
382/8: d
382/9: le(d)
382/10: len(d)
383/1: from netCDF4 import Dataset as ds
383/2: d = ds('/atmosdyn/michaesp/mincl.era-5/cdf.final/2000/10/C20001010_10','r')
383/3: d.variables['PMIN']
383/4: d.variables['PMIN'][:]
383/5: np.where(d.variables['PMIN'][:]==1)
383/6: import numpy as np
383/7: np.where(d.variables['PMIN'][:]==1)
383/8: d.variables['PMIN'][:].shape
383/9: np.where(d.variables['PMIN'][0,0,:]==1)
383/10: np.where(d.variables['PMIN'][0,0,:]==1)[0]
383/11: np.where(d.variables['PMIN'][0,0,:]==1)[1]
383/12:
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lonshort = np.linspace(-120,80,401)
latshort = np.linspace(10,80,141)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
383/13: np.where(d.variables['PMIN'][0,0,la0:la1,lo0:lo1]==1)[0]
383/14: latshort(np.where(d.variables['PMIN'][0,0,la0:la1,lo0:lo1]==1)[0])
383/15: latshort[np.where(d.variables['PMIN'][0,0,la0:la1,lo0:lo1]==1)[0]]
383/16: LAT[np.where(d.variables['PMIN'][0,0,:]==1)[0]]
384/1: import numpy as np
384/2: import pickle
384/3: f = open('Atlantic-cyclones-prior-intense-moderate-weak-MED-cyclones.txt','rb')
384/4: d = pickle.load(f)
384/5: f.close()
384/6: d
384/7: d.keys()
384/8: d['DJF'].keys()
384/9: d['DJF']['weak-cyclones.csv'].keys()
384/10: d['DJF']['weak-cyclones.csv'][50].keys()
384/11: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature'].keys()
384/12: len(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['aga'])
384/13: len(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['age'])
384/14: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['age']
384/15: np.mean(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['age'])
384/16: np.median(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['age'])
384/17: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['htminSLP']
384/18: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['htSLPmin']
384/19: len(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['htSLPmin'])
384/20: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['lifetime']
384/21: np.mean(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['lifetime'])
384/22: np.median(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['lifetime'])
384/23: d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['currentSLP']
384/24: np.mean(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['currentSLP'])
384/25: np.median(d['DJF']['weak-cyclones.csv'][50]['fourdaypriormature']['currentSLP'])
385/1: import pickle
385/2: import numpy as np
385/3: f = open('moderate-average-fields.txt','rb')
385/4: md = pickle.load(f)
385/5: f.close()
385/6: f = open('new-weak-intense-fields.txt','rb')
385/7: nwi = pickle.load(f)
385/8: f.close()
385/9: f = open('most-intense-moderate-weak-average-fields.txt','rb')
385/10: gd = pickle.load(f)
385/11: f.close()
385/12: print(md.keys())
385/13: md.items()
385/14: for sea in md.keys()
385/15:
for sea in md.keys():
    for wi in md[sea].keys():
        for ll in md[sea][wi].keys():
            for we in md[sea][wi][ll].keys():
                print(md[sea][wi][ll][we].keys())
385/16:
for sea in md.keys():
    for wi in md[sea].keys():
        for ll in md[sea][wi].keys():
            for we in md[sea][wi][ll].keys():
                print(gd[sea][wi][ll][we].keys())
                exit
385/17:
for sea in md.keys():
    for wi in md[sea].keys():
        for ll in md[sea][wi].keys():
            for we in md[sea][wi][ll].keys():
                print(gd[sea][wi][ll][we].keys())
                break
385/18: newdict = dict()
385/19:
for sea in md.keys():
    newdict[sea] = dict()
    for wi in md[sea].keys():
        newdict[sea][wi] = dict()
        for ll in md[sea][wi].keys():
            newdict[sea][wi][ll] = dict()
            for we in md[sea][wi][ll].keys():
                newdict[sea][wi][ll][we] = dict()
385/20: wi
385/21:
for sea in md.keys():
    newdict[sea] = dict()
    for wi in gd[sea].keys():
        newdict[sea][wi] = dict()
        for ll in md[sea][wi].keys():
            newdict[sea][wi][ll] = dict()
            for we in md[sea][wi][ll].keys():
                newdict[sea][wi][ll][we] = dict()
385/22:
for sea in md.keys():
    newdict[sea] = dict()
    for wi in gd[sea].keys():
        newdict[sea][wi] = dict()
        for ll in gd[sea][wi].keys():
            newdict[sea][wi][ll] = dict()
            for we in gd[sea][wi][ll].keys():
                newdict[sea][wi][ll][we] = dict()
385/23: wi
385/24:
for sea in md.keys():
    newdict[sea] = dict()
    for wi in ['weak-cyclones.csv']:
        newdict[sea][wi] = dict()
        for ll in gd[sea][wi].keys():
            newdict[sea][wi][ll] = dict()
            for we in md[sea]['moderate-cyclones.csv'][ll].keys():
                newdict[sea][wi][ll][we] = dict()
385/25: newdict[sea][wi][ll].keys()
385/26:
for sea in md.keys():
    newdict[sea] = dict()
    for wi in gd[sea].keys():
        newdict[sea][wi] = dict()
        for ll in gd[sea][wi].keys():
            newdict[sea][wi][ll] = dict()
            for we in md[sea]['moderate-cyclones.csv'][ll].keys():
                newdict[sea][wi][ll][we] = dict()
385/27:
for sea in md.keys():
    for wi in ['weak-cyclones.csv','intense-cyclones.csv']:
        for ll in gd[sea][wi].keys():
            for we in newdict[sea][wi][ll].keys():
                for var in gd[sea][wi][ll][we].keys():
                    newdict[sea][wi][ll][we][var] = gd[sea][wi][ll][we][var]
                for var in nwi[sea][wi][ll][we].keys():
                    newdict[sea][wi][ll][we][var] = nwi[sea][wi][ll][we][var]
385/28: print(newdict[sea][wi][ll][we][var])
385/29: var
385/30: print(nwi[sea][wi][ll][we].keys())
385/31:
for sea in md.keys():
    for wi in ['weak-cyclones.csv','intense-cyclones.csv']:
        for ll in gd[sea][wi].keys():
            for we in newdict[sea][wi][ll].keys():
                for var in nwi[sea][wi][ll][we].keys():
                    newdict[sea][wi][ll][we][var] = nwi[sea][wi][ll][we][var]
                for var in gd[sea][wi][ll][we].keys():
                    newdict[sea][wi][ll][we][var] = gd[sea][wi][ll][we][var]
385/32: newdict[sea][wi][ll][we][var]
385/33:
for sea in md.keys():
    for wi in md[sea].keys():
        for ll in md[sea][wi].keys():
            for we in newdict[sea][wi][ll].keys():
                for var in md[sea][wi][ll][we].keys():
                    newdict[sea][wi][ll][we][var] = md[sea][wi][ll][we][var]
385/34: f = open('new-most-intense-moderate-weak-average-fields.txt','wb')
385/35: pickle.dump(newdict,f)
385/36: f.close()
385/37: %save -r /atmosdyn2/ascherrmann/scripts/WRF/combine-right-average-data-fields.py 1-999
386/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
era5 = '/atmosdyn2/era5/cdf/'

when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']

wl = ['4','5','6','7','3','2','1','0']

which = ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lonshort = np.linspace(-120,80,401)
latshort = np.linspace(10,80,141)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

# average cyclone


cfl = np.arange(20,90.1,20)
months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
monthsn = np.arange(1,13)
plotvar = ['TH850','U300hPa','omega500','PV300hPa','Precip24','MSL']
386/2:
cmap_pv,pv_levels,norm_pv,ticklabels_pv=PV_cmap2()

units = ['K','m s$^{-1}$','Pa s$^{-1}$','PVU','mm','hPa']
cmaps = [matplotlib.cm.seismic,matplotlib.cm.gnuplot2,matplotlib.cm.BrBG,cmap_pv,matplotlib.cm.YlGnBu,matplotlib.cm.cividis]
levels = [np.arange(260,305,3),np.arange(-10,50.1,5),np.arange(-0.5,0.6,0.1),pv_levels,np.arange(0,11,1),np.arange(990,1031,5)]
norms = [BoundaryNorm(levels[0],cmaps[0].N),BoundaryNorm(levels[1],cmaps[1].N),BoundaryNorm(levels[2],cmaps[2].N),norm_pv,BoundaryNorm(levels[4],cmaps[4].N),BoundaryNorm(levels[5],cmaps[5].N)]
names = ['TH-850hPa','U-300hPa','omega-500hPa','PV-300hPa','Precip24','MSL']
386/3: mo = 'JAN'
386/4:
f = open(ps + mo + '-average-fields.txt','rb')
data = pickle.load(f)
f.close()
386/5: data.keys()
386/6: data['JAN']['intense-cyclones.csv'][50].keys()
386/7:
for mo in months[:-1]:

    f = open(ps + mo + '-average-fields.txt','rb')
    data = pickle.load(f)
    f.close()
    for wi in which[:]:
      sel = pd.read_csv(ps + mo + '-' + wi)
      for ll in [50]:
        selp = sel.iloc[:ll]
        ### calc average
        plots = dict()
        for wq,we in zip(wl,when):
            print(mo,wi,data[mo][wi][ll].keys())
386/8:
for mo in months[:-1]:

    f = open(ps + mo + '-average-fields.txt','rb')
    data = pickle.load(f)
    f.close()
    for wi in which[:]:
      sel = pd.read_csv(ps + mo + '-' + wi)
      for ll in [50]:
        selp = sel.iloc[:ll]
        ### calc average
        plots = dict()
        for wq,we in zip(wl,when):
            print(mo,wi)
            print(data[mo][wi][ll].keys())
386/9:
for mo in months[:1]:

    f = open(ps + mo + '-average-fields.txt','rb')
    data = pickle.load(f)
    f.close()
386/10: data['JAN'].keys()
386/11: data['JAN']['weak-cyclones.csv']
386/12: data['JAN']['weak-cyclones.csv'].keys()
386/13: data['JAN']['weak-cyclones.csv'][50].keys()
386/14: data['JAN']['weak-cyclones.csv'][50]['dates']
386/15: data['JAN']['moderate-cyclones.csv'][50]['dates']
387/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
era5 = '/atmosdyn2/era5/cdf/'

f = open(ps + 'new-most-intense-moderate-weak-average-fields.txt','rb')
data = pickle.load(f)
f.close()
387/2:
for sea in seasons:
    for wi in which[:]:
        sel = pd.read_csv(ps + sea + '-' + wi)
    for ll in [50, 100, 150, 200]:
        selp = sel.iloc[:ll]
        ### calc average
        plots = dict()
        for wq,we in zip(wl,when):
            wcbo = data[sea][wi][ll][we]['wcbout400freq']
            wcba = data[sea][wi][ll][we]['wcbascfreq']
            cycfreq = data[sea][wi][ll][we]['cycfreq']
            if np.any(wcbo>1):
                wcbo/=ll
            if np.any(wcba>1):
                wcba/=ll
            if np.any(cycfreq>1):
                print('cycfreq>1')
387/3:
when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']

wl = ['4','5','6','7','3','2','1','0']

which = ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']
387/4: seasons = ['DJF','MAM','JJA','SON']
387/5:
for sea in seasons:
    for wi in which[:]:
        sel = pd.read_csv(ps + sea + '-' + wi)
    for ll in [50, 100, 150, 200]:
        selp = sel.iloc[:ll]
        ### calc average
        plots = dict()
        for wq,we in zip(wl,when):
            wcbo = data[sea][wi][ll][we]['wcbout400freq']
            wcba = data[sea][wi][ll][we]['wcbascfreq']
            cycfreq = data[sea][wi][ll][we]['cycfreq']
            if np.any(wcbo>1):
                wcbo/=ll
            if np.any(wcba>1):
                wcba/=ll
            if np.any(cycfreq>1):
                print('cycfreq>1')
387/6:
for sea in seasons:
    for wi in which[:]:
        sel = pd.read_csv(ps + sea + '-' + wi)
    for ll in [50, 100, 150, 200]:
        selp = sel.iloc[:ll]
        ### calc average
        plots = dict()
        for wq,we in zip(wl,when):
            if np.any(data[sea][wi][ll][we]['wcbout400freq']>1):
                data[sea][wi][ll][we]['wcbout400freq']/=ll
            if np.any(data[sea][wi][ll][we]['wcbascfreq']>1):
                data[sea][wi][ll][we]['wcbascfreq']/=ll
387/7:
f = open(ps + 'new2-most-intense-moderate-weak-average-fields.txt','wb')
pickle.dump(f)
f.close()
387/8:
f = open(ps + 'new2-most-intense-moderate-weak-average-fields.txt','wb')
pickle.dump(data,f)
f.close()
387/9:
for sea in seasons:
    for wi in which[:]:
        sel = pd.read_csv(ps + sea + '-' + wi)
        for ll in [50, 100, 150, 200]:
            selp = sel.iloc[:ll]
            ### calc average
            plots = dict()
            for wq,we in zip(wl,when):
                if np.any(data[sea][wi][ll][we]['wcbout400freq']>1):
                    data[sea][wi][ll][we]['wcbout400freq']/=ll
                if np.any(data[sea][wi][ll][we]['wcbascfreq']>1):
                    data[sea][wi][ll][we]['wcbascfreq']/=ll
387/10:
f = open(ps + 'new2-most-intense-moderate-weak-average-fields.txt','wb')
pickle.dump(data,f)
f.close()
388/1: import pickle
388/2: f = open('new2-most-intense-moderate-weak-average-fields.txt','rb')
388/3: d = pickle.load(f)
388/4: f.close()
388/5: f = open('new-most-intense-moderate-weak-average-fields.txt','wb')
388/6: pickle.dump(d,f)
388/7: f.close()
389/1: import pickle
389/2: monthly = dict()
389/3: months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
389/4:
for mo in months:
    f = open(mo'-average-fields.txt','rb')
389/5:
for mo in months:
    f = open(mo + '-average-fields.txt','rb')
    d = picke.load(f)
    f.close()
    monthly[mo] = d[mo]
389/6:
for mo in months:
    f = open(mo + '-average-fields.txt','rb')
    d = pickle.load(f)
    f.close()
    monthly[mo] = d[mo]
389/7: monthly.keys()
389/8: monthly['JAN'].keys()
389/9: f = open('monthly-average-fields.txt','wb')
389/10: pickle.dump(monthly,f)
389/11: f.close()
390/1: import matplotlib
390/2: cmap = matplotlib.cm.RdBu
390/3:
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
390/4: cmap = matplotlib.cm.RdBu
390/5: dir(cmap)
390/6: type(cmap.reversed)
390/7: cmap2 =cmap.reversed()
391/1:
import numpy as np
import pandas as pd
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import pickle
from datetime import datetime, date, timedelta
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import os



ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
era5 = '/atmosdyn2/era5/cdf/'

ep2 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/data/'


cycmask = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'
wcbmask = '/atmosdyn/katih/PhD/data/Gridding/grid_ERA5_r05_100_hit/'


when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']


which = ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lonshort = np.linspace(-120,80,401)
latshort = np.linspace(10,80,141)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

# average cyclone

save = dict()
months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
monthsn = np.arange(1,13)
## 2D fields to be saved
VAR = ['PV300hPa','U300hPa','cycfreq','TH850','omega950','omega900','omega850','omega800','lprecip-24h','cprecip-24h','SLPcycfreq','omega500','MSL','Q850','THE850','Pat1.5PVU','Pat2PVU','wcbascfreq','wcbout500freq','wcbout400freq']

#precidorder = ['precip-06h','precip-12h','precip-18h','precip-24h']
precidorder = ['precip-24h']
wcbmiss = [np.arange(date.toordinal(date(2008,6,5))*24 + 12, date.toordinal(date(2008,6,9))*24 + 6 + 1),
           np.arange(date.toordinal(date(2014,2,2))*24 + 12, date.toordinal(date(2014,2,2))*24 + 18 + 1),
           np.arange(date.toordinal(date(2015,12,25))*24 + 12, date.toordinal(date(2015,12,26))*24 + 0 + 1)]
392/1:
import numpy as np
import pandas as pd
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import pickle
from datetime import datetime, date, timedelta
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import os



ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
era5 = '/atmosdyn2/era5/cdf/'

ep2 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/data/'


cycmask = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'
wcbmask = '/atmosdyn/katih/PhD/data/Gridding/grid_ERA5_r05_100_hit/'


when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']


which = ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lonshort = np.linspace(-120,80,401)
latshort = np.linspace(10,80,141)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

# average cyclone

save = dict()
months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
monthsn = np.arange(1,13)
## 2D fields to be saved
VAR = ['PV300hPa','U300hPa','cycfreq','TH850','omega950','omega900','omega850','omega800','lprecip-24h','cprecip-24h','SLPcycfreq','omega500','MSL','Q850','THE850','Pat1.5PVU','Pat2PVU','wcbascfreq','wcbout500freq','wcbout400freq']

#precidorder = ['precip-06h','precip-12h','precip-18h','precip-24h']
precidorder = ['precip-24h']
wcbmiss = [np.arange(date.toordinal(date(2008,6,5))*24 + 12, date.toordinal(date(2008,6,9))*24 + 6 + 1),
           np.arange(date.toordinal(date(2014,2,2))*24 + 12, date.toordinal(date(2014,2,2))*24 + 18 + 1),
           np.arange(date.toordinal(date(2015,12,25))*24 + 12, date.toordinal(date(2015,12,26))*24 + 0 + 1)]
392/2:
for mn,mo in zip(monthsn,months):
    save[mo] = dict()
    for wi in which:
      save[mo][wi] = dict()
      sel = pd.read_csv(ps + mo + '-' + wi)

      #use the ll deepest cyclones
      for ll in [50]:
        save[mo][wi][ll] = dict()
        selp = sel.iloc[:ll]
        ### calc average

        for we in when:
            save[mo][wi][ll][we] = dict()
            for var in VAR:
                save[mo][wi][ll][we][var] = np.zeros((len(lats),len(lons)))

            save[mo][wi][ll][we]['ymature'] = np.array([])
            save[mo][wi][ll][we]['xmature'] = np.array([])
            save[mo][wi][ll][we]['wcbcounter'] = 0


            for q,d in enumerate(selp[we].values):
                ep = era5 + d[:4] + '/' + d[4:6] + '/'
                cf = cycmask + d[:4] + '/' + d[4:6] + '/C' + d
                S = ds(ep + 'S' + d,mode='r')
                P = ds(ep + 'P' + d,mode='r')
                PV = S.variables['PV'][0,:,la0:la1,lo0:lo1]
                PS = S.variables['PS'][0,la0:la1,lo0:lo1]
                hyam=P.variables['hyam']  # 137 levels  #für G-file ohne levels bis
                hybm=P.variables['hybm']  #   ''
                ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
                bk=hybm[hybm.shape[0]-98:]

                ps3d=np.tile(PS[:,:],(len(ak),1,1))
                Pr=(ak/100.+bk*ps3d.T).T
                break
            break
          break
392/4:
for mn,mo in zip(monthsn,months):
    save[mo] = dict()
    for wi in which:
      save[mo][wi] = dict()
      sel = pd.read_csv(ps + mo + '-' + wi)

      #use the ll deepest cyclones
      for ll in [50]:
        save[mo][wi][ll] = dict()
        selp = sel.iloc[:ll]
        ### calc average

        for we in when:
            save[mo][wi][ll][we] = dict()
            for var in VAR:
                save[mo][wi][ll][we][var] = np.zeros((len(lats),len(lons)))

            save[mo][wi][ll][we]['ymature'] = np.array([])
            save[mo][wi][ll][we]['xmature'] = np.array([])
            save[mo][wi][ll][we]['wcbcounter'] = 0


            for q,d in enumerate(selp[we].values):
                ep = era5 + d[:4] + '/' + d[4:6] + '/'
                cf = cycmask + d[:4] + '/' + d[4:6] + '/C' + d
                S = ds(ep + 'S' + d,mode='r')
                P = ds(ep + 'P' + d,mode='r')
                PV = S.variables['PV'][0,:,la0:la1,lo0:lo1]
                PS = S.variables['PS'][0,la0:la1,lo0:lo1]
                hyam=P.variables['hyam']  # 137 levels  #für G-file ohne levels bis
                hybm=P.variables['hybm']  #   ''
                ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
                bk=hybm[hybm.shape[0]-98:]

                ps3d=np.tile(PS[:,:],(len(ak),1,1))
                Pr=(ak/100.+bk*ps3d.T).T
                break
            break
         break
392/6:
for mn,mo in zip(monthsn,months):
    save[mo] = dict()
    for wi in which:
      save[mo][wi] = dict()
      sel = pd.read_csv(ps + mo + '-' + wi)

      #use the ll deepest cyclones
      for ll in [50]:
        save[mo][wi][ll] = dict()
        selp = sel.iloc[:ll]
        ### calc average

        for we in when:
            save[mo][wi][ll][we] = dict()
            for var in VAR:
                save[mo][wi][ll][we][var] = np.zeros((len(lats),len(lons)))

            save[mo][wi][ll][we]['ymature'] = np.array([])
            save[mo][wi][ll][we]['xmature'] = np.array([])
            save[mo][wi][ll][we]['wcbcounter'] = 0


            for q,d in enumerate(selp[we].values):
                ep = era5 + d[:4] + '/' + d[4:6] + '/'
                cf = cycmask + d[:4] + '/' + d[4:6] + '/C' + d
                S = ds(ep + 'S' + d,mode='r')
                P = ds(ep + 'P' + d,mode='r')
                PV = S.variables['PV'][0,:,la0:la1,lo0:lo1]
                PS = S.variables['PS'][0,la0:la1,lo0:lo1]
                hyam=P.variables['hyam']  # 137 levels  #für G-file ohne levels bis
                hybm=P.variables['hybm']  #   ''
                ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
                bk=hybm[hybm.shape[0]-98:]

                ps3d=np.tile(PS[:,:],(len(ak),1,1))
                Pr=(ak/100.+bk*ps3d.T).T
                break
            break
       break
392/8:
for mn,mo in zip(monthsn,months):
    save[mo] = dict()
    for wi in which:
      save[mo][wi] = dict()
      sel = pd.read_csv(ps + mo + '-' + wi)

      #use the ll deepest cyclones
      for ll in [50]:
        save[mo][wi][ll] = dict()
        selp = sel.iloc[:ll]
        ### calc average

        for we in when:
            save[mo][wi][ll][we] = dict()
            for var in VAR:
                save[mo][wi][ll][we][var] = np.zeros((len(lats),len(lons)))

            save[mo][wi][ll][we]['ymature'] = np.array([])
            save[mo][wi][ll][we]['xmature'] = np.array([])
            save[mo][wi][ll][we]['wcbcounter'] = 0


            for q,d in enumerate(selp[we].values):
                ep = era5 + d[:4] + '/' + d[4:6] + '/'
                cf = cycmask + d[:4] + '/' + d[4:6] + '/C' + d
                S = ds(ep + 'S' + d,mode='r')
                P = ds(ep + 'P' + d,mode='r')
                PV = S.variables['PV'][0,:,la0:la1,lo0:lo1]
                PS = S.variables['PS'][0,la0:la1,lo0:lo1]
                hyam=P.variables['hyam']  # 137 levels  #für G-file ohne levels bis
                hybm=P.variables['hybm']  #   ''
                ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
                bk=hybm[hybm.shape[0]-98:]

                ps3d=np.tile(PS[:,:],(len(ak),1,1))
                Pr=(ak/100.+bk*ps3d.T).T
                break
            break
        break
      break
    break
392/9: Pr
392/10: Pr.shape
392/11: Pr[0]
392/12: Pr[20]
392/13: Pr[50]
392/14: Pr[60]
392/15: Pr[55]
392/16: np.min(Pr[55])
392/17: np.max(Pr[55])
392/18: np.min(Pr[40])
392/19: np.min(Pr[60])
392/20: np.min(Pr[80])
392/21: np.min(Pr[-1])
392/22: np.min(Pr[55])
392/23: np.max(Pr[57])
392/24: np.max(Pr[56])
393/1: import pandas as pd
393/2: import numpy as np
393/3:
for k in months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-weak-cyclones.csv')
393/4:
for k in ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-weak-cyclones.csv')
    print(k,df['SLP'].values[-1])
393/5:
for k in ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-weak-cyclones.csv')
    print(k,df['minSLP'].values[-1])
393/6:
for k in ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-intense-cyclones.csv')
    print(k,df['minSLP'].values[-1])
393/7:
for k in ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-intense-cyclones.csv')
    print(k,df['minSLP'].values[0])
393/8:
for k in ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']:
    df = pd.read_csv(k + '-intense-cyclones.csv')
    print(k,np.mean(df['minSLP'].values))
    df = pd.read_csv(k + '-weak-cyclones.csv')
    print(k,np.mean(df['minSLP'].values))
394/1: import pickle
394/2: months = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
394/3: f = open('monthly-average-fields.txt','rb')
394/4: gd = pickle.load(f)
394/5: f.close()
394/6: vd = ['Q850','THE850','Pat1.5PVU','Pat2PVU']
394/7:
for mo in months:
    f = open(mo + '-average-fields2.txt','rb')
    nd = pickle.load(f)
    f.close()
    f = open(mo + '-average-fields.txt','rb')
    od = pickle.load(f)
    f.close()
    for wi in ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']:
        for ll in [50]:
            for we in when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']:
                for nv in vd:
                    gd[mo][wi][ll][we][nv] = nd[mo][wi][ll][we][nv]
394/8:
for mo in months:
    f = open(mo + '-average-fields2.txt','rb')
    nd = pickle.load(f)
    f.close()
    f = open(mo + '-average-fields.txt','rb')
    od = pickle.load(f)
    f.close()
    for wi in ['weak-cyclones.csv','moderate-cyclones.csv','intense-cyclones.csv']:
        for ll in [50]:
            for we in ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']:
                for nv in vd:
                    gd[mo][wi][ll][we][nv] = nd[mo][wi][ll][we][nv]
                    od[mo][wi][ll][we][nv] = nd[mo][wi][ll][we][nv]
    f = open(mo + '-average-fields.txt','wb')
    pickle.dump(od,f)
    f.close()
394/9: gd[mo][wi][ll][we].keys()
394/10: gd[mo][wi][ll][we]['PV300hPa']
394/11: gd[mo][wi][ll][we]['THE850']
394/12: gd[mo][wi][ll][we]['wcbcounter']
394/13: gd[mo][wi][ll][we]['Pat2PVU']
394/14: f = open('monthly-average-fields.txt','wb')
394/15: pickle.dump(gd,f)
394/16: f.close()
394/17: %save -r /atmosdyn2/ascherrmann/scripts/WRF/add-variables-to-monthly-average-fields.py 1-999
395/1: import numpy as np
395/2: d = np.loadtxt('/atmosdyn/michaesp/pvstreamer.era-5/asc/2000/10/STR_20001010_10')
395/3: d = np.loadtxt('/atmosdyn/michaesp/pvstreamer.era-5/asc/2000/10/STR_20001010_10',usecols=[5,7,8])
395/4: d
395/5: TH = d[:,0]
395/6: lon = d[:,1]-180; lat = d[:,2]
395/7: TH
395/8: ids = np.where(TH==305)[0]
395/9: lon[ids]
395/10: LON = np.linspace(-180,180,721)
395/11: LAT = np.linsapce(-90,90,361)
395/12: LAT = np.linspace(-90,90,361)
395/13: np.where(LAT==lat)
395/14: np.orgrid[:3,:4]
395/15: np.ogrid[:3,:4]
395/16: len(lons)
395/17: len(lon)
395/18: import timeit
395/19: import time
395/20:
start = time.time()
for lo,la in zip(lon,lat):
   latid = np.where(LAT==la)[0][0]
   lonid = np.where(LON==lo)[0][0]
end = time.time()
395/21: print(end-start)
395/22: np.zeros((5,4))
395/23: np.zeros((5,4))[np.array([0,0,1,2]),np.array([0,1,0,3])]+=1
395/24: k = np.zeros((5,4))
395/25: k
395/26: k[np.array([0,0,1,2]),np.array([0,1,0,3])]
395/27: k[(0,0)]
395/28: lon
395/29: lon+=180
395/30: ids = np.where(lat>=0)[0]
395/31: TH=TH[ids]
395/32: lon=lon[ids]
395/33: lat=lat[ids]
395/34: loi,lai = (lon*2).astyp(int),(lat*2).astype(int)
395/35: loi,lai = (lon*2).astype(int),(lat*2).astype(int)
395/36: loi
395/37: ids = np.where((loi>=121) & (loi<=481))[0]
395/38: TH=TH[ids]
395/39: TH
395/40: lon = lon[ids]
395/41: lat = lat[ids]
395/42: lon
395/43: d = np.loadtxt('/atmosdyn/michaesp/pvstreamer.era-5/asc/2000/10/STR_20001010_10',usecols=[5,7,8])
395/44: TH = d[:,0]
395/45: lon = d[:,0]
395/46: lat = [:,2]
395/47: lat = d[:,2]
395/48: lon = d[:,1]
395/49: ids = np.where(lat>=90)[0]
395/50: ids = np.where((lon>=60) & (lon<=260))[0]
395/51: ty = np.loadtxt('/atmosdyn/michaesp/pvstreamer.era-5/asc/2000/10/STR_20001010_10',usecols=[9]).astype(str)
395/52: ty = np.loadtxt('/atmosdyn/michaesp/pvstreamer.era-5/asc/2000/10/STR_20001010_10',usecols=[9],dtype=str)
395/53: ty
396/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
396/2: f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/streamer-masksDJF-intense-cyclones.csv','rb')
396/3: d = pickle.load(f)
396/4: f.close()
396/5: df =  pd.read_csv(ps + 'DJF-intense-cyclones.csv')
396/6: when = []
396/7:
for k in df.columns:
    if k[-2:]=='re' or k=='dates':
        when.append(k)
396/8:
LON = np.linspace(-180,179.5,720)
LAT = np.linspace(-90,90,361)
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80
for we in when:
    for ids in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.contour(LON,LAT,d[we][ID][305],levels=[1,10],colors='r',linewidths=1)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        plt.show()
396/9:
LON = np.linspace(-180,179.5,720)
LAT = np.linspace(-90,90,361)
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80
for we in when:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.contour(LON,LAT,d[we][ID][305],levels=[1,10],colors='r',linewidths=1)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        plt.show()
396/10: we
396/11: d[w]
396/12: d[we]
396/13: ID
396/14: d[we][ID][305]
396/15: np.where(d[we][ID][305]==1)
396/16:
for we in when:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.contour(LON,LAT,d[we][ID][305],levels=[0.5,1,2],colors='r',linewidths=10)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        plt.show()
396/17:
for we in when:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm([0,1,2],256))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
396/18:
for we in when[:1]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm([-0.5,0,1,2],256))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/19:
for we in when[:1]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/20:
for we in when[:1]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/21:
for we in when[:1]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/22:
for we in when[-1:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/23:
for we in when[-1:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/24:
f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/streamer-masksDJF-intense-cyclones.csv','rb')

d = pickle.load(f)

f.close()
396/25:
for we in when[-1:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT,d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/26:
for we in when[-1:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        h=ax.contourf(LON,LAT[180:],d[we][ID][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(-1,2,0.5),matplotlib.cm.jet.N),levels=np.arange(-1,2,0.5))
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.colorbar(h)
plt.show()
396/27:
for we in when[:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        
        ax.contour(LON,LAT[180:],d[we][ID][305],levels=np.arange(-1,2,0.5),colors='r',linewidths=2)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
396/28:
for we in when[:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        
        ax.contour(LON,LAT[180:],d[we][ID][325],levels=np.arange(-1,2,0.5),colors='r',linewidths=2)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
396/29:
for we in when[:]:
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        
        ax.contour(LON,LAT[180:],d[we][ID][315],levels=np.arange(-1,2,0.5),colors='r',linewidths=2)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
396/30: when
396/31: wl = ['0','5','6','7','4','3','2','1']
396/32:
for q,we in zip(wl,when[:]):
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        
        ax.contour(LON,LAT[180:],d[we][ID][315],levels=np.arange(-1,2,0.5),colors='r',linewidths=2)
        ax.text(0.9,0.9,q,transform=ax.transAxes,fontweight='bold',fontsize=6)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
396/33:
for q,we in zip(wl,when[:]):
    for ID in list(d[we].keys())[:1]:
        fig = plt.figure(figsize=(6,4))
        gs = gridspec.GridSpec(ncols=1, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        
        ax.contour(LON,LAT[180:],d[we][ID][315],levels=np.arange(-1,2,0.5),colors='r',linewidths=2)
        ax.text(0.95,0.85,q,transform=ax.transAxes,fontweight='bold',fontsize=12)
        lonticks=np.arange(minlon, maxlon+1,20)
        latticks=np.arange(minlat, maxlat+1,10)
        ax.set_xticks(lonticks, crs=ccrs.PlateCarree())
        ax.set_yticks(latticks, crs=ccrs.PlateCarree())
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
        ax.set_xticklabels(labels=lonticks[:-1].astype(int),fontsize=10)
        ax.set_yticklabels(labels=latticks.astype(int),fontsize=10)
        
plt.show()
397/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
397/2: boxes = [[3.5,9.5,37,43],[12.5,18.5,41.5,45.5],[15.5,19.5,38.5,41.5],[18.5,23.5,32.5,36.5],[10.0,14.0,35,38],[30,36,33,38],[28,42,40,50],[0,10,30,37],[10,18.5,30,35]]
397/3: fig = plt.figure(figsize=(6,4))
397/4:
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/5:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/6: plt.show()
397/7: boxes = [[1.5,8.5,39,45],[12,19.5,42,46],[16,20.5,38.5,41.5],[19,24,32.5,37],[10.0,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,39],[10,18.5,30,35],[8.5,16,38,42]]
397/8: plt.close('all')
397/9: fig = plt.figure(figsize=(6,4))
397/10:
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/11:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/12: plt.show()
397/13: boxes = [[0,8.5,37,42],[12,19.5,42,46],[16,20.5,38.5,41.5],[19,24,32.5,37],[10.0,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,37],[10,18.5,30,35],[8.5,16.5,38,42],[4,12,42,46]]
397/14:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/15:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/16: plt.show()
397/17: boxes = [[0,8.5,39,42],[12,19.5,42,46],[16,20.5,38.5,41.5],[19,24,32.5,37],[10.0,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,39],[10,18.5,30,35],[8.5,16.5,38,42],[4,12,42,46]]
397/18:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/19:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/20: plt.show()
397/21: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16,20.5,38.5,41.5],[19,24,32.5,37],[10.0,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,18.5,30,35],[9.5,16.5,38,42],[4,12,42,46]]
397/22:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/23:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/24: plt.show()
397/25: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[19,24,32.5,37],[10.0,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,18.5,30,35],[9.5,16.5,38,42],[4,12,42,46]]
397/26:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/27:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
397/28: plt.show()
397/29: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[19,24,32.5,37],[8.5,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,18.5,30,35],[9.5,16.5,38,42],[4,12,42,46]]
397/30:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/31:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/32: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[19,24,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[8.5,18.5,30,35],[9.5,16.5,38,42],[4,12,42,46]]
397/33:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/34:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/35: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[19,24,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,18.5,30,35],[8.5,16.5,38,42],[4,12,42,46]]
397/36:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/37:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/38: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[20.5,24.5,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16.5,38,42],[4,12,42,46],[16,20.5,35,38]]
397/39:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/40:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/41: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[20.5,24.5,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16.5,38,42],[4,12,42,46],[16,20.5,35,38]]
397/42: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[20.5,24.5,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16.5,38,42],[4,12,42,46],[16,20.5,35,38],[20.5,27.5,38,42]]
397/43:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/44:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/45: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[20.5,24.5,32.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16.5,38,42],[4,12,42,46],[16,20.5,35,38],[20.5,27.5,37,42],[24.5,30,30,37]]
397/46:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/47:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/48: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16.5,20.5,38,42],[20.5,24.5,31.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16.5,38,42],[4,12,42,46],[16,20.5,35,38],[20.5,27.5,37,42],[24.5,30,30,37]]
397/49:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/50:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/51: boxnames = ['balearic','adriaticN','adriaticS','ionian-aegean','sicily','cyprus','black','africaE','africaC','tyrric','genua','centralMed','greece','belowgreece']
397/52: boxes = [[0,8.5,38,42],[12,19.5,42,46],[16,20.5,38,42],[20.5,24.5,31.5,37],[10,16,35,38],[30,36.5,30,38],[27.5,42,40,50],[0,10,30,38],[10,20.5,30,35],[8.5,16,38,42],[4,12,42,46],[16,20.5,35,38],[20.5,27.5,37,42],[24.5,30,30,37]]
397/53:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/54:
for b in boxes:
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
plt.show()
397/55:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/56:
for n,b in zip(boxnames,boxes):
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
    ax.text((lor-lol),lat-lab,n,fontsize=4,color='b')
plt.show()
397/57:
for n,b in zip(boxnames,boxes):
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
    ax.text((lor+lol)/2,(lat+lab)/2,n,fontsize=4,color='b')
plt.show()
397/58:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/59:
for n,b in zip(boxnames,boxes):
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
    ax.text((lor+lol)/2,(lat+lab)/2,n,fontsize=4,color='b')
plt.show()
397/60:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/61:
for n,b in zip(boxnames,boxes):
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
    ax.text((lor+lol)/2,(lat+lab)/2,n,fontsize=10,color='b')
plt.show()
397/62:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(ncols=1, nrows=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0,edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
397/63:
for n,b in zip(boxnames,boxes):
    lab,lat,lol,lor = b[2],b[3],b[0],b[1]
    ax.plot([lol,lor],[lab,lab],color='k')
    ax.plot([lol,lor],[lat,lat],color='k')
    ax.plot([lol,lol],[lab,lat],color='k')
    ax.plot([lor,lor],[lab,lat],color='k')
    ax.text((lor+lol)/2,(lat+lab)/2,n,fontsize=7,color='b')
plt.show()
397/64: %save -r /atmosdyn2/ascherrmann/scripts/WRF/cluster-DJF-cyclones.py 1-999
398/1: import pickle
398/2: f = open('DJF-individual-fields.txt','rb')
398/3: d = pickle.load(f)
398/4: f.close()
398/5: d.keys()
398/6: d['DJF']
398/7: d['DJF'].keys()
398/8: d['DJF']['intense-cyclones.csv'][200].keys()
398/9: d['DJF']['intense-cyclones.csv'][200]['dates'].keys()
398/10: d['DJF']['intense-cyclones.csv'][200]['dates'][81312].keys()
398/11: d['DJF']['intense-cyclones.csv'][200]['dates'][81312]['Q850'].shape
399/1: import pickle
399/2: f = open('streamer-masksDJF-intense-cyclones.csv','rb')
399/3: d=pickle.load(f)
399/4: f.close()
399/5: d['DJF'].keys()
399/6: d.keys()
399/7: d['dates'].keys()
399/8: d['dates'][81312].keys()
399/9: import matplotlib.pyplot as plt
399/10:
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
399/11: fig = plt.figure(figsize=(6,4))
399/12: gs = gridspec.GridSpec(nrows=0, ncols=0)
399/13: ax = fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
399/14: gs = gridspec.GridSpec(nrows=1, ncols=1)
399/15: ax = fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
399/16:
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80
399/17:
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
                ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
                ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
399/18:
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
399/19: d['dates'][81312][305].shape
399/20: import matplotlib
399/21:
from matplotlib.colors import BoundaryNorm
ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][460809][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0,2,1),matplotlib.cm.jet.N),levels=np.arange(0,2,1))
399/22: import numpy as np
399/23:
from matplotlib.colors import BoundaryNorm
ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][460809][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0,2,1),matplotlib.cm.jet.N),levels=np.arange(0,2,1))
399/24:
from matplotlib.colors import BoundaryNorm
ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][460809][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0,2,1),256),levels=np.arange(0,2,1))
399/25: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][460809][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0,2,1),256),levels=np.arange(0,2,1))
399/26: plt.show()
399/27: plt.close('all')
399/28: fig = plt.figure(figsize=(6,4))
399/29: gs = gridspec.GridSpec(nrows=1, ncols=1)
399/30: ax = fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
399/31:
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
399/32: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0,2,1),256),levels=np.arange(0,2,1))
399/33: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(np.arange(0.5,1.5,0.5),256),levels=np.arange(0.5,1.5,0.5))
399/34: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(boundaries=np.arange(0.5,1.5,0.5)),levels=np.arange(0.5,1.5,0.5))
399/35: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(boundaries=np.arange(0.5,1.5,0.5),ncolors=256),levels=np.arange(0.5,1.5,0.5))
399/36: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,norm=BoundaryNorm(boundaries=np.arange(0.5,1.5,0.5),ncolors=2),levels=np.arange(0.5,1.5,0.5))
399/37: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][305],cmap=matplotlib.cm.jet,levels=np.arange(0.5,1.5,0.5))
399/38: plt.show()
399/39: plt.close('all')
399/40: fig = plt.figure(figsize=(6,4))
399/41:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(nrows=1, ncols=1)

ax = fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())

ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())
399/42: d['dates'].keys()
399/43: ax.contourf(np.linspace(-180,179.5,720),np.linspace(0,90,181),d['dates'][406355][315],cmap=matplotlib.cm.jet,levels=np.arange(0.5,1.5,0.5))
399/44: plt.show()
400/1: import os
400/2: c = os.system('ls cluster-full-images.py')
400/3: c
400/4: os.system('ls cluster-full-images.py')
400/5: c,a = os.system('ls cluster-full-images.py')
400/6: c
400/7: a = os.system('ls cluster-full-images.py')
400/8: a
400/9: import glob
400/10: c = glob.glob('cluster-full*.py')
400/11: c
400/12: c = glob.glob('/atmosdyn2/ascherrmann/013-WRF-sim/data/*20190110_04*.txt')
400/13: c
400/14: c = glob.glob('/atmosdyn2/ascherrmann/013-WRF-sim/data/trajectories-20190110_04*.txt')
400/15: c
400/16: c = glob.glob('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV-med-traj/*20190110_04*.txt')
400/17: c
401/1:
import numpy as np
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
from numpy.random import randint as ran
import pandas as pd
import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
pd = '/atmosdyn2/ascherrmann/009-ERA-5/MED/data/'

datesDJF = np.loadtxt(ps + 'draw-dates-from-DJF.txt',dtype=str)
datesSON = np.loadtxt(ps + 'draw-dates-from-SON.txt',dtype=str)
401/2: datesDJF
401/3: len(datesDJF)
401/4: len(datesDJF)/24
401/5: len(datesDJF)/24/365
401/6:
dfD = pd.read_csv(ps + 'DJF-intense-cyclones.csv')
dfS = pd.read_csv(ps + 'SON-intense-cyclones.csv')

ncD = np.array([])
ncS = np.array([])

#### get the 6 most abundant clusters in terms of number of cyclones
for cl in np.unique(dfD['region'].values):
    ncD = np.append(ncD,len(np.where(dfD['region'].values==cl)[0]))

for cl in np.unique(dfS['region'].values):
    ncS = np.append(ncS,len(np.where(dfS['region'].values==cl)[0]))

DJFcluster = np.unique(dfD['region'].values)[np.argsort(ncD)[-6:]]
SONcluster = np.unique(dfS['region'].values)[np.argsort(ncS)[-6:]]
ncD = ncD[np.argsort(ncD)[-6:]]
ncS = ncS[np.argsort(ncS)[-6:]]
401/7: PD = '/atmosdyn2/ascherrmann/009-ERA-5/MED/data/'
401/8: import pandas as pd
401/9:
dfD = pd.read_csv(ps + 'DJF-intense-cyclones.csv')
dfS = pd.read_csv(ps + 'SON-intense-cyclones.csv')

ncD = np.array([])
ncS = np.array([])

#### get the 6 most abundant clusters in terms of number of cyclones
for cl in np.unique(dfD['region'].values):
    ncD = np.append(ncD,len(np.where(dfD['region'].values==cl)[0]))

for cl in np.unique(dfS['region'].values):
    ncS = np.append(ncS,len(np.where(dfS['region'].values==cl)[0]))

DJFcluster = np.unique(dfD['region'].values)[np.argsort(ncD)[-6:]]
SONcluster = np.unique(dfS['region'].values)[np.argsort(ncS)[-6:]]
ncD = ncD[np.argsort(ncD)[-6:]]
ncS = ncS[np.argsort(ncS)[-6:]]
401/10: ncS
401/11: ncD
401/12: DJFcluster
401/13: SONcluster
402/1:
import numpy as np
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
from numpy.random import randint as ran
import pandas as pd
import pickle

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
402/2: f = open(ps + 'DJF-boot-strap-U-data.txt','rb')
402/3: d = pickle.load(f)
402/4: f.close()
402/5:
for k in d.keys():
    l=0
    print(d[k][l])
402/6:
for k in d.keys():
    l=0
    print(d[k][l].shape)
402/7:
for k in d.keys():
    l=0
    print(np.max(d[k][l]))
403/1:
import numpy as np
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
from numpy.random import randint as ran
import pandas as pd
import pickle
import wrf
from wrf import interplevel as intp

import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
PD = '/atmosdyn2/ascherrmann/009-ERA-5/MED/data/'

dfD = pd.read_csv(ps + 'DJF-intense-cyclones.csv')
dfS = pd.read_csv(ps + 'SON-intense-cyclones.csv')

f = open(ps + 'DJF-boot-strap-U-data.txt','rb')
avDJFU = pickle.load(f)
f.close()

f = open(ps + 'DJF-boot-strap-T-data.txt','rb')
avDJFT = pickle.load(f)
f.close()

### plotting region
minlon = -120
minlat = 10
maxlat = 80
maxlon = 80

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lonticks=np.arange(minlon, maxlon+1,20)
latticks=np.arange(minlat, maxlat+1,10)
lonshort = np.linspace(-120,80,401)
latshort = np.linspace(10,80,141)

### dictionaries to save

DJFclim = ds('/atmosdyn2/ascherrmann/013-WRF-sim/DJF-clim/wrfout_d01_2000-12-01_00:00:00','r')
Pwrf = wrf.getvar(DJFclim,'pressure',meta=False)
lonwrf = np.linspace(-120,79.5,400)
latwrf = np.linspace(10,79.5,140)
Uwrf = wrf.getvar(DJFclim,'U',meta=False)
Uwrf = Uwrf[:,:,1:]/2 + Uwrf[:,:,:-1]/2
Uwrf_300hPa = intp(Uwrf,Pwrf,300.0,meta=False)
THwrf = wrf.getvar(DJFclim,'T',meta=False)
THwrf_850hPa = intp(THwrf,Pwrf,850,meta=False) + 300

anU = dict()
anT = dict()

pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/season/DJF/bootstrap/'
if not os.path.isdir(pi):
    os.mkdir(pi)

f = open(ps + 'DJF-individual-fields.txt','rb')
data = pickle.load(f)
f.close()
403/2:
when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']

wl = ['4','5','6','7','3','2','1','0']

for l in avDJFU.keys():
    anU[l] = np.zeros_like(avDJFU[l])
    anT[l] = np.zeros_like(avDJFT[l])
    for k in range(1000):
        anU[l][k,:-1,:-1] = avDJFU[l][k,:-1,:-1]-Uwrf_300hPa
        anT[l][k,:-1,:-1] = avDJFT[l][k,:-1,:-1]-THwrf_850hPawhen = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']

wl = ['4','5','6','7','3','2','1','0']

for l in avDJFU.keys():
    anU[l] = np.zeros_like(avDJFU[l])
    anT[l] = np.zeros_like(avDJFT[l])
    for k in range(1000):
        anU[l][k,:-1,:-1] = avDJFU[l][k,:-1,:-1]-Uwrf_300hPa
        anT[l][k,:-1,:-1] = avDJFT[l][k,:-1,:-1]-THwrf_850hPa
403/3:
when = ['fourdaypriormature','fivedaypriormature','sixdaypriormature','sevendaypriormature','threedaypriormature','twodaypriormature','onedaypriormature','dates']

wl = ['4','5','6','7','3','2','1','0']

for l in avDJFU.keys():
    anU[l] = np.zeros_like(avDJFU[l])
    anT[l] = np.zeros_like(avDJFT[l])
    for k in range(1000):
        anU[l][k,:-1,:-1] = avDJFU[l][k,:-1,:-1]-Uwrf_300hPa
        anT[l][k,:-1,:-1] = avDJFT[l][k,:-1,:-1]-THwrf_850hPa
403/4: we = when[0]
403/5: sd4 = data['DJF']['intense-cyclones.csv'][200][we]
403/6:
for wq,we in zip(wl[0],when[0]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0:
                    print(np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),95),np.percentile(np.sort(anU[l][:,j,i]),5))
403/7: we
403/8: when[0]
403/9:
for wq,we in zip(wl[:1],when[:1]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0:
                    print(np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),95),np.percentile(np.sort(anU[l][:,j,i]),5))
403/10:
for wq,we in zip(wl[:1],when[:1]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0:
                    print(clusavU[j,i],np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),5),np.percentile(np.sort(anU[l][:,j,i]),95))
403/11:
for wq,we in zip(wl[:1],when[:1]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0 and clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    print(clusavU[j,i],np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),5),np.percentile(np.sort(anU[l][:,j,i]),95))
403/12:
for wq,we in zip(wl[:1],when[:1]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0 and clusavU[j,i]<np.percentile(np.sort(anU[l][:,j,i]),95):
                    print(clusavU[j,i],np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),5),np.percentile(np.sort(anU[l][:,j,i]),95))
403/13:
for wq,we in zip(wl[:1],when[:1]):

    sd4 = data['DJF']['intense-cyclones.csv'][200][we]

    plotU = dict()
    plotT = dict()
    for l in avDJFU.keys():
      if l=='adriaticN':
        ids = dfD['ID'].values[np.where(dfD['region'].values==l)[0]]
        c = len(ids)

        plotU[l] = np.zeros(avDJFT[l][0].shape)
        plotT[l] = np.zeros(avDJFT[l][0].shape)

        clusavU = np.zeros(avDJFT[l][0].shape)
        clusavT = np.zeros(avDJFT[l][0].shape)

        for i in ids:
            clusavU[:-1,:-1] +=(sd4[i]['U300hPa'][:-1,:-1]-Uwrf_300hPa)/c
            clusavT[:-1,:-1] +=(sd4[i]['TH850'][:-1,:-1]-THwrf_850hPa)/c
        for j in range(avDJFU[l].shape[1]-1):
            for i in range(avDJFU[l].shape[2]-1):
    #            if clusavU[j,i]>0 and clusavU[j,i]>np.percentile(anU[l][:,j,i],95):
                if clusavU[j,i]>np.percentile(np.sort(anU[l][:,j,i]),95):
                    plotU[l][j,i] = clusavU[j,i]
                if clusavU[j,i]<0 and clusavU[j,i]<np.percentile(np.sort(anU[l][:,j,i]),5):
                    print(clusavU[j,i],np.min(anU[l][:,j,i]),np.max(anU[l][:,j,i]),np.percentile(np.sort(anU[l][:,j,i]),5),np.percentile(np.sort(anU[l][:,j,i]),95))
404/1: import cartopy
405/1: import numpy as np
405/2: np.arange(1,100)
405/3: import cartopy
406/1: import netCDF4.Dataset as ds
406/2: from netCDF4 import Dataset as ds
406/3: d = ds('PV300hPaDJF.nc','a')
406/4: d.keys()
406/5: d.variables
406/6: d.variables["PV.MEAN"][0]
406/7: d.variables["PV.MEAN"].shape
406/8: d.variables["PV.MEAN"][0,0,0]
406/9: d.variables["PV.MEAN"][0,0,-1]
406/10: d2 = d
406/11: d[0,0,0] = d[0,0,1]
406/12: d2.varaibles['PV.MEAN'][0,0,0] = d2.variables['PV.MEAN'][0,0,1]
406/13: d2.varaibles['PV.MEAN'][0,0,0] = d2.variables['PV.MEAN'][0,0,1]
406/14: d2
406/15: d2.variables['PV.MEAN'][0,0,0] = d2.variables['PV.MEAN'][0,0,1]
406/16: d2.variables['PV.MEAN'][0,0,-1] = d2.variables['PV.MEAN'][0,0,-2]
406/17: d.variables['PV.MEAN'][0,0,-1] = d.variables['PV.MEAN'][0,0,-2]
406/18: d.variables['PV.MEAN'][0,0,0] = d.variables['PV.MEAN'][0,0,1]
406/19: d.close()
406/20: d = ds('PV300hPaSON.nc','a')
406/21: d.variables['PV.MEAN'][0,0,0] = d.variables['PV.MEAN'][0,0,1]
406/22: d.variables['PV.MEAN'][0,0,-1] = d.variables['PV.MEAN'][0,0,-2]
406/23: d.close()
407/1: from netCDF4 import Dataset as ds
407/2: d = ds('PV300hPaSON.nc','a')
407/3: d.variables['PV.MEAN'][0,0,0] = d.variables['PV.MEAN'][0,0,-1]
407/4: d.close()
407/5: d = ds('PV300hPaDJF.nc','a')
407/6: d.variables['PV.MEAN'][0,0,0] = d.variables['PV.MEAN'][0,0,-1]
407/7: d.close()
408/1: import os
408/2: os.system('ls')
408/3: a,b = os.system('ls')
408/4: os.listdir('./')
408/5: ds
408/6: from netCDF4 import Dataset as ds
408/7: d = ds('251305/D19980829_19','r')
408/8: d.variables['PV']
408/9: d.variables['PV'].shape
409/1: from netCDF4 import Dataset as ds
409/2: d = ds('000542/streamer-masks.nc','r')
409/3: d
409/4: d.variables['mask'].shape
409/5:
minlon = -10
minlat = 30
maxlat = 50
maxlon = 45

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
409/6: import numpy as np
409/7:
minlon = -10
minlat = 30
maxlat = 50
maxlon = 45

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
409/8: mask = d.variables['mask'][:,la0:la1,lo0:lo1]
409/9: mask.shape
409/10: mask[0]
409/11: np.unique(mask[0])
409/12: np.unique(mask)
409/13: len(np.unique(mask))
409/14:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])

for k in range(mask.shape[0]):
    vm = np.unique(mask[k])[1:]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        a = np.append(a,len(idslat))
        lami = np.append(lami,np.min(LAT[idslat]))
        lama = np.append(lama,np.max(LAT[idslat]))
        lomi = np.append(lomi,np.min(LON[idslon]))
        loma = np.append(loma,np.max(LON[idslon]))
409/15: lami
409/16: a
409/17:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])

for k in range(mask.shape[0]):
    vm = np.unique(mask[k])[1:]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        a = np.append(a,len(idslat))
        lami = np.append(lami,np.min(LAT[la0+idslat]))
        lama = np.append(lama,np.max(LAT[la0+idslat]))
        lomi = np.append(lomi,np.min(LON[lo0+idslon]))
        loma = np.append(loma,np.max(LON[lo0+idslon]))
409/18: lami
409/19: lama
409/20: lomi
409/21: loma
409/22: a
409/23: np.percentile(a,25)
409/24: np.percentile(a,50)
409/25: np.percentile(a,75)
409/26: np.percentile(a,60)
409/27: np.percentile(a,50)
409/28: np.percentile(a,90)
409/29: np.percentile(a,91)
409/30: np.percentile(a,95)
409/31: np.sort(a)
409/32: lami[np.argsort(a)]
409/33: lama[np.argsort(a)]
409/34: %save -r /atmosdyn2/ascherrmann/scripts/WRF/evaluate-streamer-masks.py 1-999
410/1: import os
410/2: os.listdir('.')
410/3: len(os.listdir('.'))
410/4:
for f in os.listdir('.'):
    print(f)
410/5: ds
410/6: from netCDF4 import Dataset as ds
410/7: dd = ds('D19800113_13','r')
410/8: dd.variables['PV'].shape
410/9:
from netCDF4 import Dataset as ds
import numpy as np
410/10: import os
410/11:
minlon = -10
minlat = 30
maxlat = 50
maxlon = 45

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
410/12: pwd
410/13: cd ../
410/14:
d = ds('000542/streamer-masks.nc','r')
mask = d.variables['mask'][:,la0:la1,lo0:lo1]

a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
410/15:
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds(f,'r')
    PV = ds.variables['PV'][0,0,la0:la1,lo0:lo1]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=100:
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
410/16:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = ds.variables['PV'][0,0,la0:la1,lo0:lo1]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=100:
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
410/17:
from netCDF4 import Dataset as ds
import numpy as np
import os
410/18:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = dd.variables['PV'][0,0,la0:la1,lo0:lo1]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=100:
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
410/19: val
410/20: avlow
410/21: avlaw
410/22: len(val)
410/23:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = dd.variables['PV'][0,0,la0:la1,lo0:lo1]
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=200:
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
410/24: len(val)
410/25: val
410/26: import matplotlib.pyplot as plt
410/27: fig,ax = pltsubplots(4,3)
410/28: fig,ax = plt.subplots(4,3)
410/29: plt.close('all')
410/30:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = dd.variables['PV'][0,0,la0:la1,lo0:lo1]
    fig,ax = plt.subplots()
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=200:
            ax.contour(LON[lons],LAT[lats],mask,levels=[v],colors='k',linewidths=1)
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
            ax.scatter(avlo,avla,marker='d',color='k')
            ax.scatter(avlow,avlaw,marker='o',color='b')
410/31:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = dd.variables['PV'][0,0,la0:la1,lo0:lo1]
    fig,ax = plt.subplots()
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=200:
            ax.contour(LON[lons],LAT[lats],mask[k],levels=[v],colors='k',linewidths=1)
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
            ax.scatter(avlo,avla,marker='d',color='k')
            ax.scatter(avlow,avlaw,marker='o',color='b')
410/32: plt.show()
410/33: plt.close('all')
410/34: mask
410/35:
a = np.array([])
lami = np.array([])
lama = np.array([])
lomi = np.array([])
loma = np.array([])
val = np.array([])
maxPV = np.array([])
avPV = np.array([])
avlo = np.array([])
avla = np.array([])
avlow = np.array([])
avlaw = np.array([])
intePV = np.array([])
for k,f in zip(range(mask.shape[0]),os.listdir('000542/')):
    vm = np.unique(mask[k])[1:]
    dd = ds('000542/' + f,'r')
    PV = dd.variables['PV'][0,0,la0:la1,lo0:lo1]
    fig,ax = plt.subplots()
    for v in vm:
        idslat = np.where(mask[k]==v)[0]
        idslon = np.where(mask[k]==v)[1]
        if len(idslat)>=200:
            ax.contour(LON[lons],LAT[lats],mask[k],levels=[v,v + 1e-2],colors='k',linewidths=1)
            val = np.append(val,v)
            a = np.append(a,len(idslat))
            lami = np.append(lami,np.min(LAT[la0+idslat]))
            lama = np.append(lama,np.max(LAT[la0+idslat]))
            lomi = np.append(lomi,np.min(LON[lo0+idslon]))
            loma = np.append(loma,np.max(LON[lo0+idslon]))

            avlo = np.append(avlo,np.mean(LON[lo0+idslon]))
            avla = np.append(avla,np.mean(LAT[la0+idslat]))

            maxPV = np.append(maxPV,np.max(PV[idslat,idslon]))
            avPV = np.append(avPV,np.mean(PV[idslat,idslon]))
            intePV = np.append(intePV,np.sum(PV[idslat,idslon]))

            avlow = np.append(avlow,np.sum(LON[lo0+idslon] * PV[idslat,idslon])/intePV)
            avlaw = np.append(avlaw,np.sum(LAT[la0+idslat] * PV[idslat,idslon])/intePV)
            ax.scatter(avlo,avla,marker='d',color='k')
            ax.scatter(avlow,avlaw,marker='o',color='b')
    fig.show()
410/36: plt.close('all')
411/1: import numpy as np
411/2: a = np.array([])
411/3: b = np.arange(1,6); c = np.arange(1,3)
411/4: a = np.append(a,b)
411/5: a
411/6: a = np.array([b,c])
411/7: a
412/1: import numpy as np
412/2: t = np.array([])
412/3: t.size
413/1: import os
413/2: os.listdir('.')
414/1:
from netCDF4 import Dataset as ds
import numpy as np
import os
414/2:
minlon = -10
minlat = 30
maxlat = 50
maxlon = 45

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
414/3: ID = '000542/'
414/4: d = ds(ps + ID + 'streamer-masks.nc','r')
414/5: mask = d.variables['mask'][:,la0:la1,lo0:lo1]
414/6: mask0 = mask[0]
414/7: mask0.shape
414/8: mask1 = mask[1]
414/9: lab = np.zeros_like(mask0)
414/10: lab[mask0!=0] +=1
414/11: lab[mask1!0] +=1
414/12: lab[mask1!=0] +=1
414/13: np.where(lab==2)
414/14: vm = np.unique(mask0)[1:]
414/15: fm
414/16: vm
414/17: np.where((lab==2) & (mask0==31))
414/18: np.where((lab==2) & (mask0==33))
414/19: np.where((lab==2) & (mask0==34))
414/20: np.unique(mask1)
414/21: np.where((lab==2) & (mask0==104))
414/22: np.where((lab==2) & (mask1==104))
414/23: np.where((lab==2) & (mask1==106))
414/24: np.where((lab==2) & (mask1==105))
414/25: len(np.where((overlap==2) & (mask0==33))[0])/len(np.where((overlap==2) & (mask1==105))[0])
414/26: overlap=lab
414/27: len(np.where((overlap==2) & (mask0==33))[0])/len(np.where((overlap==2) & (mask1==105))[0])
414/28: len(np.where((overlap==2) & (mask0==34))[0])/len(np.where((overlap==2) & (mask1==105))[0])
414/29: len(np.where((overlap==2) & (mask0==35))[0])/len(np.where((overlap==2) & (mask1==105))[0])
414/30: np.unique(mask0)
414/31: len(np.where((overlap==2) & (mask0==31))[0])/len(np.where((overlap==2) & (mask1==105))[0])
415/1:
import pandas as pd
import os
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
we = 'sevendaypriormature'
wi = 'intense-cyclones.csv'
seasons = ['DJF','SON']

lev=300
415/2:
for sea in seasons:
    sel = pd.read_csv(dp + sea + '-' + wi)
    for q,d,ID in zip(range(200),sel[we].values,sel['ID'].values):
        print(ps + '%06d'%ID)
        print(ps + '%06d'%ID + '/%d'%lev)
        for k in range(73):
            y = int(d[:4])
            m = int(d[4:6])
            dd = int(d[6:8])
            h = int(d[9:])+3
            if (m<8 and m%2==1) or (m>=8 and m%2==0):
                md=31
            else:
                md=30
            if m==2:
                md=28
                if y%4==0:
                    md = 29

            if h>=24:
                h-=24
                dd+=1
                if dd>md:
                    dd-=md
                    m+=1
                    if m==13:
                        m=1
                        y+=1

            d = '%04d%02d%02d_%02d'%(y,m,dd,h)
            print(ps + '%06d/%d/D%s'%(ID,lev,d))
            print("clim-e5 %s PV@%dhPa.dump %stest.nc"%(d,lev,ps))
            print("mv D%s %s"%(d,ps + '%06d/%d/D%s'%(ID,lev,d)))
            break
        break
    break
416/1: import wrf
417/1: from netCDF4 import Dataset as ds
418/1: from netCDF4 import Dataset as ds
419/1: import netCDF4 import Dataset as ds
419/2: from netCDF4 import Dataset as ds
419/3: S = ('S20201010_10',mode='r')
419/4: S = ds('S20201010_10',mode='r')
419/5: S
419/6: S.variables
419/7: TH = S.variables['TH']
419/8: TH
419/9: TH.values
419/10: TH[:]
419/11: TH.shape
419/12: TH[0].shape
420/1: import helper
421/1: import helper
421/2: d = '20000102_16'
421/3: nd = helper.change_date_by_hours(d,-48)
421/4: nd
421/5: nd = helper.change_date_by_hours(d,48)
421/6: nd
421/7: nd = helper.change_date_by_hours(d,-144)
421/8: nd
421/9: import pandas as pd
421/10: df = pd.read_csv('/atmosdyn2/ascherrmann/013-WRF-sim/data/DJF-intense-cyclones.csv')
421/11:
for d in df['dates'].values:
    print(d,helper.change_date_by_hours(d,-12),helper.change_date_by_hours(d,28),helper.change_date_by_hours(d,-85))
422/1: import helper
422/2: import pandas as pd
422/3: df = pd.read_csv('/atmosdyn2/ascherrmann/013-WRF-sim/data/DJF-intense-cyclones.csv')
422/4:
for d in df['dates'].values:
    print(d,helper.change_date_by_hours(d,-12),helper.change_date_by_hours(d,28),helper.change_date_by_hours(d,-85))
422/5:
for d in df['dates'].values:
    print(d,helper.change_date_by_hours(d,-12),helper.change_date_by_hours(d,28),helper.change_date_by_hours(d,-85),helper.change_date_by_hours(d,148))
423/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds
423/2: era5 = '/atmosdyn2/era5/cdf/'
423/3: d='19850715_00'
423/4:
ep = era5 + d[:4] + '/' + d[4:6] + '/'
S = ds(ep + 'S' + d,mode='r')
P = ds(ep + 'P' + d,mode='r')
423/5: P
423/6: P.variables
423/7: P.variables['T']
423/8: P.variables['T'][:]
423/9: P.variables['T'][:].shape
423/10: P.variables['T'][0].shape
423/11: S.variables
424/1: import helper
424/2: d = '19860131_22'
424/3: nd = helper.change_date_by_hours(d,3)
424/4: nd
425/1: import pickle
425/2: f = open('overlapp-mature-individual-counts.txt','rb')
425/3: d = pickle.load(f)
425/4: f.close()
425/5: d.keys()
425/6: d[542].keys()
425/7: d[542]['300'].keys()
425/8: d[542]['450'].keys()
425/9: d[542]['450'][0].shape
425/10: d[542]['450'][0]
425/11: np.any(d[542]['450'][0]!=0)
425/12: import numpy as np
425/13: import numpy as np
425/14: np.any(d[542]['450'][0]!=0)
426/1:
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
from wrf import interplevel as intp
from netCDF4 import Dataset as ds

import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from colormaps import PV_cmap2
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert


pi = '/atmosdyn2/ascherrmann/BA/Dimitri/'
era5 = '/atmosdyn2/era5/cdf/'

minlon = -20
minlat = 15
maxlat = 60
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

PV300hPa  = np.zeros((len(lats),len(lons)))
U300hPa = np.zeros((len(lats),len(lons)))

#date in yyyymmdd_hh in time UTC
d='20180927_01'


##ERA5 data structure: cdf/yyyy/mm/ which holds P,S files etc.
ep = era5 + d[:4] + '/' + d[4:6] + '/'
S = ds(ep + 'S' + d,mode='r')
426/2:
PV = S.variables['PV'][0]
PS = S.variables['PS'][0]
TH = S.variables['TH'][0]
U = P.variables['U'][0]

### vertical levels of ERA5 files
hyam=P.variables['hyam']  # 137 levels
hybm=P.variables['hybm']  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### calculate pressure at vertical levels
ps3d=np.tile(PS[:,:],(len(ak),1,1))
Pr=(ak/100.+bk*ps3d.T).T


u300hpa = intp(U,Pr,300,meta=False)
pv300hpa = intp(PV,Pr,300,meta=False)

PV300hPa += pv300hpa[la0:la1,lo0:lo1]
U300hPa += u300hpa[la0:la1,lo0:lo1]
426/3:
P = ds(ep + 'P' + d,mode='r')
PV = S.variables['PV'][0]
PS = S.variables['PS'][0]
TH = S.variables['TH'][0]
U = P.variables['U'][0]

### vertical levels of ERA5 files
hyam=P.variables['hyam']  # 137 levels
hybm=P.variables['hybm']  #   ''
ak=hyam[hyam.shape[0]-98:] # only 98 levs are used:
bk=hybm[hybm.shape[0]-98:]

### calculate pressure at vertical levels
ps3d=np.tile(PS[:,:],(len(ak),1,1))
Pr=(ak/100.+bk*ps3d.T).T


u300hpa = intp(U,Pr,300,meta=False)
pv300hpa = intp(PV,Pr,300,meta=False)

PV300hPa += pv300hpa[la0:la1,lo0:lo1]
U300hPa += u300hpa[la0:la1,lo0:lo1]
426/4: np.argsort(PV300hPa)
426/5: np.argsort(PV300hPa).shape
426/6: np.sort(PV300hPa)
426/7: np.sort(np.flatten(PV300hPa))
426/8: np.sort(PV300hPa.flatten())
426/9: np.argsort(PV300hPa.flatten())
426/10: PV300hPa
426/11: PV300hPa.flatten()[161]
426/12: PV300hPa.shape
426/13: 13035/161
426/14: int(13035/161)
426/15: 13035%161
427/1: import wrf
428/1: ls
428/2: import pick
428/3: import pickle
428/4: f = open('same-ridge-streamer.txt','rb')
428/5: d = pickle.load(f)
428/6: f.close()
428/7: d
428/8: d.keys()
428/9: ls -lrt */400/streamer-mask.nc
428/10: ls -lrt */350/streamer-mask.nc
428/11: ls -lrt */350/streamer-mask.nc |wc -l
428/12: ls -lrt */250/streamer-mask.nc |wc -l
428/13: ls -lrt */300/streamer-mask.nc |wc -l
428/14: d.keys()
428/15: d[542].keys()
428/16: d[542]['300'].keys()
428/17: d[542]['300']['streamer'].keys()
428/18: d[542]['300']['streamer']
428/19: d[542]['300']['streamer'].size
428/20: len(d[542]['300']['streamer'])
428/21: len(d[542]['300']['ridge'])
428/22: counter = 0
428/23:
for k in d.keys():
    if len(d[k]['300']['streamer'])==0 or len(d[k]['300']['ridge'])==0:
        continue
    counter +=1
428/24: counter
428/25: f = open('same-ridge-streamer-0.8-150.txt','rb')
428/26: t = pickle.load(f)
428/27: f.close
428/28: f.close()
428/29: counter2 = 0
428/30:
for k in t.keys():
    if len(t[k]['300']['streamer'])==0 or len(t[k]['300']['ridge'])==0:
        continue
    counter2 +=1
428/31: counter2
428/32: counter3 = 0
428/33: f = open('same-ridge-streamer-0.9-200.txt','rb')
428/34: z = pickle.load(f)
428/35: f.close()
428/36:
for k in z.keys():
    if len(z[k]['300']['streamer'])==0 or len(z[k]['300']['ridge'])==0:
        continue
    counter3 +=1
428/37: counter3
429/1:
from netCDF4 import Dataset as ds
import numpy as np
import os
import pandas as pd
import pickle


import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import BoundaryNorm
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec


minlon = -70
minlat = 30
maxlat = 75
maxlon = 45

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

f = open(ps + 'same-ridge-streamer-0.9-200.txt','rb')
d = pickle.load(f)
f.close()

p ='300'
s = 'streamer'
r = 'ridge'

overlap = np.zeros((len(lats),len(lons)))

refridge = ds(ps + '325832/300/ridge-mask.nc','r')
refridge = refridge.variables['mask'][56,la0:la1,lo0:lo1]

refstream = ds(ps + '325832/300/old-mask.nc','r')
refstream = refstream.variables['mask'][56,la0:la1,lo0:lo1]

overlap[refstream==3777]+=1
overlap[refridge==4992]-=1

for k in d.keys():
    if len(d[k][p][s])==0 or len(d[k][p][r])==0:
        continue

    tmp = ds(ps + '%06d/300/streamer-mask.nc'%k,'r')
    for l in d[k][p][s]:
        f = l[0]
        mask = tmp.variables['mask'][f,la0:la1,lo0:lo1]
        overlap[mask==l[1]]+=1

    tmp = ds(ps + '%06d/300/ridge-mask.nc'%k,'r')
    for l in d[k][p][r]:
        f = l[0]
        mask = tmp.variables['mask'][f,la0:la1,lo0:lo1]
        overlap[mask==l[1]]-=1
429/2: np.max(overlap)
429/3: d[542]['300']['streamer']
429/4:
for k in d.keys():
    print(len(d[k]['300']['streamer']))
429/5:
for k in d.keys():
  if len(d[k]['300']['streamer'])>0:
    print(len(d[k]['300']['streamer']),d[k]['300']['streamer'])
430/1: ls 000542
430/2: less 000542/overlapping-streamer-tracks-300.txt
431/1: import numpy as np
431/2: t = np.array([1, 2, 3, 4, 5, 5, 6, 7, 8, 8])
431/3: np.unique(t,return_counts=True)
432/1: import pickle
432/2: f = open('ridge-streamer-types-0.8-300.txt','rb')
432/3: d = p
432/4: d = pickle.load(f)
432/5: f.close()
432/6: d.keys()
432/7: f = open('streamer-types-0.8-300.txt','rb')
432/8: s = pickle.load(f)
432/9: f.close()
432/10: s.keys()
432/11: s
432/12: s['325832']
432/13: len(s['325832'])
432/14: d['499030']['300']['streamer']
432/15: d[499030]['300']['streamer']
432/16: d[499030]['300']['ridge']
432/17: s
432/18: d
433/1: import pickle
433/2: f = open('streamer-types-0.8-300.txt','rb')
433/3: ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
433/4: f = open(ps + 'streamer-types-0.8-300.txt','rb')
433/5: s = pickle.load(f)
433/6: f.close()
433/7: s
433/8: s.keys()
433/9: len(s['325832'])
434/1: import pickle
434/2: ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
434/3: f = open(ps + 'streamer-types-0.8-300.txt','rb')
434/4: d = pickle.load(f)
434/5: f.close()
434/6: s = d
434/7: s.keys()
434/8: s['325832']
434/9: len(s['325832']))
434/10: len(s['325832'])
434/11: import numpy as np
434/12: s.keys()
435/1: import numpy as np
435/2: import pickle
435/3: ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
435/4: f = open(ps + 'streamer-types-0.8-300.txt','rb')
435/5: s = pickle.load(f)
435/6: f.close()
435/7: s.keys()
435/8: len(list(s.keys()))
435/9: len(s['325832'])
435/10: len(s['458684'])
435/11:
for k in s.keys():
    print(len(s[k]))
435/12: f = open(ps +'ridge-streamer-types-0.8-300.txt','rb')
435/13: d = pickle.load(f)
435/14: f.close()
435/15: d.keys()
435/16: d
436/1: import os
436/2: c = 0
436/3:
for dirs in os.listdir('./'):
    if dirs[-1]!='c' or dirs[-1]!='t':
        print(dirs)
        c+=1
436/4: c
436/5: dirs
436/6: dirs[-1]
436/7: c = 0
436/8:
for dirs in os.listdir('./'):
    if dirs[-1]!='c' and dirs[-1]!='t':
        print(dirs)
        c+=1
436/9: c
436/10: c = 0
436/11:
for dirs in os.listdir('./'):
    if dirs[-1]=='c' or dirs[-1]=='t':
        continue
    c+=1
    print(dirs)
436/12: c
437/1: import numpy as np
437/2: np.where(np.arange(-168,49,3)==0)
437/3: np.where(np.arange(-168,49,3)==-96)
438/1: import numpy as np
438/2: import pickle
438/3: f = open('premature-ridge-streamer-types-0.8-300-more-than-5-in-19-30.txt','rb')
438/4: d = pickle.load(f)
438/5: f.close()
438/6: d.keys()
438/7: f = open('premature-streamer-types-0.8-300-more-than-5-in-19-30.txt','rb')
438/8: s = pickle.load(f)
438/9: f.close()
438/10: s.keys()
438/11:
for k in s.keys():
    print(len(s[k]))
438/12: s['324089']
438/13: d[324089]
438/14:
for k in s.keys():
    if len(s[k])>20:
        print(k,len(s[k]))
438/15:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
438/16: import matplotlib.pyplot as plt
438/17: from netCDF4 import Dataset as ds
438/18:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
        for l in s[k]:
            pos = np.array([])
            lab = np.array([])
            for u in d[l]:
                pos = np.append(pos,u[1])
                lab = np.append(lab,u[2])
            m = np.argmin(abs(pos-24))
            cm = pos[m]
            cl = lab[m]
            D = ds('%06d/300/streamer-mask.nc'%(int(l)),'r')
            D.close()
438/19:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
        for l in s[k]:
            pos = np.array([])
            lab = np.array([])
            for u in d[l]:
                pos = np.append(pos,u[1])
                lab = np.append(lab,u[2])
            m = np.argmin(abs(pos-24))
            cm = pos[m]
            cl = lab[m]
            D = ds('%06d/300/streamer-mask.nc'%(int(l)),'r')
            D.close()
438/20:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
        for l in s[k]:
            pos = np.array([])
            lab = np.array([])
            for u in d[l]:
                print(u)
                pos = np.append(pos,u[1])
                lab = np.append(lab,u[2])
            print(pos)
            m = np.argmin(abs(pos-24))
            cm = pos[m]
            cl = lab[m]
            D = ds('%06d/300/streamer-mask.nc'%(int(l)),'r')
            D.close()
438/21:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
        for l in s[k]:
            pos = np.array([])
            lab = np.array([])
            for u in d[l]['300']['streamer']:
                print(u)
                pos = np.append(pos,u[1])
                lab = np.append(lab,u[2])
            print(pos)
            m = np.argmin(abs(pos-24))
            cm = pos[m]
            cl = lab[m]
            D = ds('%06d/300/streamer-mask.nc'%(int(l)),'r')
            D.close()
            break
        break
438/22:
for k in s.keys():
    if len(s[k])>=20:
        print(k,len(s[k]))
        for l in s[k]:
            pos = np.array([])
            lab = np.array([])
            for u in d[l]['300']['streamer']:
                pos = np.append(pos,u[1])
                lab = np.append(lab,u[2])
            m = np.argmin(abs(pos-24))
            cm = pos[m]
            cl = lab[m]
            print(cl,cm)
            D = ds('%06d/300/streamer-mask.nc'%(int(l)),'r')
            D.close()
            break
        break
438/23: %save -r /atmosdyn2/ascherrmann/scripts/WRF/ridge-patterns.py 1-999
439/1: import pickle
439/2: f = open('premature-streamer-types-0.8-300-more-than-5-in-19-30.txt','rb')
439/3: s = pickle.load(f)
439/4: f.close()
439/5: ls
439/6: f = open('mature-streamer-types-0.8-300-more-than-5-in-50-60.txt','rb')
439/7: d = pickle.load(f)
439/8: f.close()
439/9: d.keys()
439/10: d['268390'].keys()
439/11: d['268390']
440/1: import pickle
440/2: f = open('80-per-cyclones.txt','rb')
440/3: d = pickle.load(f)
440/4: f.close()
440/5: import numpy as np
440/6: np.where(d['cycano']>=0.8)[0]
440/7: len(np.where(d['cycano']>=0.8)[0])
440/8: d['cycano']
441/1: import numpy as np
441/2: import pickle
441/3: f = open('80-per-cyclones.txt','rb')
441/4: d = pickle.load(f)
441/5: f.close()
441/6: d['cycano']
441/7: d['cycano'].shape
441/8: import pickl
442/1: import pickle
442/2: import numpy as np
442/3: f = open('80-per-cyclones.txt','rb')
442/4: d = pickle.load(f)
442/5: f.close()
442/6: d['cycano'].shape
442/7: np.where(d['cycano']>=0.8)[0]
442/8: len(np.where(d['cycano']>=0.8)[0])
442/9: len(np.where(d['envano']>=0.8)[0])
442/10: len(np.where(d['advano']>=0.8)[0])
442/11: len(np.where(d['advano2']>=0.8)[0])
443/1: import numpy as np
443/2: import pickle
443/3: f = open('80-per-cyclones.txt','rb')
443/4: d = pickle.load(f)
443/5: f.close()
443/6: import pandas as pd
443/7: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
443/8: htSLP = df['htSLPmin'].values
443/9: htSLP = df['htminSLP'].values
443/10: IDs = df['ID'].values
443/11: htslp = np.array([])
443/12:
for i in d['ids']:
    htslp = np.append(htslp,htSLP[np.where(IDs==int(i))[0][0]])
443/13: len(htslp)
443/14: d['htslp'] = htslp
443/15: f = open('80-per-cyclones.txt','wb')
443/16: pickle.dump(d,f)
443/17: f.close()
443/18: np.whereI
443/19: htslp
443/20: len(np.where(htslp>=6)[0])
443/21: len(np.where(htslp>=12)[0])
443/22: d['envano'].shape
443/23: np.where(d['envano'][np.where(htslp>=6)[0]]>0.8)[0].shape
443/24: np.where(d['envano'][np.where(htslp>=12)[0]]>0.8)[0].shape
443/25: np.where(d['advano'][np.where(htslp>=12)[0]]>0.8)[0].shape
443/26: np.where(d['advano'][np.where(htslp>=6)[0]]>0.8)[0].shape
443/27: np.where(d['envano']>0.8)[0].shape
443/28: np.where(d['advano'][np.where(htslp>=3)[0]]>0.8)[0].shape
443/29: np.where(d['envano'][np.where(htslp>=3)[0]]>0.8)[0].shape
443/30: np.where(d['envano'][np.where(htslp>=3)[0]]>0.9)[0].shape
443/31: np.where(d['envano'][np.where(htslp>=6)[0]]>0.9)[0].shape
443/32: np.where(d['envano'][np.where(htslp>=12)[0]]>0.9)[0].shape
443/33: np.where(d['envano']>0.9)[0].shape
443/34: np.where(d['envano']>0.95)[0].shape
443/35: np.where(d['envano'][np.where(htslp>=12)[0]]>0.95)[0].shape
443/36: np.where(d['envano'][np.where(htslp>=6)[0]]>0.95)[0].shape
443/37: np.where(d['envano'][np.where(htslp>=3)[0]]>0.95)[0].shape
443/38: %save -r /atmosdyn2/ascherrmann/scripts/Paper1/extreme-cyclones.py 1-999
444/1: from netCDF4 import Dataset as ds
444/2: tmp = ds('/atmosdyn/era5/cdf/2010/10/H20101010_10','rb')
444/3: tmp = ds('/atmosdyn/era5/cdf/2010/10/H20101010_10','r')
444/4: tmp.variables['plev']
444/5: tmp.variables['plev'][:]
444/6: np.tile
444/7: import numpy as np
444/8: np.tile.help
444/9: help(np.tile())
444/10: np.tile(tmp.variables['plev'][:],(1,21,21))
444/11: np.tile(tmp.variables['plev'][:],(1,21,21)).shape
444/12: np.tile(tmp.variables['plev'][:],(-11,21,21)).shape
444/13: np.tile(tmp.variables['plev'][:],(-1,21,21)).shape
444/14: np.tile(tmp.variables['plev'][:],(len(tmp.variables['plev'][:]),21,21)).shape
444/15: np.tile(tmp.variables['plev'][:],(len(tmp.variables['plev'][:]),21)).shape
444/16: np.tile(tmp.variables['plev'][:],(len(tmp.variables['plev'][:]),1,1)).shape
444/17: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:]
444/18: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:].reshape(37,-1,-1)
444/19: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:]
444/20: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:, None]
444/21: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:][:,None]
444/22: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:][:,None,None]
444/23: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:][:,None,None][0]
444/24: np.ones((len(tmp.variables['plev'][:]),21,21))*tmp.variables['plev'][:][:,None,None][-1]
445/1: import numpy as np
445/2: np.ones((11,11)) * np.arange(-2.5,3,0.5)[:,None]
445/3: np.ones((11,11)) * np.arange(-2.5,3,0.5)[None,:]
446/1: import numpy as np
446/2: np.zeros((10,10,10))
446/3: k = np.zeros((10,10,10))
446/4: k[2:5,2:5,2:5] = 1
446/5: z,y,x = np.where(k!=0)
446/6: z
446/7: x
446/8: y
447/1: import numpy as np
448/1: from wrf import interplevel as intp
448/2: import numpy as np
448/3: k = np.arange(10)
448/4: k
448/5: k.shape
448/6: k.reshape(10,-1).shape
448/7: k.reshape(10,-1,-1).shape
448/8: k.reshape((10,-1,-1)).shape
448/9: k[:,None,None].shape
448/10: l = k* 2
448/11: l
448/12: intp(k[:,None,None],l[:,None,None],2,meta=False)
448/13: np.tile(k,1,1)
448/14: np.tile((k,1,1))
448/15: np.tile(k,(k.shape[0],1,1))
448/16: np.tile(k,(k.shape[0],1,1))[0]
448/17: np.tile(k,(k.shape[0],1,1))[:,:,0]
449/1: import pickle
449/2: f = open('test-PV-distance.txt','rb')
449/3: d = pickle.load(f)
449/4: f.close()
449/5: PVdi = d['pv']
449/6: np.stack((np.arange(5),np.arange(5),np.arange(5)))
449/7: import numpy as np
449/8: np.stack((np.arange(5),np.arange(5),np.arange(5)))
449/9: np.stack((np.arange(5),np.arange(5),np.arange(5)),axis=1)
449/10: f = open('test-PV-distance.txt','rb')
449/11: d = pickle.load(f)
449/12: f.close()
449/13: d.keys()
449/14: PVdi = d['pv']
449/15: r = d['r']
450/1: import pickle
450/2: f = open('test-PV-distance.txt','rb')
450/3: d = pickle.load(f)
450/4: f.close()
450/5: d['pv'].keys()
450/6: d['pv']['low'].keys()
450/7: d['pv']['low']['224329']
450/8: d['pv']['upp']['224329']
450/9: d['ghtref850']['low']['24329']
450/10: d['ghtref850']['low']['224329']
450/11: d['ghtref850']['upp']['224329']
451/1: import pickle
451/2: f = open('general-types-0.5-ridge-streamer-types-0.8-300-in-track.txt','rb')
451/3: d = pickle.load(f)
451/4: f.close()
451/5: f = open('general-types-size-0.5-streamer-types-0.8-300-in-track.txt','rb')
451/6: s = pickle.load(f)
451/7: f.close()
451/8: s.keys()
451/9: d.keys()
451/10: len(list(d.keys()))
451/11: s.keys()
451/12: s['324089,50']
451/13: np.unique(s['324089,50'])
451/14: import numpy as np
451/15: np.unique(s['324089,50'])
452/1: import numpy as np
452/2: ar = np.arange(0,21,2)
452/3: ar
452/4: np.delete(ar,2)
452/5: np.delete(ar,ar==2)
452/6: ar
452/7: (5,2)==(2,5)
452/8: (5,2)==(5,2)
453/1: import pickle
453/2: f = open('general-types-0.5-ridge-streamer-types-0.8.txt','rb')
453/3: s = pickle.load(f)
453/4: f.close()
453/5: s.keys()
453/6:
for k in s.keys():
    print(len(s[k]))
453/7:
for k in s.keys():
    print(len(s[k]),s[k])
453/8: f = open('general-types-size-0.5-ridge-streamer-types-0.8.txt','rb')
453/9: f = open('general-types-size-0.5-streamer-types-0.8.txt','rb')
453/10: d = pickle.load(f)
453/11: f.close()
453/12: d.keys()
453/13: s.keys()
453/14:
for k in d.keys():
    print(d[k])
453/15:
for k in d.keys():
    print(len(d[k]))
453/16: f = open('general-types-size-0.5-streamer-types-0.8.txt','rb')
453/17: d = pickle.load(f)
453/18: f.close()
453/19:
for k in d.keys():
    print(len(d[k]))
454/1: import pickle
454/2: f = open('general-types-size-0.2-streamer-types-0.8.txt','rb')
454/3: d = pickle.load(f)
454/4: f.close()
454/5: d.keys()
454/6: d['010917,60,3343,4524']
454/7:
for k in d.keys():
    print(len(d[k]))
454/8:
for k in d.keys():
    if len(d[k])>10:
        print(len(d[k]))
455/1: import pickle
455/2: f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/general-types-size-0.2-streamer-types-0.8.txt','rb')
455/3: d = pickle.load(f)
455/4: f.close()
455/5:
for k in d.keys():
    if len(d[k])>=20:
        print(len(d[k]))
455/6:
for k in d.keys():
    if len(d[k])>=20:
        print(k,len(d[k]))
455/7:
for k in d.keys():
    if len(d[k])>=50:
        print(k,len(d[k]))
455/8: k
455/9: d[k]
455/10: d['323113,21,1583,1881']
455/11:
for k in d.keys():
    if len(d[k])>=50:
        print(k,len(d[k]))
455/12: d['324089,55,5851,5582']
456/1: x,y,z = eval('5,3,2')
456/2: x
456/3: y
456/4: z
457/1: import os
457/2:
for f in os.listdir('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/000542/'):
    if f.startswith('D'):
        print(f)
457/3:
for f in os.listdir('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/000542/300/'):
    if f.startswith('D'):
        print(f)
458/1: import pickle
458/2: f = open('general-track-types-size-0.2-streamer-types-0.8.txt','rb')
458/3: d = pickle.load(f)
458/4: f.close()
458/5: d.keys()
458/6:
for k in d.keys():
    if len(d[k])>=50:
        print(k,len(d[k]))
458/7: d['201426,65,4451,4843']
458/8: len(d['201426,65,4451,4843'])
458/9: f = open('general-track-types-0.2-ridge-streamer-types-0.8.txt','rb')
458/10: s = pickle.load(f)
458/11: f.close()
458/12: s.keys()
458/13: s['201426,65,4451,4843']
458/14: #
458/15: s['201426,65,4451,4843'].keys()
458/16:
s['201426,65,4451,4843'][
ridge']
458/17: s['201426,65,4451,4843']['ridge']
458/18: s['201426,65,4451,4843']['streamer']
459/1: import pickle
459/2: f = open('general-track-types-0.2-ridge-streamer-types-0.8.txt','rb')
459/3: d = pickle.load(f)
459/4: f.close()
459/5: d.keys()
459/6:
for k in d.keys():
    if len(d[k])>=50:
        print(k,len(d[k]))
459/7:
for k in d.keys():
    if len(d[k])>=20:
        print(k,len(d[k]))
459/8:
for k in d.keys():
    if len(d[k])>=10:
        print(k,len(d[k]))
459/9:
for k in d.keys():
    if len(d[k])>=5:
        print(k,len(d[k]))
459/10:
for k in d.keys():
    if len(d[k])>=2:
        print(k,len(d[k]))
459/11: f = open('general-track-types-size-0.2-streamer-types-0.8.txt','rb')
459/12: s = pickle.load(f)
459/13: f.close()
459/14:
for k in s.keys():
    print(len(s[k]),s[k])
459/15:
for k in s.keys():
    if len(s[k])>=50:
        print(k,len(s[k]))
459/16: s['201426,65,4451,4843']['streamer']
459/17: s['201426,65,4451,4843']
459/18: d['201426,65,4451,4843'].keys()
459/19: d['201426,65,4451,4843']['streamer']
459/20:
from netCDF4 import Dataset as ds
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib
minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/'
era5 = '/atmosdyn2/era5/cdf/'

f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/general-track-types-size-0.2-streamer-types-0.8.txt','rb')
d = pickle.load(f)
f.close()

f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/general-track-types-size-0.2-ridge-streamer-types-0.8.txt','rb')
s = pickle.load(f)
f.close()
459/21:
f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/general-track-types-0.2-ridge-streamer-types-0.8.txt','rb')
s = pickle.load(f)
f.close()
459/22:
for k in d.keys():
    if len(d[k])>=50:
        print(k,len(d[k]))
459/23:
for k in d.keys():
    if len(d[k])>=40:
        print(k,len(d[k]))
459/24:
for k in d.keys():
    if len(d[k])>=30:
        print(k,len(d[k]))
459/25: d['516611,59,6760,4596']
459/26: s['516611,59,6760,4596']['streamer']
459/27: pwd
459/28:
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    print(f)
459/29:
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
459/30:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ol = np.array([])
    for k in d.keys():
        for l in d[k]:
            break
        break
459/31:
for k in d.keys():
    for l in d[k]:
        print(l)
    break
459/32:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys)))
    for k in d.keys():
        for l in s[k]['streamer']:
            break
        break
459/33:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for k in d.keys():
        for l in s[k]['streamer']:
            break
        break
459/34: l
459/35:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        for l in s[k]['streamer']:
            tmp = 0
            if l[0]!=f:
                continue
            break
        break
459/36: f
459/37: ID
459/38:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    print(ID)
    for q,k in enumerate(list(d.keys())):
        tmp = 0
        
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
            
            if l[1]>tmp:
                tmp = l[1]
                
        ov[ID][q]=tmp
459/39: ov[ID]
459/40:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        tmp = 0   
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
            
            if l[1]>tmp:
                tmp = l[1]
                
        ov[ID][q]=tmp
459/41:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        tmp = 0   
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
            if int(k[:6])==ID:
                continue
                
            if l[1]>tmp:
                tmp = l[1]
                
        ov[ID][q]=tmp
459/42:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = np.array([])
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k] = np.append(wi[k],(ID,np.max(ov[ID])))
459/43:
for k in d.keys():
    if len(wi[k])>10:
        print(k,len(wi[k]))
459/44: counter = 0
459/45:
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
459/46: counter
459/47: wi[k]
459/48:
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        wi[k]
459/49:
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
459/50:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = []
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k].append((ID,np.max(ov[ID])))
459/51:
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
459/52: ov
459/53:
for ID in ov.keys():
    print(np.argmax(ov[ID]))
459/54:
for ID in ov.keys():
    print(len(ov[ID]),np.argmax(ov[ID]))
459/55:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        tmp = 0   
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
                
            if l[1]>tmp:
                tmp = l[1]
                
        ov[ID][q]=tmp
459/56:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = []
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k].append((ID,np.max(ov[ID])))
459/57: wi
459/58:
counter = 0
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
459/59:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        tmp = 0   
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
            if int(k[:6])==ID:
                continue    
            if l[1]>tmp:
                tmp = l[1]
                
        ov[ID][q]=tmp
459/60:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = []
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k].append((ID,np.max(ov[ID])))
459/61:
counter = 0
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
459/62:
ov = dict()
for f in os.listdir('.'):
    if f[-1]=='c' or f[-1]=='t':
        continue
    ID = int(f)
    ov[ID] = np.zeros(len(list(d.keys())))
    for q,k in enumerate(list(d.keys())):
        tmp = 0   
        for l in s[k]['streamer']:
            if l[0]!=ID:
                continue
                
            if l[1]>tmp:
                tmp = l[1]
        if tmp==0:
            tmp=np.nan        
        ov[ID][q]=tmp
459/63:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = []
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k].append((ID,np.max(ov[ID])))
459/64:
counter = 0
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
459/65:
wi = dict()
for q,k in enumerate(list(d.keys())):
    wi[k] = []
    for ID in ov.keys():
        if np.argmax(ov[ID])==q:
            wi[k].append((ID,np.nanmax(ov[ID])))
459/66:
counter = 0
for k in d.keys():
    counter +=len(wi[k])
    if len(wi[k])>10:
        print(k,len(wi[k]))
        print(wi[k])
460/1: import pickle
460/2: f = open('100-region-season.txt','rb')
460/3: d = pickle.load(f)
460/4: f.close()
460/5: d['DJF']['central']
460/6: d
460/7: f = open('100-region-season.txt','rb')
460/8: d = pickle.load(f)
460/9: f.close()
460/10: d
460/11: f = open('100-region-season.txt','rb')
460/12: d = pickle.load(f)
460/13: f.close()
460/14: d
460/15: f = open('100-region-season.txt','rb')
460/16: d = pickle.load(f)
460/17: f.close()
460/18: d
460/19:
for k in d.keys():
    for l in d[k].keys():
        d[k][l] = np.delete(d[k][l],np.where(d[k][l]==0)[0])
460/20: import numpy as np
460/21:
for k in d.keys():
    for l in d[k].keys():
        d[k][l] = np.delete(d[k][l],np.where(d[k][l]==0)[0])
460/22: d
460/23: f = open('100-region-season.txt','wb')
460/24: pickle.dump(d,f)
460/25: f.close()
461/1:
import pandas as pd
import os
import pickle
import numpy as np
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
seasons = ['DJF','SON']

df = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/pandas-basic-data-all-deep-over-sea-12h.csv')
df = df.iloc[np.where(df['reg'].values=='MED')[0]]

dID = df['ID'].values
htminSLP = df['htSLPmin'].values
mdates = df['dates'].values

f = open(ps + '100-region-season.txt','rb')
d = pickle.load(f)
f.close()


for lev in [450]: #[250,350,400,450]:
    for sea in seasons:
        for k in d[sea].keys():
            for ID in d[sea][k]:
                print(ID)
461/2: less 4regionsPV-days.py
462/1:
import pandas as pd
import os
import numpy as np
from netCDF4 import Dataset as ds

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
df = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/pandas-basic-data-all-deep-over-sea-12h.csv')
df = df.iloc[np.where(df['reg'].values=='MED')[0]]
IDs = df['ID'].values
months = df['months'].values

seasons = ['DJF','SON']
mo = [np.array([12,1,2]),np.array([9,10,11])]
pre = [250,350,400,450]

for q,sea in enumerate(seasons):
  for pr in pre:
    av = ds(dp + 'PV%dhPa'%pr + sea + '.nc',mode='r')
    av = av.variables['PV.MEAN'][0,0]
463/1: import numpy as np
463/2: from netCDF4 import Dataset as ds
463/3: d = ds('/atmosdyn2/era5/cdf/2010/10/B20101010_10','r')
463/4: SLP = d.variables['MSL']
463/5: SLP.shape
463/6: SLP=  SLP[0]
463/7: np.sort(SLP)
463/8: np.sort(SLP).shape
463/9: np.argsort(SLP)
463/10: SLP/=100
463/11: np.sort(SLP)
463/12: SLP.flatten()
463/13: np.sort(SLP.flatten())
463/14: np.argsort(SLP.flatten())
463/15: import pickle
463/16: di = dict()
463/17: di['SLPmean'] = np.array([])
463/18: di['PVmean'] = np.array([])
463/19: di['date'] = np.array([])
463/20: d
463/21: di
463/22: f = open('test.txt','wb')
463/23: pickle.dump(di,f)
463/24: pwd
463/25: f.close()
464/1: import pickle
464/2: f = open('test.txt','rb')
464/3: di = pickle.load(f)
464/4: f.close()
464/5: SLP = di['SLPmean']
464/6: SLP
464/7: di
465/1: import pickle
465/2: f = open('general-types-size-0.2-streamer-types-0.8.txt','rb')
465/3: d = pickle.load(f)
465/4: f.close()
465/5: f = open('general-types-0.2-ridge-streamer-types-0.8.txt','rb')
465/6: s = pickle.load(f)
465/7: f.close()
465/8: s.keys()
465/9: for k in s.keys():['119324,26']
465/10:
for k in s.keys():
    if k[:6]=='119324' and k[7:9]=='26':
        print(k)
465/11:
for k in s.keys():
    if k[:6]=='119324':
        print(k)
465/12: d.keys()
465/13:
for k in d.keys():
    if k[:6]=='119324':
        print(k)
465/14: ls
465/15: ls -lrt
465/16:
for k in d.keys():
    if k[:6]=='119324':
        print(k)
465/17: s['119324,60,3192,3585'].keys()
465/18: s['119324,60,3192,3585']['ridge']
466/1: import pickle
466/2: f = open('/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/100-region-season.txt','rb')
466/3: d = pickle.load(f)
466/4: f.close()
466/5: d
466/6: d.keys()
467/1:
import numpy as np
import os
import pandas as pd
import pickle

import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper

minlon = -10
minlat = 25
maxlat = 65
maxlon = 60

minrlon = -70
minrlat = 30
maxrlat = 65
maxrlon = 0

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

lonsr = np.where((LON>=minrlon) & (LON<=maxrlon))[0]
latsr = np.where((LAT<=maxrlat) & (LAT>=minrlat))[0]

lor0,lor1,lar0,lar1 = lonsr[0],lonsr[-1]+1,latsr[0],latsr[-1]+1

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
pc = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

overlap = dict()
streamertypes = dict()

trange = np.arange(-168,49,3)
df = pd.read_csv('/atmosdyn2/ascherrmann/011-all-ERA5/data/pandas-basic-data-all-deep-over-sea-12h.csv')
dID = df['ID'].values
htminSLP = df['htSLPmin'].values
mdates = df['dates'].values
months = df['months'].values

sizecheck=0.2
checkval=0.8

pr = '300'
pool = np.array([])
counts = 0
for dirs in os.listdir(ps):
    if dirs[-1]=='c' or dirs[-1]=='t':
        continue

    counts +=1
    for kk in range(65):
        pool = np.append(pool,'%06d,%02d'%(int(dirs),kk))

overlapmeasure = np.zeros(counts * 65)
467/2: pools = np.tile((pool,overlapmeasure))
467/3: np.tile
467/4: help(np.tile())
467/5: pools = np.stack((pools,overlapmeasure),axis=1)
467/6: pools = np.stack((pool,overlapmeasure),axis=1)
467/7: pools.shape
468/1:
from netCDF4 import Dataset as ds
import numpy as np
import os
import pandas as pd
import pickle

import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper

minlon = -10
minlat = 25
maxlat = 65
maxlon = 60

minrlon = -70
minrlat = 30
maxrlat = 65
maxrlon = 0

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

lonsr = np.where((LON>=minrlon) & (LON<=maxrlon))[0]
latsr = np.where((LAT<=maxrlat) & (LAT>=minrlat))[0]

lor0,lor1,lar0,lar1 = lonsr[0],lonsr[-1]+1,latsr[0],latsr[-1]+1

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
pc = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'
468/2: f = open(ps + 'test1.txt','rb')
468/3: d = pickle.load(f)
468/4: f.close()
468/5: d
468/6: f = open(ps + 'test3.txt','rb')
468/7: dd = pickle.load(f)
468/8: f.close9)
468/9: f.close()
468/10: dd
468/11: np.sort(dd['savepool'][:,1])
468/12: np.sort(dd['470479,34,2374,4291']['savepool'][:,1])
468/13: np.sort(dd['470479,34,2374,4291']['savepool'][:,1])[-100:]
468/14: np.sort(dd['470479,34,2374,4291']['savepool'][:,1])[-10:]
468/15: np.sort(dd['470479,34,2374,4291']['savepool'][:,1])[-11:]
468/16: dd['470479,34,2374,4291']['savepool'][np.argsort(dd['470479,34,2374,4291']['savepool'][:,1])[-11:],0]
468/17: f = open(ps + 'test3.txt','rb')
468/18: ddd=pickle.load(f)
468/19: f.close()
468/20: ddd['470479,34,2374,4291']['savepool'][np.argsort(ddd['470479,34,2374,4291']['savepool'][:,1])[-11:],0]
468/21: np.sort(ddd['470479,34,2374,4291']['savepool'][:,1])[-11:]
468/22: np.sort(ddd['470479,34,2374,4291']['savepool'][:,1])[-6:]
468/23: ddd['470479,34,2374,4291']['savepool'][np.argsort(ddd['470479,34,2374,4291']['savepool'][:,1])[-6:],0]
468/24: ddd['470479,34,2374,4291'].keys
468/25: ddd['470479,34,2374,4291'].keys()
468/26: ddd['470479,34,2374,4291']['streamer']
468/27: f = open(ps + 'test4.txt','rb')
468/28: s = pickle.load(f)
468/29: f.close()
468/30: s.keys()
468/31: s
469/1:
from netCDF4 import Dataset as ds
import numpy as np
import os
import pandas as pd
import pickle

import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
469/2: ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
469/3: f = open(ps + 'full-overlap-matrix-0.8-third.txt','rb')
469/4: d = pickle.load(f)
469/5: f.close()
469/6: mat = d['matrix']
469/7: mat.shape
469/8: np.where(mat[0]!=0)
469/9: d.keys()
470/1: import numpy as np
470/2: a = np.array([[5,6,7],[8,9,1]])
470/3: a
470/4: a[np.array([0,2]),np.array([0,1])]
470/5: a[np.array([0,1]),np.array([0,1])]
470/6:
LON=np.arange(-180,180,0.5)
LAT=np.arange(-90,90.1,0.5)
470/7:
latids1,lonids1 = np.where((xx>=-5) & (xx<2) & (yy>=30) & (yy<=42))# & (LSM[0]==0))
latids2,lonids2 = np.where((xx>=2) & (xx<=42) & (yy>=30) & (yy<48))
470/8:
xx,yy=np.meshgrid(LON,LAT)

latids1,lonids1 = np.where((xx>=-5) & (xx<2) & (yy>=30) & (yy<=42))# & (LSM[0]==0))
latids2,lonids2 = np.where((xx>=2) & (xx<=42) & (yy>=30) & (yy<48))# & (LSM[0]==0))

lonids = np.append(lonids1,lonids2)
latids = np.append(latids1,latids2)
470/9: lonids
470/10: len(lonids)
470/11: latids
471/1: a = [5,[10,12],[13,14]]
471/2: x,y = a[2]
471/3: x
471/4: y
472/1: import numpy as np
472/2: import pandas as pd
472/3: import matplotlib.pyplot as plt
472/4: sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
472/5:
fig,ax = plt.subplots()
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,df['sumPV'].values,color='k')
plt.show()
472/6: import os
472/7:
fig,ax = plt.subplots()
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,df['sumPV'].values,color='k')
plt.show()
472/8: plt.close('all')
472/9:
fig,ax = plt.subplots()
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
plt.show()
472/10: plt.close('all')
472/11: from scipy.stats import pearsonr as pr
472/12:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(pr(df['minSLP'].values,abs(df['sumPV'].values)))
            
print(pr(fullslp,fullpv))
plt.show()
472/13:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/14:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='15' or r[3:5]=='15' or r[-2:]=='15':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/15:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[4:6]=='30' or r[3:5]=='30':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/16:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-2:]=='30' or r[3:5]=='30':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/17:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-3:]=='-30' or r[3:5]=='30':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/18:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--30' or r[3:5]=='30':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/19:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--30' or r[3:5]=='30' or r=='all':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/20:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--45' or r[3:5]=='45':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/21:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--60' or r[3:5]=='60':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['sumPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['sumPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['sumPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/22:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--60' or r[3:5]=='60':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['ntraj'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['ntraj'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['ntraj'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/23:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=45
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['ntraj'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['ntraj'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['ntraj'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/24:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=30
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['ntraj'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['ntraj'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['ntraj'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/25:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=15
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['ntraj'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['ntraj'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['ntraj'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/26:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=15
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['cycperPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['cycperPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['cycperPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/27:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=30
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['cycperPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['cycperPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['cycperPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/28:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=45
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['cycperPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['cycperPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['cycperPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/29:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=45
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['cycperPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['cycperPV'].values))
            print(o,r,pr(df['minSLP'].values,df['cycperPV'].values),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/30:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
val=60
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['cycperPV'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['cycperPV'].values))
            print(o,r,pr(df['minSLP'].values,abs(df['cycperPV'].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/31:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=60
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df['var'].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df['var'].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/32:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=60
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/33:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=45
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/34:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=40
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/35:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=30
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/36:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=15
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/37:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=15
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        #if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
        if r[2:6]=='--%d'%val or r[3]=='0':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/38:
fig,ax = plt.subplots()
fullslp = np.array([])
fullpv = np.array([])
var='htSLPmin'
val=15
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if r=='all':
            continue
        #if r[-4:]=='--%d'%val or r[3:5]=='%d'%val:
        if r[2:6]=='--%d'%val or r[3]=='0':
            df = pd.read_csv(sp + o + '/'+  r + '/evaluated-PV-data-per-cyclone' + o + '-' + r + '.csv')
            ax.scatter(df['minSLP'].values,abs(df[var].values),color='k')
            fullslp = np.append(fullslp,df['minSLP'].values)
            fullpv = np.append(fullpv,abs(df[var].values))
            print(o,r,pr(df['minSLP'].values,abs(df[var].values)),df['minSLP'].values.shape)
            
print(pr(fullslp,fullpv))
plt.show()
plt.close('all')
472/39: %save -r /atmosdyn2/ascherrmann/scripts/all-oceans/basic-correlations.py 1-999
473/1: import pickle
473/2: ls -lrt
473/3: f = open('DJF-west-general-types-size-0.2-streamer-types-0.8.txt','rb')
473/4: d = pickle.load(f)
473/5: f.close()
473/6: d.keys()
473/7:
for k in d.keys():
    if k[:9] == '337315,05':
        print(k)
473/8: d['337315,05,510,622']
473/9:
for l in d['337315,05,510,622']:
    if int(l[7:9])<20:
        print(l)
474/1: import mpi4py
474/2: pytorch
474/3: import pytorch
475/1: import pickle
475/2: f = open('overlap-matrix-0.8-all.txt','rb')
475/3: d = pickle.load(f)
475/4: f.close()
475/5: d['pool']
475/6: d['pool'].shape
475/7: d['overlapmeasure'].shape
475/8: d['overlapmeasure'][:10,:10]
476/1: import netCDF4 import Dataset as ds
476/2: from netCDF4 import Dataset as ds
476/3: d = ds('D19800105_22','rb')
476/4: d = ds('D19800105_22','r')
476/5: d.variables['mask'].shape
476/6: d.variables
476/7: d = ds('streamer-mask-1.5.nc','r')
476/8: d
476/9: d['mask'].shape
476/10: d['mask'][0].shape
477/1:
from netCDF4 import Dataset as ds
import numpy as np
import os
import pandas as pd
import pickle

import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper

minlon = -10
minlat = 25
maxlat = 65
maxlon = 60

minrlon = -70
minrlat = 30
maxrlat = 65
maxrlon = 0

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

lonsr = np.where((LON>=minrlon) & (LON<=maxrlon))[0]
latsr = np.where((LAT<=maxrlat) & (LAT>=minrlat))[0]

lor0,lor1,lar0,lar1 = lonsr[0],lonsr[-1]+1,latsr[0],latsr[-1]+1
477/2: lo0
477/3: lo1
477/4: la0
477/5: la1
477/6: lo1-lo0
477/7: la1-la0
477/8: lonsr,latsr
477/9: lonsr[-1]+1-lonsr[0]
477/10: latsr[-1]+1-latsr[0]
478/1: import pickle
478/2: f = open('cluster-434060-19.txt','rb')
478/3: d = pickle.load(f)
478/4: f.close()
478/5: d
479/1: import pickle
479/2: f = open('cluster-528287-21.txt','rb')
479/3: d = pickle.load(f)
479/4: f.close()
479/5: d
479/6: d['measure'].shape
479/7: len(d['measure'])
480/1: import pickle
480/2: f = open('cluster-528287-21.txt','rb')
480/3: d = pickle.load(f)
480/4: f.close()
480/5: d
480/6: d['stream']
480/7: d['stream'][0]
480/8: d['stream'][0][0]
480/9: d['stream'][0][0][1]
480/10: d['stream'][0][1]
480/11: d['stream'][0][2]
480/12: d['stream']
480/13: d['ridge']
481/1: import pickle
481/2: f = open('full-overlap-matrix-0.9-third.txt','rb')
481/3: d = pickle.load(f)
481/4: f.close()
481/5: d.keys()
481/6: d['matrix'].keys()
481/7: d['matrix'].shape
481/8: pool = d['pool']
481/9: pool
481/10: mat = d['matrix']
481/11: mat[0]
481/12: np.where(mat[0]!=0)
481/13: import num
481/14: import numpy as np
481/15: np.where(mat[0]!=0)
481/16: mat[0][np.where(mat[0]!=0)]
481/17:
for k in range(mat.shape[0]):
    if np.where(mat[k]>0)[0].shape[0]>10:
        print(k)
481/18: k
481/19: mat[k].shape
481/20: mat[k].size
481/21: c = 0
481/22:
for k in range(mat.shape[0]):
    if np.where(mat[k]>0)[0].shape[0]>10:
        print(k)
        c+=1
481/23: c
481/24:
for k in range(mat.shape[0]):
    if np.where(mat[k]>0)[0].shape[0]>10:
        print(k,np.where(mat[k]>0)[0].size)
        c+=1
481/25: pool[5582]
482/1: import numpy as np
482/2: import netCDF4 import Dataset as ds
482/3: from netCDF4 import Dataset as ds
482/4: f = open('full-overlap-matrix-0.8-third.txt','rb')
482/5: d = pickle.load(f)
482/6: import pickle
482/7: d = pickle.load(f)
482/8: mat = d['matrix']
482/9: mat.shape
482/10: tmat = mat[:10,:10]
482/11: tmat
482/12: tmat = mat[:5,:5]
482/13: tmat
482/14: tmat.T
482/15: tmat.transpose
482/16: tmat.transpose()
482/17: tmat.T
482/18: tmat+tmat.T
482/19: tmat += tmat.T
482/20: tmat
482/21: pool = d['pool']
482/22: pool[0]
482/23: list(d.keys())[:10]
482/24: d['434060,00,72,41'].keys()
482/25: d['434060,00,72,41']['streamer']
482/26: len(list(d.keys()))
482/27: mat.shape
482/28: list(d.keys())[1]
482/29: eval(list(d.keys())[1])
482/30: eval(list(d.keys())[1][10:])
483/1:
from netCDF4 import Dataset as ds
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/matrix/'
era5 = '/atmosdyn2/era5/cdf/'

sea = 'DJF'
re = 'black'
a = 0
f = open(ps + 'full-overlap-matrix-0.8-third.txt','rb')
d = pickle.load(f)
f.close()

pool = d['pool']
mat = d['matrix']
mat += mat.T
483/2: li = np.array(list(d.keys()))
483/3: mat
483/4: li.shape
483/5: li.size
483/6:
for q,k in zip(range(mat.shape[0]),li):
        arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]

    if loc.size>=10:
483/8:
for q,k in zip(range(mat.shape[0]),li):
    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]

    if loc.size>=10:
        #fig = plt.figure(figsize=(9,4))
        #gs = gridspec.GridSpec(ncols=2, nrows=1)
        #ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        #ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        #ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        #ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        #counters = np.zeros((len(lats),len(lons)))
        #counterr = np.zeros_like(counters)
        ##PV = np.zeros_like(counters)
        #MSL = np.zeros_like(counters)
        #avc = 0
        print(loc)
        for l in loc:
            t = pool[l]
            kk = int(t[7:9])
            try:
                sv,rv = eval(t[10:])
            except:
                print(t)
484/1: import pickle
484/2: f = open('genesis-cluster-309341-40.txt','rb')
484/3: d = pickle.load(f)
484/4: f.close()
484/5: d.keys()
484/6: d['stream']
484/7: d['measure']
485/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

import xarray as xr
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle

import cartopy
import matplotlib.gridspec as gridspec

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm

LON = np.round(np.linspace(-180,180,901),1)
LAT = np.round(np.linspace(0,90,226),1)

def find_nearest_grid_point(lon,lat):

    dlon = LON-lon
    dlat = LAT-lat

    lonid = np.where(abs(dlon)==np.min(abs(dlon)))[0][0]
    latid = np.where(abs(dlat)==np.min(abs(dlat)))[0][0]

    return lonid,latid


CT = 'MED'
pload = '/atmosdyn2/ascherrmann/010-IFS/ctraj/MED/use/'
psave = '/atmosdyn2/ascherrmann/010-IFS/'

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/scripts/ERA5-utils/NORO')
ZB = NORO['ZB'].values[0]
Zlon = NORO['lon']
Zlat = NORO['lat']
Emaxv = 1200
Eminv = 800
#elevation_levels = np.arange(Eminv,Emaxv,400)
elevation_levels = np.array([Eminv,1600,2400])

f = open(pload+'PV-data-' + CT + 'dPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

datadi = data['rawdata']
dit = data['dit']

gridmap = dict()
labs = helper.traced_vars_IFS()
486/1: import pickle
486/2: f = open('genesis-cluster-309341-40.txt','rb')
486/3: d = pickle.load(f)
486/4: f.close()
486/5: d
487/1:
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

setto='genesis'
ovval=0.9
if setto=='genesis':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
if setto=='mature':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/' + setto + '-matrix-%.1f/'%ovval
era5 = '/atmosdyn2/era5/cdf/'

if not os.path.isdir(pi):
    os.mkdir(pi)

a = 0
f = open(ps + setto + '-full-overlap-matrix-%.1f-all.txt'%ovval,'rb')
d = pickle.load(f)
f.close()

pool = d['pool']
mat = d['matrix']
mat += mat.T
487/2: mat
487/3: mat[0]
487/4: np.where(mat[0]!=0)
487/5:
for k in range(mat.shape[0]):
    print(len(np.where(mat[k]!=0)[0]))
487/6: pool
487/7: len(pool)
488/1: import pickle
488/2: f = open('full-overlap-matrix-0.9-all.txt','rb')
488/3: d = pickle.load(f)
488/4: f.close()
488/5: mat = d['matrix']
488/6: mat += mat.T
488/7:
for k in range(mat.shape[0]):
    arr = mat[k]
    loc = np.where((arr>0) & (arr<=2))[0]
    if loc.size>=20:
        print(len(loc))
488/8: import numpy as np
488/9:
for k in range(mat.shape[0]):
    arr = mat[k]
    loc = np.where((arr>0) & (arr<=2))[0]
    if loc.size>=20:
        print(len(loc))
488/10: f = open('full-overlap-matrix-0.9-third.txt','rb')
488/11: d2 = pickle.load(f)
488/12: mat2 = d2['matrix']
488/13: mat2 +=mat2.T
488/14:
for k in range(mat2.shape[0]):
    arr = mat2[k]
    loc = np.where((arr>0) & (arr<=2))[0]
    if loc.size>=20:
        print(len(loc))
489/1:
from netCDF4 import Dataset as ds
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

setto='mature'
setto='genesis'
ovval=0.8
#ovval=0.8
frac='third'
#frac='fourth'

if setto=='genesis':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
if setto=='mature':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/' + setto + '-matrix-%.1f-%s/'%(ovval,frac)
era5 = '/atmosdyn2/era5/cdf/'

if not os.path.isdir(pi):
    os.mkdir(pi)

a = 0
f = open(ps + setto + '-full-overlap-matrix-%.1f-%s.txt'%(ovval,frac),'rb')
d = pickle.load(f)
f.close()

pool = d['pool']
mat = d['matrix']
mat += mat.T

li = np.array(list(d.keys()))
489/2: li
489/3: pool[0]
489/4:
for q,k in zip(range(mat.shape[0]),li):

    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]
    if pool!='013375,42' and pool!='014514,33' and pool!='130632,35' and pool!='201508,34':
        continue
    if loc.size>=30:
        ids = np.array([fi[:6]])
        loc2 = np.array(loc[0])
#        print(ids)
        for l in loc:
            if not np.any(ids==pool[l][:6]):
#                print(loc2,ids)
                loc2 = np.append(loc2,l)
                ids = np.append(ids,pool[l][:6])

        if loc2.size<20:
            continue

        fig = plt.figure(figsize=(9,4))
        gs = gridspec.GridSpec(ncols=2, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        counters = np.zeros((len(lats),len(lons)))
        counterr = np.zeros_like(counters)
        PV = np.zeros_like(counters)
        MSL = np.zeros_like(counters)
        avc = 0
        fulldates = np.array([])
        for l in loc2:
            t = li[l]
            kk = int(t[7:9])
            sv,rv = eval(t[10:])

            avc+=1
            dates = np.array([])
            dirs = t[:6]

            sm = ds(ps + dirs + '/300/streamer-mask.nc','r')
            rm = ds(ps + dirs + '/300/ridge-mask.nc','r')
            sm = sm.variables['mask'][kk,la0:la1,lo0:lo1]
            rm = rm.variables['mask'][kk,la0:la1,lo0:lo1]

            for f in os.listdir(ps + dirs + '/300/'):
                if f.startswith('D'):
                    dates = np.append(dates,f)

            date = dates[kk]
            print(date,dirs,kk)
            fulldates = np.append(fulldates,date[1:])
        print(fulldates)
489/5:
for q,k in zip(range(mat.shape[0]),li):

    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]
    if fi!='013375,42' and fi!='014514,33' and fi!='130632,35' and fi!='201508,34':
        continue
    if loc.size>=30:
        ids = np.array([fi[:6]])
        loc2 = np.array(loc[0])
#        print(ids)
        for l in loc:
            if not np.any(ids==pool[l][:6]):
#                print(loc2,ids)
                loc2 = np.append(loc2,l)
                ids = np.append(ids,pool[l][:6])

        if loc2.size<20:
            continue

        fig = plt.figure(figsize=(9,4))
        gs = gridspec.GridSpec(ncols=2, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        counters = np.zeros((len(lats),len(lons)))
        counterr = np.zeros_like(counters)
        PV = np.zeros_like(counters)
        MSL = np.zeros_like(counters)
        avc = 0
        fulldates = np.array([])
        for l in loc2:
            t = li[l]
            kk = int(t[7:9])
            sv,rv = eval(t[10:])

            avc+=1
            dates = np.array([])
            dirs = t[:6]

            sm = ds(ps + dirs + '/300/streamer-mask.nc','r')
            rm = ds(ps + dirs + '/300/ridge-mask.nc','r')
            sm = sm.variables['mask'][kk,la0:la1,lo0:lo1]
            rm = rm.variables['mask'][kk,la0:la1,lo0:lo1]

            for f in os.listdir(ps + dirs + '/300/'):
                if f.startswith('D'):
                    dates = np.append(dates,f)

            date = dates[kk]
            print(date,dirs,kk)
            fulldates = np.append(fulldates,date[1:])
        print(fulldates)
489/6:
for q,k in zip(range(mat.shape[0]),li):

    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]
    if fi!='013375,42' and fi!='014514,33' and fi!='130632,35' and fi!='201508,34':
        continue
    if loc.size>=30:
        ids = np.array([fi[:6]])
        loc2 = np.array(loc[0])
#        print(ids)
        for l in loc:
            if not np.any(ids==pool[l][:6]):
#                print(loc2,ids)
                loc2 = np.append(loc2,l)
                ids = np.append(ids,pool[l][:6])

#        if loc2.size<20:
#            continue

        fig = plt.figure(figsize=(9,4))
        gs = gridspec.GridSpec(ncols=2, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        counters = np.zeros((len(lats),len(lons)))
        counterr = np.zeros_like(counters)
        PV = np.zeros_like(counters)
        MSL = np.zeros_like(counters)
        avc = 0
        fulldates = np.array([])
        for l in loc2:
            t = li[l]
            kk = int(t[7:9])
            sv,rv = eval(t[10:])

            avc+=1
            dates = np.array([])
            dirs = t[:6]

            sm = ds(ps + dirs + '/300/streamer-mask.nc','r')
            rm = ds(ps + dirs + '/300/ridge-mask.nc','r')
            sm = sm.variables['mask'][kk,la0:la1,lo0:lo1]
            rm = rm.variables['mask'][kk,la0:la1,lo0:lo1]

            for f in os.listdir(ps + dirs + '/300/'):
                if f.startswith('D'):
                    dates = np.append(dates,f)

            date = dates[kk]
            print(date,dirs,kk)
            fulldates = np.append(fulldates,date[1:])
        print(fulldates)
489/7:
for q,k in zip(range(mat.shape[0]),li):

    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]
    if fi!='013375,42' and fi!='014514,33' and fi!='130632,35' and fi!='201508,34':
        continue
    if loc.size>=30:
        ids = np.array([fi[:6]])
        loc2 = np.array(loc[0])
#        print(ids)
        for l in loc:
            if not np.any(ids==pool[l][:6]):
#                print(loc2,ids)
                loc2 = np.append(loc2,l)
                ids = np.append(ids,pool[l][:6])

#        if loc2.size<20:
#            continue

        fig = plt.figure(figsize=(9,4))
        gs = gridspec.GridSpec(ncols=2, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        counters = np.zeros((len(lats),len(lons)))
        counterr = np.zeros_like(counters)
        PV = np.zeros_like(counters)
        MSL = np.zeros_like(counters)
        avc = 0
        fulldates = np.array([])
        print(fi)
        for l in loc2:
            t = li[l]
            kk = int(t[7:9])
            sv,rv = eval(t[10:])

            avc+=1
            dates = np.array([])
            dirs = t[:6]

            sm = ds(ps + dirs + '/300/streamer-mask.nc','r')
            rm = ds(ps + dirs + '/300/ridge-mask.nc','r')
            sm = sm.variables['mask'][kk,la0:la1,lo0:lo1]
            rm = rm.variables['mask'][kk,la0:la1,lo0:lo1]

            for f in os.listdir(ps + dirs + '/300/'):
                if f.startswith('D'):
                    dates = np.append(dates,f)

            date = dates[kk]
            print(date,dirs,kk)
            fulldates = np.append(fulldates,date[1:])
        print(fulldates)
490/1:
from netCDF4 import Dataset as ds
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

setto='mature'
setto='genesis'
ovval=0.8
#ovval=0.8
frac='third'
#frac='fourth'

if setto=='genesis':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
if setto=='mature':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/' + setto + '-matrix-%.1f-%s/'%(ovval,frac)
era5 = '/atmosdyn2/era5/cdf/'

if not os.path.isdir(pi):
    os.mkdir(pi)

a = 0
f = open(ps + setto + '-full-overlap-matrix-%.1f-%s.txt'%(ovval,frac),'rb')
d = pickle.load(f)
f.close()

pool = d['pool']
mat = d['matrix']
mat += mat.T

li = np.array(list(d.keys()))
490/2:
for q,k in zip(range(mat.shape[0]),li):

    arr = mat[q]
    loc = np.where((arr>0) & (arr<=2))[0]
    fi = pool[q]
    if fi!='013375,42' and fi!='014514,33' and fi!='130632,35' and fi!='201508,34':
        continue
    if loc.size>=30:
        ids = np.array([fi[:6]])
        loc2 = np.array(loc[0])
#        print(ids)
        for l in loc:
            if not np.any(ids==pool[l][:6]):
#                print(loc2,ids)
                loc2 = np.append(loc2,l)
                ids = np.append(ids,pool[l][:6])

#        if loc2.size<20:
#            continue

        fig = plt.figure(figsize=(9,4))
        gs = gridspec.GridSpec(ncols=2, nrows=1)
        ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
        ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
        ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=1, edgecolor='black')
        ax.set_extent([minlon, maxlon, minlat, maxlat], ccrs.PlateCarree())

        counters = np.zeros((len(lats),len(lons)))
        counterr = np.zeros_like(counters)
        PV = np.zeros_like(counters)
        MSL = np.zeros_like(counters)
        avc = 0
        fulldates = np.array([])
        print(fi)
        for l in loc2:
            t = li[l]
            kk = int(t[7:9])
            sv,rv = eval(t[10:])

            avc+=1
            dates = np.array([])
            dirs = t[:6]

            sm = ds(ps + dirs + '/300/streamer-mask.nc','r')
            rm = ds(ps + dirs + '/300/ridge-mask.nc','r')
            sm = sm.variables['mask'][kk,la0:la1,lo0:lo1]
            rm = rm.variables['mask'][kk,la0:la1,lo0:lo1]

            for f in os.listdir(ps + dirs + '/300/'):
                if f.startswith('D'):
                    dates = np.append(dates,f)

            date = dates[kk]
            print(date,dirs,kk)
            fulldates = np.append(fulldates,date[1:])
        print(fulldates)
490/3:
19801204_18
19870925_16
19930217_20
19950108_11
19951101_10
20071016_19
20071111_00
20130216_18
20130217_06
20170101_04
20171023_11
20181114_23
491/1:
from netCDF4 import Dataset as ds
import numpy as np
import pickle
import os
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

minlon = -80
minlat = 30
maxlat = 85
maxlon = 60

LON = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)

lons = np.where((LON>=minlon) & (LON<=maxlon))[0]
lats = np.where((LAT<=maxlat) & (LAT>=minlat))[0]

lo0,lo1,la0,la1 = lons[0],lons[-1]+1,lats[0],lats[-1]+1

pi = '/atmosdyn2/ascherrmann/013-WRF-sim/image-output/pre-patterns/'
era5 = '/atmosdyn2/era5/cdf/'

sea = 'DJF'
re = 'black'
a = 0
setto='genesis'
setto='mature'

if setto=='genesis':
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
else:
    ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
491/2:
for fi in os.listdir(ps):
    if fi.startswith(setto+'-start-streamer-cluster') and fi.endswith('0.9.txt'):

        a+=1
        f = open(ps + fi,'rb')
        d = pickle.load(f)
        f.close()
491/3: d
491/4:
for fi in os.listdir(ps):
    if fi.startswith(setto+'-start-streamer-cluster') and fi.endswith('0.9.txt'):

        a+=1
        f = open(ps + fi,'rb')
        d = pickle.load(f)
        f.close()
        stream = d['stream']
        print(len(stream))
492/1: import numpy as np
492/2: a = np.array([5,5,5])
492/3: np.argmax(a)
493/1: import numpy as np
493/2: import pandas as pd
493/3: d = np.loadtxt('shira_mistral.csv')
493/4: d = pd.read_csv('shira_mistral.csv')
493/5: d
493/6: cat = d['6'].values
493/7: date = d['19810902'].values
493/8: date
493/9: date = date.astype(str)
493/10: date
493/11: np.where(cat==10)[0].size
493/12: date[np.where(cat==10)[0]]
493/13: date[np.where(cat==10)[0]][::10].size
493/14: import sys
493/15: sys.path/append('/atmosdyn2/ascherrmann/scripts/')
493/16: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
493/17: import helper
493/18: downloaddates = np.array([])
493/19:
for d in date[np.where(cat==10)[0]][::10]:
    downloaddates = np.append(downloaddates,helper.change_date_by_hours(d + '_12',-96))
493/20: downloaddates
493/21: import minisom
494/1:
import os
import numpy as np

sets = ['genesis','mature']
for se in sets:
    if setto=='genesis':
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
        ra0,ra1 = 38,42
    if setto=='mature':
        ra0,ra1 = 46,50
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

    for dirs in os.listdir(ps):
        if dirs[-1]=='c' or dirs[-1]=='t':
            continue
        dates = np.array([])
        for f in os.listdir(ps + dirs + '/300/'):
            if f.startswith('D'):
                dates = np.append(dates,f)
494/2:
sets = ['genesis','mature']
for se in sets:
    if se=='genesis':
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
        ra0,ra1 = 38,42
    if se=='mature':
        ra0,ra1 = 46,50
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

    for dirs in os.listdir(ps):
        if dirs[-1]=='c' or dirs[-1]=='t':
            continue
        dates = np.array([])
        for f in os.listdir(ps + dirs + '/300/'):
            if f.startswith('D'):
                dates = np.append(dates,f)

        date = dates[ra0:ra1+1]
494/3: date.size
494/4: date
494/5:
cmd = 'cdo enssum '
        for d in date:
            cmd += '%s '%d

        cmd += 'sumPV'
494/6:
cmd = 'cdo enssum '
for d in date:
            cmd += '%s '%d

cmd += 'sumPV'
494/7: cmd
495/1:
import os
import numpy as np

sets = ['genesis','mature']
for se in sets:
    if se=='genesis':
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/4regionsPV/'
        ra0,ra1 = 38,42
    if se=='mature':
        ra0,ra1 = 46,50
        ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'

    for dirs in os.listdir(ps):
        if dirs[-1]=='c' or dirs[-1]=='t':
            continue
        dates = np.array([])
        for f in os.listdir(ps + dirs + '/300/'):
            if f.startswith('D'):
                dates = np.append(dates,f)

        date = dates[ra0:ra1+1]
        cmd = 'cdo enssum '
        for d in date:
            cmd += '%s '%d

        cmd += 'sumPV'
        os.chdir(ps + dirs + '/300/')
495/2: cmd
495/3: os.system(cmd)
495/4: os.system('cdo -divc,%d sumPV avPV'%date.size)
495/5: dirs
496/1: import numpy as np
496/2: LON = np.linspace(-180,180,721)
496/3: LAT = np.linspace(-90,90,361)
496/4: np.where(LON==-10)
496/5: np.where(LON==60)
496/6: np.where(LAT==25)
496/7: np.where(LAT==55)
496/8: exi
497/1: from netCDF4 import Dataset as ds
497/2: d = ds('avPV')
497/3: d.variables
497/4: d.variables['PV']
497/5: d.variables['PV'].shape
497/6: pv = d.variables['PV'][0,0]
497/7: pv[0,:20]
497/8: pv[1,:20]
497/9: pv[-2,:20]
497/10: pv[-3,:20]
498/1: import pandas as pd
498/2: d = pd.read_csv('SOM-genesis-cluster-IDs.csv',header=None)
498/3: d
499/1:
import pandas as pd
import os
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
import matplotlib
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert

d = pd.read_csv('SOM-genesis-cluster-IDs.csv',header=None)
499/2: d.iloc[0]
499/3: d
499/4: d.iloc[0].values
500/1: import numpy as np
500/2: LON = np.linspace(-180,180,721)
500/3: np.where(LON==-70)
500/4: np.where(LON==0)
500/5: LAT = np.linspace(-90,90,361)
500/6: np.where(LAT==30)
500/7: np.where(LAT==70)
502/1: import numpy as np
502/2: from netCDF4 import Dataset as ds
502/3: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
502/4: U = d.variables['U']
502/5: U = d.variables['UU']
502/6: np.where(U[20,20:80,50:150]=np.max(U[20,20:80,50:150]))
502/7: np.where(U[20,20:80,50:150]==np.max(U[20,20:80,50:150]))
502/8: U.shape
502/9: U = U[0]
502/10: np.where(U[20,20:80,50:150]==np.max(U[20,20:80,50:150]))
502/11: ls
502/12: cd ../
502/13: ls
502/14: cd ref-mean-medium/
502/15: ls
502/16: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
502/17: U = d.variables['UU']
502/18: U = U[0]
502/19: np.where(U[20,20:80,50:150]==np.max(U[20,20:80,50:150]))
502/20: cd ../DJF-clim/
502/21: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
502/22: U = U[0]
502/23: U = d.variables['UU']
502/24: U = U[0]
502/25: np.where(U[20,20:80,50:150]==np.max(U[20,20:80,50:150]))
502/26: GHT = d.variables['GHT']
502/27: GHT[0,20,93,55]
503/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle
import xarray as xr

import cartopy
import matplotlib.gridspec as gridspec
import functools

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm

CT = 'MED'

pload = '/atmosdyn2/ascherrmann/010-IFS/ctraj/' + CT + '/use/'

f = open(pload + 'PV-data-'+CT+'dPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW-correct.txt','rb')
ldata = pickle.load(f)
f.close()
503/2: ldata['DEC'].keys()
503/3: ldata.keys()
503/4: ldata['DEC17']['073'].keys()
503/5: ldata['DEC17'].keys()
503/6: ldata['DEC17'][73.0].keys()
504/1:
import numpy as np
import pickle
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm
import pandas as pd

rdis = 400
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d-correct-distance.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()
savings = ['SLP-', 'lon-', 'lat-', 'ID-', 'hourstoSLPmin-', 'dates-']
var = []

for u,x in enumerate(savings):
    f = open(pload[:-10] + pload[-9:-4]  + x + 'furthersel.txt',"rb")
    var.append(pickle.load(f))
    f.close()

SLP = var[0]
lon = var[1]
lat = var[2]
ID = var[3]
hourstoSLPmin = var[4]
dates = var[5]
avaID = np.array([])
maturedates = np.array([])

for k in range(len(ID)):
    avaID=np.append(avaID,ID[k][0].astype(int))
    maturedates = np.append(maturedates,dates[k][abs(hourstoSLPmin[k][0]).astype(int)])

df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
df = df.loc[df['ntraj075']>=200]
504/2: df.columns
504/3: df['cycperano'].values
504/4: df['ID'].values
505/1: from netCDF4 import Dataset as ds
505/2: d = ds('/atmosdyn2/ascherrmann/013-WRF-sim/DJF-clim-max-U-at-300hPa-0.3QG/wrfout_d01_2000-12-01_00:00:00','r+')
505/3: d.dimensions
505/4: d.variables['PB'].shape
505/5: d.variables['PB'].dimension
505/6: d.variables['PB'].dimensions
505/7: time = d.dimensions['Time'].name
505/8: time
505/9: bottom_top = d.dimensions['bottom_top'].name
505/10: south_north = d.dimensions['south_north'].name
505/11: we = d.dimensions['west_east'].name
505/12: sn = d.dimensions['south_north'].name
505/13: bt = d.dimensions['bottom_top'].name
505/14: d.createVariable('MSL','f8',(time,bt,sn,we))
505/15: d.variables
505/16: d.createVariable('MSL','f8',(time,sn,we))
505/17: d.createVariable('msl','f8',(time,sn,we))
505/18: import wrf
505/19: slp = wrf.getvar(d,'slp',meta=False)
505/20: slp.shape
505/21: d.variables['msl'][0,:]=slp
505/22: d.variables['msl']
505/23: d.variables['msl'][:]
506/1: from netCDF4 import Dataset as ds
506/2: d = ds('/atmosdyn2/ascherrmann/013-WRF-sim/DJF-clim-max-U-at-300hPa-0.3QG/wrfout_d01_2000-12-01_00:00:00','r+')
506/3: d.variables['MSLP']
506/4:
if d.variables['MSLP']:
    print('true')
506/5:
if d.variables['MSLPQ']:
    print('true')
506/6:
try:
    if d.variables['MSLPQ']:
        print('true')
except:
    print('do other stuff')
507/1: import wrf
507/2: from netCDF4 import Dataset as ds
507/3: d = ds('/atmosdyn2/ascherrmann/013-WRF-sim/DJF-clim-max-U-at-300hPa-0.3QG/wrfout_d01_2000-12-01_00:00:00','r+')
507/4: lon = wrf.getvar(d,'lat')
507/5: lon = wrf.getvar(d,'lon')
507/6: lon
507/7: lon = wrf.getvar(d,'XLONG')
507/8: lon
507/9: xlon = wrf.getvar(d,'XLONG')
507/10: xlon
509/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
509/2: rdis=400
509/3:
p = '/atmosdyn2/ascherrmann/009-ERA-5/' + 'MED/cases/'
traced = np.array([])
for d in os.listdir(p):
    if(d.startswith('trajectories-mature')):
            traced = np.append(traced,d)
traced = np.sort(traced)
509/4: traced
509/5: less ../ERA5-utils/MED-cases-cyc-env.py
510/1: from netCDF4 import Dataset as ds
510/2: import wrf
510/3: d = ds('wrfout_d01_2000-12-01_00:00:00')
510/4: pv = wrf.getvar(d,'pvo',meta=False)
510/5: slp = wrf.getvar(d,'slp',meta=False)
510/6: cd ../np-DJF-clim-max-U-at-300hPa-0.7QG/
510/7: d = ds('wrfout_d01_2000-12-01_00:00:00')
510/8: pv = wrf.getvar(d,'pvo',meta=False)
510/9: slp = wrf.getvar(d,'slp',meta=False)
510/10: d.variables['MSLP']
510/11:
try:
    if d.variables['MSLP']:
        print('exists')
except:
    print('does not exist')
510/12: d = ds('wrfout_d01_2000-12-05_12:00:00')
510/13: pv = wrf.getvar(d,'pvo',meta=False)
510/14: slp = wrf.getvar(d,'slp',meta=False)
511/1: from netCDF4 import Dataset as ds
511/2: d = ds('ref-dry-clim-unpert.nc','r+')
511/3: d.variables['RH'][:] = 0
511/4: d.close()
511/5: cd ../perturbed_files/
511/6: cd dry-DJF-clim-max-U-at-300hPa-1.4QG/
511/7: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
511/8: d.variables['RH'][:] = 0
511/9: d.close()
511/10: cd ../dry-DJF-clim-max-U-at-300hPa-0.7QG/
511/11: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
511/12: d.variables['RH'][:] = 0
511/13: d.close()
511/14: cd ../dry-DJF-clim-max-U-at-300hPa-2.1QG/
511/15: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
511/16: d.variables['RH'][:] = 0
511/17: d.close()
512/1: from netCDF4 import Dataset as ds
512/2: cd sat-DJF-clim/
512/3: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
512/4: d.variables['RH'][:] = 100
512/5: d.close()
512/6: cd ../sat-DJF-clim-max-U-at-300hPa-0.7QG/
512/7: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
512/8: d.variables['RH'][:] = 100
512/9: d.close()
512/10: cd ../sat-DJF-clim-max-U-at-300hPa-1.4QG/
512/11: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
512/12: d.variables['RH'][:] = 100
512/13: d.close()
512/14: cd ../sat-DJF-clim-max-U-at-300hPa-2.1QG/
512/15: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r+')
512/16: d.variables['RH'][:] = 100
512/17: d.close()
513/1:
import pandas as pd
import os
import numpy as np
from netCDF4 import Dataset as ds
ps = '/atmosdyn2/ascherrmann/013-WRF-sim/data/PV300hPa/'
dp = '/atmosdyn2/ascherrmann/013-WRF-sim/data/'
we = 'sevendaypriormature'
wi = 'intense-cyclones.csv'
seasons = ['DJF','SON']
pre = [450]
514/1: from wrf import interplevel as intp
514/2: from wrf import getvar
514/3: from netCDF4 import Dataset as ds
514/4: d = ds('P20001204_00')
514/5: z = getvar(d,'z')
514/6: z
514/7: z[32]
514/8: z[28]
514/9: pres = getvar(d,'pressure')
514/10: pres
514/11: pres[32]
514/12: z300 = intp(z,pres,300,meta=False)
514/13: z300
514/14: :q
514/15: pv = getvar(d,'pvo',meta=False)
514/16: pv300=interplevel(pv,pres,300,meta=False)
514/17: pv300=intp(pv,pres,300,meta=False)
514/18:
lon = getvar(d,'lon',meta=False)
lat = getvar(d,'lat',meta=False)
514/19: y,x = np.where((pv300>=4) & (lon>=-5) & (lon<=20) & (lat>=20) & (lat<=45))
514/20: import numpy as np
514/21: y,x = np.where((pv300>=4) & (lon>=-5) & (lon<=20) & (lat>=20) & (lat<=45))
514/22: x
514/23: y
514/24: zeva = z300[y,x]
514/25: zeva
514/26: lon[x]
514/27: lon
514/28: lon.shape
514/29: lon[:,x]
514/30: lon.shape
514/31: lat.shape
514/32: z300.shape
514/33: lon[0,x]
514/34: lat[y,0]
514/35: x0,y0=lon[0,0],lat[0,0]
514/36: x0
514/37: y0
514/38: less startf.ll
514/39: z
514/40: zeva
514/41: pwd
514/42: less startf.ll
514/43: less startf.ll
515/1: import wrf
515/2: from netCDF4 import Dataset as ds
515/3: d = ds('wrfout_d01_2000-12-01_06:00:00')
515/4: RH = wrf.getvar(d,'RH')
515/5: t = wrf.getvar(d,'temperature')
515/6: t = wrf.getvar(d,'T')
515/7: t
515/8: t = wrf.getvar(d,'temp')
515/9: t
515/10: qv = wrf.getvar(d,'qv')
515/11: rh = wrf.getvar(d,'rh')
515/12: rh
515/13: d.close()
515/14: d = ds('wrfout_d01_2000-12-04_06:00:00')
515/15: rh = wrf.getvar(d,'rh')
515/16: rh
515/17: rh[:].shape
515/18: np.where(rh>95)[0].size
515/19: import numpy as np
515/20: np.where(rh>95)[0].size
515/21: 22*140*400
515/22: np.where(rh>95)[0].size/_
515/23: 22*140*400
515/24: np.where(rh>90)[0].size/_
515/25: 22*140*400
515/26: 44*140*400
515/27: np.where(rh>90)[0].size/_
515/28: 22*140*400
515/29: np.where(rh[:22]>90)[0].size/_
516/1: from netCDF4 import Dataset as ds
516/2: d = ds("unchanged_met_em/ref-SON-clim-unpert.nc")
516/3: d.variables['PRES'][19]
516/4: d.variables['PRES'][:].shape
516/5: d.variables['PRES'][0,19,:].shape
516/6: d.variables['PRES'][0,19,:]
516/7: d.variables['PRES'][0,20,:]
516/8: lon=np.linspace(-120,80,401)
516/9: import numpy as np
516/10: lon=np.linspace(-120,80,401)
516/11: lon
516/12: lat = np.linspace(10,80,141)
516/13: lat
516/14: np.argmax(d.variables['U'][0,20,10:70,40:150])
516/15: np.argmax(d.variables['UU'][0,20,10:70,40:150])
516/16: np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
516/17: d = ds("unchanged_met_em/ref-MAM-clim-unpert.nc")
516/18: d.variables['PRES'][0,20,:]
516/19: d.variables['PRES'][0,20,:].shape
516/20: np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
516/21: d = ds("unchanged_met_em/ref-JJA-clim-unpert.nc")
516/22: np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
516/23: d = ds("unchanged_met_em/ref-MAM-clim-unpert.nc")
516/24: d.variables['GHT'][0,20,55,46]
516/25: d = ds("unchanged_met_em/ref-DJF-clim-unpert.nc")
516/26: d.variables['GHT'][0,20,93,55]
516/27: d = ds("unchanged_met_em/ref-JJA-clim-unpert.nc")
516/28: d.variables['GHT'][0,20,84,59]
516/29: d = ds("unchanged_met_em/ref-SON-clim-unpert.nc")
516/30: d.variables['GHT'][0,20,73,59]
518/1: import numpy as np
518/2: from netCDF4 import Dataset as ds
518/3: d = ds("ref-DJF-clim-unpert.nc")
518/4: d.variables['PRES'][0,5,:]
518/5: d.variables['PRES'][0,8,:]
518/6: d.variables['PRES'][0,9,:]
518/7: d.variables['GHT'][0,9,51,99]
519/1: from netCDF4 import Dataset as ds
519/2: from wrf import getvar
519/3: from wrf import interplevel as intp
519/4: d = ds('wrfout_d01_2000-12-01_00:00:00')
519/5: pv = getvar(d,'pvo',meta=False)
519/6: pres = getvar(d,'pressure')
519/7: pv850 = intp(pv,pres,850,meta=False)
519/8: lon = getvar(d,'lon',meta=False)[0,:]
519/9: lat = getvar(d,'lat',meta=False)[:,0]
519/10: lat
519/11: lon
519/12: import matplotlib.pyplot as plt
519/13:
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import matplotlib
import cartopy.crs as ccrs
import cartopy
519/14:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
519/15: cmap,levels,norm,ticklabels=PV_cmap2()
519/16:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(nrows=1, ncols=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=10, edgecolor='black')
519/17: ax.contourf(lon,lat,pv850,cmap=cmap,norm=norm,extend='both',levels=levels)
519/18: ax.set_xlim(np.min(lon),np.max(lon))
519/19: import numpy as np
519/20: ax.set_xlim(np.min(lon),np.max(lon))
519/21: ax.set_ylim(np.min(lat),np.max(lat))
519/22: plt.show()
519/23:
d.close()
data = ds('wrfout_d01_2000-12-01_00:00:00')
519/24:
time = data.dimensions['Time'].name
bt = data.dimensions['bottom_top'].name
sn = data.dimensions['south_north'].name
we = data.dimensions['west_east'].name

data.createVariable('PVcheck','f8',(time,bt,sn,we))
data.variables['PVcheck'][0,:] = pv
data.close()
519/25: data.close()
519/26: data = ds('wrfout_d01_2000-12-01_00:00:00','r+')
519/27:
time = data.dimensions['Time'].name
bt = data.dimensions['bottom_top'].name
sn = data.dimensions['south_north'].name
we = data.dimensions['west_east'].name

data.createVariable('PVcheck','f8',(time,bt,sn,we))
data.variables['PVcheck'][0,:] = pv
data.close()
520/1: from netCDF4 import Dataset as ds
520/2: from wrf import getvar
520/3: data = ds('wrfout_d01_2000-12-01_00:00:00','r+')
520/4: pv = getvar(d,'pvo',meta=False)
520/5: pv = getvar(data,'pvo',meta=False)
520/6:
time = data.dimensions['Time'].name
bt = data.dimensions['bottom_top'].name
sn = data.dimensions['south_north'].name
we = data.dimensions['west_east'].name

data.createVariable('PVcheck','f8',(time,bt,sn,we))
data.variables['PVcheck'][0,:] = pv
data.close()
521/1: from wrf import getvar
521/2: from netCDF4 import Dataset as ds
521/3: data = ds('wrfout_d01_2000-12-01_00:00:00','r+')
521/4: pv = getvar(data,'pvo',meta=False)
521/5:
time = data.dimensions['Time'].name
bt = data.dimensions['bottom_top'].name
sn = data.dimensions['south_north'].name
we = data.dimensions['west_east'].name

data.createVariable('PVcheck','f8',(time,bt,sn,we))
data.variables['PVcheck'][0,:] = pv
data.close()
521/6: cd ../DJF-L500-double-1.4-1.4QGPV/
521/7: data = ds('wrfout_d01_2000-12-01_00:00:00','r+')
521/8: pv = getvar(data,'pvo',meta=False)
521/9:
time = data.dimensions['Time'].name
bt = data.dimensions['bottom_top'].name
sn = data.dimensions['south_north'].name
we = data.dimensions['west_east'].name

data.createVariable('PVcheck','f8',(time,bt,sn,we))
data.variables['PVcheck'][0,:] = pv
data.close()
522/1:
import wrf
from netCDF4 import Dataset as ds
import os
import numpy as np
import matplotlib.pyplot as plt

dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lon1,lat1,lon2,lat2 = -5,20,1.5,42
lon3,lat3,lon4,lat4 = 1.5,20,50,48

### time of slp measure of atlantic cyclone
hac = 12

PVpos = [[52,28],[145,84],[93,55]]
names = np.array([])
MINslp = np.array([])
MAXpv = np.array([])
522/2:
for d in os.listdir(dwrf):
#    if not d.startswith('DJF-clim-') and not d.startswith('dry-DJF-clim') and not d.startswith('sat-DJF-clim'):
#        continue
    if d=='DJF-clim-max-U-at-300hPa-hourly-2.1QG' or d=='sat-DJF-clim-max-U-at-300hPa-hourly-2.1QG':
        continue
    if not d.startswith('DJF-clim-max') and not d.startswith('DJF-clim-double') and not d.startswith('MAM-clim-max') and not d.startswith('JJA-clim-max') and not d.startswith('SON-clim-max') and not d.startswith('DJF-L300') and not d.startswith('DJF-L500'):
        continue
522/3: d
522/4: d = 'DJF-L500-double-1.4-1.4QGPV'
522/5:
if True:
    tra = np.loadtxt(tracks + d + '-filter.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]
523/1: eval('bla-te-3.5QG')
523/2:
for k in ['DJF-clim-max-U-at-300hPa-1.7QG','DJF-L300-double-2.1-0.7QGPV']:
    try:
        print(eval(k[:-2]))
    except:
        print(eval(k[:-4]))
524/1: import pickle
524/2:
rdis = 400
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d-correct-distance.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()
524/3: PVdata['rawdata']['PV'].shape
524/4: PVdata['rawdata']['415821'].keys()
524/5: len(list(PVdata['rawdata'].keys()))
525/1:
import pandas as pd
import numpy as np
import pickle
rdis = 400
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d-correct-distance.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
525/2: df['ntrajgt1PVU'].values
525/3: df['ntraj075PVU'].values
525/4: df.colums
525/5: df.columns
525/6: df['ntraj075'].values
525/7: np.where(df['ntrajgt1PVU']>=200)[0].size
525/8: np.where(df['ntrajgt1.25PVU']>=200)[0].size
525/9: np.where(df['ntrajgt1.5PVU']>=200)[0].size
526/1: import sys
526/2: sys.path.append('/home/raphaelp/phd/scripts/')
526/3: import wrf-sims
526/4: sys.path.append('/home/raphaelp/phd/scripts/')
526/5: import wrfsims
526/6: sys.path.append('/home/raphaelp/phd/scripts/')
526/7: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
526/8: import wrfsims
526/9: sim,Aids,Mids = wrfsims.provide_sim_cyclone_ids()
526/10: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
526/11: import wrfsims
526/12: sim,Aids,Mids = wrfsims.provide_sim_cyclone_ids()
527/1: import sys
527/2: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
527/3: import wrfsims
527/4: sim,Aids,Mids = wrfsims.provide_sim_cyclone_ids()
527/5: sim
527/6:
for si,ai,mi in zip(sim,Aids,Mids):
    print(si,ai,mi)
528/1: import sys
528/2: sys.path.append('/atmosdyn2/ascherrmann/scripts/')
528/3: import wrfsims
528/4: sim,Aids,Mids = wrfsims.primary_cyclone_ids()
528/5: len(sim)
528/6: len(Aids)
528/7: len(Mids)
529/1: eval('bla-5-QG-0.5')
529/2: eval('5-QG-0.5')
529/3: QG='QG'
529/4: eval('5-QG-0.5')
529/5: QG = 0
529/6: eval('5-QG-0.5')
529/7: import re
529/8: re.findall('5-QG-0.5')
529/9: re.findall(r"[-+]?(?:\d*\.\d+|\d+)", "5-QG-0.5")
529/10: import os
529/11:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        print(re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d))
529/12:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        print(d,re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d))
529/13:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        print(d,eval(re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d)))
529/14:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        k = re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d)[0]:
            if int(k)<=300:
                print('first number is 300 or less')
529/15:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        k = re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d)[0]
        if int(k)<=300:
            print('first number is 300 or less')
529/16:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        k = re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d)[0]
        if k.astype(float)<=300:
            print('first number is 300 or less')
529/17:
for d in os.listdir('./'):
    if d.endswith('-FILTER'):
        k = re.findall(r"[-+]?(?:\d*\.\d+|\d+)",d)[0]
        if float(k)<=300:
            print('first number is 300 or less')
529/18: %save -r /atmosdyn2/ascherrmann/scripts/WRF/extract-float-from-string.py 1-999
530/1: import wrfsims
530/2: a,b,c = wrfsims.primary_cyclone_ids()
530/3: len(a)
530/4: len(b)
530/5: len(c)
532/1:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.primary_cyclone_ids()
SIMS = np.array(SIMS)
532/2:
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'
532/3: SIMS
532/4: SIMS = [SIMS[np.where(SIMS=='SON-clim-max-U-300-hPa-4.2-QGPV')[0][0]]]
532/5: simid = 5
532/6:
if True:
    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    tra = np.loadtxt(tracks + sim + '-filter.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    deepening = tra[:,-2]
    IDs = tra[:,-1]

    track = [medid, atid]
532/7: sim = 'SON-clim-max-U-300-hPa-4.2-QGPV'
532/8:
if True:
    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    tra = np.loadtxt(tracks + sim + '-filter.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    deepening = tra[:,-2]
    IDs = tra[:,-1]

    track = [medid, atid]
532/9: track
532/10:
track = [medid, atid]
for tr in track[:1]:
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(comids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru in tru_array:
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/11:
track = [medid, atid]
for tr in track[:1]:
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru in tru_array:
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/12: combids
532/13:
track = [medid, atid]
for tr in track[:1]:
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            newtime = np.unique(t[combids.astype(int)])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru in tru_array:
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/14:
track = [medid, atid]
for tr in track[:1]:
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            newtime = np.unique(t[combids.astype(int)])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru in true_array:
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/15:
track = [medid, atid]
for tr in track[:1]:
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            newtime = np.unique(t[combids.astype(int)])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/16: newslp
532/17: slp[combids]
532/18: slp[combids.astype(int)]
532/19: newslp-slp[combids.astype(int)]
532/20:
track = [medid, atid]
for tr in track:
        print(tr.size)
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])
532/21:
track = [medid, atid]
for tr in track[:1]:
        print(tr.size)
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])
532/22: idvids = []
532/23:
for ids in tr:
    print(ids)
    combids = np.append(combids,np.where(IDs==ids)[0].astype(int))
    idvids.append(np.where(IDs==ids)[0])
532/24: combids.size
532/25: idvids
532/26: len(idvids)
532/27: len(idvids[0]) + len(idvids[1])
532/28: t[combids]
532/29: combids
532/30: combids = combids.astype(int)
532/31: t[combids]
532/32:
newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/33:
newtime = np.unique(t[combids])

for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/34:
track = [medid, atid]
for tr in track[1:]:
        print(tr.size)
        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]

            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]



        else: ## combine tracks
            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])
532/35: idvids = []
532/36:
for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

combids = combids.astype(int)
532/37: combids
532/38: idvids
532/39: t[idvids[0]]
532/40: t[idvids[1]]
532/41: slp[idvids[0]]
532/42: slp[idvids[1]]
532/43:
newtime = np.unique(t[combids])

for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)



                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])
532/44: newtime.size
532/45: newslp
532/46:
track = [medid, atid]
    name = ['MED','AT']
    newid = 1
    for nm,tr in zip(name,track):

        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]
            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]

        else: ## combine tracks

            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            combids = combids.astype(int)
            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)

                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])

        newids = np.ones_like(newlon)*newid
        newid+=1

    np.savetxt(tracks + 'new-tracks.txt',np.stack(newtime,newlon,newlat,newslp,newids,axis=1),fmt='%.2f',newline='\n')
532/47:
track = [medid, atid]
name = ['MED','AT']
newid = 1
for nm,tr in zip(name,track):

        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]
            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]

        else: ## combine tracks

            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            combids = combids.astype(int)
            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)

                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])

        newids = np.ones_like(newlon)*newid
        newid+=1

np.savetxt(tracks + 'new-tracks.txt',np.stack(newtime,newlon,newlat,newslp,newids,axis=1),fmt='%.2f',newline='\n')
532/48:
track = [medid, atid]
name = ['MED','AT']
newid = 1
for nm,tr in zip(name,track):

        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]
            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]

        else: ## combine tracks

            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            combids = combids.astype(int)
            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)

                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])

        newids = np.ones_like(newlon)*newid
        newid+=1

np.savetxt(tracks + 'new-tracks.txt',np.stack((newtime,newlon,newlat,newslp,newids),axis=1),fmt='%.2f',newline='\n')
532/49:
track = [medid, atid]
name = ['MED','AT']
newid = 1
ftime = np.array([])
flon= np.array([])
flat= np.array([])
fID= np.array([])
fslp = np.array([])
for nm,tr in zip(name,track):

        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]
            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]

        else: ## combine tracks

            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            combids = combids.astype(int)
            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)

                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])

        newids = np.ones_like(newlon)*newid
        newid+=1
        ftime = np.append(ftime,newtime)
        flon = np.append(flon,newlon)
        flat = np.append(flat,newlat)
        fslp = np.append(fnewslp,newslp)
        fID = np.append(fnewids,newids)
np.savetxt(tracks + 'new-tracks.txt',np.stack((ftime,flon,flat,fslp,fID),axis=1),fmt='%.2f',newline='\n')
532/50:
track = [medid, atid]
name = ['MED','AT']
newid = 1
ftime = np.array([])
flon= np.array([])
flat= np.array([])
fID= np.array([])
fslp = np.array([])
for nm,tr in zip(name,track):

        if tr.size==1:
            loc = np.where(IDs==tr[0])[0]
            newlon = tlon[loc]
            newlat = tlat[loc]
            newslp = slp[loc]
            newtime = t[loc]

        else: ## combine tracks

            newtrack= np.array([])
            newslp = np.array([])
            newlon = np.array([])
            newlat = np.array([])
            combids = np.array([])

            idvids = []
            for ids in tr:
                combids = np.append(combids,np.where(IDs==ids)[0])
                idvids.append(np.where(IDs==ids)[0])

            combids = combids.astype(int)
            newtime = np.unique(t[combids])

            for tn in newtime:
                true_array = np.array([])
                tmp_slps = np.array([])
                tmp_lons = np.array([])
                tmp_lats = np.array([])

                for ids in idvids:
                    true_array = np.append(true_array,np.any(t[ids]==tn))

                for tru,ids in zip(true_array,idvids):
                    if tru:
                        loc = np.where(t[ids]==tn)[0][0]
                        tmp_slps = np.append(tmp_slps,slp[ids[loc]])
                        tmp_lons = np.append(tmp_lons,tlon[ids[loc]])
                        tmp_lats = np.append(tmp_lats,tlat[ids[loc]])

                    else:
                        tmp_slps = np.append(tmp_slps,np.nan)
                        tmp_lons = np.append(tmp_lons,np.nan)
                        tmp_lats = np.append(tmp_lats,np.nan)

                newslp = np.append(newslp,np.nanmin(tmp_slps))
                newlon = np.append(newlon,tmp_lons[np.nanargmin(tmp_slps)])
                newlat = np.append(newlat,tmp_lats[np.nanargmin(tmp_slps)])

        newids = np.ones_like(newlon)*newid
        newid+=1
        ftime = np.append(ftime,newtime)
        flon = np.append(flon,newlon)
        flat = np.append(flat,newlat)
        fslp = np.append(fslp,newslp)
        fID = np.append(fID,newids)
np.savetxt(tracks + 'new-tracks.txt',np.stack((ftime,flon,flat,fslp,fID),axis=1),fmt='%.2f',newline='\n')
533/1: %history -g -f ipyhistory
534/1: import numpy as np
534/2: from netCDF4 import Dataset as ds
534/3:
d = ds("ref-MAM-clim-unpert.nc")
d.variables['PRES'][0,20,:]
d.variables['PRES'][0,20,:].shape
np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
534/4: d.variables['UU'][0,20,46,55]
534/5: d.variables['PRES'][0,20,:]
534/6:
d = ds("ref-DJF-clim-unpert.nc")
d.variables['PRES'][0,20,:]
d.variables['PRES'][0,20,:].shape
np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
534/7:
d = ds("ref-DJF-clim-unpert.nc")
d.variables['PRES'][0,20,:]
d.variables['PRES'][0,20,:].shape
np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
534/8:
d = ds("ref-MAM-clim-unpert.nc")
np.where(d.variables['UU'][0,20,10:70,40:150]==np.max(d.variables['UU'][0,20,10:70,40:150]))
534/9: d.variables['GHT'][0,20,56,95]
534/10:
d = ds("ref-JJA-clim-unpert.nc")
np.where(d.variables['UU'][0,20,10:80,40:160]==np.max(d.variables['UU'][0,20,10:80,40:160]))
534/11: d.variables['GHT'][0,20,74,140]
534/12:
d = ds("ref-MAM-clim-unpert.nc")
np.where(d.variables['UU'][0,20,10:80,40:160]==np.max(d.variables['UU'][0,20,10:80,40:160]))
534/13:
d = ds("ref-SON-clim-unpert.nc")
np.where(d.variables['UU'][0,20,10:80,40:160]==np.max(d.variables['UU'][0,20,10:80,40:160]))
534/14: d.variables['GHT'][0,20,72,125]
535/1: 36.92%0.25
537/1: 39.72%0.5
538/1: from netCDF4 import Dataset as ds
538/2: dM = ds('Bmean-MAM')
538/3: SSTM = dM.variables['SSTK']
538/4: SSTM.shape
538/5: SSTM = dM.variables['SSTK'][0]
538/6: dD = ds('Bmean-DJF')
538/7: SSTD = dD.variables['SSTK'][0]
538/8: SSTD-SSTM
538/9: np.where((SSTD-SSTM)!=0)
538/10: import numpy as np
538/11: np.where((SSTD-SSTM)!=0)
538/12: from matplotlib import pyplot as plt
538/13: fig,ax = plt.subplots()
538/14:
import matplotlib
ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTD-SSTM,cmap=matplotlib.cm.jet,levels=np.arange(-3,3.1,0.25))
538/15: plt.show()
538/16: plt.close('all')
538/17: fig,ax = plt.subplots()
538/18:
import matplotlib
ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTD-SSTM,cmap=matplotlib.cm.jet,levels=np.arange(-3,3.1,0.25))
538/19: plt.colorbar()
538/20: a = ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTD-SSTM,cmap=matplotlib.cm.jet,levels=np.arange(-3,3.1,0.25))
538/21: plt.colorbar(a)
538/22: plt.show()
538/23: plt.close('all')
538/24: fig,ax = plt.subplots()
538/25: a = ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTD-SSTM,cmap=matplotlib.cm.coolwarm,levels=np.arange(-3,3.1,0.25))
538/26: plt.colorbar(a)
538/27: plt.show()
538/28: dS = ds('Bmean-SON')
538/29: SSTS = dS.variables['SSTK']
538/30: SSTS = dS.variables['SSTK'][0]
538/31: plt.close('all')
538/32: fig,ax = plt.subplots()
538/33: a = ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTS-SSTD,cmap=matplotlib.cm.coolwarm,levels=np.arange(-3,3.1,0.25))
538/34: plt.colorbar(a)
538/35: plt.show()
538/36: plt.close('all')
538/37: fig,ax = plt.subplots()
538/38: a = ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTS-SSTD,cmap=matplotlib.cm.coolwarm,levels=np.arange(-4.5,4.51,0.25))
538/39: plt.colorbar(a)
538/40: plt.show()
538/41: plt.close('all')
538/42: fig,ax = plt.subplots()
538/43: a = ax.contourf(np.linspace(-180,179.5,720),np.linspace(-90,90,361),SSTS-SSTD,cmap=matplotlib.cm.coolwarm,levels=np.arange(-4.5,4.51,0.25),extend='both')
538/44: plt.colorbar(a)
538/45: plt.show()
538/46: plt.close('all')
539/1:
import pandas as pd
import numpy as np
import pickle
rdis = 400
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
539/2: df['ntraj075'].values
539/3: df.iloc[df['ntraj075']>=200]
539/4: df.iloc[df['ntraj075'].values>=200]
539/5: np.mean(df.iloc[df['ntraj075'].values>=200]['ntraj075'].values)
540/1:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')
LAT = wrf.getvar(ref,'lat')

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
    counter+=1
540/2: rainc.shape
540/3: rainc
540/4: rain = rainc + rainnc
540/5: rain
540/6: loloc,laloc = np.argmin(abs(LON-lon)),np.argmin(abs(LAT-lat))
540/7:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')
LAT = wrf.getvar(ref,'lat')

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq=0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.argmin(abs(LON-lon)),np.argmin(abs(LAT-lat))

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-10:laloc+11,loloc-10:loloc+11] * 3 * 3600
            rainold = rain
  
    counter+=1
540/8:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')
LAT = wrf.getvar(ref,'lat')

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.argmin(abs(LON-lon)),np.argmin(abs(LAT-lat))

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-10:laloc+11,loloc-10:loloc+11] * 3 * 3600
            rainold = rain
  
    counter+=1
540/9: lon
540/10: LON
540/11: LON-lon
540/12:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.argmin(abs(LON-lon)),np.argmin(abs(LAT-lat))

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-10:laloc+11,loloc-10:loloc+11] * 3 * 3600
            rainold = rain
  
    counter+=1
540/13: LON-lon
540/14: np.argmin(LON-lon)
540/15: LON
540/16: LON.shape
540/17: np.argmin(LON)
540/18: np.argmin(LON,axis=0)
540/19: np.argmin(LON,axis=1)
540/20: np.argmin(LON,axis=0)
540/21: np.min(LON)
540/22: np.argmin(LON[:])
540/23: np.where(abs(LON-lon)==np.min(abs(LON-lon)))
540/24: np.where(abs(LON-lon)==np.min(abs(LON-lon)))[0][0]
540/25:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.where(abs(LON-lon)==np.min(abs(LON-lon)))[0][0],np.where(abs(LAT-lat)==np.min(abs(LATN-lat)))[0][0]

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-10:laloc+11,loloc-10:loloc+11] * 3 * 3600
            rainold = rain
  
    counter+=1
540/26:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.where(abs(LON-lon)==np.min(abs(LON-lon)))[0][0],np.where(abs(LAT-lat)==np.min(abs(LAT-lat)))[0][0]

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-10:laloc+11,loloc-10:loloc+11] * 3 * 3600
            rainold = rain
  
    counter+=1
540/27:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.where(abs(LON-lon)==np.min(abs(LON-lon)))[0][0],np.where(abs(LAT-lat)==np.min(abs(LAT-lat)))[0][0]

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1] * 3 * 3600
            di[sim]['track'] += (rain-rainold)[laloc-20:laloc+21,loloc-20:loloc+21] * 3 * 3600
            rainold = rain
  
    counter+=1
540/28: fig,ax = plt.subplots()
540/29: ax.contourf(LON[lons],LAT[lats],di['DJF-clim']['MED'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5))
540/30: import matplotlib
540/31: ax.contourf(LON[lons],LAT[lats],di['DJF-clim']['MED'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5))
540/32: plt.show()
540/33: plt.close('all')
540/34: fig,ax = plt.subplots()
540/35: ax.contourf(LON[lons],LAT[lats],di['DJF-clim']['MED'],cmap=matplotlib.cm.jet,levels=np.arange(0,200,10),extend='both')
540/36: plt.show()
540/37: plt.close('all')
540/38:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]

lons,lats = np.where((LON>=-10)&(LON<=50))[0],np.where((LAT>=25)&(LAT<=55))[0]
lo0,lo1,la0,la1 = lons[0],lons[-1],lats[0],lats[-1]

name = ['MED','track']

di = dict()
for n in name:
    di[n] = dict()

track20=0
counter=0
SONclimc=1
di = dict()
for simid2,sim in enumerate(SIMS):
    simid = simid2+track20
    if "-not" in sim:
        continue

    medid = np.array(MEDIDS[simid])
    atid = np.array(ATIDS[simid])

    if medid.size==0:
        continue
    if SONclimc==2 and sim=='SON-clim':
        sim+='_2'
    if counter==1:
        break

    di[sim] = dict()
    di[sim]['track'] = np.zeros((41,41))
    di[sim]['MED'] = np.zeros((lats.size,lons.size))

    tra = np.loadtxt(tracks + sim + '-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        # loop over track time select cyc center in lon,lat
        # add precip +-25 gridpoints to 2D zeros
        # save summed precip in figure
        # make med region precipiation, around track time and plot cyclone track into it.

        if q==0:
            continue
        for qq2,T in enumerate(t[l]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            print(sim,T/24,"%02d"%dd)

            if dd>=10:
                print('fuck')

            if SONclimc==2 and sim=='SON-clim_2':
                sim = 'SON-clim'

            out = ds(dwrf + sim + '/wrfout_d01_2000-12-%02d_%02d:00:00'%(dd,hh))
            rainc = wrf.getvar(out,'RAINC')
            rainnc = wrf.getvar(out,'RAINNC')
            if qq==0:
                rainold = rainc + rainnc

            rain = (rainc + rainnc)
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]
            loloc,laloc = np.where(abs(LON-lon)==np.min(abs(LON-lon)))[0][0],np.where(abs(LAT-lat)==np.min(abs(LAT-lat)))[0][0]

            di[sim]['MED'] += (rain-rainold)[la0:la1+1,lo0:lo1+1]
            di[sim]['track'] += (rain-rainold)[laloc-20:laloc+21,loloc-20:loloc+21]
            rainold = rain
  
    counter+=1
540/39: fig,ax = plt.subplots()
540/40: ax.contourf(LON[lons],LAT[lats],di['DJF-clim']['MED'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5),extend='both')
540/41: plt.show()
540/42: plt.close('all')
540/43: fig,ax = plt.subplots()
540/44: ax.contourf(LON[lons],LAT[lats],di['DJF-clim']['MED'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5),extend='both')
540/45: ax.plot(tlon,tlat,color='grey',linewidth=2)
540/46: plt.show()
540/47: plt.close('all')
540/48: fig,ax = plt.subplots()
540/49: ax.contourf(np.arange(-20,20.5,0.5),np.arange(-20,20.5,0.5),di['DJF-clim']['track'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5),extend='both')
540/50: ax.contourf(np.arange(-10,10.5,0.5),np.arange(-10,10.5,0.5),di['DJF-clim']['track'],cmap=matplotlib.cm.jet,levels=np.arange(0,50,5),extend='both')
540/51: plt.show()
541/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
541/2:
f = open(pload + 'PV-data-' + 'dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()
541/3: pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
541/4:
f = open(pload + 'PV-data-' + 'dPSP-100-ZB-800-2-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()
542/1: import numpy as np
542/2: (np.array([1,0,1,0,1,0,1,0,0,0,1,0])+1)%2
543/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle
543/2:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
f = open(pload + 'PV-data-' + 'dPSP-100-ZB-800-2-400-correct-distance-noro.txt','rb')
PVdata = pickle.load(f)
f.close()
543/3: noro = PVdata['noro']
543/4: noro.keys()
544/1:
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import numpy as np
import pickle
import os
import matplotlib.patches as patch
import xarray as xr

import cartopy
import matplotlib.gridspec as gridspec
from matplotlib.legend_handler import HandlerLineCollection
544/2:
pload = '/atmosdyn2/ascherrmann/010-IFS/traj/MED/use/'

f = open(pload + 'PV-data-MEDdPSP-100-ZB-800PVedge-0.3-400.txt','rb')
PVdata = pickle.load(f)
f.close()

dipv = PVdata['dipv']
dit = PVdata['dit']
ORO = PVdata['oro']
datadi = PVdata['rawdata']
544/3: dit.keys()
544/4: dit['20171203_00-014'].keys()
545/1: rdis=400
545/2: hcyc=0
545/3:
import numpy as np
import pickle
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
from matplotlib import cm
import argparse
import cartopy
import matplotlib.gridspec as gridspec
import pandas as pd
545/4:
pload = '/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/'
pload2 = '/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/use/'
f = open(pload + 'PV-data-dPSP-100-ZB-800-2-%d-correct-distance-noro.txt'%rdis,'rb')
PVdata = pickle.load(f)
f.close()
545/5: df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
545/6: ### take only the ones with atleast 200 trajectories
545/7: thresh = '0.75'
545/8: #df = df.loc[df['ntrajgt%s'%thresh]>=200]
545/9: df = df.loc[df['ntraj075']>=200]
545/10: df = df.loc[df['htminSLP']>=hcyc]
545/11: clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
545/12: df2 = pd.DataFrame(columns=['PV','count','avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
545/13: df2['avPV'] = np.append(np.mean(clim),clim)#df2['PV']/df2['count']
545/14: dipv = PVdata['dipv']
545/15: datadi = PVdata['rawdata']
545/16: dit = PVdata['dit']
545/17: N = PVdata['noro']
545/18: O = PVdata['oro']
545/19:
SLP = df['minSLP'].values
lon = df['lon'].values
lat = df['lat'].values
ID = df['ID'].values
hourstoSLPmin = df['htminSLP'].values
print(len(ID),len(hourstoSLPmin))
maturedates = df['date'].values
545/20:
adv = np.array([])
cyc = np.array([])
env = np.array([])
c = 'cyc'
e = 'env'

ac = dict()
pressuredi = dict()

PVstart = np.array([])
PVend = np.array([])
ca = 0
ct = 0
ol = np.array([])
ol2 = np.array([])
pvloc = dict()
cycd = dict()
envd = dict()
envoro = dict()
envnoro = dict()

for h in np.arange(0,49):
    pvloc[h] = np.array([])
    cycd[h] = np.array([])
    envd[h] = np.array([])
    envnoro[h] = np.array([])
    envoro[h] = np.array([])
545/21:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
545/22: import xarray as xr
545/23:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
545/24: data = PVdata
545/25:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
545/26: poroid
545/27:
opvloc = dict()
ocycd = dict()
oenvd = dict()
oenvoro = dict()
oenvnoro = dict()

for h in np.arange(0,49):
    opvloc[h] = np.array([])
    ocycd[h] = np.array([])
    oenvd[h] = np.array([])
    oenvnoro[h] = np.array([])
    oenvoro[h] = np.array([])
for ll,k in enumerate(dipv.keys()):
    if np.all(ID!=int(k)):
      continue
    q = np.where(ID==int(k))[0][0]
    if (hourstoSLPmin[q]<(hcyc)):
        continue
    
    d = k
            
    OL = PVdata['rawdata'][d]['OL']
    pre = PVdata['rawdata'][d]['P']
    PV = PVdata['rawdata'][d]['PV']
    i = np.where(PV[:,0]>=0.75)[0]

    pvend = PV[i,0]
    pvstart = PV[i,-1]

    cypv = dipv[d][c][i,0]
    enpv = dipv[d][e][i,0]
    envno = N[d][e][i,0]
    envo = O[d][e][i,0]

    cy = np.mean(cypv)

    PVstart = np.append(PVstart,pvstart)
    PVend = np.append(PVend,pvend)
    if np.any(poroid==d):
        for h in np.arange(0,49):
             opvloc[h] = np.append(opvloc[h],PV[i,h])
             ocycd[h] = np.append(ocycd[h],dipv[d][c][i,h])
             oenvd[h] = np.append(oenvd[h],dipv[d][e][i,h])
             oenvoro[h] = np.append(oenvoro[h],O[d][e][i,h])
             oenvnoro[h] = np.append(oenvnoro[h],N[d][e][i,h])
    else:             
      for h in np.arange(0,49):
        pvloc[h] = np.append(pvloc[h],PV[i,h])
        cycd[h] = np.append(cycd[h],dipv[d][c][i,h])
        envd[h] = np.append(envd[h],dipv[d][e][i,h])
        envoro[h] = np.append(envoro[h],O[d][e][i,h])
        envnoro[h] = np.append(envnoro[h],N[d][e][i,h])
545/28:
tsc = []
cycbox = []
envbox = []
avlic = np.array([])
tenlic = np.array([])
ninetylic = np.array([])
avlie= np.array([])
tenlie = np.array([])
ninetylie= np.array([])
cy25= np.array([])
cy75= np.array([])
cy50= np.array([])
en25= np.array([])
en75= np.array([])
en50= np.array([])
pvav = np.array([])
pv10 = np.array([])
pv90 = np.array([])

avenoro = np.array([])
enoro10 = np.array([])
enoro25 = np.array([])
enoro75 = np.array([])
enoro90 = np.array([])

avennoro = np.array([])
ennoro10 = np.array([])
ennoro25 = np.array([])
ennoro75 = np.array([])
ennoro90 = np.array([])
545/29:
for h in np.flip(np.arange(0,49)):
    pvav = np.append(pvav,np.mean(pvloc[h]))
    pv10 = np.append(pv10,np.percentile(pvloc[h],10))
    pv90 = np.append(pv90,np.percentile(pvloc[h],90))
    avlic = np.append(avlic,np.mean(cycd[h]))
    tenlic = np.append(tenlic,np.percentile(np.sort(cycd[h]),10))
    ninetylic = np.append(ninetylic,np.percentile(np.sort(cycd[h]),90))
    avlie = np.append(avlie,np.mean(envd[h]))
    tenlie = np.append(tenlie,np.percentile(np.sort(envd[h]),10))
    ninetylie = np.append(ninetylie,np.percentile(np.sort(envd[h]),90))
    cy25= np.append(cy25,np.percentile(np.sort(cycd[h]),25))
    cy75= np.append(cy75,np.percentile(np.sort(cycd[h]),75))
    cy50= np.append(cy50,np.percentile(np.sort(cycd[h]),50))
    en25= np.append(en25,np.percentile(np.sort(envd[h]),25))
    en75= np.append(en75,np.percentile(np.sort(envd[h]),75))
    en50= np.append(en50,np.percentile(np.sort(envd[h]),50))

    avenoro = np.append(avenoro,np.mean(envoro[h]))
    avennoro =np.append(avennoro,np.mean(envnoro[h]))

    enoro10= np.append(enoro10,np.percentile(np.sort(envoro[h]),10))
    enoro90= np.append(enoro90,np.percentile(np.sort(envoro[h]),90))
    enoro25= np.append(enoro25,np.percentile(np.sort(envoro[h]),25))
    enoro75= np.append(enoro75,np.percentile(np.sort(envoro[h]),75))
    ennoro25= np.append(ennoro25,np.percentile(np.sort(envnoro[h]),25))
    ennoro75= np.append(ennoro75,np.percentile(np.sort(envnoro[h]),75))
    ennoro10= np.append(ennoro10,np.percentile(np.sort(envnoro[h]),10))
    ennoro90= np.append(ennoro90,np.percentile(np.sort(envnoro[h]),90))


fig,ax = plt.subplots()
ax.set_ylabel(r'PV [PVU]')
ax.set_xlabel(r'time to mature stage [h]')
ax.set_ylim(-.75,1.75)
ax.set_xlim(-48,0)
t = np.arange(-48,1)
ax.plot(t,avlic,color='r',linewidth=2)
ax.plot(t,avennoro,color='dodgerblue',linewidth=2)
ax.plot(t,avenoro,color='grey',linewidth=2)

ax.axhline(0,linewidth=1,color='k',zorder=10)
ax.fill_between(t,tenlic,ninetylic,alpha=0.5,color='red')
ax.plot(t,cy25,color='red',linewidth=2.,linestyle='--')
ax.plot(t,cy75,color='red',linewidth=2.,linestyle='--')
ax.plot(t,ennoro25,color='dodgerblue',linewidth=2.,linestyle='--')
ax.plot(t,ennoro75,color='dodgerblue',linewidth=2.,linestyle='--')
ax.fill_between(t,ennoro10,ennoro90,alpha=0.5,color='dodgerblue')
ax.plot(t,enoro25,color='grey',linewidth=2.,linestyle='--')
ax.plot(t,enoro75,color='grey',linewidth=2.,linestyle='--')
ax.fill_between(t,enoro10,enoro90,alpha=0.5,color='grey')

ax.legend(['apvc','apveNO','apveO'],loc='upper left')
ax.set_xticks(ticks=np.arange(-48,1,6))
ax.tick_params(labelright=False,right=True)
ax.set_xticklabels(labels=t[0::6])
ax.text(-0.05, 0.98,'(b)',transform=ax.transAxes,fontsize=12,va='top')
fig.savefig('/atmosdyn2/ascherrmann/paper/cyc-env-PV/review/noro-high-oro-extracted-env-cyc-PV-lines-mean-t-%d-dis-%d-%s.png'%(hcyc,rdis,thresh),dpi=300,bbox_inches="tight")

plt.close('all')
545/30:
tsc = []
cycbox = []
envbox = []
avlic = np.array([])
tenlic = np.array([])
ninetylic = np.array([])
avlie= np.array([])
tenlie = np.array([])
ninetylie= np.array([])
cy25= np.array([])
cy75= np.array([])
cy50= np.array([])
en25= np.array([])
en75= np.array([])
en50= np.array([])
pvav = np.array([])
pv10 = np.array([])
pv90 = np.array([])

avenoro = np.array([])
enoro10 = np.array([])
enoro25 = np.array([])
enoro75 = np.array([])
enoro90 = np.array([])

avennoro = np.array([])
ennoro10 = np.array([])
ennoro25 = np.array([])
ennoro75 = np.array([])
ennoro90 = np.array([])
545/31:
for h in np.flip(np.arange(0,49)):
    pvav = np.append(pvav,np.mean(opvloc[h]))
    pv10 = np.append(pv10,np.percentile(opvloc[h],10))
    pv90 = np.append(pv90,np.percentile(opvloc[h],90))
    avlic = np.append(avlic,np.mean(ocycd[h]))
    tenlic = np.append(tenlic,np.percentile(np.sort(ocycd[h]),10))
    ninetylic = np.append(ninetylic,np.percentile(np.sort(ocycd[h]),90))
    avlie = np.append(avlie,np.mean(oenvd[h]))
    tenlie = np.append(tenlie,np.percentile(np.sort(oenvd[h]),10))
    ninetylie = np.append(ninetylie,np.percentile(np.sort(oenvd[h]),90))
    cy25= np.append(cy25,np.percentile(np.sort(ocycd[h]),25))
    cy75= np.append(cy75,np.percentile(np.sort(ocycd[h]),75))
    cy50= np.append(cy50,np.percentile(np.sort(ocycd[h]),50))
    en25= np.append(en25,np.percentile(np.sort(oenvd[h]),25))
    en75= np.append(en75,np.percentile(np.sort(oenvd[h]),75))
    en50= np.append(en50,np.percentile(np.sort(oenvd[h]),50))

    avenoro = np.append(avenoro,np.mean(oenvoro[h]))
    avennoro =np.append(avennoro,np.mean(oenvnoro[h]))

    enoro10= np.append(enoro10,np.percentile(np.sort(oenvoro[h]),10))
    enoro90= np.append(enoro90,np.percentile(np.sort(oenvoro[h]),90))
    enoro25= np.append(enoro25,np.percentile(np.sort(oenvoro[h]),25))
    enoro75= np.append(enoro75,np.percentile(np.sort(oenvoro[h]),75))
    ennoro25= np.append(ennoro25,np.percentile(np.sort(oenvnoro[h]),25))
    ennoro75= np.append(ennoro75,np.percentile(np.sort(oenvnoro[h]),75))
    ennoro10= np.append(ennoro10,np.percentile(np.sort(oenvnoro[h]),10))
    ennoro90= np.append(ennoro90,np.percentile(np.sort(oenvnoro[h]),90))


fig,ax = plt.subplots()
ax.set_ylabel(r'PV [PVU]')
ax.set_xlabel(r'time to mature stage [h]')
ax.set_ylim(-.75,1.75)
ax.set_xlim(-48,0)
t = np.arange(-48,1)
ax.plot(t,avlic,color='r',linewidth=2)
ax.plot(t,avennoro,color='dodgerblue',linewidth=2)
ax.plot(t,avenoro,color='grey',linewidth=2)

ax.axhline(0,linewidth=1,color='k',zorder=10)
ax.fill_between(t,tenlic,ninetylic,alpha=0.5,color='red')
ax.plot(t,cy25,color='red',linewidth=2.,linestyle='--')
ax.plot(t,cy75,color='red',linewidth=2.,linestyle='--')
ax.plot(t,ennoro25,color='dodgerblue',linewidth=2.,linestyle='--')
ax.plot(t,ennoro75,color='dodgerblue',linewidth=2.,linestyle='--')
ax.fill_between(t,ennoro10,ennoro90,alpha=0.5,color='dodgerblue')
ax.plot(t,enoro25,color='grey',linewidth=2.,linestyle='--')
ax.plot(t,enoro75,color='grey',linewidth=2.,linestyle='--')
ax.fill_between(t,enoro10,enoro90,alpha=0.5,color='grey')

ax.legend(['apvc','apveNO','apveO'],loc='upper left')
ax.set_xticks(ticks=np.arange(-48,1,6))
ax.tick_params(labelright=False,right=True)
ax.set_xticklabels(labels=t[0::6])
ax.text(-0.05, 0.98,'(b)',transform=ax.transAxes,fontsize=12,va='top')
fig.savefig('/atmosdyn2/ascherrmann/paper/cyc-env-PV/review/noro-high-oro-only-env-cyc-PV-lines-mean-t-%d-dis-%d-%s.png'%(hcyc,rdis,thresh),dpi=300,bbox_inches="tight")

plt.close('all')
545/32: %save -r /atmosdyn2/ascherrmann/scripts/Paper1/revision-eval/noro-PV/traj-env-cyc-remove-orographic-cyclones.py 1-999
546/1:
import numpy as np
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import argparse
import pickle

parser = argparse.ArgumentParser(description="plot accumulated average PV gain that is associated with the cyclone and the environment")
parser.add_argument('rdis',default='',type=int,help='distance from center in km that should be considered as cyclonic')
args = parser.parse_args()

p = '/atmosdyn2/ascherrmann/009-ERA-5/' + 'MED/cases/'

fsl=4

#labs = helper.traced_vars_ERA5()
labs = ['time','lon','lat','P','PV']
linestyle = ['-',':']

rdis = int(args.rdis)

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 48
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,1.6])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
#cmap = ListedColormap(['saddlebrown','orange'])
#norm = BoundaryNorm([0, 0.5, 1], cmap.N)

#for uyt, txt in enumerate(traced[:]):

#    cycID=txt[-10:-4]
#    date=txt[-25:-14]

f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance-noro.txt','rb')
data = pickle.load(f)
f.close()

dipv = data['dipv']
oro = data['oro']
546/2: rdis = 400
546/3:
p = '/atmosdyn2/ascherrmann/009-ERA-5/' + 'MED/cases/'

fsl=4

#labs = helper.traced_vars_ERA5()
labs = ['time','lon','lat','P','PV']
linestyle = ['-',':']

rdis = int(args.rdis)

wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 48
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,1.6])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
#cmap = ListedColormap(['saddlebrown','orange'])
#norm = BoundaryNorm([0, 0.5, 1], cmap.N)

#for uyt, txt in enumerate(traced[:]):

#    cycID=txt[-10:-4]
#    date=txt[-25:-14]

f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance-noro.txt','rb')
data = pickle.load(f)
f.close()

dipv = data['dipv']
oro = data['oro']
546/4:
wql = 0
meandi = dict()
env = 'env'
cyc = 'cyc'
split=[cyc,env]

datadi = dict() ####raw data of traced vars
dipv = dict() ####splited pv is stored here
dit = dict() ### 1 and 0s, 1 if traj is close to center at given time, 0 if not
meandi[env] = dict()
meandi[cyc] = dict()

H = 48
xlim = np.array([-1*H,0])
#total
ylim = np.array([-0.3,1.0])
#inside pressure layers
ylim2 = np.array([-0.3,1.6])
#xlim = xlim - 12
pressure_stack = np.zeros(H+1)
#IDstart = np.append([0],np.where(htzeta[1:]<htzeta[:-1])[0]+1)

#hoursegments = np.flip(np.arange(-48,1,1))
linewidth=1.5
alpha=1.
#cmap = ListedColormap(['saddlebrown','orange'])
#norm = BoundaryNorm([0, 0.5, 1], cmap.N)

#for uyt, txt in enumerate(traced[:]):

#    cycID=txt[-10:-4]
#    date=txt[-25:-14]

f = open('/atmosdyn2/ascherrmann/009-ERA-5/MED/ctraj/use/PV-data-dPSP-100-ZB-800-2-400-correct-distance-noro.txt','rb')
data = pickle.load(f)
f.close()

dipv = data['dipv']
oro = data['oro']
546/5:
noro = data['noro']
datadi = data['rawdata']
poroid = np.array([])
for k in dipv.keys():
    cycID=k

    idp = np.where((datadi[cycID]['PV'][:,0]>=0.75))[0]
    if np.mean(oro[k]['env'][idp,0])<=0 or np.mean(dipv[k]['env'][idp,0])<=0:
        continue
    poroid = np.append(poroid,k)
546/6: poroid.size
546/7:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
546/8: import pandas as pd
546/9:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
546/10: import xarray as xr
546/11:
df = pd.read_csv('/atmosdyn2/ascherrmann/009-ERA-5/MED/traj/pandas-all-data.csv')
#thresh='1.5PVU'
thresh='075'
df = df.loc[df['ntraj%s'%thresh]>=200]
ID = df['ID'].values

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LON  = np.linspace(-180,180,721)
LAT = np.linspace(-90,90,361)
OL = NORO['OL'][0]

clim = np.loadtxt('/atmosdyn2/ascherrmann/009-ERA-5/MED/clim-avPV.txt')
df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)

df2 = pd.DataFrame(columns=['avPV'],index=['Year','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])
df2['avPV'] = np.append(np.mean(clim),clim)
poroid = np.array([])
oro = data['oro']
for k in dipv.keys():
    if np.all(ID!=int(k)):
        continue
    i = np.where(ID==int(k))[0][0]
    mon = df['mon'].values[i]

    if np.mean(oro[k]['env'][:,0])<=0:
        continue
    if np.mean(dipv[k]['env'][:,0])<=0:
        continue

    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>=0.25:
        if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon])) * np.mean(oro[k]['env'][:,0]/dipv[k]['env'][:,0]) >= 0.25:

#    if np.mean(dipv[k]['env'][:,0]/(datadi[k]['PV'][:,0]-df2['avPV'][mon]))>0.5 and np.mean(oro[k]['env'][:,0])>= 0.5 * np.mean(dipv[k]['env'][:,0]) :
            poroid = np.append(poroid,k)
546/12: poroid.size
546/13:
for k in dipv.keys():
    cycID=k

    idp = np.where((datadi[cycID]['PV'][:,0]>=0.75))[0]
    if np.mean(oro[k]['env'][idp,0])<=0 or np.mean(dipv[k]['env'][idp,0])<=0:
        continue


    fig, axes = plt.subplots(1,1,figsize=(8,6))#1,2,sharex=True, sharey=True)
    t = datadi[cycID]['time'][0]
    ax = axes
    ax.plot([],[],marker=None,ls='-',color='black',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='red',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls=':',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls='--',color='k',alpha=1.0)

    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0),color='black',alpha=0.4)
    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0)-np.mean(datadi[cycID]['PV'][idp,-1]),color='red',alpha=0.4)

    ax = axes

    for pl,key in enumerate(['cyc']):#,'env']):
        meantmp = np.mean(dipv[cycID][key][idp],axis=0)
        ax.plot(t,meantmp,color='k',ls=linestyle[pl])

    ax.plot(t,np.mean(noro[k]['env'][idp],axis=0),color='k',ls=':')
    ax.axvline(-15,color='grey',ls='-')
    ax.plot(t,np.mean(oro[cycID]['env'][idp],axis=0),ls='--',color='k')

    axes.set_xlim(xlim)
    axes.set_xticks(ticks=np.arange(-48,1,6))
    axes.set_ylim(ylim2)
    ax.legend([r'PV$(t)$',r'apv$(t)$','apvc$(t)$', 'apveNO$(t)$','apveO$(t)$'],frameon=False,loc='upper left')
    axes.tick_params(labelright=False,right=True)
    axes.set_xlabel('time until mature stage [h]')
    axes.set_ylabel('PV [PVU]')
    axes.text(-0.135,0.875,'(b)',transform=ax.transAxes,fontsize=16)
    name = 'PVevolsplit-' + cycID + '.png'
    p = '/atmosdyn2/ascherrmann/paper/cyc-env-PV/check-orocases/'
    fig.savefig(p + name,dpi=300,bbox_inches="tight")
    plt.close('all')
546/14:
for k in poroid:
    cycID=k

    idp = np.where((datadi[cycID]['PV'][:,0]>=0.75))[0]

    fig, axes = plt.subplots(1,1,figsize=(8,6))#1,2,sharex=True, sharey=True)
    t = datadi[cycID]['time'][0]
    ax = axes
    ax.plot([],[],marker=None,ls='-',color='black',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='red',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls=':',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls='--',color='k',alpha=1.0)

    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0),color='black',alpha=0.4)
    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0)-np.mean(datadi[cycID]['PV'][idp,-1]),color='red',alpha=0.4)

    ax = axes

    for pl,key in enumerate(['cyc']):#,'env']):
        meantmp = np.mean(dipv[cycID][key][idp],axis=0)
        ax.plot(t,meantmp,color='k',ls=linestyle[pl])

    ax.plot(t,np.mean(noro[k]['env'][idp],axis=0),color='k',ls=':')
    ax.axvline(-15,color='grey',ls='-')
    ax.plot(t,np.mean(oro[cycID]['env'][idp],axis=0),ls='--',color='k')

    axes.set_xlim(xlim)
    axes.set_xticks(ticks=np.arange(-48,1,6))
    axes.set_ylim(ylim2)
    ax.legend([r'PV$(t)$',r'apv$(t)$','apvc$(t)$', 'apveNO$(t)$','apveO$(t)$'],frameon=False,loc='upper left')
    axes.tick_params(labelright=False,right=True)
    axes.set_xlabel('time until mature stage [h]')
    axes.set_ylabel('PV [PVU]')
    axes.text(-0.135,0.875,'(b)',transform=ax.transAxes,fontsize=16)
    name = 'PVevolsplit-' + cycID + '.png'
    p = '/atmosdyn2/ascherrmann/paper/cyc-env-PV/check-orocases/'
    fig.savefig(p + name,dpi=300,bbox_inches="tight")
    plt.close('all')
546/15:
for k in poroid:
    cycID=k

    idp = np.where((datadi[cycID]['PV'][:,0]>=0.75))[0]

    fig, axes = plt.subplots(1,1,figsize=(8,6))#1,2,sharex=True, sharey=True)
    t = datadi[cycID]['time'][0]
    ax = axes
    ax.plot([],[],marker=None,ls='-',color='black',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='red',alpha=0.4)
    ax.plot([],[],marker=None,ls='-',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls=':',color='black',alpha=1.0)
    ax.plot([],[],marker=None,ls='--',color='k',alpha=1.0)

    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0),color='black',alpha=0.4)
    axes.plot(t,np.mean(datadi[cycID]['PV'][idp],axis=0)-np.mean(datadi[cycID]['PV'][idp,-1]),color='red',alpha=0.4)

    ax = axes

    for pl,key in enumerate(['cyc']):#,'env']):
        meantmp = np.mean(dipv[cycID][key][idp],axis=0)
        ax.plot(t,meantmp,color='k',ls=linestyle[pl])

    ax.plot(t,np.mean(noro[k]['env'][idp],axis=0),color='k',ls=':')
    ax.axvline(-15,color='grey',ls='-')
    ax.plot(t,np.mean(oro[cycID]['env'][idp],axis=0),ls='--',color='k')

    axes.set_xlim(xlim)
    axes.set_xticks(ticks=np.arange(-48,1,6))
    axes.set_ylim(ylim2)
    ax.legend([r'PV$(t)$',r'apv$(t)$','apvc$(t)$', 'apveNO$(t)$','apveO$(t)$'],frameon=False,loc='upper left')
    axes.tick_params(labelright=False,right=True)
    axes.set_xlabel('time until mature stage [h]')
    axes.set_ylabel('PV [PVU]')
    axes.text(-0.135,0.875,'(b)',transform=ax.transAxes,fontsize=16)
    name = 'PVevolsplit-' + cycID + '.png'
    p = '/atmosdyn2/ascherrmann/paper/cyc-env-PV/check-orocases/'
    fig.savefig(p + name,dpi=300,bbox_inches="tight")
    plt.close('all')
546/16: poroid
546/17: poroid.astype(int)
546/18: sort(poroid.astype(int))
546/19: np.sort(poroid.astype(int))
547/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle
import xarray as xr
547/2:
CT = 'MED'

pload = '/atmosdyn2/ascherrmann/010-IFS/ctraj/' + CT + '/use/'

f = open(pload + 'PV-data-'+CT+'dPSP-100-ZB-800PVedge-0.3-400-correct-distance.txt','rb')
data = pickle.load(f)
f.close()

f = open('/atmosdyn2/ascherrmann/010-IFS/data/All-CYC-entire-year-NEW-correct.txt','rb')
ldata = pickle.load(f)
f.close()
547/3: ldata['DEC17'][73.0].keys()
548/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

import xarray as xr
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm

LON = np.round(np.linspace(-180,180,721),1)
LAT = np.round(np.linspace(0,90,361),1)

def find_nearest_grid_point(lon,lat):

    dlon = LON-lon
    dlat = LAT-lat

    lonid = np.where(abs(dlon)==np.min(abs(dlon)))[0][0]
    latid = np.where(abs(dlat)==np.min(abs(dlat)))[0][0]

    return lonid,latid

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
imageout = '/atmosdyn2/ascherrmann/011-all-ERA5/'
save = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/scripts/ERA5-utils/NORO')
ZB = NORO['ZB'].values[0]
Zlon = NORO['lon']
Zlat = NORO['lat']
Eminv = 800
elevation_levels = np.array([Eminv,100000])

gridmap = dict()

ecounter = np.zeros((LAT.size,LON.size))
nccounter = np.zeros((LAT.size,LON.size))
ccounter = np.zeros((LAT.size,LON.size))
necounter = np.zeros((LAT.size,LON.size))

gecounter = np.zeros((LAT.size,LON.size))
gccounter = np.zeros((LAT.size,LON.size))

PVedge=0.75
cyc = 'cyc'
env = 'env'
zbb = 800
548/2: deltaPSP=100
548/3:
f = open(save + 'global-cyclone-high-PV-frequency-cyc-env-0.15.txt','rb')
gridmap = pickle.load(f)
f.close()

ccounter = gridmap['ccounter']
nccounter = gridmap['nccounter']
ecounter = gridmap['ecounter']
necounter = gridmap['necounter']
gccounter = gridmap['gccounter']
gecounter = gridmap['gecounter']
548/4: np.where(ccounter>0)
548/5: np.where(ccounter>200)
548/6: ccounter.shape
548/7:
fig = plt.figure(figsize=(10,8))
gs = gridspec.GridSpec(nrows=1, ncols=1)
548/8: ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
548/9:
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=2, edgecolor='black')
548/10:
what = ['ccounter','nccounter','ecounter','necounter','gccounter','gecounter']
minpltlatc = -90
minpltlonc = -180

maxpltlatc = 90
maxpltlonc = 180
####
#### absolute trajectory numbers
####
pvr_levels = np.array([200,400,600,800,1100,1500,2000,2500,3000])
cmap = plt.cm.YlGnBu
ap = cmap
minv =np.min(pvr_levels)
maxv =np.max(pvr_levels)
cmap ,norm = colbar(ap,minv,maxv,len(pvr_levels))
ticklabels=np.round(pvr_levels,1)
ticklabels=pvr_levels
548/11: ax.contourf(LON,LAT,ccounter,levels=pvr_levels,cmap=cmap,norm=norm,zorder=1,extend='max')
548/12: plt.show()
548/13: LON
548/14: LON.shape
548/15: LAT.size
548/16: LON.size
548/17: ccounter.shape
548/18: np.where(ccounter[:180]>200)
548/19: plt.close('all')
548/20: fig = plt.figure(figsize=(10,8))
548/21: gs = gridspec.GridSpec(nrows=1, ncols=1)
548/22: ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
548/23:
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=2, edgecolor='black')
548/24: ax.contourf(LON,LAT[:180],ccounter[:180],levels=pvr_levels,cmap=cmap,norm=norm,zorder=1,extend='max')
548/25: plt.show()
548/26: plt.close('all')
548/27:
for :
fig = plt.figure(figsize=(10,8))
548/28:
for :
fig = plt.figure(figsize=(10,8))
548/29:
for :
 fig = plt.figure(figsize=(10,8))
548/30:
fig = plt.figure(figsize=(10,8))
gs = gridspec.GridSpec(nrows=1, ncols=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=2, edgecolor='black')
548/31: ax.contourf(LON,LAT[:50],ccounter[:50],levels=pvr_levels,cmap=cmap,norm=norm,zorder=1,extend='max')
548/32:
minpltlatc = -90
minpltlonc = -180

maxpltlatc = 90
maxpltlonc = 180
548/33: maxpltlatc = -65
548/34: ax.set_extent([minpltlonc, maxpltlonc, minpltlatc, maxpltlatc], ccrs.PlateCarree())
548/35: plt.show()
548/36: ccounter[:50]
548/37: np.where(ccounter[:50]>0)
548/38: np.where(ccounter[:50]>200)
548/39: np.where(ccounter[50:100]>200)
548/40: np.where(ccounter[50:100]>200).shape
548/41: np.where(ccounter[50:100]>200)[0].size
548/42: np.where(ccounter[-100:-50]>200)[0].size
548/43: LON
548/44: LAT
549/1:
import numpy as np
import os
import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
sys.path.append('/atmosdyn2/ascherrmann/scripts/')

import xarray as xr
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.patches as patch
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import pickle

def colbar(cmap,minval,maxval,nlevels):
    maplist = [cmap(i) for i in range(cmap.N)]
    newmap = ListedColormap(maplist)
    norm = BoundaryNorm(pvr_levels,cmap.N)
    return newmap, norm

LON = np.round(np.linspace(-180,180,721),1)
LAT = np.round(np.linspace(0,90,361),1)

def find_nearest_grid_point(lon,lat):

    dlon = LON-lon
    dlat = LAT-lat

    lonid = np.where(abs(dlon)==np.min(abs(dlon)))[0][0]
    latid = np.where(abs(dlat)==np.min(abs(dlat)))[0][0]

    return lonid,latid

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
imageout = '/atmosdyn2/ascherrmann/011-all-ERA5/'
save = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

NORO = xr.open_dataset('/atmosdyn2/ascherrmann/scripts/ERA5-utils/NORO')
ZB = NORO['ZB'].values[0]
Zlon = NORO['lon']
Zlat = NORO['lat']
Eminv = 800
elevation_levels = np.array([Eminv,100000])

gridmap = dict()

ecounter = np.zeros((LAT.size,LON.size))
nccounter = np.zeros((LAT.size,LON.size))
ccounter = np.zeros((LAT.size,LON.size))
necounter = np.zeros((LAT.size,LON.size))

gecounter = np.zeros((LAT.size,LON.size))
gccounter = np.zeros((LAT.size,LON.size))

PVedge=0.75
cyc = 'cyc'
env = 'env'
zbb = 800
549/2: deltaPSP=100
549/3:
f = open(save + 'global-cyclone-high-PV-frequency-cyc-env-0.15.txt','rb')
gridmap = pickle.load(f)
f.close()

ccounter = gridmap['ccounter']
nccounter = gridmap['nccounter']
ecounter = gridmap['ecounter']
necounter = gridmap['necounter']
gccounter = gridmap['gccounter']
gecounter = gridmap['gecounter']
549/4: np.where(ccounter[-100:-50]>200)[0].size
549/5: np.where(ccounter[50:100]>200)[0].size
549/6: np.where(ccounter[:180]>200)[0].size
549/7:
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        print(o,r)
549/8:
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        if o!='SP' or r!='ge--60-l--45':
            continue
        print(o,r)
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        f = open(sp + o + '/' + r  + '/PV-data' + o + '-' + r + '-dPSP-' + str(deltaPSP) + '-ZB-' + str(zbb) + '-%d.txt'%rdis,'rb')
        data = pickle.load(f)
        f.close()
549/9: datadi = data['rawdata']
550/1:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/atmosdyn2/ascherrmann/scripts/')
import wrfsims
import numpy as np
import matplotlib.pyplot as plt
import re
import pickle
from scipy.stats import pearsonr as pr

SIMS,ATIDS,MEDIDS = wrfsims.upper_ano_only()
SIMS = np.array(SIMS)
550/2:
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')[0]
LAT = wrf.getvar(ref,'lat')[:,0]
550/3:
import cartopy.crs as ccrs
import cartopy
import matplotlib.gridspec as gridspec
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
from colormaps import PV_cmap2
cmap,levels,norm,ticklabels=PV_cmap2()
550/4:
minlon = -15
maxlon = 50
minlat = 20
maxlat = 60
550/5: djfic = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01:00:00')
550/6: ls /atmosdyn2/ascherrmann/013-WRF-sim/DJF-clim/
550/7: djfic = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
550/8: djfic.variables.keys()
550/9:
for k in djfic.variables.keys():
    print(k)
550/10: DJFMSLP = djfic.variables['MSLP']
550/11: DJFMSLP
550/12: DJFMSLP = djfic.variables['MSLP'][0,:]
550/13: mamic = ds(dwrf + 'MAM-clim/wrfout_d01_2000-12-01_00:00:00')
550/14: MAMMSLP = mamic.variables['MSLP'][0,:]
550/15: dMSLP = DJFMSLP-MAMMSLP
550/16: fig = plt.figure(figsize=(10,8))
550/17: gs = gridspec.GridSpec(nrows=1, ncols=1)
550/18: ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
550/19: ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=2, edgecolor='black')
550/20: h = ax.contourf(LON,LAT,dMSLP,cmap=matplotlib.cm.BrBG,levels=np.arange(-10,11,2),extend='both')
550/21: import matplotlib
550/22: h = ax.contourf(LON,LAT,dMSLP,cmap=matplotlib.cm.BrBG,levels=np.arange(-10,11,2),extend='both')
550/23: ax.set_extent([minlon,maxlon,minlat,maxlat])
550/24: cbax = fig.add_axes([0.0, 0.0, 0.1, 0.1])
550/25: cbar=plt.colorbar(h, ticks=levels,cax=cbax)
550/26: func=resize_colorbar_vert(cbax, ax, pad=0.0, size=0.015)
550/27: fig.canvas.mpl_connect('draw_event', func)
550/28: plt.show()
550/29: plt.close('all')
550/30: %save -r /atmosdyn2/ascherrmann/scripts/Paper2/MSLP-difference-in-ICS.py 1-999
551/1: np.ones((5,5)).flatten
551/2: import numpy as np
551/3: import numpy as np
551/4: np.ones((5,5)).flatten
551/5: np.ones((5,5)).flatten()
551/6: np.ones((5,5)).flatten().size
552/1: from netCDF4 import Dataset as ds
552/2: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
552/3: d.variables.keys()
552/4: d.variables['CLONG']
552/5: d.variables['CLONG'][:]
554/1: from netCDF4 import Dataset as ds
554/2: nc1 = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
554/3: nc1.variables.keys()
555/1: from netCDF4 import Dataset as ds
555/2: d = ds('met_em.d02.2000-12-01_00:00:00.nc','r')
555/3: d.variables.keys()
557/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import os
import pickle
import xarray as xr
import matplotlib
import cartopy.crs as ccrs
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER
import matplotlib.pyplot as plt
557/2:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
557/3:
tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)

tracks = np.sort(tracks)
557/4: tracks
557/5: tracks[346:]
557/6: fdate = tracks[0]
557/7: d = np.loadtxt(trackpath + fdate,skiprows=4)
557/8: np.unique(d[:,-1])
557/9: np.unique(d[:,-1]).size
557/10:
ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
ids = np.append(ids,len(d[:,-1]))
557/11: ids.size
557/12: ids
558/1: import pickle
558/2: f = open('NA-96h-pre-track-deep-over-sea-12h.txt','rb')
558/3: d = pickle.load(f)
558/4: f.close()
558/5: d.keys()
558/6: d
558/7: d.shape
558/8: f = open('MED-96h-pre-track-deep-over-sea-12h.txt','rb')
558/9: d = pickle.load(f)
558/10: f.close()
558/11: d.shape
558/12: d[0]
558/13: d[1]
559/1: %history -g -f ipyhistory
560/1:
import numpy as np
import pickle
import xarray as xr
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

regions = ['MED','NA','SA','NP','SP','IO']
560/2: add = 'deep-over-sea'
560/3:
LONG = np.arange(-180,180,0.5)
LATG = np.arange(-90,90.1,0.5)
560/4:
hoursel = 12
add = add + '-%dh'%hoursel
560/5: mature = dict()
560/6:
for r in regions[:]:
    f  = open(p + r + '-mature-' + add + '.txt','rb')
    mature[r] = pickle.load(f)
    f.close()
560/7: r = 'MED
560/8: r = 'MED'
560/9: m = mature[r]
560/10: m
560/11: m.shape
560/12:
regtmp = dict()
slpdi = dict()
fulldi = dict()
lon=dict()
lat=dict()
htSLPmin = dict()
dates =dict()
for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])
    lon[r] =np.array([])
    lat[r]= np.array([])
    htSLPmin[r] = np.array([])
    dates[r] = np.array([])


### that loop generates arrays containing all cyclones in that region
for k in range(1979,1980):
  #load SLP,LON,LAT,ID,etc into tmp
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '-' + add + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
560/13: add = 'deep-over-sea'
560/14:
regtmp = dict()
slpdi = dict()
fulldi = dict()
lon=dict()
lat=dict()
htSLPmin = dict()
dates =dict()
for r in regions:
    regtmp[r] = np.array([])
    slpdi[r] = np.array([])
    lon[r] =np.array([])
    lat[r]= np.array([])
    htSLPmin[r] = np.array([])
    dates[r] = np.array([])


### that loop generates arrays containing all cyclones in that region
for k in range(1979,1980):
  #load SLP,LON,LAT,ID,etc into tmp
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '-' + add + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
560/15: tmp.keys()
560/16: tmp['ID-']
560/17: len(tmp['ID-'])
560/18: len(tmp['lon-'])
560/19: tmp['lon-']
560/20: tmp['hourstoSLPmin-']
560/21: :q
560/22: tmp['dates']
560/23: tmp['dates-']
561/1: import pickle
561/2: f = open('loopcheck.txt','rb')
561/3: d = pickle.load(f)
561/4: f.close()
561/5: d.keys()
561/6: d['date']
561/7: d['originalIDs']
561/8: d['originalIDs'].size
561/9: d['lat'].size
561/10: d['lon'].size
561/11: d['slp'].size
561/12: d['htslp'].size
561/13: d['ht'].size
561/14: d['lon']-d['ht']
561/15: np.all(d['lon']-d['ht']==0)
561/16: import numpy as np
561/17: np.all(d['lon']-d['ht']==0)
561/18: d['slp']
561/19: IDc = 12682
561/20:
import pandas as pd
import numpy as np
import pickle
import os

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'

regions = ['MED','NA','SA','NP','SP','IO']
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

add = 'deep-over-sea'
wrongfiles = np.array([])
wronght = np.array([])
wronglon = np.array([])
wronglat = np.array([])
wrongslp = np.array([])
for k in range(1979,1980):
    #load SLP,LON,LAT,ID,etc into tmp
    tmp = dict()
    for x in savings:
        f = open(p + x + str(k) + '-' + add + '.txt',"rb")
        tmp[x] = pickle.load(f)
        f.close()

    for l, ID in enumerate(tmp['ID-']):
        if ID!=IDc:
            continue
        tmplon = np.array(tmp['lon-'][l])
        tmplat = np.array(tmp['lat-'][l])
        tmpslp = np.array(tmp['SLP-'][l])
        tmpht = np.array(tmp['hourstoSLPmin-'][l])

        date = tmp['dates-'][l][0]

        track = np.loadtxt(trackpath+'fi_' + date[:6],skiprows=4)
        ids = track[:,-1]

        if not np.any(ids==ID):
            wrongfiles=np.append(wrongfiles,ID)
            continue

        loc = np.where(ids==ID)[0]
        lon = track[loc,1]
        lat = track[loc,2]
        slp = track[loc,3]
        ht = track[loc,0]-track[loc[np.argmin(slp)],0]

        compht = ht-tmpht
        if not np.all(compht==0):
            wronght = np.append(wronght,ID)

        complat = lat-tmplat
        if not np.all(complat==0):
            wronglat = np.append(wronglat,ID)

        complat = lon-tmplon
        if not np.all(compht==0):
            wronglon = np.append(wronglon,ID)

        compslp= slp-tmpslp
        if not np.all(compht==0):
            wrongslp = np.append(wrongslp,ID)
561/21: tmplon
561/22: lon
561/23: lon-tmplon
562/1: IDc = 12682
563/1: IDc = 12682
563/2:
import pandas as pd
import numpy as np
import pickle
import os

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'

regions = ['MED','NA','SA','NP','SP','IO']
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

add = 'deep-over-sea'
wrongfiles = np.array([])
wronght = np.array([])
wronglon = np.array([])
wronglat = np.array([])
wrongslp = np.array([])
for k in range(1979,1980):
    #load SLP,LON,LAT,ID,etc into tmp
    tmp = dict()
    for x in savings:
        f = open(p + x + str(k) + '-' + add + '.txt',"rb")
        tmp[x] = pickle.load(f)
        f.close()

    for l, ID in enumerate(tmp['ID-']):
        if ID!=IDc:
            continue
        tmplon = np.array(tmp['lon-'][l])
        tmplat = np.array(tmp['lat-'][l])
        tmpslp = np.array(tmp['SLP-'][l])
        tmpht = np.array(tmp['hourstoSLPmin-'][l])

        date = tmp['dates-'][l][0]

        track = np.loadtxt(trackpath+'fi_' + date[:6],skiprows=4)
        ids = track[:,-1]

        if not np.any(ids==ID):
            wrongfiles=np.append(wrongfiles,ID)
            continue

        loc = np.where(ids==ID)[0]
        lon = track[loc,1]
        lat = track[loc,2]
        slp = track[loc,3]
        ht = track[loc,0]-track[loc[np.argmin(slp)],0]

        compht = ht-tmpht
        if not np.all(compht==0):
            wronght = np.append(wronght,ID)

        complat = lat-tmplat
        if not np.all(complat==0):
            wronglat = np.append(wronglat,ID)

        complat = lon-tmplon
        if not np.all(compht==0):
            wronglon = np.append(wronglon,ID)

        compslp= slp-tmpslp
        if not np.all(compht==0):
            wrongslp = np.append(wrongslp,ID)
563/3: ht
563/4: tmpht
563/5: slp
563/6: slp[28:32]
563/7: slp[25:35]
563/8: tmpslp[25:35]
563/9: SLPmin = np.where(slp == np.min(slp))[0][-1]
563/10: SLPmin
563/11: np.argmin(slp)
564/1: import pickle
564/2: f = open('loopcheck.txt','rb')
564/3: d = pickle.load(f)
564/4: f.close()
564/5:
for k in d.keys():
    print(k,d[k].size)
564/6: d['lat']
563/12: IDc = 3116
563/13:
import pandas as pd
import numpy as np
import pickle
import os

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'

regions = ['MED','NA','SA','NP','SP','IO']
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

add = 'deep-over-sea'
wrongfiles = np.array([])
wronght = np.array([])
wronglon = np.array([])
wronglat = np.array([])
wrongslp = np.array([])
for k in range(1979,1980):
    #load SLP,LON,LAT,ID,etc into tmp
    tmp = dict()
    for x in savings:
        f = open(p + x + str(k) + '-' + add + '.txt',"rb")
        tmp[x] = pickle.load(f)
        f.close()

    for l, ID in enumerate(tmp['ID-']):
        if ID!=IDc:
            continue
        tmplon = np.array(tmp['lon-'][l])
        tmplat = np.array(tmp['lat-'][l])
        tmpslp = np.array(tmp['SLP-'][l])
        tmpht = np.array(tmp['hourstoSLPmin-'][l])

        date = tmp['dates-'][l][0]

        track = np.loadtxt(trackpath+'fi_' + date[:6],skiprows=4)
        ids = track[:,-1]

        if not np.any(ids==ID):
            wrongfiles=np.append(wrongfiles,ID)
            continue

        loc = np.where(ids==ID)[0]
        lon = track[loc,1]
        lat = track[loc,2]
        slp = track[loc,3]
        ht = track[loc,0]-track[loc[np.argmin(slp)],0]

        compht = ht-tmpht
        if not np.all(compht==0):
            wronght = np.append(wronght,ID)

        complat = lat-tmplat
        if not np.all(complat==0):
            wronglat = np.append(wronglat,ID)

        complat = lon-tmplon
        if not np.all(compht==0):
            wronglon = np.append(wronglon,ID)

        compslp= slp-tmpslp
        if not np.all(compht==0):
            wrongslp = np.append(wrongslp,ID)
563/14: lat-tmplat
563/15: lon-tmplon
565/1: :q
565/2:
import pandas as pd
import numpy as np
import pickle

regions = ['MED','NA','SA','NP','SP','IO']
mature = dict()
other = dict()
pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
psave =pload

#### raw data
for r in regions:
    f = open(pload + r + '-96h-pre-track-deep-over-sea-12h.txt','rb')
    mature[r] = pickle.load(f)
    f.close()
565/3: r = 'MED'
565/4: mature[r]
565/5: mature[r].shape
565/6: import pandas as pd
565/7:
pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
psave =pload
565/8: df = pd.read_csv(psave + 'pandas-' + r + '-track-data-all-deep-over-sea-12h.csv')
565/9: df
566/1: import numpy as np
566/2: import matplotlib.pyplot as plt
566/3: import sys
566/4: sys.path.append('/home/ascherrmann/scripts/')
566/5: tracks = '/home/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'
566/6: ntracks = '/home/ascherrmann/scripts/WRF/nestedcyclone-tracking/out/'
566/7: otrack = np.loadtxt(tracks + 'DJF-clim-max-U-at-300-hPa-1.4-QGPV-new-tracks.txt',skiprows=4)
566/8: ntracks = '/atmosdyn2/ascherrmann/scripts/WRF/nestedcyclone-tracking/out/'
566/9: tracks = '/atmosdyn2/ascherrmann/scripts/WRF/cyclone-tracking-wrf/out/'
566/10: otrack = np.loadtxt(tracks + 'DJF-clim-max-U-at-300-hPa-1.4-QGPV-new-tracks.txt',skiprows=4)
566/11: tra = otrack
566/12:
t = tra[:,0]
tlon,tlat = tra[:,1],tra[:,2]
slp = tra[:,3]
IDs = tra[:,-1]
566/13: loc = np.where(IDs==2)[0]
566/14: lo = np.where(slp[loc] ==np.min(slp[loc]))[0][0]
566/15: tm = t[loc[lo]]
566/16: dm =helper.simulation_time_to_day_string(tm)
566/17: import helper
566/18: dm =helper.simulation_time_to_day_string(tm)
566/19: fig = plt.figure(figsize=(8,6))
566/20: import matplotlib.gridspec as gridspec
566/21: gs = gridspec.GridSpec(nrows=1, ncols=1)
566/22: ax = fig.add_subplot(gs[0,0])
566/23: ax.plot(1 + t[loc]/24,slp[loc],color='b')
566/24:
ax.set_xlabel('simulation time [d]')
ax.set_xlim(1+t[loc[0]]/24,1+t[loc[-1]]/24)
ax.set_ylabel('SLP [hPa]')
ax.set_ylim(990,1015)
566/25: tra = np.loadtxt(ntracks + 'nested-test-01-new-tracks.txt',skiprows=4)
566/26: ntracks = '/atmosdyn2/ascherrmann/scripts/WRF/nested-cyclone-tracking/out/'
566/27: tra = np.loadtxt(ntracks + 'nested-test-01-new-tracks.txt',skiprows=4)
566/28:
t = tra[:,0]
tlon,tlat = tra[:,1],tra[:,2]
slp = tra[:,3]
IDs = tra[:,-1]
566/29: loc = np.where(IDs==2)[0]
566/30: lo = np.where(slp[loc] ==np.min(slp[loc]))[0][0]
566/31: tm = t[loc[lo]]
566/32: dm =helper.simulation_time_to_day_string(tm)
566/33: ax.plot(1 + t[loc]/24,slp[loc],color='purple',linestyle='--')
566/34: tra = np.loadtxt(ntracks + 'nested-test-02-new-tracks.txt',skiprows=4)
566/35:
t = tra[:,0]
tlon,tlat = tra[:,1],tra[:,2]
slp = tra[:,3]
IDs = tra[:,-1]
566/36: loc = np.where(IDs==2)[0]
566/37: ax.plot(1 + t[loc]/24,slp[loc],color='red',linestyle=':')
566/38: plt.show()
566/39: ax.legend(['single domain 0.5$^{\circ}$','nested domain 0.5$^{\circ}$','nested domain 0.1$^{\circ}$'],loc='upper right')
566/40: pwd
566/41: fig.savefig('/atmosdyn2/ascherrmann/paper/NA-MED-link/nested-domain-SLP-evo-difference.png',dpi=300,bbox_inches="tight")
566/42: plt.close('all')
566/43: %save -r /atmosdyn2/ascherrmann/scripts/Paper2/nested-domain-SLP-evolution-difference.py 1-999
566/44: %save -r /home/ascherrmann/scripts/Paper2/nested-domain-SLP-evolution-difference.py 1-999
568/1: import pickle
568/2: f = open('loopcheck.txt','rb')
568/3: d = pickle.load(f)
568/4: f.close()
568/5: d.keys()
568/6: d['ht'].size
568/7: d['slp'].size
568/8: d['date'].size
568/9: d['lat']
568/10: d['lon']
569/1: import numpy as np
569/2: np.argsort(np.array([7,2,9,3,1,0,29,0,1,3]))
569/3: order = np.argsort(np.array([7,2,9,3,1,0,29,0,1,3]))
569/4: np.array(['a','b','c','d','e','f','g','h','j'])[order]
569/5: np.array(['a','b','c','d','e','f','g','h','j','k'])[order]
569/6: b = dict()
569/7: b['MED'] = np.array(['a','b','c','d','e','f','g','h','j','k'])
569/8: b['MED']
569/9: b['MED'] = b['MED'][order]
569/10: b['MED']
570/1: ID = 5965
570/2:
import numpy as np
import pickle
570/3:
p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'

regions = ['MED','NA','SA','NP','SP','IO']
570/4: add = 'deep-over-sea'
570/5: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
570/6: import pandas as pd
570/7: df = pd.read_csv(p + 'data/pandas-basic-data-all-deep-over-sea-12h.csv')
570/8: df = pd.read_csv(p + 'pandas-basic-data-all-deep-over-sea-12h.csv')
570/9: df.columns
570/10: df.iloc[df['ID']==ID]
570/11: df['ID'].values
570/12: np.where(df['ID'].values==ID)
570/13: ID
570/14: np.unique(df['ID'].values,return_counts=True)
570/15: v,c = np.unique(df['ID'].values,return_counts=True)
570/16: np.where(c>1)[0]
570/17: np.where(c>1)[0].size
570/18:
other = dict()
for r in ['NP']:
    f = open(pload + r + '-mature-deep-over-sea-12h.txt','rb')
    other[r] = pickle.load(f)
    f.close()
570/19: pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
570/20:
other = dict()
for r in ['NP']:
    f = open(pload + r + '-mature-deep-over-sea-12h.txt','rb')
    other[r] = pickle.load(f)
    f.close()
570/21: other
570/22: other['NP'].shape
570/23: df = pd.DataFrame(other['MED'],columns=['ID','lon','lat','htSLPmin','minSLP','dates'])
570/24: df = pd.DataFrame(other['NP'],columns=['ID','lon','lat','htSLPmin','minSLP','dates'])
570/25: df['reg'] = 'NP'
570/26: df
570/27: cols = list(df.columns)
570/28: df = df[[cols[-1]] + cols[:-1]]
570/29: df
570/30: df['test']='NA'
570/31: df
570/32: a,c = np.unique(df['ID'].values,return_counts=True)
570/33: np.where(c>1)[0].size
570/34: a
570/35: df['ID'].values
570/36: np.where(df['ID'].values==100005)[0]
570/37: np.where(df['ID'].values=='100005.0')
570/38: np.where(c>1)[0]
570/39: a[274]
570/40: np.where(df['ID'].values=='10541.0')
570/41: df.iloc[[12558,17824]]
570/42:
import numpy as np
import pickle
savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']

p = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
regions = ['MED','NA','SA','NP','SP','IO']
add = 'deep-over-sea'

ids = np.array([])
### that loop generates arrays containing all cyclones in that region
for k in range(1979,1980):
  #load SLP,LON,LAT,ID,etc into tmp
  tmp = dict()
  for x in savings:
    if x!='ID-':
        continue
    f = open(p + x + str(k) + '-' + add + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
570/43: tmp
570/44: tmp.keys()
570/45: tmp['ID']
570/46: tmp['ID-']
570/47: ls /atmosdyn2/ascherrmann/011-all-ERA5/data/
570/48: ls /atmosdyn2/ascherrmann/011-all-ERA5/data/SLP*deep-over-sea.txt
570/49: tracks
570/50: import os
570/51:
tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)

tracks = np.sort(tracks)
570/52: trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
570/53:
tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)

tracks = np.sort(tracks)
570/54: tracks
570/55: tracks = tracks[346:-12]
570/56: tracks
570/57: tracks = tracks[:-1]
570/58: tracks
570/59: yeartmp = 1979
570/60: gID = np.array([])
570/61: lID = np.array([])
570/62:
import pickle
ID = []
for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    if ((yeartmp-year)!=0):
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/63: a,c =np.unique(gID,return_counts=True)
570/64: print(np.where(c>1)[0].size)
570/65: np.max(c)
570/66:
import pickle
ID = []
for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    if ((yeartmp-year)!=0):
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        lID = np.array([])
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/67: a,c =np.unique(gID,return_counts=True)
570/68: print(np.where(c>1)[0].size)
570/69: gID = np.array([])
570/70: lID = np.array([])
570/71:
import pickle
ID = []
for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    if ((yeartmp-year)!=0):
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        lID = np.array([])
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/72: a,c =np.unique(gID,return_counts=True)
570/73: print(np.where(c>1)[0].size)
570/74:
import pickle
ID = []
gID = np.array([])
lID = np.array([])
for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    print(fdate,year,yeartmp)
    if ((yeartmp-year)!=0):
        print(save)
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        lID = np.array([])
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/75:
import pickle
ID = []
gID = np.array([])
lID = np.array([])
for qqq,fdate in enumerate(tracks[346:]):
    year = int(fdate[-6:-2])
    print(fdate,year,yeartmp)
    if ((yeartmp-year)!=0):
        print(fdate,'save')
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        lID = np.array([])
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/76: tracks
570/77:
import pickle
ID = []
gID = np.array([])
lID = np.array([])
yeartmp=1979
for qqq,fdate in enumerate(tracks[:]):
    year = int(fdate[-6:-2])
    print(fdate,year,yeartmp)
    if ((yeartmp-year)!=0):
        print(fdate,'save')
        gID = np.append(gID,lID)
        f = open('/home/ascherrmann/scripts/redo-allocean/ID-%d.txt'%yeartmp,'wb')
        pickle.dump(ID,f)
        f.close()
        lID = np.array([])
        
    yeartmp=year
    d = np.loadtxt(trackpath + fdate,skiprows=4)
    ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
    ids = np.append(ids,len(d[:,-1]))
    for k,i in enumerate(ids[:-1]):
        ID.append(d[i,-1])
        lID = np.append(lID,d[i,-1])
    a,c = np.unique(lID,return_counts=True)
    print(np.where(c>1)[0].size)
570/78: a,c =np.unique(gID,return_counts=True)
570/79: print(np.where(c>1)[0].size)
571/1:
import numpy as np
import os
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
571/2:
import pickle
import pandas as pd
571/3:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'

for o in os.listdir(sp):
    if o!='NP' and o!='SP':
        continue

    for r in os.listdir(sp + o):
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = drft['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat[loc],float(eval(matpos[loctr])[1]))
571/4:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'

for o in os.listdir(sp):
    if o!='NP' and o!='SP':
        continue

    for r in os.listdir(sp + o):
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = dftr['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat[loc],float(eval(matpos[loctr])[1]))
571/5:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'

for o in os.listdir(sp):
    if o!='NP' and o!='SP':
        continue

    for r in os.listdir(sp + o):
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = dftr['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat1[loc],float(eval(matpos[loctr])[1]))
571/6:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
counter = dict()
for o in os.listdir(sp):
    counter[o] = dict()

    for r in os.listdir(sp + o):
        counter[o][r] = 0
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = dftr['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat1[loc],float(eval(matpos[loctr])[1]))
                counter[o][r] +=1
571/7:
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        print(o,r,counter[o][r])
571/8:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
counter = dict()
weirdids = dict()
for o in os.listdir(sp):
    counter[o] = dict()
    weirids[o] = dict()
    for r in os.listdir(sp + o):
        counter[o][r] = 0
        weirdids[o][r] = np.array([])
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = dftr['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat1[loc],float(eval(matpos[loctr])[1]))
                counter[o][r] +=1
                weirdids[o][r] = np.append(weirdids[o][r],cycID)
571/9:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
counter = dict()
weirdids = dict()
for o in os.listdir(sp):
    counter[o] = dict()
    weirdids[o] = dict()
    for r in os.listdir(sp + o):
        counter[o][r] = 0
        weirdids[o][r] = np.array([])
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        traj = np.array([])
        for d in os.listdir(sp + o + '/' + r):
            if(d.startswith('trajectories-mature')):
                traj = np.append(traj,d)

        ###
        ### region data loading
        ###
        df = pd.read_csv(dpth + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + o + '-tracks-deepest-' + r + '.csv')

        ###
        ### real calculation
        ###

        ids = df['ID'].values
        lon1,lat1 = df['lon'].values,df['lat'].values
        idstr = dftr['ID'].values
        matpos = dftr['0'].values
        htminSLPs = df['htSLPmin'].values
        for uyt2, txt in enumerate(traj[:]):
            cycID = txt[-10:-4]
            loc = np.where(ids==int(cycID))[0][0]
            loctr = np.where(idstr==int(cycID))[0][0]
            htminSLP = htminSLPs[loc]
            if lon1[loc]!=float(eval(matpos[loctr])[0]) or lat1[loc]!=float(eval(matpos[loctr])[1]):
                print('ocean','reg','ID','nIDpandasdata','nIDtrackdata','londata','lontrack','latdata','lattrack')
                print(o,r,cycID,np.where(ids==int(cycID))[0].size,np.where(idstr==int(cycID))[0].size,lon1[loc],float(eval(matpos[loctr])[0]),lat1[loc],float(eval(matpos[loctr])[1]))
                counter[o][r] +=1
                weirdids[o][r] = np.append(weirdids[o][r],cycID)
571/10: weirdids
571/11: import pickle
571/12: f = open('/home/ascherrmann/scripts/all-ocean/weird-track-data-ids.txt','wb')
571/13: f = open('/home/ascherrmann/scripts/all-oceans/weird-track-data-ids.txt','wb')
571/14: pickle.dump(weirdids,f)
571/15: f.close()
571/16: fwi  = np.array([])
571/17:
for o in os.listdir(sp):
    for r in os.listdir(sp + o):
        fwi = np.append(fwi,weirdids[o][r])
571/18: fwi.size
571/19:
pload = '/atmosdyn2/ascherrmann/011-all-ERA5/data/'
psave =pload
571/20: df = pd.read_csv(pload + 'pandas-basic-data-all-deep-over-sea-12h.csv')
571/21: ID = df['ID'].values
571/22:
for i in fwi:
    print(np.where(ID==i)[0].size)
571/23:
for i in fwi:
    print(np.where(ID==int(i))[0].size)
571/24: loc = np.array([])
571/25:
for i in fwi:
    loc = np.append(loc,np.where(ID==int(i))[0])
    print(np.where(ID==int(i))[0].size)
571/26: loc
571/27: wdf = df.iloc[loc]
571/28: wdf
571/29: trloc = np.array([])
571/30: regions
571/31: regions = ['MED','NA','SA','NP','SP','IO']
571/32:
FULLDI = dict()
MATUREDATA = dict()
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    FULLDI[r] = pickle.load(f)
    f.close()

    f = open(p + r + '-mature-' + add + '.txt','rb')
    MATUREDATA[r] = pickle.load(f)
    f.close()
571/33: p = pload
571/34:
FULLDI = dict()
MATUREDATA = dict()
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    FULLDI[r] = pickle.load(f)
    f.close()

    f = open(p + r + '-mature-' + add + '.txt','rb')
    MATUREDATA[r] = pickle.load(f)
    f.close()
571/35: add = 'deep-over-sea'
571/36:
FULLDI = dict()
MATUREDATA = dict()
for r in regions[:]:
    f = open(p + r + '-' + add + '.txt',"rb")
    FULLDI[r] = pickle.load(f)
    f.close()

    f = open(p + r + '-mature-' + add + '.txt','rb')
    MATUREDATA[r] = pickle.load(f)
    f.close()
571/37:
for r in regions[:]:
    print(np.array(list(FULLDI[r].keys())).size,np.array(list(MATUREDATA[r].keys())).size)
571/38:
for r in regions[:]:
    print(np.array(list(FULLDI[r].keys())).size,MATUREDATA[r].shape)
571/39:
for r in regions[:]:
    print(np.array(list(FULLDI[r].keys())).size,MATUREDATA[r].shape[0])
571/40:
for r in regions[:]:
    print(np.array(list(FULLDI[r].keys())).sizei-MATUREDATA[r].shape[0])
571/41:
for r in regions[:]:
    print(np.array(list(FULLDI[r].keys())).size-MATUREDATA[r].shape[0])
571/42:
for r in regions[:]:
    print(r,np.array(list(FULLDI[r].keys())).size-MATUREDATA[r].shape[0])
571/43: FULLDI[r].keys()
571/44: FULLDI[r].keys().type
571/45: np.array(list(FULLDI[r].keys()))
571/46:
if np.any(np.array(list(FULLDI[r].keys()))==411223):
    print('test')
571/47: savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']
571/48:
for k in range(1979,1980):
  #load SLP,LON,LAT,ID,etc into tmp
  tmp = dict()
  for x in savings:
    f = open(p + x + str(k) + '-' + add + '.txt',"rb")
    tmp[x] = pickle.load(f)
    f.close()
571/49: tmp['ID-']
571/50:
base = 8e5
count = 0
for IDSS in tmp['ID-']:
    listcheck = np.array(list(FULLDI.keys()))
    if np.any(listcheck==IDSS):
        print(IDSS,base+count)
        count+=1
571/51:
base = 8e5
count = 0
for IDSS in tmp['ID-']:
    listcheck = np.array(list(FULLDI[r].keys()))
    if np.any(listcheck==IDSS):
        print(IDSS,base+count)
        count+=1
571/52: %save -r /home/ascherrmann/scripts/all-ocean/ids-checking.py 1-999
571/53: %save -r /home/ascherrmann/scripts/all-oceans/ids-checking.py 1-999
572/1: import numpy as np
572/2: np.arange(-45,1)
572/3: htminslp = 45
572/4: np.arange(-45,1)[45]
572/5: np.arange(-45,1)[:45]
572/6: np.arange(-45,1)[:45+1]
572/7: np.arange(-127,1)
572/8: np.delete(np.arange(-127,1),np.arange(0,len(np.arange(-127,1))-97))
572/9: np.delete(np.arange(-127,1),np.arange(0,len(np.arange(-127,1))-97))[-96]
572/10: np.ones(98)[-1*len(np.arange(-48,1)):] = np.arange(-48,1)
572/11: lontrack = np.ones(98)
572/12: lontrack[-1*len(np.arange(-48,1)):] = np.arange(-48,1)
572/13: lontrack
572/14: np.vstack((lontrack,lontrack))
572/15: np.vstack((lontrack,lontrack)).shape
573/1: import pickle
573/2: f = open('/home/ascherrmann/double-cyclone-track-ids.txt','rb')
573/3: d = pickle.load(f)
573/4: f.close()
573/5: d.keys()
573/6: test = d['doubleidtotrackdict']
573/7: test
573/8: np.array(test.keys())
573/9: import numpy as np
573/10: np.array(test.keys())
573/11: np.array(test.keys()).size
573/12: np.array(list(test.keys())).size
573/13: np.array(list(test.keys()))
573/14: less check-era5-track.py
573/15: test
573/16:
trackfiles = np.array([])
for k in test.keys():
    if not np.any(trackfiles==(test[k][0],test[k][1])):
        np.append(trackfiles,(test[k][0],test[k][1]))
573/17: trackfiles
573/18: (test[k][0],test[k][1])
573/19:
trackfiles1 = np.array([])
trackfiles2 = np.array([])
for k in test.keys():
    if not np.any(trackfiles1==test[k][0]):
        np.append(trackfiles1,test[k][0])
    if not np.any(trackfiles2==test[k][1]):
        np.append(trackfiles2,test[k][1])
573/20: test[k]
573/21: test[k][0]
573/22: trackfiles1
573/23: not np.any(trackfiles1,test[k][0])
573/24:
trackfiles1 = np.array([])
trackfiles2 = np.array([])
for k in test.keys():
    if not np.any(trackfiles1==int(test[k][0][3:])):
        np.append(trackfiles1,int(test[k][0][3:]))
    if not np.any(trackfiles2==int(test[k][1][3:])):
        np.append(trackfiles2,int(test[k][1][3:]))
573/25: trackfiles1
573/26: int(test[k][0][3:])
573/27:
trackfiles1 = np.array([])
trackfiles2 = np.array([])
for k in test.keys():
        np.append(trackfiles1,int(test[k][0][3:]))
        np.append(trackfiles2,int(test[k][1][3:]))
573/28: trackfiles1
573/29: test[k][0][3:]
573/30: int(test[k][0][3:])
573/31:
for k in test.keys():
    print(k)
573/32:
a = []
b = []
for k in test.keys():
    a.append(int(test[k][0][3:]))
573/33: a
573/34:
a = []
b = []
for k in test.keys():
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/35: b
573/36: a
573/37:
a = []
b = []
c = np.array([])
for k in test.keys():
    c = np.append(c,(int(test[k][0][3:]),int(test[k][1][3:])))
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/38: c
573/39:
a = []
b = []
c = np.array([])
for k in test.keys():
    c = np.append(c,((int(test[k][0][3:]),int(test[k][1][3:]))))
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/40: c
573/41:
a = []
b = []
c = np.array([],dtype=object)
for k in test.keys():
    c = np.append(c,((int(test[k][0][3:]),int(test[k][1][3:]))))
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/42: c
573/43:
a = []
b = []
c = np.empty(len(list[test.keys()]),dtype=object)
for q,k in enumerate(test.keys()):
    c[q] = (int(test[k][0][3:]),int(test[k][1][3:]))
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/44:
a = []
b = []
c = np.empty(len(list(test.keys())),dtype=object)
for q,k in enumerate(test.keys()):
    c[q] = (int(test[k][0][3:]),int(test[k][1][3:]))
    a.append(int(test[k][0][3:]))
    b.append(int(test[k][1][3:]))
573/45: c
573/46: np.unique(c)
573/47: np.savetxt('/home/ascherrmann/trackpairs.txt',np.unique(c),fmt='%d',delimiter=' ',newline='\n')
573/48: np.savetxt('/home/ascherrmann/trackpairs.txt',np.unique(c),fmt='%o',delimiter=' ',newline='\n')
573/49:
c = np.empty(len(list(test.keys())),dtype=object)
ids = np.array([])
for q,k in enumerate(test.keys()):
    c[q] = (int(test[k][0][3:]),int(test[k][1][3:]))
573/50:
c = np.empty(len(list(test.keys())),dtype=object)
ids = np.array([])
for q,k in enumerate(test.keys()):
    c[q] = (int(test[k][0][3:]),int(test[k][1][3:]))
    ids = np.append(ids,int(k))
573/51: ids
573/52: a,b = np.unique(c,return_counts)
573/53: a,b = np.unique(c,return_counts=True)
573/54: b
573/55: np.max(b)
573/56: b.size
573/57: save = np.empty((21,1086))
573/58: a
573/59: a[0][0]
573/60: a[0][1]
573/61:
for s in range(21):
    save[s,0] = a[s][0]
    save[s,1] = a[s][1]
    for q,i in enumerate(np.where(c==a[2])[0]):
        save[s,2+q] = i
573/62: save = np.empty((21,1086))
573/63:
for s in range(21):
    save[s,0] = a[s][0]
    save[s,1] = a[s][1]
    for q,i in enumerate(np.where(c==a[s])[0]):
        save[s,2+q] = i
573/64: save
573/65: save = np.zeros((21,1086))
573/66: a
573/67: np.where(c==a[0])
573/68: c
573/69: np.sort(c)
573/70: order = np.argsort(c)
573/71: ids = ids[order]
573/72: c = c[order]
573/73: np.sort(a)
573/74: b
573/75: c[11]
573/76: c[1058]
573/77: save
573/78: save = np.zeros((21,1086))
573/79:
pos = 0
for q,bb in enumerate(b):
    save[s,0] = a[s][0]
    save[s,1] = a[s][1]
    save[s,2:2+bb] = ids[pos:pos+bb]
    pos+=bb
573/80: save
573/81: save.shape
573/82: a[s][0]
573/83: s
573/84: save = np.zeros((21,1086))
573/85:
pos = 0
for s,bb in enumerate(b):
    save[s,0] = a[s][0]
    save[s,1] = a[s][1]
    save[s,2:2+bb] = ids[pos:pos+bb]
    pos+=bb
573/86: save
573/87: np.where(save[:,-1]!=0)
573/88: np.savetxt('/home/ascherrmann/trackpairs.txt',save,fmt='%d',delimiter=' ',newline='\n')
573/89: %save -r /home/ascherrmann/scripts/all-oceans/create-track-pairs-ids.txt 1-999
574/1:
import numpy as np
import os
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import matplotlib.collections as mcoll
from matplotlib.colors import ListedColormap, BoundaryNorm
import pickle
import pandas as pd


deltaPSP = 100
zbb = 800

LON=np.round(np.linspace(-180,180,721),1)
LAT=np.round(np.linspace(-90,90,361),1)
574/2:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
newids = dict()
for o in os.listdir(sp):
    if o!='MED':
        continue
    for r in os.listdir(sp + o):
        newids[o][r] = np.array([])
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        df = pd.read_csv(dpth + 'new-' + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + 'new-' + o + '-tracks-deepest-' + r + '.csv')
574/3:
H = 96

sp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dpth = '/atmosdyn2/ascherrmann/011-all-ERA5/data/usecyc/'
newids = dict()
for o in os.listdir(sp):
    if o!='MED':
        continue
    for r in os.listdir(sp + o):
       
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        df = pd.read_csv(dpth + 'new-' + o + '-data-deepest-' + r + '.csv')
        dftr = pd.read_csv(dpth + 'new-' + o + '-tracks-deepest-' + r + '.csv')
574/4: df
574/5: dftr
574/6: dftr[0]
574/7: dftr['0']
574/8: matpos = dftr['0'].values
574/9: matpos
574/10: lon1,lat1 = df['lon'].values,df['lat'].values
574/11: lon1
574/12: lat1
574/13:
for lo,la,ma in zip(lon1,lat1,matpos):
    loc,lac = eval(matpos)
    if(lon1!=loc) or (lat1!=lac):
        print(lo,la,ma)
574/14:
for lo,la,ma in zip(lon1,lat1,matpos):
    loc,lac = eval(ma)
    if(lon1!=loc) or (lat1!=lac):
        print(lo,la,ma)
574/15: ma
574/16: eval(ma)
574/17:
for lo,la,ma in zip(lon1,lat1,matpos):
    loc,lac = eval(ma)[0],eval(ma)[1]
    if(lon1!=loc) or (lat1!=lac):
        print(lo,la,ma)
574/18: loc
574/19:
for lo,la,ma in zip(lon1,lat1,matpos):
    loc,lac = eval(ma)
    if(lo!=loc) or (la!=lac):
        print(lo,la,ma)
574/20: f = open(sp + o + '/' + r  + '/new-PV-data' + o + '-' + r + '-dPSP-' + str(deltaPSP) + '-ZB-' + str(zbb) + '-%d.txt'%rdis,'rb')
574/21: o='MED'
574/22: r
574/23: f = open(sp + o + '/' + r  + '/new-PV-data' + o + '-' + r + '-dPSP-' + str(deltaPSP) + '-ZB-' + str(zbb) + '-%d.txt'%rdis,'rb')
574/24: data = pickle.load(f)
574/25: f.close()
574/26: rawdata = data['rawdata')
574/27: rawdata = data['rawdata']
574/28: rawdata.keys()
574/29: rawdata['317732']
574/30: rawdata['317732'].keys()
574/31: rawdata['317732']['lon'].shape
574/32: rawdata['317732']['lime'].shape
574/33: rawdata['317732']['time']
574/34:
for cycID in rawdata.keys():
    cycID = int(cycID)
    try:
        loc = np.where(ids==cycID)[0]
        if loc.size>1:
            print('double cycID in df',cycID)
        loc = loc[0]
    except:
        print('skip id df'cycID)
        continue
    try:
        loctr = np.where(idstr==cycID)[0]
574/35:
for cycID in rawdata.keys():
    cycID = int(cycID)
    try:
        loc = np.where(ids==cycID)[0]
        if loc.size>1:
            print('double cycID in df',cycID)
        loc = loc[0]
    except:
        print('skip id df',cycID)
        continue
    try:
        loctr = np.where(idstr==cycID)[0]
        if loctr.size>1:
            print('double cycID in dftr,cycID)
        loctr = loctr[0]
    except:
        print('skip id dftr',cycID)
        continue
574/36:
for cycID in rawdata.keys():
    CycID = int(cycID)
    try:
        loc = np.where(ids==CycID)[0]
        if loc.size>1:
            print('double cycID in df',CycID)
        loc = loc[0]
    except:
        print('skip id df',CycID)
        continue
    try:
        loctr = np.where(idstr==CycID)[0]
        if loctr.size>1:
            print('double cycID in dftr',CycID)
        loctr = loctr[0]
    except:
        print('skip id dftr',CycID)
        continue
    lom,lam = lon1[loc],lat1[loc]
    lont,latt = np.mean(rawdata[cycID]['lon'][:,0]),np.mean(rawdata[cycID]['lat'][:,0])
    dlon,dlat = lom-lont,lam-latt
    if helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam)>200:
        print(cycID,lom,lam,lont,latt,helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam))
574/37: ids
574/38: df
574/39:
ids = df['ID'].values
        idstr = dftr['ID'].values
574/40:
ids = df['ID'].values
idstr = dftr['ID'].values
574/41: lon1,lat1 = df['lon'].values,df['lat'].values
574/42:
for cycID in rawdata.keys():
    CycID = int(cycID)
    try:
        loc = np.where(ids==CycID)[0]
        if loc.size>1:
            print('double cycID in df',CycID)
        loc = loc[0]
    except:
        print('skip id df',CycID)
        continue
    try:
        loctr = np.where(idstr==CycID)[0]
        if loctr.size>1:
            print('double cycID in dftr',CycID)
        loctr = loctr[0]
    except:
        print('skip id dftr',CycID)
        continue
    lom,lam = lon1[loc],lat1[loc]
    lont,latt = np.mean(rawdata[cycID]['lon'][:,0]),np.mean(rawdata[cycID]['lat'][:,0])
    dlon,dlat = lom-lont,lam-latt
    if helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam)>200:
        print(cycID,lom,lam,lont,latt,helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam))
574/43:
for cycID in rawdata.keys():
    CycID = int(cycID)
    try:
        loc = np.where(ids==CycID)[0]
        if loc.size>1:
            print('double cycID in df',CycID)
        loc = loc[0]
    except:
        print('skip id df',CycID)
        continue
    try:
        loctr = np.where(idstr==CycID)[0]
        if loctr.size>1:
            print('double cycID in dftr',CycID)
        loctr = loctr[0]
    except:
        print('skip id dftr',CycID)
        continue
    lom,lam = lon1[loc],lat1[loc]
    lont,latt = np.mean(rawdata[cycID]['lon'][:,0]),np.mean(rawdata[cycID]['lat'][:,0])
    dlon,dlat = lom-lont,lam-latt
#    if helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam)>200:
    print(cycID,lom,lam,lont,latt,helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,lam))
574/44: data.keys()
574/45: dit = data['dit']
574/46: dit.keys()
574/47: deltaPV = np.zeros(datadi[cycID]['time'].shape)
574/48: deltaPV = np.zeros(rawdata[cycID]['time'].shape)
574/49: deltaPV[:,1:] = rawdata[cycID]['PV'][:,:-1]-rawdata[cycID]['PV'][:,1:]
574/50:
env = 'env'
cyc = 'cyc'
noro = 'noro'

split=[cyc,env]
574/51: dipv
574/52: dipv = dict()
574/53:
datadi = rawdata
for cycID in rawdata.keys():
    dipv[cycID] = dict()
    deltaPV = np.zeros(rawdata[cycID]['time'].shape)
    deltaPV[:,1:] = rawdata[cycID]['PV'][:,:-1]-rawdata[cycID]['PV'][:,1:]
    for key in split:
        ttmp[key] = dit[cycID][key][:,:-1]
        dipv[cycID][key] = np.zeros(datadi[cycID]['time'].shape)
        dipv[cycID][key][:,:-1] = np.flip(np.cumsum(np.flip(deltaPV[:,1:]*ttmp[key][:,:],axis=1),axis=1),axis=1)
574/54: ttmp = dict()
574/55:
datadi = rawdata
for cycID in rawdata.keys():
    dipv[cycID] = dict()
    deltaPV = np.zeros(rawdata[cycID]['time'].shape)
    deltaPV[:,1:] = rawdata[cycID]['PV'][:,:-1]-rawdata[cycID]['PV'][:,1:]
    for key in split:
        ttmp[key] = dit[cycID][key][:,:-1]
        dipv[cycID][key] = np.zeros(datadi[cycID]['time'].shape)
        dipv[cycID][key][:,:-1] = np.flip(np.cumsum(np.flip(deltaPV[:,1:]*ttmp[key][:,:],axis=1),axis=1),axis=1)
574/56:
import matplotlib
import matplotlib.pyplot as plt
574/57:
for o in os.listdir(sp):
    if o!='MED':
        continue
    for r in os.listdir(sp + o):
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        t = -1 * np.arange(0,H+1)

        APV = dict()
        PV = np.zeros(H+1)
        for key in split:
            APV[key] = np.zeros(H+1)

        for cycID in dipv.keys():
            PV += np.sum(datadi[cycID]['PV'],axis=0)
            c += len(datadi[cycID]['PV'][:,0])
            for key in split:
                APV[key] += np.sum(dipv[cycID][key],axis=0)
        avPV = PV/c
        for key in split:
            APV[key] /=c
        APV['both'] = APV[cyc] + APV[env]
574/58: c = 0
574/59:
for o in os.listdir(sp):
    if o!='MED':
        continue
    for r in os.listdir(sp + o):
        ###
        ### pre stuff
        ###
        if r=='ge-0-l-15' or r=='ge--15-l-0' or r=='ge-15-l-30' or r=='ge--30-l--15' or r=='all':
            rdis=400
        else:
            rdis=800
        t = -1 * np.arange(0,H+1)

        APV = dict()
        PV = np.zeros(H+1)
        for key in split:
            APV[key] = np.zeros(H+1)

        for cycID in dipv.keys():
            PV += np.sum(datadi[cycID]['PV'],axis=0)
            c += len(datadi[cycID]['PV'][:,0])
            for key in split:
                APV[key] += np.sum(dipv[cycID][key],axis=0)
        avPV = PV/c
        for key in split:
            APV[key] /=c
        APV['both'] = APV[cyc] + APV[env]
574/60:
xlim = np.array([-1*H,0])
ylim = np.array([-0.3,2.2])
574/61:
fig,ax = plt.subplots()
ax.plot([],[],marker=None,ls='-',color='grey')
ax.plot([],[],marker=None,ls='-',color='lightcoral')
ax.plot([],[],marker=None,ls='-',color='k')
ax.plot([],[],marker=None,ls=':',color='k')

ax.set_ylabel('acc. PV [PVU]')
ax.set_xlabel('time until mature stage [h]')
ax.legend(pllegend,fontsize=fsl,loc='upper left')
ax.set_xticks(ticks=np.arange(-H,1,6))
ax.set_xlim(xlim)
ylimp = ylim
574/62: pllegend = ['PV','$\Delta$ PV',cyc,env]
574/63: ax.legend(pllegend,fontsize=fsl,loc='upper left')
574/64: fsl=6
574/65: ax.legend(pllegend,fontsize=fsl,loc='upper left')
574/66: ax.set_xticks(ticks=np.arange(-H,1,6))
574/67: ax.set_xlim(xlim)
574/68: ax.tick_params(right=True,labelright=False)
574/69: ax.plot(t,avPV,color='grey')
574/70:
for c,ls,k in zip(['lightcoral','k','k'],['-','-',':'],['both',cyc,env]):
            ax.plot(t,APV[k],color=c,linestyle=ls)
574/71: name = '/atmosdyn2/ascherrmann/011-ERA5-all/new-test-MED-APV.png'
574/72: fig.savefig(name,dpi=300,bbox_inches='tight')
574/73: name = '/atmosdyn2/ascherrmann/011-all-ERA5/new-test-MED-APV.png'
574/74: fig.savefig(name,dpi=300,bbox_inches='tight')
575/1: import sys
575/2: sys.path.append('/home/ascherrmann/scripts/')
575/3: import helper
575/4: trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
575/5: fdate = trackpath + 'fi_201001'
575/6: helper.change_date_by_hours(fdate[-6:],238)
575/7: helper.change_date_by_hours(fdate[-6:] + '01_00',238)
575/8: helper.change_date_by_hours(fdate[-6:] + '01_00',224)
575/9: helper.change_date_by_hours(fdate[-6:] + '01_00',240)
575/10: from netCDF4 import Dataset as ds
575/11: ds('/atmosdyn/michaesp/mincl.era-5/cdf.final/2010/10/C20101001_02','r')
575/12: data = ds('/atmosdyn/michaesp/mincl.era-5/cdf.final/2010/10/C20101001_02','r')
575/13: data.variables['LABEL'].shape
575/14: import xarray as xr
575/15: NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
575/16: NORO['OL'].values.shape
575/17: np.max(NORO['OL'].values[0])
575/18: import numpy as np
575/19: np.max(NORO['OL'].values[0])
575/20: np.unique(data.variables['LABEL'])
575/21: np.unique(data.variables['LABEL'][0,0])
575/22: np.mean(NORO['OL'].values[0][data.variables['LABEL'][0,0]==415806.])
575/23: NORO['ZB'].values[0]
575/24: np.mean(NORO['ZB'].values[0][data.variables['LABEL'][0,0]==415806.])
576/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import os
import pickle
import xarray as xr
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
masks = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)


###
### remove tracks before 1979

tracks = np.sort(tracks)[346:]

regions = ['MED','NA','SA','NP','NP','SP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']#,'AO','GI']
oregions = ['MED','NA','SA','NP','SP','IO','AO']
boundaries = ['lon','lat']

NAlatup = 60
SB = -60

LONR = [np.array([-5,2,42]),#MED
       np.array([-98,-94,-90,-85,-75,-5,15]),#NA
       np.array([-67,20]),#SA
       np.array([-180,-98,-94,-85,-76]),#NP
       np.array([100,180]),#NP
       np.array([-180,-67]),#SP
       np.array([120,140,180]),#SP
       np.array([20,100,120,140]),#IO
        np.array([-10,11,42]),#EU
        np.array([-170,-75,-64,-55]),#NAL
        np.array([-85,-30]),#SAL
        np.array([42,50,180]),#AS
        np.array([-20,11,42,52]),#AF
        np.array([110,165]),#AU
       np.array([-180,180]),#AO
#        np.array([-180,-76]),#AO
#        np.array([-75,-64,-55,-10]),#GI
        ]

LATR = [np.array([28,42,28,48]),#MED
        np.array([17.5,NAlatup,16,NAlatup,14,NAlatup,10,NAlatup,0,NAlatup,50,NAlatup]),#NA
        np.array([SB,0]),#SA
        np.array([0,68,0,16,0,13,0,8]),#NP
        np.array([0,68]),#NP
        np.array([SB,0]),#SP
        np.array([-17,0,SB,0]),#SP
        np.array([SB,28,SB,0,SB,-17]),#IO
        np.array([37,75,34,75]),#EU
        np.array([16,75,16,75,16,68]),#NAL
        np.array([-60,16]),#SAL
        np.array([12,75,-10,75]),#AS
        np.array([-35,37,-35,32,-35,12]),#AF
        np.array([-45,-10]),#AU
        np.array([60,83]),#AO]
        ]
576/2:
NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LSM = NORO['OL'].values[0]
ZB = NORO['ZB'].values[0]

LON = np.arange(-180,180,0.5)
LAT = np.arange(-90,90.1,0.5)

SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
REG = []

savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']
yeartmp = 1979
576/3: fdate
576/4: fdate = trackpath + 'fi_201001'
577/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import os
import pickle
import xarray as xr
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
masks = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)


###
### remove tracks before 1979

tracks = np.sort(tracks)[346:]

regions = ['MED','NA','SA','NP','NP','SP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']#,'AO','GI']
oregions = ['MED','NA','SA','NP','SP','IO','AO']
boundaries = ['lon','lat']

NAlatup = 60
SB = -60

LONR = [np.array([-5,2,42]),#MED
       np.array([-98,-94,-90,-85,-75,-5,15]),#NA
       np.array([-67,20]),#SA
       np.array([-180,-98,-94,-85,-76]),#NP
       np.array([100,180]),#NP
       np.array([-180,-67]),#SP
       np.array([120,140,180]),#SP
       np.array([20,100,120,140]),#IO
        np.array([-10,11,42]),#EU
        np.array([-170,-75,-64,-55]),#NAL
        np.array([-85,-30]),#SAL
        np.array([42,50,180]),#AS
        np.array([-20,11,42,52]),#AF
        np.array([110,165]),#AU
       np.array([-180,180]),#AO
#        np.array([-180,-76]),#AO
#        np.array([-75,-64,-55,-10]),#GI
        ]

LATR = [np.array([28,42,28,48]),#MED
        np.array([17.5,NAlatup,16,NAlatup,14,NAlatup,10,NAlatup,0,NAlatup,50,NAlatup]),#NA
        np.array([SB,0]),#SA
        np.array([0,68,0,16,0,13,0,8]),#NP
        np.array([0,68]),#NP
        np.array([SB,0]),#SP
        np.array([-17,0,SB,0]),#SP
        np.array([SB,28,SB,0,SB,-17]),#IO
        np.array([37,75,34,75]),#EU
        np.array([16,75,16,75,16,68]),#NAL
        np.array([-60,16]),#SAL
        np.array([12,75,-10,75]),#AS
        np.array([-35,37,-35,32,-35,12]),#AF
        np.array([-45,-10]),#AU
        np.array([60,83]),#AO]
        ]
577/2:
NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LSM = NORO['OL'].values[0]
ZB = NORO['ZB'].values[0]

LON = np.arange(-180,180,0.5)
LAT = np.arange(-90,90.1,0.5)

SLP = []
lon = []
lat = []
dates = []
hourstoSLPmin = []
ID = []
REG = []

savings = ['SLP-','lon-','lat-','ID-','hourstoSLPmin-','dates-','REG-']
yeartmp = 1979
577/3: fdate = trackpath + 'fi_201001'
577/4:
d = np.loadtxt(fdate,skiprows=4)
ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
ids = np.append(ids,len(d[:,-1]))

    for k,i in enumerate(ids[:-1]):
        SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]

        ## filter tracks that are less than 24h long and the saved ones have a reasonable development and decay
        htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
        if htcheck[0]>-12 or htcheck[-1]<12:
            print('skip',htcheck)
            continue
577/5:
d = np.loadtxt(fdate,skiprows=4)
ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
ids = np.append(ids,len(d[:,-1]))

for k,i in enumerate(ids[:-1]):
        SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][-1]

        ## filter tracks that are less than 24h long and the saved ones have a reasonable development and decay
        htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
        if htcheck[0]>-12 or htcheck[-1]<12:
            print('skip',htcheck)
            continue
577/6:
d = np.loadtxt(fdate,skiprows=4)
ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
ids = np.append(ids,len(d[:,-1]))

for k,i in enumerate(ids[:-1]):
        SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0]

        ## filter tracks that are less than 24h long and the saved ones have a reasonable development and decay
        htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
        if htcheck[0]>-12 or htcheck[-1]<12:
            print('skip',htcheck)
            continue
578/1: import sys
578/2: sys.path.append('/home/ascherrmann/scripts/')
578/3: import helper
578/4: helper.change_date_by_hours('20171001_00',np.array([20,10,800,240]))
578/5: import numpy as np
578/6: helper.change_date_by_hours('20171001_00',np.array([20,10,800,240]))
579/1: import numpy as np
579/2: ht = np.arange(0,129)
579/3: ht
579/4: np.delete(ht,np.arange(97,len(ht)))
579/5: nt = np.ones(98)*500
579/6: nt[1:1+ht.size] = ht
579/7: nt[1:1+ht.size] = np.delete(ht,np.arange(97,len(ht)))
579/8: nt
579/9: nt = np.ones(98)*500
579/10: ht = np.arange(0,78)
579/11: nt[1:1+ht.size] = np.delete(ht,np.arange(97,len(ht)))
579/12: nt
579/13: ht
580/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import os
import pickle
import xarray as xr
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
masks = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

tracks = np.array([])
for d in os.listdir(trackpath):
    if(d.startswith('fi_')):
        if(d[-1]!='s'):
            tracks = np.append(tracks,d)


###
### remove tracks before 1979

tracks = np.sort(tracks)[346:]

regions = ['MED','NA','SA','NP','NP','SP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']#,'AO','GI']
oregions = ['MED','NA','SA','NP','SP','IO','AO']
boundaries = ['lon','lat']

NAlatup = 60
SB = -60

LONR = [np.array([-5,2,42]),#MED
       np.array([-98,-94,-90,-85,-75,-5,15]),#NA
       np.array([-67,20]),#SA
       np.array([-180,-98,-94,-85,-76]),#NP
       np.array([100,180]),#NP
       np.array([-180,-67]),#SP
       np.array([120,140,180]),#SP
       np.array([20,100,120,140]),#IO
        np.array([-10,11,42]),#EU
        np.array([-170,-75,-64,-55]),#NAL
        np.array([-85,-30]),#SAL
        np.array([42,50,180]),#AS
        np.array([-20,11,42,52]),#AF
        np.array([110,165]),#AU
       np.array([-180,180]),#AO
#        np.array([-180,-76]),#AO
#        np.array([-75,-64,-55,-10]),#GI
        ]

LATR = [np.array([28,42,28,48]),#MED
        np.array([17.5,NAlatup,16,NAlatup,14,NAlatup,10,NAlatup,0,NAlatup,50,NAlatup]),#NA
        np.array([SB,0]),#SA
        np.array([0,68,0,16,0,13,0,8]),#NP
        np.array([0,68]),#NP
        np.array([SB,0]),#SP
        np.array([-17,0,SB,0]),#SP
        np.array([SB,28,SB,0,SB,-17]),#IO
        np.array([37,75,34,75]),#EU
        np.array([16,75,16,75,16,68]),#NAL
        np.array([-60,16]),#SAL
        np.array([12,75,-10,75]),#AS
        np.array([-35,37,-35,32,-35,12]),#AF
        np.array([-45,-10]),#AU
        np.array([60,83])]
580/2: indomain=0
580/3:
for q, r in enumerate(regions):
            if indomain==1:
                break
            ## if cyclone mask is more than 70% over land for ocean regions skip it
            if np.any(oregions==r) and seamask>0.7:
                continue

            londom=LONR[q]
            latdom=LATR[q]

            for b,o in enumerate(londom[:-1]):
                print(r,o,londom[b+1],latdom[2*b],latdom[2*b+1])
581/1: import numpy as np
581/2: tracks = np.loadtxt('/atmosdyn/michaesp/mincl.era-5/tracks/fi_201010',skiprows=4)
581/3: track
581/4: tracks
581/5: tracks.shape
581/6: less /atmosdyn/michaesp/mincl.era-5/tracks/fi_201010
581/7: d = tracks
581/8: ids = np.append(0,np.where((d[1:,-1]-d[:-1,-1])!=0)[0] + 1)
581/9: ids = np.append(ids,len(d[:,-1]))
581/10: ids
581/11: d[43025:43324]
581/12: d[43025:43324].shape
581/13: SLPmin = np.where(d[43025:43324,3]==np.min(d[43025:43324,3]))[0][0]
581/14: SLPmin
581/15: d[43025:43324][SLPmin]
581/16:
for k,i in enumerate(ids[:-1]):
    print(i,ids[k+1])
581/17:
for k,i in enumerate(ids[:-1]):
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0]
    htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
    if htcheck[0]>-12 or htcheck[-1]<12:
        continue
    print(i,ids[k+1],SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0])
581/18:
for k,i in enumerate(ids[:-1]):
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0]
    htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
    if htcheck[0]>-12 or htcheck[-1]<12:
        continue
    print(i,ids[k+1],SLPmin)# = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0])
581/19:
for k,i in enumerate(ids[:-1]):
    SLPmin = np.where(d[i:ids[k+1],3] == np.min(d[i:ids[k+1],3]))[0][0]
    htcheck = d[i:ids[k+1],0]-d[i:ids[k+1],0][SLPmin]
    if htcheck[0]>-12 or htcheck[-1]<12:
        continue
    print(i,ids[k+1],SLPmin,d[i:ids[k+1],1][SLPmin],d[i:ids[k+1],2][SLPmin])
588/1: import numpy as np
588/2: import xarray as xr
588/3:
p = '/atmosdyn2/ascherrmann/014-mega/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
masks = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

tracks = np.array([])
for files in os.listdir(trackpath):
    if(files.startswith('fi_')):
        if(files[-1]!='s'):
            tracks = np.append(tracks,files)

###
### remove tracks before 1979

tracks = np.sort(tracks)[346:]
588/4:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import os
import pickle
import xarray as xr
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
trackpath = '/atmosdyn/michaesp/mincl.era-5/tracks/'
masks = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'

tracks = np.array([])
for files in os.listdir(trackpath):
    if(files.startswith('fi_')):
        if(files[-1]!='s'):
            tracks = np.append(tracks,files)

###
### remove tracks before 1979

tracks = np.sort(tracks)[346:]
588/5:
NORO = xr.open_dataset('/atmosdyn2/ascherrmann/009-ERA-5/MED/data/NORO')
LSM = NORO['OL'].values[0]
ZB = NORO['ZB'].values[0]

LON = np.arange(-180,180,0.5)
LAT = np.arange(-90,90.1,0.5)
588/6: tracks[0]
588/7: int(9.57364e+05)
588/8: data = np.loadtxt(trackpath + tracks[0],skiprows=4)
588/9: ids = np.where(data[:,-1]==957364)[0]
588/10: ids
588/11: md = data[ids]
588/12: md
588/13: t,lon,lat = md[:,0],md[:,1],md[:,2]
588/14: slp = md[:,3]
588/15: slp
588/16: SLPmin = np.where(slp==np.min(slp))[0][0]
588/17: SLPmin
588/18: t[SLPmin],lon[SLPmin],lat[SLPmin]
588/19: import sys
588/20: sys.path.append('/home/ascherrmann/scripts/')
588/21: import helper
588/22: helper.change_date_by_hours('19790101_00',201)
588/23: from netCDF4 import Dataset as ds
588/24: flag = ds('/atmosdyn/michaesp/mincl.era-5/cdf.final/1979/01/C19790109_09','r')
588/25: flag.keys
588/26: flag.variables
588/27: flag.vriables['LABEL'].shape
588/28: flag.variables['LABEL'].shape
588/29: LABEL = flag.variables['LABEL'][0,0]
588/30: LABEL
588/31: LABEL[LABEL==957364]
588/32: LSM
588/33: LSM[LABEL==957364]
588/34: np.mean(LSM[LABEL==957364])
589/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import pickle
import os
import pandas as pd
from netCDF4 import Dataset as ds
589/2: era5 = '/atmosdyn2/era5/cdf/'
589/3: ref = ds(era5 + '2010/10/S20101010_10')
589/4: ak = ref.variables['hyam'][:]
589/5: ak
589/6: ak.shape
589/7: ak.size
589/8: bk = ref.variables['hybm'][:]
589/9: bk
589/10: PS=1013.12
589/11: P = 0.01 * s.hyam.values[137-98:] + s.hybm.values[137-98:] * PS
589/12: P = 0.01 * ak[137-98:] + bk[137-98:] * PS
589/13: P
589/14: P = 0.01 * ak[137-98:] + bk[137-98:] * PS*100
589/15: P
589/16: P = 0.01 * ak[137-98:] + bk[137-98:] * PS
589/17: P
589/18: 137-98
589/19: P = 0.01 * ak[137-98:50] + bk[137-98:50] * PS
589/20: P
589/21: P = 0.01 * ak[137-98+30:] + bk[137-98+30:] * PS
589/22: P
589/23: P = 0.01 * ak[137-98+50:] + bk[137-98+50:] * PS
589/24: P
589/25: P = 0.01 * ak[137-98+60:] + bk[137-98+60:] * PS
589/26: P
589/27: ref.variables['PS'].shape
589/28: lon = np.array([23])
589/29: lat = np.array([34])
589/30: import sys
589/31: sys.path.append('/home/ascherrmann/scripts/')
589/32: import helper
589/33: clonids,clatids=helper.ERA5_radial_ids_correct(200,lat[0])
589/34: clonids
589/35: vi /home/ascherrmann/scripts/helper.py
589/36: less /home/ascherrmann/scripts/helper.py
589/37: ref.variables['PV'].shape
589/38: PV[0,:,0,0]
589/39: ref.variables['PV'][0,:,0,0]
589/40: ref.variables['PV'][0,:,1,1]
589/41: ref.variables['PV'][0,:,200,300]
589/42: ref.variables['PV'][0,60:,200,300]
589/43: S.variables['PS']
589/44: ref.variables['PS']
589/45: ak
589/46: ak.size
589/47: 0.01 * ak[137-98+60:] + bk[137-98+60:]*ref.variables['PS'][0]
589/48: 0.01 * ak[137-98+60:] + bk[137-98+60:,None]*ref.variables['PS'][0]
589/49: 0.01 * ak[137-98+60:] + bk[137-98+60:]*np.tile(ref.variables['PS'][0],(1,1,bk[137-98+60:].size))
589/50: 0.01 * ak[137-98+60:] + bk[137-98+60:]*np.tile(ref.variables['PS'][0],(bk[137-98+60:].size,1,1))
589/51: (0.01 * ak[137-98+60:] + bk[137-98+60:]*np.tile(ref.variables['PS'][0],(bk[137-98+60:].size,1,1)).T).T
589/52: (0.01 * ak[137-98+60:] + bk[137-98+60:]*np.tile(ref.variables['PS'][0],(bk[137-98+60:].size,1,1)).T).T.shape
589/53: clonids
589/54: clonids+=80
589/55: clatids
589/56: clatids+=210
589/57: PS = ref.variables[0]
589/58: PS = ref.variables['PS'][0]
589/59: PS.shape
589/60: PS[clatids,clonids]
589/61: PS[clatids.astype(int),clonids.astype(int)]
589/62: PS[clatids.astype(int),clonids.astype(int)].size
589/63: clatids.size
589/64: PV
589/65: PV = ref.variables['PV'][0]
589/66: PV.shape
589/67: PV[60:,clatids,clonids].shape
589/68: PV[60:,clatids.astype(int),clonids.astype(int)].shape
589/69: P = (0.01 * ak[137-98+60] + bk[137-98+60] * np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk[137-98+60].size,1,1)).T).T
589/70: P.shape
589/71: P = (0.01 * ak[137-98+60] + bk[137-98+60] * np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk[137-98+60].size,1)).T).T
589/72: P.shae
589/73: P.shape
589/74: PS[clatids.astype(int),clonids.astype(int)]
589/75: np.tile(PS[clatids.astype(int),clonids.astype(int)],(38,1)).shape
589/76: P = np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk[137-98+60].size,1))
589/77: P.shape
589/78: bk[137-98+60].size
589/79: P = np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk[137-98+60:].size,1))
589/80: P.shape
589/81: P = (0.01 * ak[137-98+60] + bk[137-98+60] * np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk[137-98+60:].size,1)).T).T
589/82: P.shape
589/83: P.size
589/84: P
589/85: np.where((P>700))
589/86: P
589/87: PS
589/88: PS.shape
589/89: PS[clatids.astype(int),clonids.astype(int)]
589/90: np.tile(PS[clatids.astype(int),clonids.astype(int)],(38,1)).shape
589/91: np.tile(PS[clatids.astype(int),clonids.astype(int)],(38,1))
589/92: ps = np.tile(PS[clatids.astype(int),clonids.astype(int)],(38,1))
589/93: ak = ak[137-98+60:]
589/94: bk = bk[137-98+60:]
589/95: P = (0.01 * ak + bk * np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk.size,1,1)).T).T
589/96: P.shape
589/97: P = (0.01 * ak + bk * np.tile(PS[clatids.astype(int),clonids.astype(int)],(bk.size,1)).T).T
589/98: P.shape
589/99: P
589/100: np.where((P>700)&(P<975))
589/101: clatids
589/102: pid,posids = np.where((P>700)&(P<975))
589/103: posids
589/104: clatids[posids]
590/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import pickle
import os
import pandas as pd
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
era5 = '/atmosdyn2/era5/cdf/'

Lat = np.arange(-90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

reg = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']

ref = ds(era5 + '2010/10/S20101010_10','r')
ak = ref.variables['hyam'][137-98+60:]
bk = ref.variables['hybm'][137-98+60:]
ref.close()
590/2:
for r in r[:1]:
    if not os.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    ntrajectories = np.array([])
    for da,lo,la in zip(dates[:10],lon[:10],lat[:10]):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        S = ds(filepath + 'S' + da,'r')
        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        PS = S.variables['PS'][0,clat,clon]

        pt = np.array([])
        plat = np.array([])
        plon = np.array([])
        pv = s.PV.values[0,60:,clat,clon]

        P = (0.01 * ak + bk * np.tile(PS,(bk.size,1)).T).T
        print(P.shape,pv.shape)
        if la>=0:
            pid,posids = np.where((P>=700) & (P<=975) & (pv>=0.75))
        else:
            pid,posids = np.where((P>=700) & (P<=975) & (pv<=-0.75))

        pt = P[pid,posids]
        plat = Lat[clatids[posids].astype(int)]
        plon = Lon[clonids[posids].astype(int)]

        save = np.zeros((len(pt),4))
        save[:,1] = plon
        save[:,2] = plat
        save[:,3] = pt

        ntrajectories = np.append(ntrajectories,pt.size)
590/3:
for r in reg[:1]:
    if not os.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    ntrajectories = np.array([])
    for da,lo,la in zip(dates[:10],lon[:10],lat[:10]):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        S = ds(filepath + 'S' + da,'r')
        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        PS = S.variables['PS'][0,clat,clon]

        pt = np.array([])
        plat = np.array([])
        plon = np.array([])
        pv = s.PV.values[0,60:,clat,clon]

        P = (0.01 * ak + bk * np.tile(PS,(bk.size,1)).T).T
        print(P.shape,pv.shape)
        if la>=0:
            pid,posids = np.where((P>=700) & (P<=975) & (pv>=0.75))
        else:
            pid,posids = np.where((P>=700) & (P<=975) & (pv<=-0.75))

        pt = P[pid,posids]
        plat = Lat[clatids[posids].astype(int)]
        plon = Lon[clonids[posids].astype(int)]

        save = np.zeros((len(pt),4))
        save[:,1] = plon
        save[:,2] = plat
        save[:,3] = pt

        ntrajectories = np.append(ntrajectories,pt.size)
590/4:
for r in reg[:1]:
    if not os.path.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    ntrajectories = np.array([])
    for da,lo,la in zip(dates[:10],lon[:10],lat[:10]):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        S = ds(filepath + 'S' + da,'r')
        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        PS = S.variables['PS'][0,clat,clon]

        pt = np.array([])
        plat = np.array([])
        plon = np.array([])
        pv = s.PV.values[0,60:,clat,clon]

        P = (0.01 * ak + bk * np.tile(PS,(bk.size,1)).T).T
        print(P.shape,pv.shape)
        if la>=0:
            pid,posids = np.where((P>=700) & (P<=975) & (pv>=0.75))
        else:
            pid,posids = np.where((P>=700) & (P<=975) & (pv<=-0.75))

        pt = P[pid,posids]
        plat = Lat[clatids[posids].astype(int)]
        plon = Lon[clonids[posids].astype(int)]

        save = np.zeros((len(pt),4))
        save[:,1] = plon
        save[:,2] = plat
        save[:,3] = pt

        ntrajectories = np.append(ntrajectories,pt.size)
590/5:
for r in reg[:1]:
    if not os.path.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    ntrajectories = np.array([])
    for da,lo,la in zip(dates[:10],lon[:10],lat[:10]):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        S = ds(filepath + 'S' + da,'r')
        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        PS = S.variables['PS'][0,clat,clon]

        pt = np.array([])
        plat = np.array([])
        plon = np.array([])
        pv = S.variables['PV'][0,60:,clat,clon]

        P = (0.01 * ak + bk * np.tile(PS,(bk.size,1)).T).T
        print(P.shape,pv.shape)
        if la>=0:
            pid,posids = np.where((P>=700) & (P<=975) & (pv>=0.75))
        else:
            pid,posids = np.where((P>=700) & (P<=975) & (pv<=-0.75))

        pt = P[pid,posids]
        plat = Lat[clatids[posids].astype(int)]
        plon = Lon[clonids[posids].astype(int)]

        save = np.zeros((len(pt),4))
        save[:,1] = plon
        save[:,2] = plat
        save[:,3] = pt

        ntrajectories = np.append(ntrajectories,pt.size)
592/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import pickle
import os
import pandas as pd
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
era5 = '/atmosdyn2/era5/cdf/'

Lat = np.arange(-90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

reg = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']

ref = ds(era5 + '2010/10/S20101010_10','r')
ak = ref.variables['hyam'][137-98+60:]
bk = ref.variables['hybm'][137-98+60:]
ref.close()

for r in reg[:1]:
    if not os.path.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    dates = dates[:10]
    lon = lon[:10]
    lat = lat[:10]
    ntrajectories = np.array([])
592/2: lon
592/3:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)
592/4: filepath
592/5: la
592/6: lo
592/7: da
592/8: CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)
592/9: CLONIDS
592/10: clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
592/11: clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]
592/12: clat = clat.astype(int)
592/13: clon = clon.astype(int)
592/14: clon[clon>=720]-=720
592/15: S = ds(filepath + 'S' + da,'r')
592/16: PS = S.variables['PS'][0,clat,clon]
592/17: pv = S.variables['PV'][0,60:,clat,clon]
593/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import pickle
import os
import pandas as pd
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
era5 = '/atmosdyn2/era5/cdf/'

Lat = np.arange(-90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

reg = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']

ref = ds(era5 + '2010/10/S20101010_10','r')
ak = ref.variables['hyam'][137-98+60:]
bk = ref.variables['hybm'][137-98+60:]
ref.close()

for r in reg[:1]:
    if not os.path.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    dates = dates[:10]
    lon = lon[:10]
    lat = lat[:10]
    ntrajectories = np.array([])
593/2:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)
593/3:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)
        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720
593/4: S = ds(filepath + 'S' + da,'r')
593/5: PS = S.variables['PS'][0,clat,clon]
593/6: S.variables['PV'].shape
593/7: pv = S.variables['PV'][0]
593/8: pv.shape
593/9: pv = pv[60:]
593/10: pv = pv[:,clat,clon]
593/11:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        S = ds(filepath + 'S' + da,'r')
        PS = S.variables['PS'][0,clat,clon]
        pv = S.variables['PV'][0]
        S.close()
        pv = pv[60:]
        pv = pv[:,clat,clon]
594/1:
import numpy as np
import sys
sys.path.append('/home/ascherrmann/scripts/')
import helper
import pickle
import os
import pandas as pd
from netCDF4 import Dataset as ds

p = '/atmosdyn2/ascherrmann/014-mega/data/'
era5 = '/atmosdyn2/era5/cdf/'

Lat = np.arange(-90,90.1,0.5)
Lon = np.arange(-180,180.1,0.5)

reg = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']

ref = ds(era5 + '2010/10/S20101010_10','r')
ak = ref.variables['hyam'][137-98+60:]
bk = ref.variables['hybm'][137-98+60:]
ref.close()

for r in reg[:1]:
    if not os.path.isdir(p + '/traj/' + r):
        os.mkdir(p + '/traj/' + r)

    df = pd.read_csv(p + r + '-mature-stage-data.csv')
    dates,lon,lat = df['date'].values,df['lon'].values,df['lat'].values
    dates = dates[:1]
    lon = lon[:1]
    lat = lat[:1]
594/2:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        S = ds(filepath + 'S' + da,'r')
594/3: clon
594/4: clat
594/5: S.variables['PS'].shape
594/6: S.variables['PS'][0].shape
594/7: S.variables['PS'][0][clat,clon].shape
594/8: PS = S.variables['PS'][0,clat,clon]
594/9: PS.shape
594/10: PS = S.variables['PS'][0][clat,clon]
594/11: PS.shape
594/12:
for da,lo,la in zip(dates,lon,lat):
        year,month = da[:4],da[4:6]
        filepath = era5 + '%s/%s/'%(year,month)

        CLONIDS,CLATIDS = helper.ERA5_radial_ids_correct(200,la)

        clon = CLONIDS + np.where(abs(Lon-lo)==np.min(abs(Lon-lo)))[0][0]
        clat = CLATIDS + np.where(abs(Lat-la)==np.min(abs(Lat-la)))[0][0]

        clat = clat.astype(int)
        clon = clon.astype(int)

        clon[clon>=720]-=720

        S = ds(filepath + 'S' + da,'r')
        PS = S.variables['PS'][0][clat,clon]
        pv = S.variables['PV'][0][60:][clat,clon]
594/13: PS.shape
594/14: S.variables['PV'][0].shape
594/15: S.variables['PV'][0][60:].shape
594/16: S.variables['PV'][0][60:][:,clat,clon].shape
595/1:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/014-mega/data/'
regions = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']
bd = np.array([-60,-45,-30,-15,0,15,30,45,60])

for r in reg:
    tmp = pd.read_csv(p + r + '-test.csv')
    lat = tmp['lat'].values
    ID = tmp['ID'].values
    ntraj = tmp['ntraj'].values
595/2: reg = regions
595/3:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/014-mega/data/'
regions = ['MED','NA','SA','NP','SP','IO','EU','NAL','SAL','AS','AF','AU','AO']
bd = np.array([-60,-45,-30,-15,0,15,30,45,60])

for r in reg:
    tmp = pd.read_csv(p + r + '-test.csv')
    lat = tmp['lat'].values
    ID = tmp['ID'].values
    ntraj = tmp['ntraj'].values
595/4: ntraj
595/5: np.where(ntraj>400)[0]
595/6: np.where(ntraj>400)[0].size
595/7: slp = tmp['SLPmin'].values
595/8: slp = tmp['minSLP'].values
595/9: slp
595/10: rdf
595/11: colums = tmp.columns
595/12: rdf = pd.DataFrame(columns=columns)
595/13: columns = tmp.columns
595/14: rdf = pd.DataFrame(columns=columns)
595/15:
for q,b in enumerate(bd2[:-1]):
    ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
595/16: bd2 = np.array([60,90])
595/17:
for q,b in enumerate(bd2[:-1]):
    ids = np.where((lat>=b) & (lat<bd[q+1]))[0]
595/18: ids
595/19: lat
595/20: b
595/21:
for q,b in enumerate(bd2[:-1]):
    ids = np.where((lat>=b) & (lat<bd2[q+1]))[0]
595/22: ids
595/23: tmp
595/24: df.sort_values('minSLP')
595/25: tmp.sort_values('minSLP')
595/26: tmp
595/27: tmp.iloc[ids]
595/28: tmp.sort_values('minSLP').iloc[np.arange(0,2000)]
595/29: tmp.sort_values('minSLP').iloc[np.arange(0,2000)].loc[tmp.sort_values('minSLP').iloc[np.arange(0,2000)]['ntraj']>1500]
595/30: tmp.sort_values('minSLP').loc[tmp.sort_values('minSLP')['ntraj']>1500]
596/1:
import numpy as np
import pandas as pd

p = '/atmosdyn2/ascherrmann/014-mega/data/'
reg = ['MED']
596/2:
for r in reg:
    tmp = pd.read_csv(p + r + '-test.csv')
    lat = tmp['lat'].values
    ID = tmp['ID'].values
    ntraj = tmp['ntraj'].values

    columns = tmp.columns
596/3:
if r=='MED' or r=='AO':
        rdf = pd.DataFrame(columns=columns)
596/4: tm = tmp.sort_values('minSLP')
596/5: tm
596/6: tm = tm.loc[tm['ntraj']>=400]
596/7: tm
597/1:
import pandas as pd
import os
from shutil import copyfile

tp = '/atmosdyn2/ascherrmann/014-mega/data/run-traj/'
oldtp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
dtp = '/atmosdyn2/ascherrmann/014-mega/data/done-traj/'
597/2:
for o in os.listdir(tp):
    for r in os.listdir(tp + o):
        if os.path.isdir(oldtp + o + '/' + r):
            for of in os.listdir(oldtp + o + '/' + r):
                date = of[19:30]
                ID = '0' + of[-10:-4]
                end = date + '-ID-' + ID + '.txt'
                print(date,ID,end)
597/3:
for o in os.listdir(tp):
    for r in os.listdir(tp + o):
        if os.path.isdir(oldtp + o + '/' + r):
            for of in os.listdir(oldtp + o + '/' + r):
                date = of[20:30]
                ID = '0' + of[-10:-4]
                end = date + '-ID-' + ID + '.txt'
                print(o,r,date,ID,end)
597/4:
for o in os.listdir(tp):
    for r in os.listdir(tp + o):
        if os.path.isdir(oldtp + o + '/' + r):
            for of in os.listdir(oldtp + o + '/' + r):
                date = of[20:31]
                ID = '0' + of[-10:-4]
                end = date + '-ID-' + ID + '.txt'
                print(o,r,date,ID,end)
597/5: ls /atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/MED/all
597/6:
for o in os.listdir(tp):
    for r in os.listdir(tp + o):
        if os.path.isdir(oldtp + o + '/' + r):
            for of in os.listdir(oldtp + o + '/' + r):
                if not of.startswith('trajectories-mature-'):
                    continue
                date = of[20:31]
                ID = '0' + of[-10:-4]
                end = date + '-ID-' + ID + '.txt'
                print(o,r,date,ID,end)
597/7: ls oldtp + 'NA/ge-60-l-90/'
597/8: oldtp = '/atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/'
597/9: ls oldtp + 'NA/ge-60-l-90/'
597/10: print(oldtp + 'NA/ge-60-l-90/')
597/11: ls /atmosdyn2/ascherrmann/011-all-ERA5/data/global-trajectories/NA/ge-60-l-90/
598/1: import os
598/2: import numpy as np
598/3: os.listdir('./')
598/4: np.array(os.listdir('./'))
599/1:
import wrf
from netCDF4 import Dataset as ds
import os
import sys
sys.path.append('/home/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS01,MEDIDS02 = wrfsims.nested_ids()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/nested-cyclone-tracking/out/'

ref = ds(dwrf + 'DJF-clim/wrfout_d01_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')
LAT = wrf.getvar(ref,'lat')

name = ['AT','MED']
var=['t','slp','PV850','PV300']
599/2:
for simid, sim in enumerate(SIMS):
    if not os.path.exists(tracks + sim + '-PV-tracks.txt'):
        continue

    fig,ax = plt.subplots()
    ax.plot([],[],color='dodgerblue')
    ax.plot([],[],color='orange')
    ax.plot([],[],color='r')

    ax2=ax.twinx()
    ax3=ax.twiny()

    tra = np.loadtxt(tracks + sim + '-PV-tracks.txt')

    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]
#    pv950_700=tra[:,-2]
#    pv400_200=tra[:,-3]
    pv850=tra[:,5]
    pv300=tra[:,4]
599/3: plt.close('all')
599/4: pv300
599/5: pv850
599/6:
import os
import sys
sys.path.append('/home/ascherrmann/scripts/')
import wrfsims
import helper
import numpy as np
import matplotlib.pyplot as plt


SIMS,ATIDS,MEDIDS,MEDIDS2 = wrfsims.nested_ids()
SIMS = np.array(SIMS)
dwrf = '/atmosdyn2/ascherrmann/013-WRF-sim/'
tracks = '/atmosdyn2/ascherrmann/scripts/WRF/nested-cyclone-tracking/out/'

ref = ds(dwrf + 'nested-DJF-clim-max-U-at-300hPa-0.3QG/wrfout_d02_2000-12-01_00:00:00')
LON = wrf.getvar(ref,'lon')
LAT = wrf.getvar(ref,'lat')

name = ['AT','MED']
var=['t','slp','PV850','PV300','PV400-200','PV950-700']

di = dict()
for n in name:
    di[n] = dict()
599/7:
for simid,sim in enumerate(SIMS[:1]):
    print(sim)

    medid = np.array(MEDIDS2[simid])
    atid = np.array(ATIDS[simid])
    if sim=='nested-test' or sim.startswith('DJF-nested'):
        continue
    if medid.size==0:
        continue

    tra = np.loadtxt(tracks + sim + '-02-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        for v in var:
            di[name[q]][v] = np.zeros_like(t[l])

        di[name[q]]['t'] = t[l]
        di[name[q]]['slp'] = slp[l]
        if q==0:
            continue

        for v in var:
            di[name[q]][v] = np.zeros_like(t[l])

        di[name[q]]['t'] = t[l]
        di[name[q]]['slp'] = slp[l]

        for qq2,T in enumerate(di[name[q]]['t'][:1]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            out = ds(dwrf + sim + '/wrfout_d02_2000-12-%02d_%02d:00:00'%(dd,hh))
            PV = wrf.getvar(out,'pvo')
            P = wrf.getvar(out,'pressure')
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]

            dlon = LON-lon
            dlat = LAT-lat


            distance = helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,LAT)
            lai200,loi200 = np.where(distance<=100)
            lai400,loi400 = np.where(distance<=400)
            PV300 = wrf.interplevel(PV[:,lai400,loi400],P[:,lai400,loi400],300,meta=False)
599/8:
for simid,sim in enumerate(SIMS[:6]):
    print(sim)

    medid = np.array(MEDIDS2[simid])
    atid = np.array(ATIDS[simid])
    if sim=='nested-test' or sim.startswith('DJF-nested'):
        continue
    if medid.size==0:
        continue

    tra = np.loadtxt(tracks + sim + '-02-new-tracks.txt')
    t = tra[:,0]
    tlon,tlat = tra[:,1],tra[:,2]
    slp = tra[:,3]
    IDs = tra[:,-1]

    locat,locmed = np.where(IDs==1)[0],np.where(IDs==2)[0]
    loc = [locat,locmed]
    for q,l in enumerate(loc):
        for v in var:
            di[name[q]][v] = np.zeros_like(t[l])

        di[name[q]]['t'] = t[l]
        di[name[q]]['slp'] = slp[l]
        if q==0:
            continue

        for v in var:
            di[name[q]][v] = np.zeros_like(t[l])

        di[name[q]]['t'] = t[l]
        di[name[q]]['slp'] = slp[l]

        for qq2,T in enumerate(di[name[q]]['t'][:1]):
            qq=qq2
            dd = 1 + int(int(T)/24)
            hh = int(T)%24

            out = ds(dwrf + sim + '/wrfout_d02_2000-12-%02d_%02d:00:00'%(dd,hh))
            PV = wrf.getvar(out,'pvo')
            P = wrf.getvar(out,'pressure')
            lon = tlon[l[qq]]
            lat = tlat[l[qq]]

            dlon = LON-lon
            dlat = LAT-lat


            distance = helper.convert_dlon_dlat_to_radial_dis_new(dlon,dlat,LAT)
            lai200,loi200 = np.where(distance<=100)
            lai400,loi400 = np.where(distance<=400)
            PV300 = wrf.interplevel(PV[:,lai400,loi400],P[:,lai400,loi400],300,meta=False)
599/9: PV300
599/10: PV.shape
599/11: PV300.shape
599/12: lai400
599/13: lai400.shape
599/14: PV[:].shape
599/15: PV[:][:,lai400].shape
599/16: PV[:,lai400].shape
599/17: PV[:,lai400,loi400].shape
599/18: lai400.shape
599/19: PV.shape
599/20: PV[0,lai400,loi400]
599/21: PV[0,lai400,loi400].shape
599/22: PV[0,lai400][loi400].shape
599/23: PV[0,lai400].shape
599/24: PV[:][:,lai400,loi400].shape
599/25: PV[0].shape
599/26: PV[0][np.array([(0,2),(10,10)])].shape
599/27: PV[0][np.array([(0,2),(10,10)])]
599/28: PV[0][2,1].shape
599/29: PV[0][2,1]
599/30: lai,loi
599/31: lai4000
599/32: lai400
599/33: loi400
599/34: PV[:,194,279].shape
599/35: PV[:,lai400,loi400].shape
599/36: PV[:,np.where(distance<=400)].shape
599/37: np.where(distance<=400).shape
599/38: np.where(distance<=400)
599/39: PV[0,np.where(distance<=400)]
599/40: PV[0,(194,279)]
599/41: PV[0,np.ix_(194,279)]
599/42: PV[0,np.ix_((194),(279))]
599/43: PVcheck = np.zeros((PV[:,0,0].size,lai400.size))
599/44: PVcheck.shape
599/45:
for q,lo,la in zip(range(lai400.size),loi400,lai400):
    PVcheck[:,q] = PV[:,la,lo]
599/46: PVcheck.shape
599/47: PV[:,lai400[:,np.newaxis],loi400[np.newaxis,:]]
599/48: PV.shape
599/49: lai400[:,np.newaxis].shape
599/50: loi400[np.newaxis,:].shape
599/51: PV[0][lai].shape
599/52: PV[0][lai400].shape
599/53: PV[0][lai400][:,loi400].shape
599/54: im = np.arange(1,37).reshape((6, 6))
599/55: im
599/56:
ix = np.array([1, 3, 5])
iy = np.array([1, 3, 5])
599/57:
ix = np.array([1, 3, 5])
>>> iy = np.array([1, 3, 5])
599/58: ix
599/59: iy
599/60: im[ix[:, np.newaxis], iy[np.newaxis, :]]
599/61: ix[:,np.newaxis].shape
599/62: PV[0][lai400[:,np.newaxis],loi400[np.newaxis,:]]
599/63: lai400
599/64: loi400
599/65: pv2d = PV[0]
599/66: pv2d.shape
599/67: pv2d[lai400][:,loi400].ravel()
599/68: np.array(pv2d[lai400][:,loi400]).ravel()
599/69: np.array(pv2d[lai400][:,loi400]).ravel().shape
599/70:
PVcheck = np.zeros((PV[:,0,0],lai200.size))
            Pcheck = np.zeros_like(PVcheck)

            for q,lo,la in zip(range(lai200.size),loi200,lai200):
                PVcheck[:,q] = PV[:,la,lo]
                Pcheck[:,q] = P[:,la,lo]
599/71:
PVcheck = np.zeros((PV[:,0,0],lai200.size))
Pcheck = np.zeros_like(PVcheck)

for q,lo,la in zip(range(lai200.size),loi200,lai200):
                PVcheck[:,q] = PV[:,la,lo]
                Pcheck[:,q] = P[:,la,lo]
599/72:
PVcheck = np.zeros((PV[:,0,0].size,lai200.size))
Pcheck = np.zeros_like(PVcheck)

for q,lo,la in zip(range(lai200.size),loi200,lai200):
                PVcheck[:,q] = PV[:,la,lo]
                Pcheck[:,q] = P[:,la,lo]
599/73: Pcheck
599/74: PV850 = wrf.interplevel(PVcheck,Pcheck,300,meta=False)
603/1:
import numpy as np
import netCDF4
import argparse

import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import matplotlib
import cartopy.crs as ccrs
import cartopy

import wrf

import sys
sys.path.append('/home/raphaelp/phd/scripts/basics/')
from useful_functions import get_field_at_level,resize_colorbar_horz,resize_colorbar_vert
603/2: sim = 'nested-MAM-400-km-east-from-max-300-hPa-1.4-QGPV'
603/3: dom='02'
603/4:
p = '/atmosdyn2/ascherrmann/013-WRF-sim/' + sim + '/'
fb = 'wrfout_d%s_2000-12-'%dom
sb = 'PS-PV-2000-'
fe = ':00:00'
603/5: trackdata = np.loadtxt('/atmosdyn2/ascherrmann/scripts/WRF/nest-test-tracking/out/' + sim + '-' + dom + '-filter.txt')
603/6: trackdata
603/7: trackdata[trackdata[:,0]==132]
603/8:
t = trackdata[:,0]
lont = trackdata[:,1]
latt = trackdata[:,2]
IDS = trackdata[:,-1]

PSlevel = np.arange(975,1031,3)
cmap = matplotlib.cm.jet
norm = plt.Normalize(np.min(PSlevel),np.max(PSlevel))
ticklabels=PSlevel
levels=PSlevel
PVcon = np.array([2])
603/9: t
603/10: 5 * 24
603/11: 5 * 24 + 12
603/12: d = 6
603/13: h = '12'
603/14: dt = (d-1)*24 + int(h)
603/15: dt
603/16: p + fb + '%02d_'%d + h + fe
603/17: np.any(t==dt)
603/18: f = p + fb + '%02d_'%d + h + fe
603/19: data = netCDF4.Dataset(f)
603/20: SLP = wrf.getvar(data,'slp')
603/21: lon = wrf.getvar(data,'lon')[0]
603/22: lat = wrf.getvar(data,'lat')[:,0]
603/23:
fig = plt.figure(figsize=(6,4))
gs = gridspec.GridSpec(nrows=1, ncols=1)
ax=fig.add_subplot(gs[0,0],projection=ccrs.PlateCarree())
ax.add_feature(cartopy.feature.NaturalEarthFeature('physical',name='land',scale='50m'),zorder=0, edgecolor='black',facecolor='lightgrey',alpha=0.7)
ax.add_feature(cartopy.feature.GSHHSFeature(scale='low'),zorder=10, edgecolor='black')
603/24:
if np.any(t==dt):
            locs = np.where(t==dt)[0]
            if dom=='01':
                ax.scatter(lont[locs],latt[locs],marker='x',color='grey')
                for ul in locs:
                    ax.text(lont[ul],latt[ul],'%02d'%IDS[ul],fontsize=8,zorder=2000,color='white',fontweight='bold')
            else:
                for ul in locs:
                    if lont[ul]<np.min(lon) or lont[ul]>np.max(lon) or latt[ul]<np.min(lat) or latt[ul]>np.max(lat):
                        continue
                    ax.scatter(lont[ul],latt[ul],marker='x',color='grey')
                    ax.text(lont[ul],latt[ul],'%02d'%IDS[ul],fontsize=8,zorder=2000,color='white',fontweight='bold')
603/25: plt.show()
604/1: import sys
604/2: sys.path.append('/home/ascherrmann/scripts/')
604/3: import wrfsims
604/4: SIMS,ATIDS,MEDIDS,MEDIDS2 = wrfsims.nested_ids()
604/5: len(SIMS)
604/6: len(ATIDS)
604/7:
for sim,atid in zip(SIMS,ATIDS):
    print(sim,atid)
604/8: len(MEDIDS01)
604/9: len(MEDIDS)
604/10: len(MEDIDS2)
605/1: era5 = '/atmosdyn2/era5/cdf/'
605/2: from netCDF4 import Dataset as ds
605/3: d = ds(era5+'2010/10/S20101010_10','r')
605/4: PV = d.variables['PV'][0]
605/5: PV.shape
605/6: PV = d.variables['PV'][0,:,200:,:]
605/7: PV.shape
605/8: PS = d.variables['PS'][0,200:,:]
605/9: PS.shape
606/1: import numpy as np
606/2: from wrf import interplevel as intp
606/3: from netCDF4 import Dataset as ds
606/4: from matplotlib import pyplot as plt
606/5: fig,ax = plt.subplots()
606/6: era5 = '/atmosdyn2/era5/cdf/'
606/7: d = ds(era5+'2000/12/S20001201_00','r')
606/8: ak = d.variables['hyam']
606/9: ak
606/10: ak = d.variables['hyam'][:]
606/11: ak
606/12: ak[137]
606/13: ak[136-98:]
606/14: ak=ak[ak.size-98:]
606/15: bk = d.variables['hybm'][136-98:]
606/16: bk
606/17: bk.size
606/18: ak.size
606/19: bk = d.variables['hybm'][137-98:]
606/20: PS = d.variables['PS'][0,200:,:]
606/21: p3d = np.tile(PS,(ak.size,1,1))
606/22: p3d
606/23: p3d.shape
606/24: P = (0.01 * ak + bk * p3d.T).T
606/25: PV = d.variables['PV'][0,:,200:,:]
606/26: pv300 = intp(PV,P,300,meta=False)
606/27: con = ax.contourf(np.linspace(-180,179.5,720),np.linspace(10,90,161),pv300,levels=[2])
606/28: con = ax.contour(np.linspace(-180,179.5,720),np.linspace(10,90,161),pv300,levels=[2])
606/29: plt.show()
606/30: con
606/31: con.collections
606/32: con.collections[0].get_paths()[0]
606/33: p=con.collections[0].get_paths()[0]
606/34: v=p.vertices
606/35: x=v[:,0]
606/36: y=v[:,1]
606/37: con.attrs()
606/38: con.att()
606/39: con.attrs
606/40: dir(con)
606/41: dir(con.collections)
606/42: dir(con.collections[0])
606/43: x
606/44: y
606/45: figg,ax=plt.subplots()
606/46: ax.plot(x,y)
606/47: figg.show()
606/48: allpath=con.collections[0].get_paths()
606/49: allpath
606/50: allpath.shape
606/51: len(allpath)
606/52: plt.close(figg)
606/53: figg,ax=plt.subplots()
606/54:
for p in allpath:
    x = p.vertices[:,0]
    y = p.vertices[:,1]
    ax.plot(x,y)
606/55: figg.show()
607/1: import wrfsims
607/2: sim,at,med=wrfsims.sppt_ids()
607/3: len(sim)
607/4: len(at)
607/5: len(med)
608/1: import pandas as pd
608/2: df = pd.read_csv('DJF-intense-cyclones.csv')
608/3: df
608/4: df.columns
608/5: df.dates.values
608/6: df.loc[df.dates.values=='20040122_14']
608/7: less /atmosdyn/michaesp/mincl.era-5/tracks/fi_200401
609/1:
import numpy as np
import netCDF4
609/2: from netCDF4 import Dataset as ds
609/3: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
609/4: d.variables.keys()
609/5:
for var in ['TT','RH','UU','VV','GHT','PMSL']:
    print(d.variables[var])
609/6:
for var in ['TT','RH','UU','VV','GHT']:
    #print(d.variables[var])
    print(d.variables[var][:][0,:,:130,:].shape)
609/7: d.close
609/8: d.close()
609/9: d = ds('met_em.d01.2000-12-01_00:00:00.nc','a')
609/10:
for var in ['TT','RH','UU','VV','GHT']:
    #print(d.variables[var])
    d.variables[var][:][0,:,:130,:]=d.variables[var][:][0,:,10:,:]
609/11: cp ../DJF-clim-max-U-at-300hPa-1.4QG/met_em.d01.2000-12-01_00\:00\:00.nc .
609/12: od = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
609/13: d = ds('met_em.d01.2000-12-01_00:00:00.nc','a')
609/14:
for var in ['TT','RH','UU','VV','GHT']:
    #print(d.variables[var])
    d.variables[var][:][0,:,:-10,:]=od.variables[var][:][0,:,10:,:]
609/15: d.close()
609/16: pwd
610/1: from netCDF4 import Dataset as ds
610/2: od = ds('../DJF-clim-max-U-at-300hPa-1.4QG/met_em.d01.2000-12-01_00:00:00.nc','r')
610/3: d = ds('met_em.d01.2000-12-01_00:00:00.nc','a')
610/4:
for var in ['TT','RH','UU','VV','GHT']:
    d.variables[var][0,:,:-10,:]=od.variables[var][:][0,:,10:,:]
610/5: d.variables['PMSL'][0,:-10,:]=od.variables['PMSL'][0,10:,:]
610/6: d.close()
610/7: d = ds('met_em.d01.2000-12-01_00:00:00.nc','a')
610/8: dir(d)
610/9: d.WEST-EAST_GRID_DIMENSION
610/10: d.cornerlats
610/11: d.cornerlats()
610/12: d.variables
610/13: dir(d)
610/14: d.renameDimension
610/15: d.Dimension
610/16: d.corner_lons
610/17: d.corner_lats
610/18: d.corner_lats=np.array([10.25, 74.75, 74.75, 10.25, 10.25, 74.75, 74.75, 10.25, 10.  , 75.  , 75.  , 10.  , 10.  , 75.  , 75.  , 10.  ], dtype=float32)
610/19: import numpy as np
610/20: d.corner_lats=np.array([10.25, 74.75, 74.75, 10.25, 10.25, 74.75, 74.75, 10.25, 10.  , 75.  , 75.  , 10.  , 10.  , 75.  , 75.  , 10.  ], dtype=float32)
610/21: d.corner_lats=np.array([10.25, 74.75, 74.75, 10.25, 10.25, 74.75, 74.75, 10.25, 10.  , 75.  , 75.  , 10.  , 10.  , 75.  , 75.  , 10.  ], dtype=float)
610/22: d.corner_lats=np.array([10.25, 74.75, 74.75, 10.25, 10.25, 74.75, 74.75, 10.25, 10.  , 75.  , 75.  , 10.  , 10.  , 75.  , 75.  , 10.  ], dtype='float32')
610/23: d.srx
610/24: d.sr_x
610/25: d.sr_y
611/1: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
611/2: from netCDF4 import Dataset as ds
611/3: d = ds('met_em.d01.2000-12-01_00:00:00.nc','r')
611/4: d = ds('../DJF-clim-max-U-300hPa-1.4QG/met_em.d01.2000-12-01_00:00:00.nc','r')
611/5: d = ds('../DJF-clim-max-U-at-300hPa-1.4QG/met_em.d01.2000-12-01_00:00:00.nc','r')
611/6: dir(d)
611/7: d.ncattrs
611/8: d.ncattrs()
611/9: dir(d)
612/1: from netCDF4 import Dataset as ds
612/2: od = ds('../DJF-clim-max-U-at-300hPa-1.4QG/met_em.d01.2000-12-01_00:00:00.nc','r')
612/3: d = ds('met_em.nc','a')
612/4:
for var in ['TT','RH','UU','VV','GHT']:
    d.variables[var][0]=od.variables[var][0,:,:,:-10]
612/5: d.close()
612/6: cd ../south_shift/
612/7: d = ds('met_em.nc','a')
612/8:
for var in ['TT','RH','UU','VV','GHT']:
    d.variables[var][0]=od.variables[var][0,:,10:,:]
612/9: d.close()
612/10: cp met_em.nc met_em_slp.nc
612/11: d = ds('met_em_slp.nc','a')
612/12:
for var in ['TT','RH','UU','VV','GHT']:
    d.variables[var][0]=od.variables[var][0,:,10:,:]
d.variables['PMSL'][0,:,:]=od.variables['PMSL'][0,10:,:]
612/13: d.close()
612/14: cd ../east_shift/
612/15: cp met_em.nc met_em_slp_shift.nc
612/16: d = ds('met_em_slp_shift.nc','a')
612/17:
for var in ['TT','RH','UU','VV','GHT']:
    d.variables[var][0]=od.variables[var][0,:,:,:-10]
d.variables['PMSL'][0]=od.variables['PMSL'][0,:,:-10]
612/18: d.close()
613/1: a = ['%03d' for x in range(1,11)]
613/2: a
613/3: a = ['%03d'%x for x in range(1,11)]
613/4: a
614/1: from netCDF4 import Dataset as ds
614/2:
datapath_3h_3l='/net/litho/atmosdyn/roethlim/data/supervising/T_anom_cyc/budget/'
datapath_dailyav = '/net/litho/atmosdyn/roethlim/data/supervising/T_anom_cyc/budget_daily/'
614/3: date = '20131223_10'
614/4: ym=date[:6]
614/5:
cycmask = '/atmosdyn/michaesp/mincl.era-5/cdf.final/'#+ "year/month/CYYYYMMDD_HH"
era5 = '/atmosdyn2/era5/cdf/' #+ "year/month/CYYYYMMDD_HH"
seltrack = '/atmosdyn2/ascherrmann/BA/Jan/'
614/6: tracks,dates = np.loadtxt(seltrack + 'tracks-%s.txt'%ym),np.loadtxt(seltrack + 'dates-%s.txt'%ym)
614/7: import numpy as np
614/8: tracks,dates = np.loadtxt(seltrack + 'tracks-%s.txt'%ym),np.loadtxt(seltrack + 'dates-%s.txt'%ym)
614/9: dates
614/10: tracks,dates = np.loadtxt(seltrack + 'tracks-%s.txt'%ym),np.genfromtxt(seltrack + 'dates-%s.txt'%ym,dtype='str')
614/11: dates
614/12: dates[:,1]
614/13: np.where(dates[:,1]==date)[0]
614/14: dates[np.where(dates[:,1]==date)[0],0]
614/15: ids = dates[np.where(dates[:,1]==date)[0],0]
614/16: ids = dates[np.where(dates[:,1]==date)[0],0].astype(int)
614/17: tracks
614/18:
for i in ids:
    loc = np.where(tracks[:,-1]==i)[0]
    locm = np.argmin(tracks[loc,3])
    htminslp = tracks[loc,0]-tracks[loc[locm],0]
614/19: inde = np.where(dates[:,1]==date)[0]
614/20:
for i,ii in zip(inde,ids):
    loc = np.where(tracks[:,-1]==ii)[0]
    locm = np.argmin(tracks[loc,3])
    htminslp = tracks[i,0]-tracks[loc[locm],0]
    print(htminslp)
   1: %history -g -f last-ipyhist.txt
